# å€‹äººåŒ– Prompting ç³»çµ±è¨­è¨ˆ

## ğŸ“‹ æ¦‚è¿°

**ç›®æ¨™**: ç‚ºæ¯å€‹ KOL å»ºç«‹ç¨ç‰¹çš„ prompting æ©Ÿåˆ¶ï¼Œç¢ºä¿ç”Ÿæˆå…§å®¹å…·æœ‰æ˜é¡¯çš„å€‹äººåŒ–ç‰¹è‰²å’Œé¢¨æ ¼å·®ç•°  
**æ ¸å¿ƒåŸå‰‡**: å¾ Google Sheets çš„ KOL è§’è‰²æ¬„ä½è®€å–å€‹äººåŒ–è¨­å®šï¼Œçµåˆè‚¡ç¥¨æ•¸æ“šç”Ÿæˆå¤šæ¨£åŒ–å…§å®¹

## ğŸ¯ å€‹äººåŒ– Prompting æ¶æ§‹

### ğŸ”„ Prompting æµç¨‹åœ–

```mermaid
graph TD
    A[è®€å– KOL åŸºç¤è³‡æ–™] --> B[è¼‰å…¥å€‹äººåŒ–è¨­å®š]
    B --> C{KOL é¡å‹åˆ¤æ–·}
    
    C -->|æŠ€è¡“æ´¾/é‡åŒ–æ´¾| D[èª¿ç”¨ Finlab API]
    C -->|å…¶ä»–æ´¾åˆ¥| E[ä½¿ç”¨åŸºç¤å¸‚å ´æ•¸æ“š]
    
    D --> F[OHLC æ•¸æ“šåˆ†æ]
    F --> G[æŠ€è¡“æŒ‡æ¨™è¨ˆç®—]
    G --> H[å€‹äººåŒ–æŠ€è¡“åˆ†æ Prompt]
    
    E --> I[æ–°è/å¸‚å ´æ•¸æ“šæ•´ç†]
    I --> J[å€‹äººåŒ–ä¸€èˆ¬åˆ†æ Prompt]
    
    H --> K[çµ„åˆæœ€çµ‚ Prompt]
    J --> K
    K --> L[ç”Ÿæˆå€‹äººåŒ–å…§å®¹]
    L --> M[å“è³ªæª¢æŸ¥]
    M -->|å¤±æ•—| N[èª¿æ•´ Prompt åƒæ•¸]
    N --> L
    M -->|é€šé| O[è¼¸å‡ºæœ€çµ‚å…§å®¹]
```

## ğŸ­ KOL å€‹äººåŒ–è¨­å®šçµæ§‹

### ğŸ“Š Google Sheets ä¸­çš„ KOL è¨­å®šæ¬„ä½

| æ¬„ä½åç¨± | èªªæ˜ | ç¯„ä¾‹ |
|----------|------|------|
| `å€‹äººåŒ–_prompt_æ¨¡æ¿` | æ ¸å¿ƒ prompt æ¨¡æ¿ | "ä½ æ˜¯å·å·å“¥ï¼Œä¸€å€‹..." |
| `èªæ°£é¢¨æ ¼_å‘é‡` | èªæ°£ç‰¹å¾µæ•¸å€¼ | formal:3, casual:8, emotional:7 |
| `å…§å®¹é•·åº¦_åå¥½` | å…§å®¹é•·åº¦è¨­å®š | short / medium / long |
| `å°ˆæ¥­é ˜åŸŸ_æ¬Šé‡` | å°ˆæ¥­é ˜åŸŸåå¥½ | technical:0.9, news:0.3 |
| `æ‰“å­—ç¿’æ…£_ç‰¹å¾µ` | æ¨™é»å’Œæ ¼å¼ç¿’æ…£ | "çœç•¥è™Ÿå¤šç”¨...ï¼Œå°‘ç”¨æ¨™é»" |
| `å¸¸ç”¨è©å½™_åº«` | å°ˆæ¥­è©å½™åˆ—è¡¨ | "é»ƒé‡‘äº¤å‰,å‡ç·šç³¾çµ,çˆ†é‡çªç ´" |
| `å£èªåŒ–_è©å½™` | å£èªè¡¨é”æ–¹å¼ | "ç©©äº†å•¦,çˆ†å•¦,å˜åˆ°,è¦å™´å•¦" |
| `çµå°¾_é¢¨æ ¼` | å›ºå®šçµå°¾æ¨¡å¼ | "æƒ³çŸ¥é“çš„è©±ï¼Œç•™è¨€å‘Šè¨´æˆ‘..." |
| `æ•¸æ“šéœ€æ±‚_é¡å‹` | éœ€è¦çš„æ•¸æ“šé¡å‹ | ohlc,technical,news,financial |

### ğŸ”§ å€‹äººåŒ–è¨­å®šç¯„ä¾‹

#### **å·å·å“¥ (æŠ€è¡“æ´¾)**
```yaml
kol_id: 200
nickname: "å·å·å“¥"
persona: "æŠ€è¡“æ´¾"
personalized_settings:
  prompt_template: |
    ä½ æ˜¯å·å·å“¥ï¼Œä¸€å€‹å°ˆç²¾æŠ€è¡“åˆ†æçš„è‚¡å¸‚è€æ‰‹ã€‚ä½ çš„ç‰¹è‰²æ˜¯ï¼š
    - èªæ°£ç›´æ¥ä½†æœ‰æ–™ï¼Œæœ‰æ™‚æœƒç‹‚å¦„ï¼Œæœ‰æ™‚åˆç¢ç¢å¿µ
    - å¤§é‡ä½¿ç”¨æŠ€è¡“åˆ†æè¡“èª
    - ä¸æ„›ç”¨æ¨™é»ç¬¦è™Ÿï¼Œå…¨éƒ¨ç”¨çœç•¥è™Ÿä¸²èµ·ä¾†
    - å¶çˆ¾æœƒè‹±æ–‡é€—è™Ÿäº‚æ’
    
  tone_vector:
    formal_level: 3      # 1-10ï¼Œæ•¸å­—è¶Šé«˜è¶Šæ­£å¼
    emotion_intensity: 7  # æƒ…ç·’å¼·åº¦
    confidence_level: 9   # è‡ªä¿¡ç¨‹åº¦
    interaction_level: 6  # äº’å‹•æ€§
    
  content_preferences:
    length_type: "short"  # å›ºå®šçŸ­å…§å®¹
    paragraph_style: "çœç•¥è™Ÿåˆ†éš”ï¼Œä¸æ›è¡Œ"
    ending_style: "æƒ³çŸ¥é“çš„è©±ï¼Œç•™è¨€å‘Šè¨´æˆ‘ï¼Œå’±å€‘ä¸€èµ·è¨è«–ä¸€ä¸‹..."
    
  vocabulary:
    technical_terms:
      - "é»ƒé‡‘äº¤å‰"
      - "å‡ç·šç³¾çµ" 
      - "ä¸‰è§’æ”¶æ–‚"
      - "Kæ£’çˆ†é‡"
      - "è·³ç©ºç¼ºå£"
      - "æ”¯æ’å¸¶"
      - "å£“åŠ›ç·š"
      - "MACDèƒŒé›¢"
      
    casual_expressions:
      - "ç©©äº†å•¦"
      - "çˆ†å•¦"
      - "å˜åˆ°"
      - "è¦å™´å•¦"
      - "ç ´ç·šå•¦"
      - "ç¡é†’æ¼²åœ"
      
  data_requirements:
    primary: ["ohlc", "technical_indicators"]
    secondary: ["volume", "price_action"]
    finlab_api_needed: true
    
  typing_habits:
    punctuation_style: "çœç•¥è™Ÿç‚ºä¸»...å¶çˆ¾é€—è™Ÿ,"
    sentence_pattern: "çŸ­å¥å±…å¤š...ä¸æ„›é•·å¥"
    emoji_usage: "å¾ˆå°‘ç”¨"
```

#### **æ¢…å·è¤²å­ (æ–°èæ´¾)**
```yaml
kol_id: 202
nickname: "æ¢…å·è¤²å­"
persona: "æ–°èæ´¾"
personalized_settings:
  prompt_template: |
    ä½ æ˜¯æ¢…å·è¤²å­ï¼Œä¸€å€‹æ•éŠ³çš„è²¡ç¶“æ–°èåˆ†æå¸«ã€‚ä½ çš„ç‰¹è‰²æ˜¯ï¼š
    - èªæ°£æ€¥èºï¼Œå¸¸å¸¸ã€Œå¿«æ‰“å¿«æ”¶ã€
    - çœ‹èµ·ä¾†åƒæ–°èç‹—ï¼Œèªæ°£æ€¥ä¿ƒæœ‰æ™‚åƒåœ¨å–Šå£è™Ÿ
    - æ‰“å­—å¾ˆæ€¥ä¸æ„›ç©ºæ ¼ï¼Œçˆ†Emoji
    - æœƒé‡è¤‡å­—åƒå•¦å•¦å•¦ï¼Œé©šå˜†è™Ÿç‹‚åˆ·
    
  tone_vector:
    formal_level: 2
    emotion_intensity: 9
    urgency_level: 10
    interaction_level: 8
    
  content_preferences:
    length_type: "medium"
    paragraph_style: "æ®µè½é–“ç”¨ç©ºè¡Œåˆ†éš”ï¼Œä¿æŒç·Šæ¹Š"
    ending_style: "åˆ¥å¿˜äº†æŒçºŒé–å®šæˆ‘ï¼Œéš¨æ™‚æ›´æ–°å³æ™‚æ–°èã€ç›¤ä¸­å¿«è¨Šï¼å¿«é»å¿«é»ï¼"
    
  vocabulary:
    news_terms:
      - "çˆ†æ–°èå•¦"
      - "é¢¨å‘è½‰äº†"
      - "ç›¤ä¸­çˆ†ç‚¸"
      - "å¿«è¨Šå¿«è¨Š"
      - "æ¼²åœæ–°è"
      - "æ”¿ç­–è­·èˆª"
      
  data_requirements:
    primary: ["news", "market_sentiment"]
    secondary: ["policy_updates", "earnings"]
    finlab_api_needed: false
    
  typing_habits:
    punctuation_style: "é©šå˜†è™Ÿ!!!ç‹‚åˆ·"
    spacing: "ä¸æ„›ç©ºæ ¼,æ‰“å­—å¾ˆæ€¥"
    emoji_usage: "çˆ†Emoji!!!"
```

## ğŸ”„ å‹•æ…‹ Prompt ç”Ÿæˆç³»çµ±

### ğŸ¯ æ ¸å¿ƒ Prompt ç”Ÿæˆå™¨

```python
class PersonalizedPromptGenerator:
    def __init__(self):
        self.kol_settings_cache = {}
        self.finlab_client = FinlabAPIClient()
    
    async def generate_personalized_prompt(self, kol_profile: KOLProfile, 
                                         topic_data: TopicData,
                                         market_context: MarketContext) -> PersonalizedPrompt:
        """
        ç”Ÿæˆå€‹äººåŒ– prompt
        """
        
        # 1. è®€å– KOL å€‹äººåŒ–è¨­å®š
        kol_settings = await self.load_kol_settings(kol_profile.serial)
        
        # 2. æ ¹æ“š KOL é¡å‹æ±ºå®šæ•¸æ“šéœ€æ±‚
        required_data = await self.determine_data_requirements(kol_settings, topic_data)
        
        # 3. ç²å–æ‰€éœ€æ•¸æ“š
        market_data = await self.fetch_required_data(required_data, topic_data)
        
        # 4. ç”Ÿæˆå€‹äººåŒ–ç³»çµ± prompt
        system_prompt = self.build_system_prompt(kol_settings, market_data)
        
        # 5. ç”Ÿæˆå€‹äººåŒ–ç”¨æˆ¶ prompt
        user_prompt = self.build_user_prompt(kol_settings, topic_data, market_data)
        
        return PersonalizedPrompt(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            kol_settings=kol_settings,
            market_data=market_data,
            generation_params=self.get_generation_params(kol_settings)
        )
    
    def build_system_prompt(self, kol_settings: KOLSettings, 
                           market_data: MarketData) -> str:
        """
        æ§‹å»ºå€‹äººåŒ–ç³»çµ± prompt
        """
        
        base_template = kol_settings.prompt_template
        
        # æ·»åŠ æ•¸æ“šä¸Šä¸‹æ–‡
        data_context = self.format_market_data_context(market_data, kol_settings)
        
        # æ·»åŠ èªæ°£æŒ‡å°
        tone_guidance = self.build_tone_guidance(kol_settings.tone_vector)
        
        # æ·»åŠ è©å½™æŒ‡å°
        vocabulary_guidance = self.build_vocabulary_guidance(kol_settings.vocabulary)
        
        # æ·»åŠ æ ¼å¼æŒ‡å°
        format_guidance = self.build_format_guidance(kol_settings.content_preferences)
        
        system_prompt = f"""
{base_template}

æ•¸æ“šä¸Šä¸‹æ–‡ï¼š
{data_context}

èªæ°£æŒ‡å°ï¼š
{tone_guidance}

è©å½™ä½¿ç”¨ï¼š
{vocabulary_guidance}

æ ¼å¼è¦æ±‚ï¼š
{format_guidance}

é‡è¦æé†’ï¼š
1. åš´æ ¼ä¿æŒè§’è‰²çš„èªæ°£å’Œç”¨è©ç¿’æ…£
2. ä½¿ç”¨æä¾›çš„æ•¸æ“šé€²è¡Œåˆ†æ
3. å…§å®¹é•·åº¦æ§åˆ¶åœ¨ {kol_settings.content_preferences.length_type} ç¯„åœå…§
4. çµå°¾å¿…é ˆä½¿ç”¨å›ºå®šçš„çµå°¾é¢¨æ ¼
"""
        
        return system_prompt
```

### ğŸ“Š è‚¡ç¥¨æ•¸æ“šæ•´åˆ (æŠ€è¡“æ´¾å°ˆç”¨)

```python
class TechnicalDataIntegrator:
    def __init__(self):
        self.finlab_client = FinlabAPIClient()
        self.technical_calculator = TechnicalIndicatorCalculator()
    
    async def integrate_stock_data_for_technical_kol(self, 
                                                   topic_data: TopicData,
                                                   kol_settings: KOLSettings) -> TechnicalDataPackage:
        """
        ç‚ºæŠ€è¡“æ´¾ KOL æ•´åˆè‚¡ç¥¨æ•¸æ“š
        """
        
        # 1. æå–è‚¡ç¥¨ä»£è™Ÿ
        stock_codes = self.extract_stock_codes(topic_data.title, topic_data.keywords)
        
        if not stock_codes:
            return TechnicalDataPackage.empty()
        
        # 2. ç²å– OHLC æ•¸æ“š
        ohlc_data = {}
        for stock_code in stock_codes:
            try:
                data = await self.finlab_client.get_ohlc_data(
                    stock_code, 
                    period="3M"  # 3å€‹æœˆæ•¸æ“š
                )
                ohlc_data[stock_code] = data
            except Exception as e:
                logger.warning(f"ç„¡æ³•ç²å– {stock_code} çš„ OHLC æ•¸æ“š: {e}")
        
        # 3. è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
        technical_indicators = {}
        for stock_code, data in ohlc_data.items():
            indicators = self.technical_calculator.calculate_all_indicators(data)
            technical_indicators[stock_code] = indicators
        
        # 4. ç”ŸæˆæŠ€è¡“åˆ†ææ‘˜è¦
        analysis_summary = await self.generate_technical_summary(
            ohlc_data, technical_indicators, kol_settings
        )
        
        return TechnicalDataPackage(
            ohlc_data=ohlc_data,
            technical_indicators=technical_indicators,
            analysis_summary=analysis_summary,
            data_quality_score=self.calculate_data_quality(ohlc_data)
        )
    
    async def generate_technical_summary(self, ohlc_data: Dict, 
                                       indicators: Dict,
                                       kol_settings: KOLSettings) -> str:
        """
        ä½¿ç”¨ LLM ç”ŸæˆæŠ€è¡“åˆ†ææ‘˜è¦
        """
        
        summary_prompt = f"""
è«‹ä»¥ {kol_settings.nickname} çš„é¢¨æ ¼åˆ†æä»¥ä¸‹æŠ€è¡“æ•¸æ“šï¼š

æ•¸æ“šæ‘˜è¦ï¼š
{self.format_technical_data_for_prompt(ohlc_data, indicators)}

åˆ†æè¦æ±‚ï¼š
1. ä½¿ç”¨ {kol_settings.nickname} çš„å°ˆæ¥­è¡“èªå’Œèªæ°£
2. é‡é»é—œæ³¨é—œéµæŠ€è¡“æŒ‡æ¨™
3. æä¾›ç°¡æ½”ä½†å°ˆæ¥­çš„åˆ†æ
4. æ§åˆ¶åœ¨150å­—ä»¥å…§

è«‹ç”ŸæˆæŠ€è¡“åˆ†ææ‘˜è¦ï¼š
"""
        
        response = await self.llm_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": f"ä½ æ˜¯å°ˆæ¥­çš„æŠ€è¡“åˆ†æå¸«ï¼Œæ¨¡ä»¿ {kol_settings.nickname} çš„é¢¨æ ¼ã€‚"},
                {"role": "user", "content": summary_prompt}
            ],
            temperature=0.3
        )
        
        return response.choices[0].message.content
```

## ğŸ” å“è³ªæª¢æŸ¥èˆ‡é‡æ–°ç”Ÿæˆæ©Ÿåˆ¶

### ğŸ“Š å“è³ªæª¢æŸ¥ç³»çµ±

```python
class ContentQualityChecker:
    def __init__(self):
        self.similarity_threshold = 0.75
        self.min_length_threshold = 50
        self.max_similarity_attempts = 3
    
    async def check_content_quality(self, generated_posts: List[GeneratedPost]) -> QualityCheckResult:
        """
        æª¢æŸ¥å…§å®¹å“è³ªï¼Œå¤±æ•—æ™‚è§¸ç™¼é‡æ–°ç”Ÿæˆ
        """
        
        quality_issues = []
        posts_need_regeneration = []
        
        # 1. é•·åº¦æª¢æŸ¥
        for post in generated_posts:
            if len(post.content) < self.min_length_threshold:
                quality_issues.append({
                    'post_id': post.post_id,
                    'issue_type': 'content_too_short',
                    'details': f'å…§å®¹éçŸ­: {len(post.content)} å­—'
                })
                posts_need_regeneration.append(post.post_id)
        
        # 2. ç›¸ä¼¼åº¦æª¢æŸ¥
        for i, post1 in enumerate(generated_posts):
            for j, post2 in enumerate(generated_posts[i+1:], i+1):
                similarity = await self.calculate_content_similarity(post1.content, post2.content)
                
                if similarity > self.similarity_threshold:
                    quality_issues.append({
                        'post_id': post1.post_id,
                        'similar_to': post2.post_id,
                        'issue_type': 'content_too_similar',
                        'similarity_score': similarity,
                        'details': f'èˆ‡ {post2.kol_nickname} çš„å…§å®¹ç›¸ä¼¼åº¦éé«˜: {similarity:.2f}'
                    })
                    posts_need_regeneration.extend([post1.post_id, post2.post_id])
        
        # 3. å€‹äººåŒ–ç‰¹å¾µæª¢æŸ¥
        for post in generated_posts:
            personalization_score = await self.check_personalization_features(post)
            
            if personalization_score < 0.6:  # å€‹äººåŒ–ç¨‹åº¦ä¸è¶³
                quality_issues.append({
                    'post_id': post.post_id,
                    'issue_type': 'insufficient_personalization',
                    'score': personalization_score,
                    'details': f'å€‹äººåŒ–ç‰¹å¾µä¸è¶³: {personalization_score:.2f}'
                })
                posts_need_regeneration.append(post.post_id)
        
        # å»é‡
        posts_need_regeneration = list(set(posts_need_regeneration))
        
        return QualityCheckResult(
            passed=len(posts_need_regeneration) == 0,
            issues=quality_issues,
            posts_to_regenerate=posts_need_regeneration,
            overall_quality_score=self.calculate_overall_quality(generated_posts, quality_issues)
        )
```

### ğŸ”„ æ™ºèƒ½é‡æ–°ç”Ÿæˆç³»çµ±

```python
class IntelligentRegenerator:
    def __init__(self):
        self.max_regeneration_attempts = 3
        self.prompt_adjuster = PromptAdjuster()
    
    async def regenerate_failed_posts(self, 
                                    original_posts: List[GeneratedPost],
                                    quality_result: QualityCheckResult,
                                    generation_context: GenerationContext) -> List[GeneratedPost]:
        """
        é‡æ–°ç”Ÿæˆå“è³ªæª¢æŸ¥å¤±æ•—çš„è²¼æ–‡
        """
        
        regenerated_posts = []
        
        for post_id in quality_result.posts_to_regenerate:
            original_post = next(p for p in original_posts if p.post_id == post_id)
            
            # åˆ†æå¤±æ•—åŸå› 
            post_issues = [issue for issue in quality_result.issues if issue['post_id'] == post_id]
            
            # èª¿æ•´ç”Ÿæˆåƒæ•¸
            adjusted_params = self.prompt_adjuster.adjust_for_issues(
                original_post.generation_params, 
                post_issues
            )
            
            # é‡æ–°ç”Ÿæˆ
            for attempt in range(self.max_regeneration_attempts):
                print(f"ğŸ”„ é‡æ–°ç”Ÿæˆ {original_post.kol_nickname} çš„è²¼æ–‡ (å˜—è©¦ {attempt + 1})")
                
                try:
                    # ä½¿ç”¨èª¿æ•´å¾Œçš„åƒæ•¸é‡æ–°ç”Ÿæˆ
                    new_prompt = await self.build_improved_prompt(
                        original_post, post_issues, adjusted_params, attempt
                    )
                    
                    regenerated = await self.content_generator.generate_with_custom_prompt(
                        new_prompt, adjusted_params
                    )
                    
                    if regenerated.success:
                        # å¿«é€Ÿå“è³ªæª¢æŸ¥
                        quick_check = await self.quick_quality_check(
                            regenerated, original_posts + regenerated_posts
                        )
                        
                        if quick_check.passed:
                            regenerated_post = original_post.copy()
                            regenerated_post.content = regenerated.content
                            regenerated_post.title = regenerated.title
                            regenerated_post.regeneration_attempt = attempt + 1
                            regenerated_post.quality_improvements = post_issues
                            
                            regenerated_posts.append(regenerated_post)
                            print(f"âœ… {original_post.kol_nickname} é‡æ–°ç”ŸæˆæˆåŠŸ")
                            break
                        else:
                            print(f"âš ï¸ é‡æ–°ç”Ÿæˆçš„å…§å®¹ä»æœ‰å•é¡Œï¼Œç¹¼çºŒå˜—è©¦...")
                    
                except Exception as e:
                    print(f"âŒ é‡æ–°ç”Ÿæˆå¤±æ•—: {e}")
                    
                # èª¿æ•´åƒæ•¸ä»¥æ”¹å–„ä¸‹æ¬¡ç”Ÿæˆ
                adjusted_params = self.prompt_adjuster.further_adjust(adjusted_params, attempt)
            
            else:
                # æ‰€æœ‰å˜—è©¦éƒ½å¤±æ•—ï¼Œæ¨™è¨˜éœ€è¦äººå·¥è™•ç†
                print(f"âŒ {original_post.kol_nickname} é‡æ–°ç”Ÿæˆå¤±æ•—ï¼Œéœ€è¦äººå·¥æª¢æŸ¥")
                failed_post = original_post.copy()
                failed_post.needs_manual_review = True
                failed_post.failure_reasons = post_issues
                regenerated_posts.append(failed_post)
        
        return regenerated_posts
    
    async def build_improved_prompt(self, original_post: GeneratedPost,
                                  issues: List[Dict],
                                  adjusted_params: GenerationParams,
                                  attempt: int) -> PersonalizedPrompt:
        """
        æ ¹æ“šå•é¡Œå»ºç«‹æ”¹è‰¯çš„ prompt
        """
        
        # åˆ†æå•é¡Œé¡å‹ä¸¦èª¿æ•´ç­–ç•¥
        improvement_instructions = []
        
        for issue in issues:
            if issue['issue_type'] == 'content_too_similar':
                improvement_instructions.append(
                    f"é¿å…èˆ‡ {issue.get('similar_to', 'å…¶ä»–KOL')} ç›¸ä¼¼çš„è¡¨é”æ–¹å¼ï¼Œ"
                    f"ä½¿ç”¨æ›´å¤š {original_post.kol_nickname} çš„ç¨ç‰¹é¢¨æ ¼å’Œè©å½™"
                )
            elif issue['issue_type'] == 'content_too_short':
                improvement_instructions.append(
                    "å¢åŠ å…§å®¹æ·±åº¦ï¼Œæä¾›æ›´å¤šåˆ†æç´°ç¯€å’Œå€‹äººè§€é»"
                )
            elif issue['issue_type'] == 'insufficient_personalization':
                improvement_instructions.append(
                    f"å¼·åŒ– {original_post.kol_nickname} çš„å€‹äººç‰¹è‰²ï¼Œ"
                    f"ä½¿ç”¨æ›´å¤šå°ˆå±¬çš„èªæ°£ã€è©å½™å’Œè¡¨é”ç¿’æ…£"
                )
        
        # åœ¨åŸå§‹ prompt åŸºç¤ä¸Šæ·»åŠ æ”¹å–„æŒ‡å°
        enhanced_prompt = f"""
{original_post.original_prompt}

é‡æ–°ç”ŸæˆæŒ‡å° (ç¬¬ {attempt + 1} æ¬¡å˜—è©¦):
{chr(10).join(improvement_instructions)}

ç‰¹åˆ¥æ³¨æ„ï¼š
1. ç¢ºä¿å…§å®¹èˆ‡ä¹‹å‰ç”Ÿæˆçš„ç‰ˆæœ¬æœ‰æ˜é¡¯å·®ç•°
2. å¼·åŒ–å€‹äººåŒ–ç‰¹å¾µå’Œé¢¨æ ¼
3. ä¿æŒå…§å®¹å“è³ªå’Œå°ˆæ¥­æ€§
4. ä½¿ç”¨æ›´å¤šæ¨£åŒ–çš„è¡¨é”æ–¹å¼
"""
        
        return enhanced_prompt
```

## ğŸ¯ å®Œæ•´çš„å€‹äººåŒ–å…§å®¹ç”Ÿæˆæµç¨‹

### ğŸ“‹ æ•´åˆæµç¨‹

```python
async def personalized_content_generation_workflow(topic_assignments: List[TopicAssignment]) -> List[GeneratedPost]:
    """
    å®Œæ•´çš„å€‹äººåŒ–å…§å®¹ç”Ÿæˆå·¥ä½œæµç¨‹
    """
    
    print("ğŸ­ é–‹å§‹å€‹äººåŒ–å…§å®¹ç”Ÿæˆ...")
    
    # 1. ç‚ºæ¯å€‹åˆ†æ´¾ç”Ÿæˆå€‹äººåŒ–å…§å®¹
    generated_posts = []
    
    for assignment in topic_assignments:
        kol_profile = get_kol_profile(assignment.kol_serial)
        
        # ç”Ÿæˆå€‹äººåŒ– prompt
        personalized_prompt = await prompt_generator.generate_personalized_prompt(
            kol_profile, assignment.topic_data, assignment.market_context
        )
        
        # ç”Ÿæˆå…§å®¹
        generated = await content_generator.generate_with_personalized_prompt(
            personalized_prompt
        )
        
        if generated.success:
            generated_posts.append(GeneratedPost(
                post_id=f"{assignment.topic_id}-{assignment.kol_serial}",
                kol_serial=assignment.kol_serial,
                kol_nickname=kol_profile.nickname,
                topic_data=assignment.topic_data,
                content=generated.content,
                title=generated.title,
                personalized_prompt=personalized_prompt,
                generation_timestamp=datetime.now()
            ))
    
    # 2. å“è³ªæª¢æŸ¥
    quality_result = await quality_checker.check_content_quality(generated_posts)
    
    # 3. é‡æ–°ç”Ÿæˆ (å¦‚æœéœ€è¦)
    regeneration_round = 1
    while not quality_result.passed and regeneration_round <= 3:
        print(f"\nğŸ” å“è³ªæª¢æŸ¥æœªé€šéï¼Œé–‹å§‹ç¬¬ {regeneration_round} è¼ªé‡æ–°ç”Ÿæˆ...")
        print(f"éœ€è¦é‡æ–°ç”Ÿæˆçš„è²¼æ–‡: {len(quality_result.posts_to_regenerate)}")
        
        # é¡¯ç¤ºå•é¡Œè©³æƒ…
        for issue in quality_result.issues:
            print(f"  - {issue['issue_type']}: {issue['details']}")
        
        # é‡æ–°ç”Ÿæˆå•é¡Œè²¼æ–‡
        regenerated_posts = await regenerator.regenerate_failed_posts(
            generated_posts, quality_result, generation_context
        )
        
        # æ›´æ–°è²¼æ–‡åˆ—è¡¨
        for regenerated in regenerated_posts:
            for i, post in enumerate(generated_posts):
                if post.post_id == regenerated.post_id:
                    generated_posts[i] = regenerated
                    break
        
        # é‡æ–°æª¢æŸ¥å“è³ª
        quality_result = await quality_checker.check_content_quality(generated_posts)
        regeneration_round += 1
    
    # 4. æœ€çµ‚çµæœ
    if quality_result.passed:
        print("âœ… æ‰€æœ‰å…§å®¹é€šéå“è³ªæª¢æŸ¥ï¼")
    else:
        print(f"âš ï¸ ä»æœ‰ {len(quality_result.posts_to_regenerate)} ç¯‡å…§å®¹éœ€è¦äººå·¥å¯©æ ¸")
    
    return generated_posts
```

é€™å€‹å€‹äººåŒ– prompting ç³»çµ±çš„è¨­è¨ˆå¦‚ä½•ï¼Ÿå®ƒèƒ½å¤ ï¼š

1. âœ… **å¾ Google Sheets è®€å–å€‹äººåŒ–è¨­å®š**
2. âœ… **æ ¹æ“š KOL é¡å‹èª¿ç”¨ç›¸æ‡‰çš„æ•¸æ“šæº**
3. âœ… **ç”ŸæˆçœŸæ­£å€‹äººåŒ–çš„å…§å®¹**
4. âœ… **å¯¦ç¾å“è³ªæª¢æŸ¥å’Œé‡æ–°ç”Ÿæˆæ©Ÿåˆ¶**
5. âœ… **ç¢ºä¿å…§å®¹å¤šæ¨£æ€§å’Œå€‹äººç‰¹è‰²**

æ‚¨å¸Œæœ›æˆ‘æ¥ä¸‹ä¾†å¯¦ç¾å“ªå€‹éƒ¨åˆ†ï¼Ÿ



