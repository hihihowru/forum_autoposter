#!/usr/bin/env python3
"""
å¢å¼·ç‰ˆæ–°è©±é¡Œåˆ†æ´¾å’Œç™¼æ–‡ç³»çµ±
æ•´åˆå¤šé€±æœŸæŠ€è¡“åˆ†æã€å€‹äººåŒ– Promptã€å…§å®¹å“è³ªæª¢æŸ¥
"""

import os
import sys
import asyncio
import logging
from datetime import datetime
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# åŸæœ‰å°å…¥
from src.clients.cmoney.cmoney_client import CMoneyClient, LoginCredentials
from src.clients.google.sheets_client import GoogleSheetsClient
from src.services.assign.assignment_service import AssignmentService, TopicData
from src.services.classification.topic_classifier import TopicClassifier

# æ–°å¢å°å…¥ - å¢å¼·ç‰ˆåŠŸèƒ½
from src.services.analysis.enhanced_technical_analyzer import EnhancedTechnicalAnalyzer
from src.services.content.personalized_prompt_generator import PersonalizedPromptGenerator
from src.services.content.content_quality_checker import ContentQualityChecker, GeneratedPost
from src.services.content.content_regenerator import ContentRegenerator
# from src.services.sheets.enhanced_sheets_recorder import EnhancedSheetsRecorder  # æš«æ™‚ç§»é™¤
from src.services.content.data_driven_content_generator import create_data_driven_content_generator

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedTopicAssignmentFlow:
    """å¢å¼·ç‰ˆè©±é¡Œåˆ†æ´¾æµç¨‹"""
    
    def __init__(self):
        # åˆå§‹åŒ–åŸæœ‰æœå‹™
        self.sheets_client = GoogleSheetsClient(
            credentials_file=os.getenv('GOOGLE_CREDENTIALS_FILE', 'credentials/google-service-account.json'),
            spreadsheet_id=os.getenv('GOOGLE_SHEETS_ID', '148CUhBxqE-BZDPTKaAmOJG6m52CxB4KrxD9p5LikN2s')
        )
        
        self.cmoney_client = CMoneyClient()
        self.assignment_service = AssignmentService(self.sheets_client)
        self.topic_classifier = TopicClassifier()
        
        # åˆå§‹åŒ–å¢å¼·ç‰ˆæœå‹™
        finlab_key = os.getenv('FINLAB_API_KEY')
        if not finlab_key:
            raise ValueError("æœªæ‰¾åˆ° FINLAB_API_KEY ç’°å¢ƒè®Šæ•¸")
        
        self.technical_analyzer = EnhancedTechnicalAnalyzer()
        self.content_generator = create_data_driven_content_generator(finlab_key)
        self.prompt_generator = PersonalizedPromptGenerator()
        self.quality_checker = ContentQualityChecker()
        self.content_regenerator = ContentRegenerator(self.prompt_generator, self.quality_checker)
        # self.sheets_recorder = EnhancedSheetsRecorder(self.sheets_client)  # æš«æ™‚ç§»é™¤
        
        print("ğŸš€ å¢å¼·ç‰ˆè©±é¡Œåˆ†æ´¾æµç¨‹åˆå§‹åŒ–å®Œæˆ")
    
    async def run_enhanced_flow(self):
        """åŸ·è¡Œå¢å¼·ç‰ˆè©±é¡Œåˆ†æ´¾æµç¨‹"""
        
        print("\n" + "="*80)
        print("ğŸ”¬ å¢å¼·ç‰ˆç†±é–€è©±é¡Œåˆ†æ´¾èˆ‡ç™¼æ–‡æµç¨‹")
        print("ğŸ“Š æ–°åŠŸèƒ½ï¼šæŠ€è¡“åˆ†æ + å€‹äººåŒ– Prompt + å“è³ªæª¢æŸ¥")
        print("="*80)
        
        try:
            # æ­¥é©Ÿ 1: ç²å–ç†±é–€è©±é¡Œ
            topics = await self._fetch_trending_topics()
            
            # æ­¥é©Ÿ 2: è©±é¡Œåˆ†é¡å’Œè‚¡ç¥¨æå–
            classified_topics_with_stocks = await self._classify_and_extract_stocks(topics)
            
            # æ­¥é©Ÿ 3: KOL åˆ†æ´¾ï¼ˆæå‰ï¼‰
            topic_assignments = self._assign_kols(classified_topics_with_stocks)
            
            # æ­¥é©Ÿ 4: è‚¡ç¥¨åˆ†é…èˆ‡æŠ€è¡“åˆ†æ
            assignments_with_stocks = await self._assign_stocks_and_analyze(topic_assignments)
            
            # æ­¥é©Ÿ 5: è‚¡ç¥¨æ¨™ç±¤è™•ç†
            assignments_with_tags = self._process_stock_tags(assignments_with_stocks)
            
            # æ­¥é©Ÿ 6: å¢å¼·ç‰ˆå…§å®¹ç”Ÿæˆ
            generated_posts = await self._generate_enhanced_content(assignments_with_tags)
            
            # æ­¥é©Ÿ 7: å…§å®¹å“è³ªæª¢æŸ¥èˆ‡é‡æ–°ç”Ÿæˆ
            quality_posts = await self._quality_check_and_regenerate(generated_posts)
            
            # æ­¥é©Ÿ 8: å¢å¼·ç‰ˆ Google Sheets è¨˜éŒ„
            await self._record_to_enhanced_sheets(quality_posts)
            
            # æ­¥é©Ÿ 9: ç™¼æ–‡ç¢ºèªèˆ‡å¯¦éš›ç™¼æ–‡
            await self._confirm_and_publish(quality_posts)
            
        except Exception as e:
            logger.error(f"å¢å¼·ç‰ˆæµç¨‹åŸ·è¡Œå¤±æ•—: {e}")
            print(f"âŒ æµç¨‹åŸ·è¡Œå¤±æ•—: {e}")
    
    async def _fetch_trending_topics(self):
        """æ­¥é©Ÿ 1: ç²å–ç†±é–€è©±é¡Œ"""
        
        print("\nğŸ“ˆ æ­¥é©Ÿ 1: ç²å–ç†±é–€è©±é¡Œ")
        print("-" * 40)
        
        credentials = LoginCredentials(
            email='forum_200@cmoney.com.tw',
            password='N9t1kY3x'
        )
        
        token = await self.cmoney_client.login(credentials)
        topics = await self.cmoney_client.get_trending_topics(token.token)
        
        print(f"âœ… ç²å–åˆ° {len(topics)} å€‹ç†±é–€è©±é¡Œ")
        
        # é¡¯ç¤ºå‰5å€‹è©±é¡Œ
        for i, topic in enumerate(topics[:5], 1):
            print(f"  {i}. {topic.title}")
            print(f"     ğŸ“Š ID: {topic.id}")
            if hasattr(topic, 'relatedStockSymbols') and topic.relatedStockSymbols:
                print(f"     ğŸ“ˆ ç›¸é—œè‚¡ç¥¨: {', '.join(topic.relatedStockSymbols[:3])}")
        
        return topics[:3]  # åªè™•ç†å‰3å€‹è©±é¡Œ
    
    async def _classify_and_extract_stocks(self, topics):
        """æ­¥é©Ÿ 2: è©±é¡Œåˆ†é¡å’Œè‚¡ç¥¨æå–"""
        
        print("\nğŸ·ï¸ æ­¥é©Ÿ 2: è©±é¡Œåˆ†é¡å’Œè‚¡ç¥¨æå–")
        print("-" * 40)
        
        classified_topics = []
        
        for topic in topics:
            print(f"ğŸ“‹ åˆ†æè©±é¡Œ: {topic.title}")
            
            # è©±é¡Œåˆ†é¡
            classification = self.topic_classifier.classify_topic(topic.id, topic.title, topic.name)
            print(f"  ğŸ·ï¸ åˆ†é¡çµæœ: {classification.persona_tags}")
            
            # æ™ºèƒ½è‚¡ç¥¨æå–
            stock_symbols = self._extract_stocks_from_topic(topic)
            if stock_symbols:
                print(f"  ğŸ“ˆ ç›¸é—œè‚¡ç¥¨: {', '.join(stock_symbols)}")
            else:
                print(f"  ğŸ“ˆ ç›¸é—œè‚¡ç¥¨: ç„¡")
            
            classified_topics.append({
                'id': topic.id,
                'title': topic.title,
                'name': topic.name,
                'classification': classification,
                'stock_symbols': stock_symbols
            })
        
        return classified_topics
    
    def _extract_stocks_from_topic(self, topic):
        """æ™ºèƒ½è‚¡ç¥¨æå–"""
        import re
        
        stocks = []
        title = topic.title
        
        # 1. å¾APIåŸå§‹æ•¸æ“šæå–
        if hasattr(topic, 'relatedStockSymbols') and topic.relatedStockSymbols:
            stocks.extend(topic.relatedStockSymbols)
        
        # 2. å¾æ¨™é¡Œæå–è‚¡ç¥¨ä»£è™Ÿï¼ˆ4-5ä½æ•¸å­—ï¼‰
        stock_codes = re.findall(r'\b\d{4,5}\b', title)
        stocks.extend(stock_codes)
        
        # 3. å…¬å¸åç¨±å°æ‡‰è‚¡ç¥¨ä»£è™Ÿ
        company_mapping = {
            'å°ç©é›»': '2330', 'TSMC': '2330',
            'è¼é”': 'NVDA', 'NVIDIA': 'NVDA',
            'é´»æµ·': '2317', 'è¯ç™¼ç§‘': '2454',
            'å°é”é›»': '2308', 'ä¸­è¯é›»': '2412',
            'åœ‹æ³°é‡‘': '2882', 'å¯Œé‚¦é‡‘': '2881',
            'é•·æ¦®': '2603', 'é™½æ˜': '2609'
        }
        
        for company, code in company_mapping.items():
            if company in title:
                stocks.append(code)
        
        # 4. å¤§ç›¤è©±é¡Œå„ªå…ˆä½¿ç”¨å€‹è‚¡è€ŒéETF
        if any(keyword in title for keyword in ['å¤§ç›¤', 'å°è‚¡', 'æŒ‡æ•¸']):
            # å„ªå…ˆä½¿ç”¨æœ‰æŠ€è¡“åˆ†æåƒ¹å€¼çš„å€‹è‚¡
            popular_stocks = ['2330', '2317', '2454', '2308', '2412']  # å°ç©é›»ã€é´»æµ·ã€è¯ç™¼ç§‘ã€å°é”é›»ã€ä¸­è¯é›»
            stocks.extend(popular_stocks[:2])  # å–å‰2æª”
            # å‚™é¸ETF
            stocks.extend(['0050', '0056'])
        
        # 5. å»é‡ä¸¦éæ¿¾
        unique_stocks = list(dict.fromkeys(stocks))  # ä¿æŒé †åºå»é‡
        
        # éæ¿¾ç¾è‚¡ï¼ˆæš«æ™‚ä¸æ”¯æŒæŠ€è¡“åˆ†æï¼‰
        tw_stocks = [s for s in unique_stocks if not s.isalpha() or len(s) <= 5]
        
        # 6. å„ªå…ˆé¸æ“‡å€‹è‚¡ï¼ŒETFç‚ºå‚™é¸
        individual_stocks = [s for s in tw_stocks if not self._is_etf(s)]
        etf_stocks = [s for s in tw_stocks if self._is_etf(s)]
        
        # å„ªå…ˆå€‹è‚¡ï¼Œä¸è¶³å†ç”¨ETFè£œå……
        final_stocks = individual_stocks[:2] + etf_stocks[:1]
        
        return final_stocks[:3]  # æœ€å¤š3æª”è‚¡ç¥¨
    
    def _is_etf(self, stock_id: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºETF"""
        etf_codes = ['0050', '0056', '00878', '00919', '00940', '006208']
        return stock_id in etf_codes
    
    async def _evaluate_technical_analysis(self, classified_topics):
        """æ­¥é©Ÿ 3: æŠ€è¡“åˆ†æè©•ä¼°"""
        
        print("\nğŸ“Š æ­¥é©Ÿ 3: å¤šé€±æœŸæŠ€è¡“åˆ†æè©•ä¼°")
        print("-" * 40)
        
        topics_with_analysis = []
        
        for topic in classified_topics:
            print(f"ğŸ”¬ åˆ†æè©±é¡Œ: {topic['title']}")
            
            topic_analysis = {
                'topic': topic,
                'stock_analyses': {},
                'overall_score': 0,
                'confidence': 0,
                'effective_count': 0
            }
            
            # å°æ¯æ”¯ç›¸é—œè‚¡ç¥¨é€²è¡ŒæŠ€è¡“åˆ†æ
            for stock_symbol in topic['stock_symbols']:
                print(f"  ğŸ“ˆ åˆ†æè‚¡ç¥¨: {stock_symbol}")
                
                try:
                    analysis = await self.technical_analyzer.get_enhanced_stock_analysis(stock_symbol)
                    
                    if analysis:
                        topic_analysis['stock_analyses'][stock_symbol] = analysis
                        print(f"    âœ… è©•åˆ†: {analysis.overall_score:.1f}/10")
                        print(f"    ğŸ¯ ä¿¡å¿ƒåº¦: {analysis.confidence_score:.1f}%")
                        print(f"    ğŸ“Š æœ‰æ•ˆæŒ‡æ¨™: {len(analysis.effective_indicators)} å€‹")
                        
                        # ç´¯ç©è©•åˆ†
                        topic_analysis['overall_score'] += analysis.overall_score
                        topic_analysis['confidence'] += analysis.confidence_score
                        topic_analysis['effective_count'] += len(analysis.effective_indicators)
                    else:
                        print(f"    âŒ æŠ€è¡“åˆ†æå¤±æ•—")
                
                except Exception as e:
                    print(f"    âš ï¸ åˆ†æéŒ¯èª¤: {e}")
            
            # è¨ˆç®—è©±é¡Œæ•´é«”è©•åˆ†
            if topic_analysis['stock_analyses']:
                stock_count = len(topic_analysis['stock_analyses'])
                topic_analysis['overall_score'] /= stock_count
                topic_analysis['confidence'] /= stock_count
                
                print(f"  ğŸ¯ è©±é¡Œæ•´é«”è©•åˆ†: {topic_analysis['overall_score']:.1f}/10")
                print(f"  ğŸ¯ å¹³å‡ä¿¡å¿ƒåº¦: {topic_analysis['confidence']:.1f}%")
            else:
                print(f"  âŒ ç„¡æœ‰æ•ˆæŠ€è¡“åˆ†æ")
            
            topics_with_analysis.append(topic_analysis)
        
        return topics_with_analysis
    
    def _filter_effective_topics(self, topics_with_analysis):
        """æ­¥é©Ÿ 4: æœ‰æ•ˆè©±é¡Œç¯©é¸"""
        
        print("\nğŸ” æ­¥é©Ÿ 4: æœ‰æ•ˆè©±é¡Œç¯©é¸")
        print("-" * 40)
        
        effective_topics = []
        
        for topic_analysis in topics_with_analysis:
            topic = topic_analysis['topic']
            score = topic_analysis['overall_score']
            confidence = topic_analysis['confidence']
            effective_count = topic_analysis['effective_count']
            
            print(f"ğŸ“‹ è©•ä¼°è©±é¡Œ: {topic['title']}")
            print(f"  ğŸ“Š è©•åˆ†: {score:.1f}/10")
            print(f"  ğŸ¯ ä¿¡å¿ƒåº¦: {confidence:.1f}%")
            print(f"  ğŸ“ˆ æœ‰æ•ˆæŒ‡æ¨™: {effective_count} å€‹")
            
            # æš«æ™‚æ”¾å¯¬ç¯©é¸æ¢ä»¶ï¼šæœ‰è‚¡ç¥¨æ•¸æ“šå³å¯
            has_stocks = len(topic['stock_symbols']) > 0
            
            if has_stocks:
                effective_topics.append(topic_analysis)
                print(f"  âœ… é€šéç¯©é¸ï¼Œå°‡ç”¨æ–¼å…§å®¹ç”Ÿæˆï¼ˆæš«æ™‚æ”¾å¯¬æŠ€è¡“åˆ†æè¦æ±‚ï¼‰")
            else:
                print(f"  âŒ æœªé€šéç¯©é¸ï¼Œç„¡ç›¸é—œè‚¡ç¥¨æ•¸æ“š")
        
        print(f"\nğŸ¯ ç¯©é¸çµæœ: {len(effective_topics)}/{len(topics_with_analysis)} å€‹è©±é¡Œé€šé")
        
        return effective_topics
    
    def _assign_kols(self, classified_topics):
        """æ­¥é©Ÿ 3: KOL åˆ†æ´¾ï¼ˆæå‰ï¼‰"""
        
        print("\nğŸ‘¥ æ­¥é©Ÿ 3: KOL åˆ†æ´¾")
        print("-" * 40)
        
        # è¼‰å…¥ KOL è³‡æ–™
        self.assignment_service.load_kol_profiles()
        active_kols = [kol for kol in self.assignment_service._kol_profiles if kol.enabled]
        print(f"âœ… è¼‰å…¥ {len(active_kols)} å€‹æ´»èº KOL")
        
        all_assignments = []
        
        for topic_data in classified_topics:
            # å»ºç«‹ TopicData ç‰©ä»¶
            topic_data_obj = TopicData(
                topic_id=topic_data['id'],
                title=topic_data['title'],
                input_index=0,
                persona_tags=topic_data['classification'].persona_tags,
                industry_tags=topic_data['classification'].industry_tags,
                event_tags=topic_data['classification'].event_tags,
                stock_tags=topic_data['classification'].stock_tags,
                classification=topic_data['classification']
            )
            
            # åˆ†æ´¾ KOL (æ¯å€‹è©±é¡Œæœ€å¤š 2 å€‹ KOL)
            assignments = self.assignment_service.assign_topics([topic_data_obj], max_assignments_per_topic=2)
            
            print(f"ğŸ“‹ è©±é¡Œ: {topic_data['title']}")
            print(f"ğŸ‘¥ åˆ†æ´¾çµ¦ {len(assignments)} å€‹ KOL")
            
            for assignment in assignments:
                kol = next((k for k in active_kols if k.serial == assignment.kol_serial), None)
                if kol:
                    print(f"  âœ… {kol.nickname} ({kol.persona})")
                    
                    # åŠ å…¥è©±é¡Œè³‡æ–™
                    assignment_data = {
                        'assignment': assignment,
                        'kol': kol,
                        'topic_analysis': {
                            'topic': topic_data,
                            'classification': topic_data['classification']
                        }
                    }
                    all_assignments.append(assignment_data)
        
        return all_assignments
    
    async def _assign_stocks_and_analyze(self, topic_assignments):
        """æ­¥é©Ÿ 4: è‚¡ç¥¨åˆ†é…èˆ‡æŠ€è¡“åˆ†æ"""
        
        print("\nğŸ“ˆ æ­¥é©Ÿ 4: è‚¡ç¥¨åˆ†é…èˆ‡æŠ€è¡“åˆ†æ")
        print("-" * 40)
        
        assignments_with_stocks = []
        
        for assignment_data in topic_assignments:
            assignment = assignment_data['assignment']
            kol = assignment_data['kol']
            topic_analysis = assignment_data['topic_analysis']
            topic = topic_analysis['topic']
            
            print(f"ğŸ“Š ç‚º {kol.nickname} åˆ†é…è‚¡ç¥¨ä¸¦é€²è¡ŒæŠ€è¡“åˆ†æ")
            print(f"ğŸ“‹ è©±é¡Œ: {topic['title']}")
            
            # å¾è©±é¡Œä¸­ç²å–ç›¸é—œè‚¡ç¥¨
            related_stocks = topic.get('stock_symbols', [])
            if not related_stocks:
                print(f"  âš ï¸ ç„¡ç›¸é—œè‚¡ç¥¨ï¼Œè·³éæŠ€è¡“åˆ†æ")
                assignment_data['stock_analyses'] = {}
                assignment_data['assigned_stocks'] = []
                assignments_with_stocks.append(assignment_data)
                continue
            
            print(f"  ğŸ“ˆ ç›¸é—œè‚¡ç¥¨: {', '.join(related_stocks)}")
            
            # å°æ¯æ”¯è‚¡ç¥¨é€²è¡ŒæŠ€è¡“åˆ†æ
            stock_analyses = {}
            for stock_symbol in related_stocks:
                print(f"  ğŸ”¬ åˆ†æè‚¡ç¥¨: {stock_symbol}")
                
                try:
                    analysis = await self.technical_analyzer.get_enhanced_stock_analysis(stock_symbol)
                    
                    if analysis:
                        stock_analyses[stock_symbol] = analysis
                        print(f"    âœ… è©•åˆ†: {analysis.overall_score:.1f}/10")
                        print(f"    ğŸ¯ ä¿¡å¿ƒåº¦: {analysis.confidence_score:.1f}%")
                    else:
                        print(f"    âŒ æŠ€è¡“åˆ†æå¤±æ•—")
                
                except Exception as e:
                    print(f"    âš ï¸ åˆ†æéŒ¯èª¤: {e}")
            
            # ä¿å­˜åˆ†æçµæœ
            assignment_data['stock_analyses'] = stock_analyses
            assignment_data['assigned_stocks'] = related_stocks
            assignments_with_stocks.append(assignment_data)
        
        return assignments_with_stocks
    
    def _process_stock_tags(self, assignments_with_stocks):
        """æ­¥é©Ÿ 5: è‚¡ç¥¨æ¨™ç±¤è™•ç†"""
        
        print("\nğŸ·ï¸ æ­¥é©Ÿ 5: è‚¡ç¥¨æ¨™ç±¤è™•ç†")
        print("-" * 40)
        
        assignments_with_tags = []
        
        # æŒ‰è©±é¡Œåˆ†çµ„ï¼Œç‚ºæ¯å€‹è©±é¡Œçš„KOLéš¨æ©Ÿåˆ†é…è‚¡ç¥¨
        topic_groups = {}
        for assignment_data in assignments_with_stocks:
            topic_id = assignment_data['topic_analysis']['topic']['id']
            if topic_id not in topic_groups:
                topic_groups[topic_id] = []
            topic_groups[topic_id].append(assignment_data)
        
        for topic_id, topic_assignments in topic_groups.items():
            topic = topic_assignments[0]['topic_analysis']['topic']
            all_stocks = topic_assignments[0].get('assigned_stocks', [])
            
            print(f"ğŸ“‹ è™•ç†è©±é¡Œ: {topic['title']}")
            print(f"  ğŸ“ˆ å¯ç”¨è‚¡ç¥¨: {', '.join(all_stocks)}")
            
            # ç‚ºæ¯å€‹KOLéš¨æ©Ÿåˆ†é…è‚¡ç¥¨å­é›†
            import random
            for i, assignment_data in enumerate(topic_assignments):
                kol = assignment_data['kol']
                
                # éš¨æ©Ÿé¸æ“‡1-3å€‹è‚¡ç¥¨ï¼ˆè‡³å°‘1å€‹ï¼‰
                num_stocks = min(random.randint(1, 3), len(all_stocks))
                kol_stocks = random.sample(all_stocks, num_stocks)
                
                print(f"  ğŸ‘¤ {kol.nickname}: åˆ†é…è‚¡ç¥¨ {', '.join(kol_stocks)}")
                
                # æº–å‚™ commodityTags
                commodity_tags = []
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºå¤§ç›¤è©±é¡Œï¼Œå¦‚æœæ˜¯å‰‡åŠ å…¥ TWA00
                if any(keyword in topic['title'] for keyword in ['å¤§ç›¤', 'å°è‚¡', 'æŒ‡æ•¸', 'å°ç©é›»', '2330']):
                    commodity_tags.append({
                        "type": "Stock", 
                        "key": "TWA00",
                        "bullOrBear": 0  # é è¨­ç‚ºä¸­æ€§
                    })
                    print(f"    ğŸ·ï¸ åŠ å…¥å¤§ç›¤æ¨™ç±¤: TWA00")
                
                # åŠ å…¥åˆ†é…çš„è‚¡ç¥¨æ¨™ç±¤
                for stock_symbol in kol_stocks:
                    commodity_tags.append({
                        "type": "Stock", 
                        "key": stock_symbol,
                        "bullOrBear": 0  # é è¨­ç‚ºä¸­æ€§
                    })
                
                tag_strs = [f"{tag['type']}:{tag['key']}" for tag in commodity_tags]
                print(f"    ğŸ·ï¸ æœ€çµ‚æ¨™ç±¤: {tag_strs}")
                
                # æ›´æ–°åˆ†é…çš„è‚¡ç¥¨å’Œæ¨™ç±¤è³‡è¨Š
                assignment_data['assigned_stocks'] = kol_stocks
                assignment_data['commodity_tags'] = commodity_tags
                assignments_with_tags.append(assignment_data)
        
        return assignments_with_tags
    
    def _get_stock_name(self, stock_symbol: str) -> str:
        """å°‡è‚¡ç¥¨ä»£è™Ÿè½‰æ›ç‚ºå…¬å¸åç¨±"""
        stock_name_mapping = {
            '2330': 'å°ç©é›»',
            '2317': 'é´»æµ·',
            '2454': 'è¯ç™¼ç§‘',
            '2308': 'å°é”é›»',
            '2412': 'ä¸­è¯é›»',
            '2882': 'åœ‹æ³°é‡‘',
            '2881': 'å¯Œé‚¦é‡‘',
            '2603': 'é•·æ¦®',
            '2609': 'é™½æ˜',
            '2634': 'æ¼¢ç¿”',
            '8033': 'é›·è™',
            '1303': 'å—äº',
            '2359': 'æ‰€ç¾…é–€',
            '1504': 'æ±å…ƒ',
            '8927': 'å¯Œé‚¦åª’',
            '8932': 'æ™ºé‚¦',
            'TWA00': 'å°è‚¡æŒ‡æ•¸'
        }
        return stock_name_mapping.get(stock_symbol, stock_symbol)
    
    async def _generate_enhanced_content(self, assignments_with_tags):
        """æ­¥é©Ÿ 6: å¢å¼·ç‰ˆå…§å®¹ç”Ÿæˆ"""
        
        print("\nâœ¨ æ­¥é©Ÿ 6: å¢å¼·ç‰ˆå…§å®¹ç”Ÿæˆ")
        print("-" * 40)
        
        generated_posts = []
        
        for assignment_data in assignments_with_tags:
            assignment = assignment_data['assignment']
            kol = assignment_data['kol']
            topic_analysis = assignment_data['topic_analysis']
            topic = topic_analysis['topic']
            stock_analyses = assignment_data.get('stock_analyses', {})
            assigned_stocks = assignment_data.get('assigned_stocks', [])
            commodity_tags = assignment_data.get('commodity_tags', [])
            
            print(f"ğŸ­ ç‚º {kol.nickname} ç”Ÿæˆå…§å®¹")
            print(f"ğŸ“‹ è©±é¡Œ: {topic['title']}")
            
            try:
                # æº–å‚™è‚¡ç¥¨æ•¸æ“š - éœ€è¦è½‰æ›ç‚º StockMarketData å°è±¡
                from src.services.content.data_driven_content_generator import StockMarketData, MarketContext
                from src.services.content.technical_explanation_generator import technical_explanation_generator
                
                stock_data_map = {}
                for stock_symbol, analysis in stock_analyses.items():
                    # å‰µå»º StockMarketData å°è±¡
                    stock_data_map[stock_symbol] = StockMarketData(
                        stock_id=stock_symbol,
                        stock_name=self._get_stock_name(stock_symbol),
                        date=analysis.analysis_date if hasattr(analysis, 'analysis_date') and isinstance(analysis.analysis_date, str) else '2025-08-29',
                        open=analysis.current_price,  # æš«æ™‚ä½¿ç”¨æ”¶ç›¤åƒ¹
                        high=analysis.current_price,  # æš«æ™‚ä½¿ç”¨æ”¶ç›¤åƒ¹
                        low=analysis.current_price,   # æš«æ™‚ä½¿ç”¨æ”¶ç›¤åƒ¹
                        close=analysis.current_price,
                        volume=0,  # æš«æ™‚è¨­ç‚º 0
                        daily_change=0.0,  # æš«æ™‚è¨­ç‚º 0
                        daily_change_pct=0.0,  # æš«æ™‚è¨­ç‚º 0
                        technical_summary=f"æŠ€è¡“æŒ‡æ¨™è©•åˆ†: {analysis.overall_score:.1f}/10 (ä¿¡å¿ƒåº¦: {analysis.confidence_score:.1f}%)"
                    )
                
                # ä½¿ç”¨æ•¸æ“šé©…å‹•å…§å®¹ç”Ÿæˆå™¨
                content_result = await self.content_generator.generate_data_driven_content(
                    kol_profile={
                        'serial': kol.serial,
                        'nickname': kol.nickname,
                        'persona': kol.persona
                    },
                    topic_data={
                        'id': topic['id'],
                        'title': topic['title'],
                        'keywords': topic['classification'].persona_tags + topic['classification'].industry_tags
                    },
                    stock_assignments=[{
                        'topic_data': topic,
                        'kol_profile': {
                            'serial': kol.serial,
                            'nickname': kol.nickname,
                            'persona': kol.persona
                        },
                        'assigned_stocks': [{'stock_id': symbol, 'stock_name': self._get_stock_name(symbol)} 
                                          for symbol in assigned_stocks],
                        'analysis_angle': f'{kol.persona}çš„æ·±åº¦åˆ†æ'
                    }],
                    stock_data_map=stock_data_map,
                    market_context=MarketContext(
                        market_sentiment=f"æŠ€è¡“é¢è©•åˆ†: {topic_analysis.get('overall_score', 0):.1f}/10",
                        sector_performance="æŒçºŒè§€å¯Ÿ",
                        macro_factors="å…§å¤–è³‡åˆ†æ­§å½±éŸ¿å¸‚å ´æƒ…ç·’",
                        news_highlights=topic['title']
                    )
                )
                
                if content_result:
                    # å»ºç«‹è²¼æ–‡ç‰©ä»¶
                    post_id = f"{topic['id']}-{kol.serial}"
                    post = GeneratedPost(
                        post_id=post_id,
                        kol_serial=kol.serial,
                        kol_nickname=kol.nickname,
                        persona=kol.persona,
                        title=content_result.get('title', ''),
                        content=content_result.get('content', ''),
                        topic_title=topic['title'],
                        topic_id=topic['id'],  # ä¿å­˜å®Œæ•´çš„ topic ID
                        generation_params=content_result.get('generation_metadata', {}).get('generation_params', {}),
                        created_at=datetime.now()
                    )
                    
                    # åŠ å…¥é¡å¤–è³‡æ–™
                    post.topic_analysis = topic_analysis
                    post.stock_analyses = stock_analyses
                    post.generation_metadata = content_result.get('generation_metadata', {})
                    
                    # ä¿å­˜ç™¼æ–‡ç”¨çš„è‚¡ç¥¨æ¨™ç±¤ï¼ˆä½¿ç”¨æ–°çš„ commodity_tagsï¼‰
                    post.commodity_tags = commodity_tags
                    post.related_stocks = assigned_stocks
                    
                    generated_posts.append(post)
                    print(f"  âœ… ç”ŸæˆæˆåŠŸ: {len(content_result.get('content', ''))} å­—")
                else:
                    print(f"  âŒ ç”Ÿæˆå¤±æ•—")
                
            except Exception as e:
                logger.error(f"å…§å®¹ç”Ÿæˆå¤±æ•—: {e}")
                print(f"  âŒ ç”ŸæˆéŒ¯èª¤: {e}")
        
        print(f"\nğŸ¯ ç”Ÿæˆçµæœ: {len(generated_posts)} ç¯‡å…§å®¹")
        return generated_posts
    
    async def _quality_check_and_regenerate(self, generated_posts):
        """æ­¥é©Ÿ 7: å…§å®¹å“è³ªæª¢æŸ¥èˆ‡é‡æ–°ç”Ÿæˆ"""
        
        print("\nğŸ” æ­¥é©Ÿ 7: å…§å®¹å“è³ªæª¢æŸ¥èˆ‡é‡æ–°ç”Ÿæˆ")
        print("-" * 40)
        
        quality_posts = []
        
        for post in generated_posts:
            print(f"ğŸ” æª¢æŸ¥ {post.kol_nickname} çš„å…§å®¹å“è³ª")
            
            # å“è³ªæª¢æŸ¥
            quality_score, quality_issues = await self.quality_checker.check_content_quality(post)
            
            print(f"  ğŸ“Š å“è³ªè©•åˆ†: {quality_score:.1f}/10")
            quality_passed = quality_score >= 6.0  # è¨­å®šé€šéé–€æª»
            print(f"  âœ… é€šéæª¢æŸ¥: {quality_passed}")
            
            if quality_passed:
                quality_posts.append(post)
                print(f"  âœ… å“è³ªè‰¯å¥½ï¼Œä¿ç•™å…§å®¹")
            else:
                print(f"  âš ï¸ å“è³ªä¸è¶³ï¼Œå˜—è©¦é‡æ–°ç”Ÿæˆ...")
                print(f"  ğŸ“‹ å•é¡Œ: {[issue.description for issue in quality_issues]}")
                
                # é‡æ–°ç”Ÿæˆ (æœ€å¤š1æ¬¡)
                regenerated = await self.content_regenerator.regenerate_single_post(
                    original_post=post,
                    issues=quality_issues,
                    generation_context={},
                    all_posts=generated_posts
                )
                
                if regenerated and regenerated.success:
                    print(f"  âœ… é‡æ–°ç”ŸæˆæˆåŠŸ")
                    quality_posts.append(regenerated.final_post)
                else:
                    print(f"  âŒ é‡æ–°ç”Ÿæˆå¤±æ•—ï¼Œä¿ç•™åŸå…§å®¹")
                    quality_posts.append(post)
        
        print(f"\nğŸ¯ å“è³ªæª¢æŸ¥çµæœ: {len(quality_posts)}/{len(generated_posts)} ç¯‡é€šé")
        return quality_posts
    
    async def _record_to_enhanced_sheets(self, posts):
        """æ­¥é©Ÿ 8: å¢å¼·ç‰ˆ Google Sheets è¨˜éŒ„"""
        
        print("\nğŸ“ æ­¥é©Ÿ 8: è¨˜éŒ„åˆ°å¢å¼·ç‰ˆ Google Sheets")
        print("-" * 40)
        
        try:
            # è®€å–ç¾æœ‰çš„Google Sheetsçµæ§‹
            sheet_name = "è²¼æ–‡è¨˜éŒ„è¡¨"
            existing_data = self.sheets_client.read_sheet(sheet_name)
            
            if not existing_data:
                print("âŒ ç„¡æ³•è®€å–Google Sheetsçµæ§‹")
                return
            
            # ç²å–æ¨™é¡Œè¡Œ
            headers = existing_data[0] if existing_data else []
            if not headers:
                print("âŒ ç„¡æ³•ç²å–æ¨™é¡Œè¡Œ")
                return
                
            print(f"ğŸ“‹ æª¢æ¸¬åˆ° {len(headers)} å€‹æ¬„ä½")
            
            # æº–å‚™æ–°è¡Œæ•¸æ“š
            new_rows = []
            
            for post in posts:
                print(f"  ğŸ“ æº–å‚™è¨˜éŒ„ {post.kol_nickname} çš„å…§å®¹åˆ° Google Sheets")
                print(f"     Post ID: {post.post_id}")
                
                # æº–å‚™å®Œæ•´çš„è¡Œæ•¸æ“šï¼ŒæŒ‰ç…§Google Sheetsçš„æ¬„ä½é †åº
                row_data = []
                
                # æ ¹æ“šæ¨™é¡Œè¡Œæ˜ å°„æ•¸æ“š
                for header in headers:
                    if header == "è²¼æ–‡ID":
                        row_data.append(post.post_id)
                    elif header == "KOL Serial":
                        row_data.append(post.kol_serial)
                    elif header == "KOL æš±ç¨±":
                        row_data.append(post.kol_nickname)
                    elif header == "KOL ID":
                        row_data.append(post.kol_serial)  # å‡è¨­IDåŒserial
                    elif header == "Persona":
                        row_data.append(post.persona)
                    elif header == "Content Type":
                        row_data.append("æŠ€è¡“åˆ†æè²¼æ–‡")
                    elif header == "å·²æ´¾ç™¼TopicIndex":
                        row_data.append("1")
                    elif header == "å·²æ´¾ç™¼TopicID":
                        row_data.append(post.topic_id)
                    elif header == "â€“":
                        row_data.append("")
                    elif header == "å·²æ´¾ç™¼TopicKeywords":
                        topic_keywords = getattr(post, 'topic_analysis', {}).get('topic', {}).get('classification', {})
                        if hasattr(topic_keywords, 'persona_tags'):
                            keywords = topic_keywords.persona_tags + getattr(topic_keywords, 'industry_tags', [])
                            row_data.append(", ".join(keywords))
                        else:
                            row_data.append("")
                    elif header == "ç”Ÿæˆæ¨™é¡Œ":
                        # åªæ”¾æ¨™é¡Œ
                        row_data.append(post.title)
                    elif header == "ç”Ÿæˆå…§å®¹":
                        # åªæ”¾å…§å®¹ï¼Œä¸åŒ…å«æ¨™é¡Œ
                        row_data.append(post.content)
                    elif header == "ç†±é–€è©±é¡Œæ¨™é¡Œ":
                        row_data.append(post.topic_title)
                    elif header == "ç™¼æ–‡ç‹€æ…‹":
                        row_data.append("å·²ç”Ÿæˆ")
                    elif header == "ä¸Šæ¬¡æ’ç¨‹æ™‚é–“":
                        row_data.append(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    elif header == "ç™¼æ–‡æ™‚é–“æˆ³è¨˜":
                        row_data.append("")
                    elif header == "æœ€è¿‘éŒ¯èª¤è¨Šæ¯":
                        row_data.append("")
                    elif header == "å¹³å°ç™¼æ–‡ID":
                        row_data.append("")
                    elif header == "å¹³å°ç™¼æ–‡URL":
                        row_data.append("")
                    elif header == "articleid":
                        row_data.append("")
                    elif header == "ç†±é–€è©±é¡Œæ¨™é¡Œ":
                        row_data.append(post.topic_title)
                    elif header == "è§¸ç™¼æ”¯ç·šé¡å‹":
                        row_data.append("enhanced_trending_topics")
                    elif header == "è§¸ç™¼äº‹ä»¶ID":
                        row_data.append(f"enhanced_{datetime.now().strftime('%Y%m%d_%H%M')}")
                    elif header == "èª¿ç”¨æ•¸æ“šä¾†æºåº«":
                        row_data.append("finlab_ohlc,cmoney_api,technical_analysis,openai_gpt")
                    elif header == "æ•¸æ“šä¾†æºç‹€æ…‹":
                        row_data.append("finlab:success,cmoney:success,technical:success,openai:success")
                    elif header == "Agentæ±ºç­–ç´€éŒ„":
                        overall_score = getattr(post, "topic_analysis", {}).get("overall_score", 0)
                        row_data.append(f"å¢å¼·ç‰ˆæŠ€è¡“åˆ†æè©•åˆ†é€šé: {overall_score:.1f}/10")
                    elif header == "ç™¼æ–‡é¡å‹":
                        row_data.append("æŠ€è¡“åˆ†æè²¼æ–‡")
                    elif header == "æ–‡ç« é•·åº¦é¡å‹":
                        row_data.append("medium")
                    elif header == "å…§æ–‡å­—æ•¸":
                        row_data.append(str(len(post.content)))
                    elif header == "å…§æ–‡é•·åº¦åˆ†é¡":
                        content_length = len(post.content)
                        if content_length < 200:
                            row_data.append("çŸ­")
                        elif content_length < 500:
                            row_data.append("ä¸­")
                        else:
                            row_data.append("é•·")
                    elif header == "KOLæ¬Šé‡è¨­å®š":
                        row_data.append("1.0")
                    elif header == "å…§å®¹ç”Ÿæˆæ™‚é–“":
                        row_data.append(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    elif header == "KOLè¨­å®šç‰ˆæœ¬":
                        row_data.append("v3.0_enhanced_with_technical_analysis")
                    elif header == "æ–‡ç« é•·åº¦å‘é‡":
                        row_data.append("0.7")
                    elif header == "èªæ°£å‘é‡":
                        row_data.append("0.7")
                    elif header == "temperatureè¨­å®š":
                        row_data.append("0.8")
                    elif header == "body parameter":
                        # å°‡è‚¡ç¥¨æ¨™ç±¤å’Œç¤¾å€è©±é¡Œè½‰æ›ç‚ºæ­£ç¢ºçš„APIæ ¼å¼
                        body_params = {}
                        
                        # æ·»åŠ  commodityTags (åŒ…å« bullOrBear å­—æ®µ)
                        if hasattr(post, 'commodity_tags') and post.commodity_tags:
                            # è½‰æ›ç‚ºæ­£ç¢ºçš„æ ¼å¼ï¼Œæ·»åŠ  bullOrBear å­—æ®µ
                            formatted_tags = []
                            for tag in post.commodity_tags:
                                formatted_tag = {
                                    "type": tag.get("type", "Stock"),
                                    "key": tag.get("key", ""),
                                    "bullOrBear": 0  # é è¨­ç‚ºä¸­æ€§
                                }
                                formatted_tags.append(formatted_tag)
                            body_params["commodityTags"] = formatted_tags
                        
                        # æ·»åŠ  communityTopic
                        if hasattr(post, 'topic_id') and post.topic_id:
                            body_params["communityTopic"] = {"id": post.topic_id}
                        
                        row_data.append(str(body_params))
                    elif header == "å“è³ªæª¢æŸ¥è¼ªæ•¸":
                        row_data.append("1")
                    elif header == "å“è³ªè©•åˆ†":
                        quality_score = getattr(post, 'quality_score', 8.0)
                        row_data.append(str(quality_score))
                    elif header == "å“è³ªå•é¡Œè¨˜éŒ„":
                        row_data.append("")
                    elif header == "é‡æ–°ç”Ÿæˆæ¬¡æ•¸":
                        row_data.append("0")
                    elif header == "å“è³ªæ”¹é€²è¨˜éŒ„":
                        row_data.append("")
                    else:
                        # å°æ–¼å…¶ä»–æ¬„ä½ï¼Œå¡«å…¥ç©ºå€¼
                        row_data.append("")
                
                # ç¢ºä¿è¡Œæ•¸æ“šé•·åº¦èˆ‡æ¨™é¡Œè¡Œä¸€è‡´
                while len(row_data) < len(headers):
                    row_data.append("")
                
                new_rows.append(row_data)
                
                # é¡¯ç¤ºè‚¡ç¥¨æ¨™ç±¤
                if hasattr(post, 'commodity_tags') and post.commodity_tags:
                    tag_strs = [f"{tag['type']}:{tag['key']}" for tag in post.commodity_tags]
                    print(f"     è‚¡ç¥¨æ¨™ç±¤: {tag_strs}")
                
                print(f"  âœ… è¨˜éŒ„ {post.kol_nickname} çš„å…§å®¹")
            
            # å¯«å…¥Google Sheets
            if new_rows:
                try:
                    # ä½¿ç”¨ append_sheet æ–¹æ³•è¿½åŠ æ–°æ•¸æ“š
                    result = self.sheets_client.append_sheet(sheet_name, new_rows)
                    print(f"ğŸ“Š æˆåŠŸè¨˜éŒ„ {len(posts)} ç¯‡å…§å®¹åˆ° Google Sheets")
                    print(f"  ğŸ“ APIå›æ‡‰: {result}")
                except Exception as e:
                    print(f"âŒ Google Sheetså¯«å…¥å¤±æ•—: {e}")
                    import traceback
                    traceback.print_exc()
            else:
                print("âš ï¸ æ²’æœ‰æ–°æ•¸æ“šéœ€è¦å¯«å…¥")
            
        except Exception as e:
            logger.error(f"Google Sheets è¨˜éŒ„å¤±æ•—: {e}")
            print(f"âŒ è¨˜éŒ„å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    async def _confirm_and_publish(self, posts):
        """æ­¥é©Ÿ 9: ç™¼æ–‡ç¢ºèªèˆ‡å¯¦éš›ç™¼æ–‡"""
        
        print("\nğŸ“¢ æ­¥é©Ÿ 9: ç™¼æ–‡ç¢ºèªèˆ‡å¯¦éš›ç™¼æ–‡")
        print("-" * 40)
        
        if not posts:
            print("âŒ æ²’æœ‰å…§å®¹å¯ç™¼æ–‡")
            return
        
        print(f"ğŸ“‹ æº–å‚™ç™¼æ–‡å…§å®¹é è¦½:")
        for i, post in enumerate(posts, 1):
            print(f"\nã€ç¬¬ {i} ç¯‡ã€‘")
            print(f"  ğŸ“ Post ID: {post.post_id}")
            print(f"  ğŸ‘¤ KOL: {post.kol_nickname} ({post.persona})")
            print(f"  ğŸ“‹ æ¨™é¡Œ: {post.title}")
            print(f"  ğŸ“ å­—æ•¸: {len(post.content)} å­—")
            
            # é¡¯ç¤ºæŠ€è¡“åˆ†ææ‘˜è¦
            if hasattr(post, 'stock_analyses') and post.stock_analyses:
                for stock_id, analysis in post.stock_analyses.items():
                    print(f"  ğŸ“Š {stock_id}: {analysis.overall_score:.1f}/10åˆ†")
        
        print(f"\nğŸ¯ å…± {len(posts)} ç¯‡å…§å®¹æº–å‚™ç™¼æ–‡")
        
        # å¯¦éš›ç™¼æ–‡
        print("\nğŸš€ é–‹å§‹å¯¦éš›ç™¼æ–‡...")
        published_posts = []
        
        for i, post in enumerate(posts, 1):
            print(f"\nğŸ“¤ ç™¼æ–‡ç¬¬ {i} ç¯‡: {post.kol_nickname}")
            
            try:
                # æº–å‚™ç™¼æ–‡æ•¸æ“š
                from src.clients.cmoney.cmoney_client import ArticleData
                
                # æº–å‚™ commodityTags
                commodity_tags = []
                if hasattr(post, 'commodity_tags') and post.commodity_tags:
                    commodity_tags = post.commodity_tags
                
                # æº–å‚™ communityTopic
                community_topic = None
                if hasattr(post, 'topic_id') and post.topic_id:
                    community_topic = {"id": post.topic_id}
                
                # å‰µå»ºæ–‡ç« æ•¸æ“š
                article_data = ArticleData(
                    title=post.title,
                    text=post.content,
                    community_topic=community_topic,
                    commodity_tags=commodity_tags
                )
                
                # ç²å– KOL ç™»å…¥æ†‘è­‰
                kol_credentials = await self._get_kol_credentials(post.kol_serial)
                if not kol_credentials:
                    print(f"  âŒ ç„¡æ³•ç²å– {post.kol_nickname} çš„ç™»å…¥æ†‘è­‰")
                    continue
                
                # ç™»å…¥ä¸¦ç™¼æ–‡
                access_token_obj = await self.cmoney_client.login(kol_credentials)
                if not access_token_obj:
                    print(f"  âŒ {post.kol_nickname} ç™»å…¥å¤±æ•—")
                    continue
                
                # ç™¼æ–‡
                publish_result = await self.cmoney_client.publish_article(access_token_obj.token, article_data)
                
                if publish_result.success:
                    print(f"  âœ… ç™¼æ–‡æˆåŠŸ!")
                    print(f"    ğŸ“ Article ID: {publish_result.post_id}")
                    print(f"    ğŸ”— URL: {publish_result.post_url}")
                    
                    # æ›´æ–°ç™¼æ–‡ç‹€æ…‹
                    await self._update_post_status(post.post_id, publish_result)
                    
                    published_posts.append({
                        'post': post,
                        'result': publish_result
                    })
                else:
                    print(f"  âŒ ç™¼æ–‡å¤±æ•—: {publish_result.error_message}")
                    
            except Exception as e:
                print(f"  âŒ ç™¼æ–‡éç¨‹å‡ºéŒ¯: {e}")
                import traceback
                traceback.print_exc()
        
        print(f"\nğŸ“Š ç™¼æ–‡çµæœç¸½çµ:")
        print(f"  âœ… æˆåŠŸç™¼æ–‡: {len(published_posts)} ç¯‡")
        print(f"  âŒ ç™¼æ–‡å¤±æ•—: {len(posts) - len(published_posts)} ç¯‡")
        
        if published_posts:
            print("\nğŸ‰ ç™¼æ–‡å®Œæˆï¼è«‹æª¢æŸ¥ CMoney å¹³å°ç¢ºèªç™¼æ–‡çµæœ")
    
    async def _get_kol_credentials(self, kol_serial: str):
        """ç²å– KOL ç™»å…¥æ†‘è­‰"""
        try:
            from src.clients.cmoney.cmoney_client import LoginCredentials
            
            # å¾ Google Sheets è®€å– KOL é…ç½®
            kol_data = self.sheets_client.read_sheet("åŒå­¸æœƒå¸³è™Ÿç®¡ç†")
            if len(kol_data) <= 1:
                return None
            
            headers = kol_data[0]
            serial_index = None
            email_index = None
            password_index = None
            
            for i, header in enumerate(headers):
                if 'åºè™Ÿ' in header:
                    serial_index = i
                elif 'Email' in header or 'å¸³è™Ÿ' in header:
                    email_index = i
                elif 'å¯†ç¢¼' in header:
                    password_index = i
            
            if serial_index is None or email_index is None or password_index is None:
                return None
            
            # æŸ¥æ‰¾å°æ‡‰çš„ KOL
            for row in kol_data[1:]:
                if len(row) > max(serial_index, email_index, password_index):
                    if str(row[serial_index]) == str(kol_serial):
                        return LoginCredentials(
                            email=row[email_index],
                            password=row[password_index]
                        )
            
            return None
            
        except Exception as e:
            logger.error(f"ç²å– KOL æ†‘è­‰å¤±æ•—: {e}")
            return None
    
    async def _update_post_status(self, post_id: str, publish_result):
        """æ›´æ–°ç™¼æ–‡ç‹€æ…‹åˆ° Google Sheets"""
        try:
            # è®€å–ç¾æœ‰æ•¸æ“š
            sheet_data = self.sheets_client.read_sheet("è²¼æ–‡è¨˜éŒ„è¡¨")
            if len(sheet_data) <= 1:
                return
            
            headers = sheet_data[0]
            
            # æ‰¾åˆ°éœ€è¦æ›´æ–°çš„æ¬„ä½ç´¢å¼•
            post_id_index = None
            status_index = None
            timestamp_index = None
            platform_id_index = None
            platform_url_index = None
            articleid_index = None
            
            for i, header in enumerate(headers):
                if header == "è²¼æ–‡ID":
                    post_id_index = i
                elif header == "ç™¼æ–‡ç‹€æ…‹":
                    status_index = i
                elif header == "ç™¼æ–‡æ™‚é–“æˆ³è¨˜":
                    timestamp_index = i
                elif header == "å¹³å°ç™¼æ–‡ID":
                    platform_id_index = i
                elif header == "å¹³å°ç™¼æ–‡URL":
                    platform_url_index = i
                elif header == "articleid":
                    articleid_index = i
            
            if post_id_index is None:
                return
            
            # æŸ¥æ‰¾å°æ‡‰çš„è¡Œä¸¦æ›´æ–°
            for i, row in enumerate(sheet_data[1:], 2):  # å¾ç¬¬2è¡Œé–‹å§‹
                if len(row) > post_id_index and row[post_id_index] == post_id:
                    # æº–å‚™æ›´æ–°æ•¸æ“š
                    update_data = []
                    
                    # æ›´æ–°ç™¼æ–‡ç‹€æ…‹
                    if status_index is not None:
                        update_data.append(f"B{status_index + 1}")
                        update_data.append("å·²ç™¼æ–‡")
                    
                    # æ›´æ–°ç™¼æ–‡æ™‚é–“æˆ³è¨˜
                    if timestamp_index is not None:
                        update_data.append(f"B{timestamp_index + 1}")
                        update_data.append(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    
                    # æ›´æ–°å¹³å°ç™¼æ–‡ID
                    if platform_id_index is not None and publish_result.post_id:
                        update_data.append(f"B{platform_id_index + 1}")
                        update_data.append(publish_result.post_id)
                    
                    # æ›´æ–°å¹³å°ç™¼æ–‡URL
                    if platform_url_index is not None and publish_result.post_url:
                        update_data.append(f"B{platform_url_index + 1}")
                        update_data.append(publish_result.post_url)
                    
                    # æ›´æ–°articleid
                    if articleid_index is not None and publish_result.post_id:
                        update_data.append(f"B{articleid_index + 1}")
                        update_data.append(publish_result.post_id)
                    
                    # åŸ·è¡Œæ›´æ–°
                    if update_data:
                        # æº–å‚™æ›´æ–°çš„è¡Œæ•¸æ“š
                        updated_row = row.copy()
                        
                        # æ›´æ–°ç™¼æ–‡ç‹€æ…‹
                        if status_index is not None:
                            updated_row[status_index] = "å·²ç™¼æ–‡"
                        
                        # æ›´æ–°ç™¼æ–‡æ™‚é–“æˆ³è¨˜
                        if timestamp_index is not None:
                            updated_row[timestamp_index] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        
                        # æ›´æ–°å¹³å°ç™¼æ–‡ID
                        if platform_id_index is not None and publish_result.post_id:
                            updated_row[platform_id_index] = publish_result.post_id
                        
                        # æ›´æ–°å¹³å°ç™¼æ–‡URL
                        if platform_url_index is not None and publish_result.post_url:
                            updated_row[platform_url_index] = publish_result.post_url
                        
                        # æ›´æ–°articleid
                        if articleid_index is not None and publish_result.post_id:
                            updated_row[articleid_index] = publish_result.post_id
                        
                        # å¯«å…¥æ›´æ–°å¾Œçš„è¡Œ
                        range_name = f"è²¼æ–‡è¨˜éŒ„è¡¨!A{i}:AM{i}"
                        self.sheets_client.write_sheet("è²¼æ–‡è¨˜éŒ„è¡¨", [updated_row], range_name)
                        
                        print(f"  ğŸ“ æ›´æ–°ç™¼æ–‡ç‹€æ…‹: {post_id}")
                        print(f"    Article ID: {publish_result.post_id}")
                        print(f"    URL: {publish_result.post_url}")
                        print(f"    âœ… å·²æ›´æ–° Google Sheets")
            
        except Exception as e:
            logger.error(f"æ›´æ–°ç™¼æ–‡ç‹€æ…‹å¤±æ•—: {e}")
            print(f"  âš ï¸ æ›´æ–°ç™¼æ–‡ç‹€æ…‹å¤±æ•—: {e}")

async def main():
    """ä¸»å‡½æ•¸"""
    
    try:
        flow = EnhancedTopicAssignmentFlow()
        await flow.run_enhanced_flow()
        
    except Exception as e:
        logger.error(f"ä¸»æµç¨‹åŸ·è¡Œå¤±æ•—: {e}")
        print(f"âŒ ä¸»æµç¨‹åŸ·è¡Œå¤±æ•—: {e}")

if __name__ == "__main__":
    asyncio.run(main())
