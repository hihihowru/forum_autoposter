#!/usr/bin/env python3
"""
å®šæ™‚ç™¼æ–‡ç³»çµ± - å¾å‚™ä»½æ–‡ä»¶è®€å–å¯¦éš›è²¼æ–‡æ•¸æ“š
"""
import asyncio
import logging
import json
import glob
import os
from datetime import datetime
from typing import List, Dict, Any
from src.core.main_workflow_engine import MainWorkflowEngine

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ScheduledPublisher:
    """å®šæ™‚ç™¼æ–‡å™¨"""
    
    def __init__(self):
        self.workflow_engine = MainWorkflowEngine()
        self.published_count = 0
        self.target_count = 4  # å…ˆç™¼å››ç¯‡
        self.available_posts = []
        self.current_post_index = 0
        
    def load_posts_from_backup(self):
        """å¾å‚™ä»½æ–‡ä»¶è¼‰å…¥è²¼æ–‡"""
        try:
            backup_files = glob.glob("data/backup/post_record_*.json")
            backup_files.sort()
            
            logger.info(f"ğŸ“ æ‰¾åˆ° {len(backup_files)} å€‹å‚™ä»½æ–‡ä»¶")
            
            for file_path in backup_files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚º ready_to_post ç‹€æ…‹
                    if data.get('status') == 'ready_to_post':
                        post = {
                            'post_id': data.get('post_id'),
                            'kol_serial': data.get('kol_serial'),
                            'kol_nickname': data.get('kol_nickname'),
                            'title': data.get('title'),
                            'content': data.get('content'),
                            'stock_id': data.get('stock_id'),
                            'stock_name': data.get('stock_name'),
                            'analysis_type': data.get('analysis_type'),
                            'file_path': file_path
                        }
                        self.available_posts.append(post)
                        
                except Exception as e:
                    logger.error(f"âŒ è®€å–æ–‡ä»¶ {file_path} å¤±æ•—: {e}")
            
            logger.info(f"ğŸ“‹ è¼‰å…¥ {len(self.available_posts)} ç¯‡å¾…ç™¼æ–‡è²¼æ–‡")
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥å‚™ä»½æ–‡ä»¶å¤±æ•—: {e}")
    
    async def publish_posts(self, posts_per_batch: int = 2):
        """ç™¼æ–‡æ‰¹æ¬¡"""
        try:
            logger.info(f"ğŸš€ é–‹å§‹ç¬¬ {(self.published_count // 2) + 1} æ‰¹æ¬¡ç™¼æ–‡...")
            
            # ç²å–å¾…ç™¼æ–‡çš„è²¼æ–‡
            posts_to_publish = []
            for i in range(posts_per_batch):
                if self.current_post_index < len(self.available_posts):
                    posts_to_publish.append(self.available_posts[self.current_post_index])
                    self.current_post_index += 1
            
            if not posts_to_publish:
                logger.warning("âš ï¸ æ²’æœ‰æ›´å¤šå¾…ç™¼æ–‡çš„è²¼æ–‡")
                return False
            
            # ç™¼æ–‡
            for post in posts_to_publish:
                success = await self.publish_single_post(post)
                if success:
                    self.published_count += 1
                    logger.info(f"âœ… ç¬¬ {self.published_count} ç¯‡ç™¼æ–‡æˆåŠŸ: {post['post_id']}")
                else:
                    logger.error(f"âŒ ç™¼æ–‡å¤±æ•—: {post['post_id']}")
            
            logger.info(f"ğŸ“Š æœ¬æ‰¹æ¬¡å®Œæˆï¼Œå·²ç™¼æ–‡ {self.published_count}/{self.target_count} ç¯‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹æ¬¡ç™¼æ–‡å¤±æ•—: {e}")
            return False
    
    async def publish_single_post(self, post: Dict[str, Any]) -> bool:
        """ç™¼æ–‡å–®ç¯‡è²¼æ–‡"""
        try:
            logger.info(f"ğŸ“ æº–å‚™ç™¼æ–‡: {post['title'][:30]}...")
            logger.info(f"ğŸ¯ KOL: {post['kol_nickname']}")
            logger.info(f"ğŸ“ˆ è‚¡ç¥¨: {post['stock_name']}({post['stock_id']})")
            logger.info(f"ğŸ“Š åˆ†æé¡å‹: {post['analysis_type']}")
            
            # æ¨¡æ“¬ç™¼æ–‡éç¨‹
            await asyncio.sleep(2)  # æ¨¡æ“¬ç™¼æ–‡æ™‚é–“
            
            # æ›´æ–°ç™¼æ–‡ç‹€æ…‹
            await self.update_post_status(post['post_id'], 'published')
            
            logger.info(f"âœ… ç™¼æ–‡æˆåŠŸ: {post['post_id']}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç™¼æ–‡å¤±æ•—: {e}")
            return False
    
    async def update_post_status(self, post_id: str, status: str):
        """æ›´æ–°è²¼æ–‡ç‹€æ…‹"""
        try:
            # é€™è£¡æ‡‰è©²èª¿ç”¨ Google Sheets API æ›´æ–°ç‹€æ…‹
            logger.info(f"ğŸ“‹ æ›´æ–°è²¼æ–‡ç‹€æ…‹: {post_id} -> {status}")
            
            # ä¿å­˜ç™¼æ–‡è¨˜éŒ„
            await self.save_publishing_record(post_id, status)
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç‹€æ…‹å¤±æ•—: {e}")
    
    async def save_publishing_record(self, post_id: str, status: str):
        """ä¿å­˜ç™¼æ–‡è¨˜éŒ„"""
        try:
            record = {
                'post_id': post_id,
                'publish_time': datetime.now().isoformat(),
                'status': status,
                'publisher': 'scheduled_publisher'
            }
            
            # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
            os.makedirs('data/publishing_records', exist_ok=True)
            filename = f"publishing_record_{post_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = os.path.join('data/publishing_records', filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(record, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ ç™¼æ–‡è¨˜éŒ„å·²ä¿å­˜: {filepath}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç™¼æ–‡è¨˜éŒ„å¤±æ•—: {e}")
    
    async def run_scheduled_publishing(self, interval_minutes: int = 1):
        """é‹è¡Œå®šæ™‚ç™¼æ–‡"""
        try:
            # è¼‰å…¥è²¼æ–‡æ•¸æ“š
            self.load_posts_from_backup()
            
            if not self.available_posts:
                logger.error("âŒ æ²’æœ‰å¯ç™¼æ–‡çš„è²¼æ–‡")
                return
            
            logger.info(f"â° é–‹å§‹å®šæ™‚ç™¼æ–‡ç³»çµ±")
            logger.info(f"ğŸ“Š ç›®æ¨™ç™¼æ–‡æ•¸: {self.target_count}")
            logger.info(f"ğŸ“‹ å¯ç”¨è²¼æ–‡æ•¸: {len(self.available_posts)}")
            logger.info(f"â±ï¸ ç™¼æ–‡é–“éš”: {interval_minutes} åˆ†é˜")
            logger.info(f"ğŸ“¦ æ¯æ‰¹æ¬¡: 2 ç¯‡")
            
            while self.published_count < self.target_count:
                current_time = datetime.now()
                logger.info(f"ğŸ• ç•¶å‰æ™‚é–“: {current_time.strftime('%H:%M:%S')}")
                
                # ç™¼æ–‡
                success = await self.publish_posts(2)
                
                if not success:
                    logger.warning("âš ï¸ æœ¬æ‰¹æ¬¡ç™¼æ–‡å¤±æ•—ï¼Œç­‰å¾…ä¸‹æ¬¡å˜—è©¦")
                
                # æª¢æŸ¥æ˜¯å¦å®Œæˆ
                if self.published_count >= self.target_count:
                    logger.info(f"ğŸ‰ å®Œæˆæ‰€æœ‰ç™¼æ–‡ç›®æ¨™ï¼å…±ç™¼æ–‡ {self.published_count} ç¯‡")
                    break
                
                # æª¢æŸ¥æ˜¯å¦é‚„æœ‰è²¼æ–‡å¯ç™¼
                if self.current_post_index >= len(self.available_posts):
                    logger.warning("âš ï¸ æ²’æœ‰æ›´å¤šè²¼æ–‡å¯ç™¼")
                    break
                
                # ç­‰å¾…ä¸‹ä¸€æ‰¹æ¬¡
                if self.published_count < self.target_count:
                    logger.info(f"â³ ç­‰å¾… {interval_minutes} åˆ†é˜å¾Œé€²è¡Œä¸‹ä¸€æ‰¹æ¬¡...")
                    await asyncio.sleep(interval_minutes * 60)
            
            logger.info("âœ… å®šæ™‚ç™¼æ–‡ç³»çµ±å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å®šæ™‚ç™¼æ–‡ç³»çµ±å¤±æ•—: {e}")

async def main():
    """ä¸»å‡½æ•¸"""
    try:
        publisher = ScheduledPublisher()
        await publisher.run_scheduled_publishing(interval_minutes=1)
        
    except Exception as e:
        logger.error(f"âŒ ä¸»ç¨‹åºå¤±æ•—: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())











