#!/usr/bin/env python3
"""
FinLab æ•¸æ“šç·©å­˜ç®¡ç†å™¨
å¯¦ç¾æ•¸æ“šç·©å­˜æ©Ÿåˆ¶ï¼Œé™ä½ API èª¿ç”¨æ¬¡æ•¸
"""

import os
import asyncio
import logging
import json
from typing import Dict, List, Any, Optional
from datetime import datetime, date
from pathlib import Path
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FinLabDataCache:
    """FinLab æ•¸æ“šç·©å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.api_key = os.getenv('FINLAB_API_KEY')
        if not self.api_key:
            raise ValueError("ç¼ºå°‘ FINLAB_API_KEY ç’°å¢ƒè®Šæ•¸")
        
        # ç·©å­˜ç›®éŒ„
        self.cache_dir = Path("./cache/finlab_data")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ç·©å­˜æ•¸æ“š
        self.cache_data = {}
        self.cache_date = None
        
        # æ•¸æ“šè¡¨é…ç½®
        self.data_tables = {
            'price': {
                'open': 'price:é–‹ç›¤åƒ¹',
                'high': 'price:æœ€é«˜åƒ¹',
                'low': 'price:æœ€ä½åƒ¹',
                'close': 'price:æ”¶ç›¤åƒ¹',
                'volume': 'price:æˆäº¤è‚¡æ•¸',
                'amount': 'price:æˆäº¤é‡‘é¡'
            },
            'revenue': {
                'current_month': 'monthly_revenue:ç•¶æœˆç‡Ÿæ”¶',
                'previous_month': 'monthly_revenue:ä¸Šæœˆç‡Ÿæ”¶',
                'last_year_same_month': 'monthly_revenue:å»å¹´ç•¶æœˆç‡Ÿæ”¶',
                'mom_change_pct': 'monthly_revenue:ä¸Šæœˆæ¯”è¼ƒå¢æ¸›(%)',
                'yoy_change_pct': 'monthly_revenue:å»å¹´åŒæœˆå¢æ¸›(%)',
                'ytd_revenue': 'monthly_revenue:ç•¶æœˆç´¯è¨ˆç‡Ÿæ”¶',
                'last_year_ytd': 'monthly_revenue:å»å¹´ç´¯è¨ˆç‡Ÿæ”¶',
                'ytd_change_pct': 'monthly_revenue:å‰æœŸæ¯”è¼ƒå¢æ¸›(%)'
            },
            'earnings': {
                'eps': 'fundamental_features:æ¯è‚¡ç¨…å¾Œæ·¨åˆ©',
                'revenue_growth': 'fundamental_features:ç‡Ÿæ”¶æˆé•·ç‡',
                'profit_growth': 'fundamental_features:ç¨…å¾Œæ·¨åˆ©æˆé•·ç‡',
                'operating_profit': 'fundamental_features:ç‡Ÿæ¥­åˆ©ç›Š',
                'net_profit': 'fundamental_features:æ­¸å±¬æ¯å…¬å¸æ·¨åˆ©',
                'gross_margin': 'fundamental_features:ç‡Ÿæ¥­æ¯›åˆ©ç‡',
                'net_margin': 'fundamental_features:ç¨…å¾Œæ·¨åˆ©ç‡'
            }
        }
        
        logger.info("FinLab æ•¸æ“šç·©å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _get_cache_file_path(self, data_type: str) -> Path:
        """ç²å–ç·©å­˜æ–‡ä»¶è·¯å¾‘"""
        today = date.today().strftime('%Y%m%d')
        return self.cache_dir / f"{data_type}_{today}.json"
    
    def _is_cache_valid(self, data_type: str) -> bool:
        """æª¢æŸ¥ç·©å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆç•¶æ—¥æœ‰æ•ˆï¼‰"""
        cache_file = self._get_cache_file_path(data_type)
        if not cache_file.exists():
            return False
        
        # æª¢æŸ¥æ–‡ä»¶ä¿®æ”¹æ™‚é–“æ˜¯å¦ç‚ºä»Šå¤©
        file_mtime = datetime.fromtimestamp(cache_file.stat().st_mtime)
        return file_mtime.date() == date.today()
    
    def _load_cache(self, data_type: str) -> Optional[Dict[str, Any]]:
        """è¼‰å…¥ç·©å­˜æ•¸æ“š"""
        try:
            cache_file = self._get_cache_file_path(data_type)
            if cache_file.exists():
                with open(cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    logger.info(f"âœ… è¼‰å…¥ {data_type} ç·©å­˜æ•¸æ“šï¼ŒåŒ…å« {len(data)} å€‹æ•¸æ“šè¡¨")
                    return data
        except Exception as e:
            logger.error(f"è¼‰å…¥ {data_type} ç·©å­˜å¤±æ•—: {e}")
        
        return None
    
    def _save_cache(self, data_type: str, data: Dict[str, Any]):
        """ä¿å­˜ç·©å­˜æ•¸æ“š"""
        try:
            cache_file = self._get_cache_file_path(data_type)
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… ä¿å­˜ {data_type} ç·©å­˜æ•¸æ“šåˆ° {cache_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜ {data_type} ç·©å­˜å¤±æ•—: {e}")
    
    async def fetch_and_cache_data(self, data_type: str) -> Dict[str, Any]:
        """ç²å–ä¸¦ç·©å­˜æ•¸æ“š"""
        # æª¢æŸ¥ç·©å­˜æ˜¯å¦æœ‰æ•ˆ
        if self._is_cache_valid(data_type):
            cached_data = self._load_cache(data_type)
            if cached_data:
                return cached_data
        
        # ç·©å­˜ç„¡æ•ˆï¼Œé‡æ–°ç²å–æ•¸æ“š
        logger.info(f"ğŸ”„ é‡æ–°ç²å– {data_type} æ•¸æ“š...")
        
        try:
            import finlab
            from finlab import data
            
            # ç™»å…¥
            finlab.login(self.api_key)
            
            # ç²å–æ•¸æ“š
            fetched_data = {}
            tables = self.data_tables.get(data_type, {})
            
            for table_name, table_key in tables.items():
                try:
                    data_source = data.get(table_key)
                    if data_source is not None:
                        # è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„æ ¼å¼
                        serializable_data = {}
                        for stock_id in data_source.columns:
                            stock_data = data_source[stock_id].dropna()
                            if len(stock_data) > 0:
                                # åªä¿å­˜æœ€æ–°çš„å¹¾å€‹æ•¸æ“šé»
                                latest_data = stock_data.tail(5)
                                serializable_data[stock_id] = {
                                    'values': latest_data.tolist(),
                                    'dates': [str(d) for d in latest_data.index],
                                    'latest_value': float(latest_data.iloc[-1]),
                                    'latest_date': str(latest_data.index[-1])
                                }
                        
                        fetched_data[table_name] = {
                            'table_key': table_key,
                            'data': serializable_data,
                            'total_stocks': len(serializable_data),
                            'fetch_time': datetime.now().isoformat()
                        }
                        
                        logger.info(f"âœ… ç²å– {table_name}: {len(serializable_data)} éš»è‚¡ç¥¨")
                    else:
                        logger.warning(f"âš ï¸ ç„¡æ³•ç²å– {table_name} æ•¸æ“š")
                        
                except Exception as e:
                    logger.error(f"ç²å– {table_name} å¤±æ•—: {e}")
            
            # ä¿å­˜ç·©å­˜
            self._save_cache(data_type, fetched_data)
            
            return fetched_data
            
        except Exception as e:
            logger.error(f"ç²å– {data_type} æ•¸æ“šå¤±æ•—: {e}")
            return {}
    
    async def get_stock_ohlc_data(self, stock_id: str, stock_name: str) -> Optional[Dict[str, Any]]:
        """ç²å–è‚¡ç¥¨ OHLC æ•¸æ“š"""
        try:
            # ç²å–åƒ¹æ ¼æ•¸æ“š
            price_data = await self.fetch_and_cache_data('price')
            
            if not price_data or 'close' not in price_data:
                logger.warning(f"âš ï¸ ç„¡æ³•ç²å– {stock_name} åƒ¹æ ¼æ•¸æ“š")
                return None
            
            close_data = price_data['close']['data']
            if stock_id not in close_data:
                logger.warning(f"âš ï¸ è‚¡ç¥¨ {stock_id} ä¸åœ¨åƒ¹æ ¼æ•¸æ“šä¸­")
                return None
            
            # ç²å– OHLC æ•¸æ“š
            stock_close = close_data[stock_id]
            latest_date = stock_close['latest_date']
            
            # å¾ç·©å­˜ä¸­ç²å–å…¶ä»–åƒ¹æ ¼æ•¸æ“š
            open_data = price_data.get('open', {}).get('data', {}).get(stock_id, {})
            high_data = price_data.get('high', {}).get('data', {}).get(stock_id, {})
            low_data = price_data.get('low', {}).get('data', {}).get(stock_id, {})
            volume_data = price_data.get('volume', {}).get('data', {}).get(stock_id, {})
            
            # æ§‹å»º OHLC æ•¸æ“š
            ohlc_data = {
                'date': latest_date,
                'close': stock_close['latest_value'],
                'open': open_data.get('latest_value', stock_close['latest_value']),
                'high': high_data.get('latest_value', stock_close['latest_value']),
                'low': low_data.get('latest_value', stock_close['latest_value']),
                'volume': volume_data.get('latest_value', 0),
                'daily_change': 0.0,
                'daily_change_pct': 0.0
            }
            
            # è¨ˆç®—æ¼²è·Œå¹…
            if ohlc_data['open'] > 0:
                ohlc_data['daily_change'] = ohlc_data['close'] - ohlc_data['open']
                ohlc_data['daily_change_pct'] = (ohlc_data['daily_change'] / ohlc_data['open']) * 100
            
            logger.info(f"âœ… ç²å–åˆ° {stock_name} OHLC æ•¸æ“š")
            return ohlc_data
            
        except Exception as e:
            logger.error(f"ç²å– {stock_name} OHLC æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    async def get_stock_revenue_data(self, stock_id: str, stock_name: str) -> Optional[Dict[str, Any]]:
        """ç²å–è‚¡ç¥¨ç‡Ÿæ”¶æ•¸æ“š"""
        try:
            # ç²å–ç‡Ÿæ”¶æ•¸æ“š
            revenue_data = await self.fetch_and_cache_data('revenue')
            
            if not revenue_data or 'current_month' not in revenue_data:
                logger.warning(f"âš ï¸ ç„¡æ³•ç²å– {stock_name} ç‡Ÿæ”¶æ•¸æ“š")
                return None
            
            current_month_data = revenue_data['current_month']['data']
            if stock_id not in current_month_data:
                logger.warning(f"âš ï¸ è‚¡ç¥¨ {stock_id} ä¸åœ¨ç‡Ÿæ”¶æ•¸æ“šä¸­")
                return None
            
            # ç²å–ç‡Ÿæ”¶ç›¸é—œæ•¸æ“š
            stock_revenue = current_month_data[stock_id]
            latest_date = stock_revenue['latest_date']
            latest_revenue = stock_revenue['latest_value']
            
            # å¾ç·©å­˜ä¸­ç²å–å¢é•·ç‡æ•¸æ“š
            mom_data = revenue_data.get('mom_change_pct', {}).get('data', {}).get(stock_id, {})
            yoy_data = revenue_data.get('yoy_change_pct', {}).get('data', {}).get(stock_id, {})
            
            revenue_result = {
                'revenue': latest_revenue,
                'yoy_growth': yoy_data.get('latest_value', 0.0),
                'mom_growth': mom_data.get('latest_value', 0.0),
                'period': latest_date[:7],  # å– YYYY-MM
                'date': latest_date
            }
            
            logger.info(f"âœ… ç²å–åˆ° {stock_name} ç‡Ÿæ”¶æ•¸æ“š")
            return revenue_result
            
        except Exception as e:
            logger.error(f"ç²å– {stock_name} ç‡Ÿæ”¶æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    async def get_stock_earnings_data(self, stock_id: str, stock_name: str) -> Optional[Dict[str, Any]]:
        """ç²å–è‚¡ç¥¨è²¡å ±æ•¸æ“š"""
        try:
            # ç²å–è²¡å ±æ•¸æ“š
            earnings_data = await self.fetch_and_cache_data('earnings')
            
            if not earnings_data or 'eps' not in earnings_data:
                logger.warning(f"âš ï¸ ç„¡æ³•ç²å– {stock_name} è²¡å ±æ•¸æ“š")
                return None
            
            eps_data = earnings_data['eps']['data']
            if stock_id not in eps_data:
                logger.warning(f"âš ï¸ è‚¡ç¥¨ {stock_id} ä¸åœ¨è²¡å ±æ•¸æ“šä¸­")
                return None
            
            # ç²å– EPS æ•¸æ“š
            stock_eps = eps_data[stock_id]
            latest_date = stock_eps['latest_date']
            latest_eps = stock_eps['latest_value']
            
            # å¾ç·©å­˜ä¸­ç²å–å…¶ä»–è²¡å ±æ•¸æ“š
            revenue_growth_data = earnings_data.get('revenue_growth', {}).get('data', {}).get(stock_id, {})
            profit_growth_data = earnings_data.get('profit_growth', {}).get('data', {}).get(stock_id, {})
            gross_margin_data = earnings_data.get('gross_margin', {}).get('data', {}).get(stock_id, {})
            net_margin_data = earnings_data.get('net_margin', {}).get('data', {}).get(stock_id, {})
            
            earnings_result = {
                'eps': latest_eps,
                'period': latest_date,
                'date': latest_date,
                'revenue_growth': revenue_growth_data.get('latest_value', 0.0),
                'profit_growth': profit_growth_data.get('latest_value', 0.0),
                'gross_margin': gross_margin_data.get('latest_value', 0.0),
                'net_margin': net_margin_data.get('latest_value', 0.0)
            }
            
            logger.info(f"âœ… ç²å–åˆ° {stock_name} è²¡å ±æ•¸æ“š")
            return earnings_result
            
        except Exception as e:
            logger.error(f"ç²å– {stock_name} è²¡å ±æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def get_cache_status(self) -> Dict[str, Any]:
        """ç²å–ç·©å­˜ç‹€æ…‹"""
        status = {}
        
        for data_type in self.data_tables.keys():
            cache_file = self._get_cache_file_path(data_type)
            is_valid = self._is_cache_valid(data_type)
            
            status[data_type] = {
                'cache_exists': cache_file.exists(),
                'is_valid': is_valid,
                'cache_file': str(cache_file),
                'last_modified': None
            }
            
            if cache_file.exists():
                mtime = datetime.fromtimestamp(cache_file.stat().st_mtime)
                status[data_type]['last_modified'] = mtime.isoformat()
        
        return status

async def test_finlab_cache():
    """æ¸¬è©¦ FinLab ç·©å­˜åŠŸèƒ½"""
    print("ğŸ§ª FinLab æ•¸æ“šç·©å­˜æ¸¬è©¦")
    print("=" * 60)
    
    try:
        cache_manager = FinLabDataCache()
        
        # æ¸¬è©¦è‚¡ç¥¨
        test_stocks = [
            ('6732', 'æ˜‡ä½³é›»å­'),
            ('4968', 'ç«‹ç©'),
            ('3491', 'æ˜‡é”ç§‘æŠ€')
        ]
        
        print("\nğŸ“Š æ¸¬è©¦ OHLC æ•¸æ“šç²å–:")
        for stock_id, stock_name in test_stocks:
            ohlc_data = await cache_manager.get_stock_ohlc_data(stock_id, stock_name)
            if ohlc_data:
                print(f"âœ… {stock_name}: æ”¶ç›¤åƒ¹ {ohlc_data['close']:.2f}, æ¼²è·Œå¹… {ohlc_data['daily_change_pct']:.2f}%")
            else:
                print(f"âŒ {stock_name}: ç²å–å¤±æ•—")
        
        print("\nğŸ’° æ¸¬è©¦ç‡Ÿæ”¶æ•¸æ“šç²å–:")
        for stock_id, stock_name in test_stocks:
            revenue_data = await cache_manager.get_stock_revenue_data(stock_id, stock_name)
            if revenue_data:
                print(f"âœ… {stock_name}: ç‡Ÿæ”¶ {revenue_data['revenue']:,.0f}, å¹´å¢ç‡ {revenue_data['yoy_growth']:.2f}%")
            else:
                print(f"âŒ {stock_name}: ç²å–å¤±æ•—")
        
        print("\nğŸ“ˆ æ¸¬è©¦è²¡å ±æ•¸æ“šç²å–:")
        for stock_id, stock_name in test_stocks:
            earnings_data = await cache_manager.get_stock_earnings_data(stock_id, stock_name)
            if earnings_data:
                print(f"âœ… {stock_name}: EPS {earnings_data['eps']:.2f}, æœŸé–“ {earnings_data['period']}")
            else:
                print(f"âŒ {stock_name}: ç²å–å¤±æ•—")
        
        print("\nğŸ“‹ ç·©å­˜ç‹€æ…‹:")
        cache_status = cache_manager.get_cache_status()
        for data_type, status in cache_status.items():
            print(f"   {data_type}: {'âœ… æœ‰æ•ˆ' if status['is_valid'] else 'âŒ ç„¡æ•ˆ'}")
        
        print("\nğŸ‰ ç·©å­˜æ¸¬è©¦å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ç·©å­˜æ¸¬è©¦å¤±æ•—: {e}")

if __name__ == "__main__":
    asyncio.run(test_finlab_cache())
