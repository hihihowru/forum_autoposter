import os
import requests
import json
from fastapi import FastAPI, BackgroundTasks, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncio
import sys
import json
from dotenv import load_dotenv
import logging

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

print("ğŸš€ é–‹å§‹è¼‰å…¥æ¨¡çµ„...")

# å°å…¥æ”¹é€²çš„å…§å®¹ç”Ÿæˆå™¨
from improved_content_generator import generate_improved_kol_content
# å°å…¥GPTå…§å®¹ç”Ÿæˆå™¨
from gpt_content_generator import gpt_generator

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
print("ğŸ“ è¼‰å…¥ç’°å¢ƒè®Šæ•¸...")
load_dotenv(os.path.join(os.path.dirname(__file__), '../../../../.env'))
print("âœ… ç’°å¢ƒè®Šæ•¸è¼‰å…¥å®Œæˆ")

# ä½¿ç”¨PostgreSQLæœå‹™
print("ğŸ“¦ å°å…¥PostgreSQLæœå‹™...")
from postgresql_service import PostgreSQLPostRecordService
# å°å…¥æ•¸æ“šæ¨¡å‹ (CommodityTag å°‡åœ¨éœ€è¦æ™‚å‹•æ…‹å°å…¥)
try:
    from post_record_service import CommunityTopic, GenerationParams, PostRecordCreate, PostRecordUpdate
    print("âœ… æ ¸å¿ƒæ•¸æ“šæ¨¡å‹å°å…¥å®Œæˆ")
except ImportError as e:
    print(f"âŒ æ•¸æ“šæ¨¡å‹å°å…¥å¤±æ•—: {e}")
print("âœ… PostgreSQLæœå‹™å°å…¥å®Œæˆ")

print("ğŸ—ï¸ å‰µå»ºFastAPIæ‡‰ç”¨...")
app = FastAPI(title="Posting Service", description="è™›æ“¬KOLè‡ªå‹•ç™¼æ–‡æœå‹™")
print("âœ… FastAPIæ‡‰ç”¨å‰µå»ºå®Œæˆ")

# æ·»åŠ  CORS ä¸­é–“ä»¶
print("ğŸŒ æ·»åŠ CORSä¸­é–“ä»¶...")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒæ‡‰è©²é™åˆ¶ç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
print("âœ… CORSä¸­é–“ä»¶æ·»åŠ å®Œæˆ")

# åŒ…å«è·¯ç”±æ¨¡çµ„
print("ğŸ›£ï¸ è¼‰å…¥è·¯ç”±æ¨¡çµ„...")
from routes import main_router
app.include_router(main_router)
print("âœ… è·¯ç”±æ¨¡çµ„è¼‰å…¥å®Œæˆ")

# API ç«¯é»é…ç½®
print("âš™ï¸ é…ç½®APIç«¯é»...")
TRENDING_API_URL = os.getenv("TRENDING_API_URL", "http://localhost:8004")
SUMMARY_API_URL = os.getenv("SUMMARY_API_URL", "http://summary-api:8003")
OHLC_API_URL = os.getenv("OHLC_API_URL", "http://ohlc-api:8001")
print("âœ… APIç«¯é»é…ç½®å®Œæˆ")

# åˆå§‹åŒ–PostgreSQLæ•¸æ“šåº«æœå‹™
print("ğŸ’¾ æº–å‚™PostgreSQLæ•¸æ“šåº«æœå‹™...")
# å»¶é²åˆå§‹åŒ–ï¼Œé¿å…å•Ÿå‹•æ™‚é€£æ¥æ•¸æ“šåº«
post_record_service = None

def get_post_record_service():
    """ç²å–PostgreSQLæœå‹™å¯¦ä¾‹ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰"""
    global post_record_service
    if post_record_service is None:
        print("ğŸ’¾ åˆå§‹åŒ–PostgreSQLæ•¸æ“šåº«æœå‹™...")
        post_record_service = PostgreSQLPostRecordService()
        print("âœ… PostgreSQLæ•¸æ“šåº«æœå‹™åˆå§‹åŒ–å®Œæˆ")
    return post_record_service

class PostingRequest(BaseModel):
    stock_code: Optional[str] = None
    stock_name: Optional[str] = None
    kol_serial: Optional[str] = None
    kol_persona: str = "technical"
    content_style: str = "chart_analysis"
    target_audience: str = "active_traders"
    auto_post: bool = True
    post_to_thread: Optional[str] = None
    batch_mode: bool = False
    session_id: Optional[int] = None
    # å…§å®¹é•·åº¦è¨­å®š
    content_length: str = "medium"
    max_words: int = 1000
    # æ–°å¢æ•¸æ“šæºç›¸é—œæ¬„ä½
    data_sources: Optional[Dict[str, Any]] = None
    # æ–°èæ™‚é–“ç¯„åœè¨­å®š
    news_time_range: Optional[str] = "d2"
    explainability_config: Optional[Dict[str, Any]] = None
    news_config: Optional[Dict[str, Any]] = None
    # æ¨™ç±¤é…ç½®
    tags_config: Optional[Dict[str, Any]] = None
    # å…±äº« commodity tags (ç”¨æ–¼æ‰¹é‡ç”Ÿæˆ)
    shared_commodity_tags: Optional[List[Dict[str, Any]]] = None
    # ç†±é–€è©±é¡Œç›¸é—œæ¬„ä½
    topic_id: Optional[str] = None
    topic_title: Optional[str] = None

class PostingResult(BaseModel):
    success: bool
    post_id: Optional[str] = None
    content: Optional[Dict] = None
    error: Optional[str] = None
    timestamp: datetime

class BatchPostRequest(BaseModel):
    session_id: int
    posts: List[Dict[str, Any]]
    batch_config: Dict[str, Any]
    data_sources: Optional[Dict[str, Any]] = None
    explainability_config: Optional[Dict[str, Any]] = None
    news_config: Optional[Dict[str, Any]] = None
    tags_config: Optional[Dict[str, Any]] = None  # æ–°å¢ï¼šæ¨™ç±¤é…ç½®

class BatchPostResponse(BaseModel):
    success: bool
    post_id: Optional[str] = None
    content: Optional[Dict] = None
    error: Optional[str] = None
    timestamp: str
    progress: Optional[Dict[str, Any]] = None

class AutoPostingConfig(BaseModel):
    enabled: bool = True
    interval_minutes: int = 60
    max_posts_per_day: int = 10
    kol_personas: List[str] = ["technical", "fundamental", "news_driven"]

@app.post("/post/auto", response_model=PostingResult)
async def auto_post_content(background_tasks: BackgroundTasks, config: AutoPostingConfig):
    """è‡ªå‹•ç™¼æ–‡ - æ ¹æ“šç†±é–€è©±é¡Œè‡ªå‹•ç”Ÿæˆå…§å®¹ä¸¦ç™¼æ–‡"""
    
    try:
        # 1. ç²å–ç†±é–€è©±é¡Œ
        trending_response = requests.get(f"{TRENDING_API_URL}/trending", params={"limit": 5})
        trending_response.raise_for_status()
        trending_topics = trending_response.json()
        
        if not trending_topics.get("topics"):
            return PostingResult(
                success=False,
                error="æ²’æœ‰æ‰¾åˆ°ç†±é–€è©±é¡Œ",
                timestamp=datetime.now()
            )
        
        # 2. é¸æ“‡ç¬¬ä¸€å€‹ç†±é–€è©±é¡Œ
        topic = trending_topics["topics"][0]
        stock_id = topic["stock_ids"][0] if topic["stock_ids"] else "2330"
        
        # 3. ç²å–ç›¸é—œæ–°èç´ æ
        news_response = requests.get(f"{TRENDING_API_URL}/news/stock/{stock_id}", params={"limit": 3})
        news_items = []
        if news_response.status_code == 200:
            news_items = news_response.json().get("news", [])
        
        # 4. ç”ŸæˆKOLå…§å®¹
        content_request = {
            "stock_id": stock_id,
            "kol_persona": config.kol_personas[0],
            "content_style": "chart_analysis",
            "target_audience": "active_traders"
        }
        
        summary_response = requests.post(f"{SUMMARY_API_URL}/generate-kol-content", json=content_request)
        summary_response.raise_for_status()
        kol_content = summary_response.json()
        
        # 5. æ•´åˆæ–°èç´ æåˆ°å…§å®¹ä¸­
        enhanced_content = enhance_content_with_news(kol_content, topic, news_items)
        
        # 6. ç™¼æ–‡åˆ°æŒ‡å®šå¹³å°
        if config.enabled:
            background_tasks.add_task(post_to_platform, enhanced_content, topic)
        
        return PostingResult(
            success=True,
            post_id=f"post_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            content=enhanced_content,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        return PostingResult(
            success=False,
            error=str(e),
            timestamp=datetime.now()
        )

@app.post("/post/simple")
async def simple_post_content(request: PostingRequest):
    """ç°¡åŒ–ç‰ˆè²¼æ–‡ç”Ÿæˆï¼Œè·³éè¤‡é›œé‚è¼¯ç›´æ¥å­˜å…¥æ•¸æ“šåº«"""
    try:
        print(f"ğŸš€ ç°¡åŒ–æ¨¡å¼ï¼šé–‹å§‹ç”Ÿæˆè²¼æ–‡")
        
        # åŸºæœ¬åƒæ•¸
        stock_id = request.stock_code or "2330"
        stock_name = request.stock_name or "å°ç©é›»"
        kol_serial = int(request.kol_serial) if request.kol_serial else 200
        session_id = request.session_id or 1  # ä½¿ç”¨ç°¡å–®æ•¸å­— 1, 2, 3...
        
        # å‰µå»ºç°¡å–®å…§å®¹
        simple_content = {
            "title": f"{stock_name}({stock_id}) - æŠ€è¡“åˆ†æ",
            "content": f"ä»Šæ—¥{stock_name}è¡¨ç¾å¦‚ä½•ï¼Ÿè®“æˆ‘å€‘ä¾†çœ‹çœ‹æŠ€è¡“é¢çš„ç‹€æ³...",
            "stock_code": stock_id,
            "stock_name": stock_name,
            "kol_serial": kol_serial,
            "session_id": session_id,
            "post_id": f"simple_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "status": "pending_review",
            "created_at": datetime.now().isoformat()
        }
        
        # å˜—è©¦ä¿å­˜åˆ°æ•¸æ“šåº«ï¼ˆä¸ä½¿ç”¨ CommodityTagï¼‰
        try:
            from postgresql_service import PostgreSQLPostRecordService
            post_service = PostgreSQLPostRecordService()
            
            # ç²å– KOL æš±ç¨±
            kol_nickname = f"KOL-{kol_serial}"  # é»˜èªåç¨±
            try:
                from kol_service import kol_service
                kol_data = kol_service.get_kol_by_serial(kol_serial)
                if kol_data and 'nickname' in kol_data:
                    kol_nickname = kol_data['nickname']
            except Exception as kol_error:
                print(f"âš ï¸ ç²å– KOL ä¿¡æ¯å¤±æ•—ï¼Œä½¿ç”¨é»˜èªåç¨±: {kol_error}")
            
            # å‰µå»ºç°¡åŒ–çš„è²¼æ–‡è¨˜éŒ„ï¼Œä¸åŒ…å« commodity_tags
            post_record = post_service.create_post_record_simple(
                stock_code=stock_id,
                stock_name=stock_name,
                kol_serial=str(kol_serial),
                kol_nickname=kol_nickname,
                session_id=session_id
            )
            
            simple_content["database_saved"] = True
            simple_content["database_post_id"] = post_record.post_id if post_record else None
            print(f"âœ… ç°¡åŒ–è²¼æ–‡å·²ä¿å­˜åˆ°æ•¸æ“šåº«: {simple_content['database_post_id']}")
            
        except Exception as db_error:
            print(f"âš ï¸ æ•¸æ“šåº«ä¿å­˜å¤±æ•—ï¼Œä½†å…§å®¹ç”ŸæˆæˆåŠŸ: {db_error}")
            simple_content["database_saved"] = False
            simple_content["database_error"] = str(db_error)
        
        print(f"âœ… ç°¡åŒ–è²¼æ–‡ç”Ÿæˆå®Œæˆ")
        
        return {
            "success": True,
            "post_id": simple_content["post_id"],
            "content": simple_content,
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        import traceback
        print(f"âŒ ç°¡åŒ–æ¨¡å¼éŒ¯èª¤: {e}")
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now()
        }

@app.post("/post/manual", response_model=PostingResult)
async def manual_post_content(request: PostingRequest):
    """æ‰‹å‹•ç™¼æ–‡ - æŒ‡å®šè‚¡ç¥¨å’ŒKOLé¢¨æ ¼"""
    
    print(f"ğŸš€ é–‹å§‹æ‰‹å‹•ç™¼æ–‡ç”Ÿæˆ - è«‹æ±‚åƒæ•¸: {request}")
    print(f"ğŸ“ å…§å®¹é•·åº¦è¨­å®š: content_length={request.content_length}, max_words={request.max_words}")
    
    # æ·»åŠ èª¿è©¦ä¿¡æ¯
    print(f"ğŸ” å¾Œç«¯èª¿è©¦ - æ¥æ”¶åˆ°çš„åƒæ•¸:")
    print(f"  - tags_config: {request.tags_config}")
    print(f"  - topic_tags: {request.tags_config.get('topic_tags', {}) if request.tags_config else {}}")
    print(f"  - mixed_mode: {request.tags_config.get('topic_tags', {}).get('mixed_mode', False) if request.tags_config else False}")
    print(f"  - topic_id: {request.topic_id}")
    print(f"  - topic_title: {request.topic_title}")
    
    try:
        # å¦‚æœå‰ç«¯æŒ‡å®šäº†è‚¡ç¥¨ä»£è™Ÿï¼Œä½¿ç”¨æŒ‡å®šçš„è‚¡ç¥¨
        if request.stock_code:
            stock_id = request.stock_code
            stock_name = request.stock_name or f"è‚¡ç¥¨{stock_id}"
            print(f"ğŸ“Š ä½¿ç”¨æŒ‡å®šè‚¡ç¥¨: {stock_name}({stock_id})")
        else:
            # å¦å‰‡ç²å–ç†±é–€è‚¡ç¥¨
            print("ğŸ“ˆ ç²å–ç†±é–€è‚¡ç¥¨...")
            try:
                trending_stocks_response = requests.get(f"{TRENDING_API_URL}/trending/stocks", params={"limit": 10})
                trending_stocks_response.raise_for_status()
                trending_stocks = trending_stocks_response.json()
                
                if not trending_stocks.get("stocks"):
                    print("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç†±é–€è‚¡ç¥¨")
                    return PostingResult(
                        success=False,
                        error="æ²’æœ‰æ‰¾åˆ°ç†±é–€è‚¡ç¥¨",
                        timestamp=datetime.now()
                    )
                
                # é¸æ“‡ç¬¬ä¸€å€‹ç†±é–€è‚¡ç¥¨
                stock = trending_stocks["stocks"][0]
                stock_id = stock["stock_id"]
                stock_name = stock.get("stock_name", f"è‚¡ç¥¨{stock_id}")
                print(f"ğŸ“ˆ é¸æ“‡ç†±é–€è‚¡ç¥¨: {stock_name}({stock_id})")
            except Exception as e:
                print(f"âš ï¸ ç²å–ç†±é–€è‚¡ç¥¨å¤±æ•—: {e}")
                stock_id = "2330"
                stock_name = "å°ç©é›»"
                print(f"ğŸ“ˆ ä½¿ç”¨é è¨­è‚¡ç¥¨: {stock_name}({stock_id})")
        
        print(f"âœ… è‚¡ç¥¨ç¢ºå®š: {stock_name}({stock_id})")
        
        # å°å…¥æ–°çš„æœå‹™
        print("ğŸ”§ å°å…¥æœå‹™æ¨¡çµ„...")
        try:
            from serper_integration import serper_service
            from smart_data_source_assigner import smart_assigner, KOLProfile, StockProfile
            from publish_service import publish_service
            print("âœ… æœå‹™æ¨¡çµ„å°å…¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æœå‹™æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
            raise
        
        # 1. æ™ºèƒ½æ•¸æ“šæºåˆ†é…
        print(f"ğŸ¯ é–‹å§‹æ™ºèƒ½æ•¸æ“šæºåˆ†é…: {stock_id}, {request.kol_persona}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å‰ç«¯å‚³ä¾†çš„æ•¸æ“šæºé…ç½®
        if request.data_sources:
            print(f"ğŸ“Š ä½¿ç”¨å‰ç«¯æ•¸æ“šæºé…ç½®: {request.data_sources}")
            # ä½¿ç”¨å‰ç«¯é…ç½®çš„æ•¸æ“šæº
            primary_sources = []
            if request.data_sources.get('stock_price_api'):
                primary_sources.append('ohlc_api')
            if request.data_sources.get('monthly_revenue_api'):
                primary_sources.append('revenue_api')
            if request.data_sources.get('financial_report_api'):
                primary_sources.append('financial_api')
            if request.data_sources.get('news_sources', []):
                primary_sources.append('serper_api')
            
            # å‰µå»ºæ¨¡æ“¬çš„æ•¸æ“šæºåˆ†é…çµæœ
            from smart_data_source_assigner import DataSourceAssignment, DataSourceType
            data_source_assignment = DataSourceAssignment(
                primary_sources=[DataSourceType(source) for source in primary_sources if hasattr(DataSourceType, source)],
                secondary_sources=[],
                excluded_sources=[],
                assignment_reason=f"åŸºæ–¼å‰ç«¯é…ç½®: {', '.join(primary_sources)}",
                confidence_score=0.9
            )
        else:
            # ä½¿ç”¨æ™ºèƒ½åˆ†é…é‚è¼¯
            kol_profile = KOLProfile(
                serial=int(request.kol_serial) if request.kol_serial else 1,
                nickname=f"KOL-{request.kol_serial or '1'}",
                persona=request.kol_persona,
                expertise_areas=[request.kol_persona],
                content_style=request.content_style,
                target_audience=request.target_audience
            )
            
            stock_profile = StockProfile(
                stock_code=stock_id,
                stock_name=stock_name,
                industry="ç§‘æŠ€",  # å¯ä»¥å¾APIç²å–
                market_cap="medium",  # å¯ä»¥å¾APIç²å–
                volatility="medium",  # å¯ä»¥å¾APIç²å–
                news_frequency="medium"  # å¯ä»¥å¾APIç²å–
            )
            
            # åˆ†é…æ•¸æ“šæº
            data_source_assignment = smart_assigner.assign_data_sources(kol_profile, stock_profile)
        
        print(f"âœ… æ•¸æ“šæºåˆ†é…å®Œæˆ: {data_source_assignment.assignment_reason}")
        print(f"ğŸ“Š ä¸»è¦æ•¸æ“šæº: {[s.value for s in data_source_assignment.primary_sources]}")
        
        # 2. ç²å–Serperæ–°èæ•¸æ“š - ä½¿ç”¨å‰ç«¯é…ç½®çš„é—œéµå­—
        print(f"ğŸ” é–‹å§‹ç²å–Serperæ–°èæ•¸æ“š: {stock_id}")
        try:
            # æå–æ–°èæœå°‹é—œéµå­—é…ç½®
            search_keywords = None
            time_range = "d2"  # é è¨­æ™‚é–“ç¯„åœ
            
            if request.news_config:
                # æå–æœå°‹é—œéµå­—
                if request.news_config.get('search_keywords'):
                    search_keywords = request.news_config.get('search_keywords')
                    print(f"ğŸ“ ä½¿ç”¨å‰ç«¯æ–°èé—œéµå­—é…ç½®: {len(search_keywords)} å€‹é—œéµå­—")
                    for kw in search_keywords:
                        print(f"   - {kw.get('type', 'custom')}: {kw.get('keyword', '')}")
                
                # æå–æ™‚é–“ç¯„åœè¨­å®š
                if request.news_config.get('time_range'):
                    time_range = request.news_config.get('time_range')
                    print(f"â° ä½¿ç”¨å‰ç«¯æ™‚é–“ç¯„åœè¨­å®š: {time_range}")
                elif request.news_time_range:
                    time_range = request.news_time_range
                    print(f"â° ä½¿ç”¨è«‹æ±‚æ™‚é–“ç¯„åœè¨­å®š: {time_range}")
            else:
                print("ğŸ“ ä½¿ç”¨é è¨­æ–°èæœå°‹é—œéµå­—")
            
            serper_analysis = serper_service.get_comprehensive_stock_analysis(
                stock_id, 
                stock_name, 
                search_keywords=search_keywords,
                time_range=time_range
            )
            news_items = serper_analysis.get('news_items', [])
            limit_up_analysis = serper_analysis.get('limit_up_analysis', {})
            print(f"âœ… Serperåˆ†æå®Œæˆ: æ‰¾åˆ° {len(news_items)} å‰‡æ–°è")
        except Exception as e:
            print(f"âš ï¸ Serperåˆ†æå¤±æ•—: {e}")
            serper_analysis = {'news_items': [], 'limit_up_analysis': {}}
            news_items = []
            limit_up_analysis = {}
        
        # 3. ç”ŸæˆKOLå…§å®¹ - å¼·åˆ¶ä½¿ç”¨æ–°èåˆ†æAgent
        print(f"âœï¸ é–‹å§‹ç”ŸæˆKOLå…§å®¹: {stock_id}, {request.kol_persona}")
        
        try:
            # å¼·åˆ¶ä½¿ç”¨æ–°èåˆ†æAgent
            if news_items:
                print(f"ğŸ¤– å¼·åˆ¶ä½¿ç”¨æ–°èåˆ†æAgentåˆ†æ {len(news_items)} å‰‡æ–°è")
                from news_analysis_agent import NewsAnalysisAgent
                # å‰µå»ºæ–°çš„å¯¦ä¾‹ä»¥ç¢ºä¿API Keyæ­£ç¢ºè¼‰å…¥
                news_agent = NewsAnalysisAgent()
                kol_content = news_agent.analyze_stock_news(
                    stock_id, stock_name, news_items, request.kol_persona, 
                    request.content_length, request.max_words
                )
                print(f"âœ… Agentå…§å®¹ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
            else:
                print("âš ï¸ æ²’æœ‰æ–°èæ•¸æ“šï¼Œä½¿ç”¨GPTç”Ÿæˆå™¨")
                kol_content = gpt_generator.generate_stock_analysis(
                    stock_id=stock_id,
                    stock_name=stock_name,
                    kol_persona=request.kol_persona,
                    serper_analysis=serper_analysis,
                    data_sources=[source.value for source in data_source_assignment.primary_sources],
                    content_length=request.content_length,
                    max_words=request.max_words
                )
                print(f"âœ… GPTå…§å®¹ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
        except Exception as e:
            print(f"âŒ Agentå…§å®¹ç”Ÿæˆå¤±æ•—: {e}")
            # å›é€€åˆ°æ”¹é€²çš„å…§å®¹ç”Ÿæˆå™¨
            kol_content = generate_improved_kol_content(
                stock_id=stock_id,
                stock_name=stock_name,
                kol_persona=request.kol_persona,
                content_style=request.content_style,
                target_audience=request.target_audience,
                serper_analysis=serper_analysis,
                data_sources=[source.value for source in data_source_assignment.primary_sources]
            )
            print(f"âœ… å›é€€å…§å®¹ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
        
        # 4. æ•´åˆæ–°èç´ æå’Œæ•¸æ“šæºè³‡è¨Š
        print("ğŸ”— æ•´åˆæ–°èç´ æå’Œæ•¸æ“šæºè³‡è¨Š...")
        try:
            enhanced_content = enhance_content_with_serper_data(
                kol_content, 
                serper_analysis, 
                data_source_assignment
            )
            print("âœ… å…§å®¹æ•´åˆå®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ å…§å®¹æ•´åˆå¤±æ•—: {e}")
            enhanced_content = kol_content
        
        # 5. å…§å®¹æª¢æŸ¥å’Œä¿®å¾©ï¼ˆåœ¨æ–°èæ•´åˆå¾Œé€²è¡Œï¼‰
        print("ğŸ” é–‹å§‹å…§å®¹æª¢æŸ¥å’Œä¿®å¾©...")
        try:
            from content_checker import ContentChecker
            content_checker = ContentChecker()
            
            # æª¢æŸ¥ä¸¦ä¿®å¾©å…§å®¹ï¼ˆæª¢æŸ¥ content_md å­—æ®µï¼‰
            content_to_check = enhanced_content.get('content_md', enhanced_content.get('content', ''))
            check_result = content_checker.check_and_fix_content(
                content_to_check,
                stock_name,
                stock_id,
                request.kol_persona,
                request.kol_serial
            )
            
            if check_result['success']:
                print(f"âœ… å…§å®¹æª¢æŸ¥å®Œæˆ: {check_result['fix_method']} ä¿®å¾©")
                if check_result['issues_found']:
                    print(f"ğŸ”§ ç™¼ç¾å•é¡Œ: {', '.join(check_result['issues_found'])}")
                
                # ä½¿ç”¨ä¿®å¾©å¾Œçš„å…§å®¹ï¼Œä½†ä¿ç•™æ–°èä¾†æº
                # æª¢æŸ¥æ˜¯å¦æœ‰æ–°èä¾†æºéœ€è¦ä¿ç•™
                news_sources_section = ""
                if "æ–°èä¾†æº:" in enhanced_content['content']:
                    news_sources_start = enhanced_content['content'].find("æ–°èä¾†æº:")
                    news_sources_section = enhanced_content['content'][news_sources_start:]
                    print(f"ğŸ” ä¿ç•™æ–°èä¾†æº: {len(news_sources_section)} å­—")
                
                enhanced_content['content'] = check_result['fixed_content']
                enhanced_content['content_md'] = check_result['fixed_content']
                
                # å¦‚æœæœ‰æ–°èä¾†æºï¼Œé‡æ–°æ·»åŠ 
                if news_sources_section:
                    enhanced_content['content'] += "\n\n" + news_sources_section
                    enhanced_content['content_md'] += "\n\n" + news_sources_section
                    print(f"âœ… æ–°èä¾†æºå·²é‡æ–°æ·»åŠ : {len(news_sources_section)} å­—")
                enhanced_content['content_check'] = check_result
            else:
                print(f"âš ï¸ å…§å®¹æª¢æŸ¥å¤±æ•—: {check_result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                
        except Exception as e:
            print(f"âš ï¸ å…§å®¹æª¢æŸ¥å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
        
        # æ·»åŠ é¡å¤–çš„æ¬„ä½ä»¥ç¬¦åˆå‰ç«¯æœŸæœ›
        enhanced_content.update({
            "stock_code": stock_id,
            "stock_name": stock_name,
            "kol_serial": request.kol_serial or "1",
            "session_id": request.session_id,
            "batch_mode": request.batch_mode
        })
        
        # æº–å‚™å•†å“æ¨™ç±¤
        print("ğŸ·ï¸ æº–å‚™å•†å“æ¨™ç±¤...")
        # ç”Ÿæˆ commodity tags (æš«æ™‚ç¦ç”¨ä»¥è§£æ±ºå°å…¥å•é¡Œ)
        commodity_tags = []
        print("âš ï¸ å•†å“æ¨™ç±¤åŠŸèƒ½æš«æ™‚ç¦ç”¨ï¼Œä¸å½±éŸ¿è²¼æ–‡ç”Ÿæˆ")
        
        print(f"âœ… ç”Ÿæˆçš„å•†å“æ¨™ç±¤: {commodity_tags}")
        print(f"ğŸ“Š è‚¡ç¥¨ä»£è™Ÿ: {stock_id}, è‚¡ç¥¨åç¨±: {stock_name}")
        print(f"ğŸ‘¤ KOLåºè™Ÿ: {request.kol_serial}")
        
        # æº–å‚™ç¤¾ç¾¤è©±é¡Œ
        community_topic = None
        if request.post_to_thread:
            community_topic = CommunityTopic(id=request.post_to_thread)
            print(f"ğŸ’¬ ç¤¾ç¾¤è©±é¡Œ: {request.post_to_thread}")
        
        # æº–å‚™ç”Ÿæˆåƒæ•¸ - æ•´åˆæ•¸æ“šæºè³‡è¨Š
        print("âš™ï¸ æº–å‚™ç”Ÿæˆåƒæ•¸...")
        generation_params = GenerationParams(
            kol_persona=request.kol_persona,
            content_style=request.content_style,
            target_audience=request.target_audience,
            batch_mode=request.batch_mode,
            data_sources=[source.value for source in data_source_assignment.primary_sources],
            session_id=request.session_id,
            technical_indicators=[]
        )
        print("âœ… ç”Ÿæˆåƒæ•¸æº–å‚™å®Œæˆ")
        
        # å‰µå»ºè²¼æ–‡è¨˜éŒ„
        print("ğŸ’¾ é–‹å§‹ä¿å­˜è²¼æ–‡è¨˜éŒ„åˆ°è³‡æ–™åº«...")
        try:
            # æš«æ™‚ç¦ç”¨ CommodityTag æ¨¡å‹è½‰æ›
            commodity_tag_models = []
            print("âš ï¸ CommodityTag æ¨¡å‹è½‰æ›æš«æ™‚ç¦ç”¨")
            
            # ç¢ºä¿ä½¿ç”¨å­˜åœ¨çš„ KOL
            from kol_service import kol_service
            available_kol_ids = list(kol_service.kol_credentials.keys())
            if request.kol_serial and str(request.kol_serial) in available_kol_ids:
                kol_serial = int(request.kol_serial)
            else:
                # ä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨çš„ KOL
                kol_serial = int(available_kol_ids[0])
                print(f"âš ï¸ KOL {request.kol_serial} ä¸å­˜åœ¨ï¼Œä½¿ç”¨ KOL {kol_serial}")
            
            # æº–å‚™è²¼æ–‡è¨˜éŒ„æ•¸æ“š
            print(f"ğŸ“ æº–å‚™è²¼æ–‡è¨˜éŒ„æ•¸æ“š: {enhanced_content.get('title', 'æœªå‘½åè²¼æ–‡')}")
            print(f"ğŸ” è²¼æ–‡è¨˜éŒ„æ•¸æ“šè©³æƒ…: session_id={request.session_id}, stock_code={stock_id}")
            
        except Exception as e:
            print(f"âŒ æº–å‚™è²¼æ–‡è¨˜éŒ„æ•¸æ“šå¤±æ•—: {e}")
            # ä¸è¨­ç½® error ç‹€æ…‹ï¼Œç¹¼çºŒå˜—è©¦ä¿å­˜åˆ°æ•¸æ“šåº«
        
        # è™•ç†ç†±é–€è©±é¡Œ IDï¼ˆæ··å’Œæ¨¡å¼ï¼‰- åœ¨ä¿å­˜åˆ°æ•¸æ“šåº«ä¹‹å‰åŸ·è¡Œ
        print("ğŸ” é–‹å§‹è™•ç†ç†±é–€è©±é¡Œ IDï¼ˆæ··å’Œæ¨¡å¼ï¼‰")
        topic_id = request.topic_id
        topic_title = request.topic_title
        
        # èª¿è©¦æ—¥èªŒ
        print(f"ğŸ” èª¿è©¦æ¨™ç±¤æ¨¡å¼æ¢ä»¶:")
        print(f"  - topic_id: {topic_id}")
        print(f"  - topic_title: {topic_title}")
        print(f"  - tags_config: {request.tags_config}")
        print(f"  - tag_mode: {request.tags_config.get('tag_mode', 'stock_tags') if request.tags_config else 'stock_tags'}")
        print(f"  - topic_tags: {request.tags_config.get('topic_tags', {}) if request.tags_config else {}}")
        print(f"  - mixed_mode: {request.tags_config.get('topic_tags', {}).get('mixed_mode', False) if request.tags_config else False}")
        
        # æª¢æŸ¥æ¨™ç±¤æ¨¡å¼æ¢ä»¶
        tag_mode = request.tags_config.get('tag_mode', 'stock_tags') if request.tags_config else 'stock_tags'
        mixed_mode_enabled = request.tags_config and request.tags_config.get('topic_tags', {}).get('mixed_mode', False)
        topic_tags_enabled = request.tags_config and request.tags_config.get('topic_tags', {}).get('enabled', False)
        
        print(f"ğŸ” æ¨™ç±¤æ¨¡å¼æ¢ä»¶æª¢æŸ¥:")
        print(f"  - request.tags_config å­˜åœ¨: {bool(request.tags_config)}")
        print(f"  - tag_mode: {tag_mode}")
        print(f"  - mixed_mode_enabled: {mixed_mode_enabled}")
        print(f"  - topic_id ç‚ºç©º: {not topic_id}")
        
        # åˆ¤æ–·æ˜¯å¦éœ€è¦è‡ªå‹•ç²å–ç†±é–€è©±é¡Œ
        should_auto_fetch_topic = (
            (not topic_id or topic_id == 'auto_fetch') and  # æ²’æœ‰æä¾› topic_id æˆ–æ˜ç¢ºè¦æ±‚è‡ªå‹•ç²å–
            (
                tag_mode == 'topic_tags' or  # ç´”ç†±é–€è©±é¡Œæ¨¡å¼
                tag_mode == 'both' or  # æ··åˆæ¨¡å¼
                mixed_mode_enabled or  # æˆ–è€…å•Ÿç”¨äº†æ··å’Œæ¨¡å¼
                topic_id == 'auto_fetch'  # æˆ–è€…æ˜ç¢ºè¦æ±‚è‡ªå‹•ç²å–
            )
        )
        
        print(f"  - æ‡‰è©²è‡ªå‹•ç²å–ç†±é–€è©±é¡Œ: {should_auto_fetch_topic}")
        
        # å¦‚æœæ²’æœ‰æä¾› topic_id ä½†éœ€è¦ç†±é–€è©±é¡Œæ¨™ç±¤ï¼Œè‡ªå‹•å¾ trending API ç²å–
        if should_auto_fetch_topic:
            try:
                print("ğŸ”„ è‡ªå‹•ç²å–ç†±é–€è©±é¡Œï¼ˆåŸºæ–¼æ¨™ç±¤æ¨¡å¼ï¼‰...")
                print(f"ğŸ” èª¿ç”¨ trending API: {TRENDING_API_URL}/trending")
                trending_response = requests.get(f"{TRENDING_API_URL}/trending", params={"limit": 1})
                print(f"ğŸ” trending API éŸ¿æ‡‰ç‹€æ…‹: {trending_response.status_code}")
                trending_response.raise_for_status()
                trending_data = trending_response.json()
                print(f"ğŸ” trending API éŸ¿æ‡‰æ•¸æ“š: {trending_data}")
                
                if trending_data.get("topics") and len(trending_data["topics"]) > 0:
                    trending_topic = trending_data["topics"][0]
                    topic_id = trending_topic.get("id")
                    topic_title = trending_topic.get("title")
                    print(f"âœ… è‡ªå‹•ç²å–åˆ°ç†±é–€è©±é¡Œ - ID: {topic_id}, æ¨™é¡Œ: {topic_title}")
                    print(f"ğŸ” å®Œæ•´è©±é¡Œæ•¸æ“š: {trending_topic}")
                else:
                    print("âš ï¸ æœªç²å–åˆ°ç†±é–€è©±é¡Œæ•¸æ“š")
                    print(f"ğŸ” éŸ¿æ‡‰æ•¸æ“šçµæ§‹: {trending_data}")
            except Exception as e:
                print(f"âŒ ç²å–ç†±é–€è©±é¡Œå¤±æ•—: {e}")
                import traceback
                print(f"ğŸ” éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        
        # ä¿å­˜åˆ°æ•¸æ“šåº« - ä½¿ç”¨å®Œæ•´çš„ enhanced_content
        try:
            post_service = get_post_record_service()
            
            # æº–å‚™å®Œæ•´çš„è²¼æ–‡æ•¸æ“š
            print(f"ğŸ” æº–å‚™ä¿å­˜åˆ°æ•¸æ“šåº«çš„ topic_id: {topic_id}")
            print(f"ğŸ” æº–å‚™ä¿å­˜åˆ°æ•¸æ“šåº«çš„ topic_title: {topic_title}")
            
            post_data = {
                'session_id': request.session_id or 1,
                'kol_serial': int(request.kol_serial or 200),
                'kol_nickname': f"KOL-{request.kol_serial or 200}",
                'kol_persona': request.kol_persona,
                'stock_code': request.stock_code or "2330",
                'stock_name': request.stock_name or "å°ç©é›»",
                'title': enhanced_content.get("title", f"ã€KOL-{request.kol_serial or 200}ã€‘{request.stock_name or 'å°ç©é›»'}({request.stock_code or '2330'}) ç›¤å¾Œåˆ†æ"),
                'content': enhanced_content.get("content", ""),
                'content_md': enhanced_content.get("content_md", ""),
                'status': 'draft',
                'technical_analysis': enhanced_content.get("technical_analysis"),
                'serper_data': enhanced_content.get("serper_data"),
                'quality_score': enhanced_content.get("quality_score"),
                'ai_detection_score': enhanced_content.get("ai_detection_score"),
                'risk_level': enhanced_content.get("risk_level"),
                'topic_id': topic_id,  # ä½¿ç”¨è™•ç†å¾Œçš„ topic_id
                'topic_title': topic_title,  # ä½¿ç”¨è™•ç†å¾Œçš„ topic_title
                'generation_params': json.dumps({
                    "method": "manual",
                    "kol_persona": request.kol_persona,
                    "content_style": request.content_style,
                    "target_audience": request.target_audience,
                    "topic_id": topic_id,
                    "topic_title": topic_title,
                    "tag_mode": tag_mode,
                    "topic_tags_enabled": topic_tags_enabled,
                    "mixed_mode": mixed_mode_enabled,
                    "created_at": datetime.now().isoformat()
                })
            }
            
            print(f"ğŸ” å®Œæ•´çš„ post_data: {post_data}")
            
            # å‰µå»ºå®Œæ•´çš„è²¼æ–‡è¨˜éŒ„
            post_record = post_service.create_post_record(post_data)
            
            print(f"âœ… è²¼æ–‡è¨˜éŒ„ä¿å­˜æˆåŠŸ: {post_record.post_id}")
            enhanced_content["post_id"] = post_record.post_id
            enhanced_content["status"] = "draft"  # è¨­ç½®ç‚º draft ç‹€æ…‹
            
            # å°‡ topic_id å’Œ topic_title æ·»åŠ åˆ° enhanced_content ä¸­
            if topic_id:
                enhanced_content["topic_id"] = topic_id
                enhanced_content["topic_title"] = topic_title
                print(f"âœ… å·²æ›´æ–° enhanced_content ä¸­çš„è©±é¡Œä¿¡æ¯: {topic_id} - {topic_title}")
            
        except Exception as db_error:
            print(f"âŒ ä¿å­˜è²¼æ–‡è¨˜éŒ„å¤±æ•—: {db_error}")
            enhanced_content["post_id"] = f"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            enhanced_content["status"] = "error"
        
        # ç™¼æ–‡
        if request.auto_post:
            print("ğŸš€ æº–å‚™è‡ªå‹•ç™¼æ–‡...")
            background_tasks = BackgroundTasks()
            background_tasks.add_task(post_to_platform, enhanced_content, {"id": request.post_to_thread})
            print("âœ… è‡ªå‹•ç™¼æ–‡ä»»å‹™å·²åŠ å…¥èƒŒæ™¯ä»»å‹™")
        
        print(f"ğŸ‰ ç™¼æ–‡ç”Ÿæˆå®Œæˆ: {enhanced_content.get('post_id')}")
        
        return PostingResult(
            success=True,
            post_id=enhanced_content.get("post_id", f"post_{datetime.now().strftime('%Y%m%d_%H%M%S')}"),
            content=enhanced_content,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        return PostingResult(
            success=False,
            error=str(e),
            timestamp=datetime.now()
        )

def generate_kol_content_direct(stock_id: str, stock_name: str, kol_persona: str, content_style: str, target_audience: str) -> Dict:
    """ç›´æ¥ç”ŸæˆKOLå…§å®¹ - åŸºæ–¼åŸæœ¬çš„ç›¤å¾Œæ¼²åœè…³æœ¬æ¶æ§‹"""
    
    # KOLäººè¨­é…ç½®
    kol_personas = {
        "technical": {
            "name": "æŠ€è¡“å¤§å¸«",
            "style": "å°ˆæ¥­ä¸”è‡ªä¿¡",
            "focus": "åœ–è¡¨åˆ†æã€æŠ€è¡“æŒ‡æ¨™",
            "language": "æŠ€è¡“è¡“èªè±å¯Œï¼Œæ•¸æ“šå°å‘"
        },
        "fundamental": {
            "name": "åƒ¹å€¼æŠ•è³‡å¤§å¸«", 
            "style": "ç©©é‡ä¸”æ·±æ€ç†Ÿæ…®",
            "focus": "åŸºæœ¬é¢åˆ†æã€è²¡å ±è§£è®€",
            "language": "é‚è¼¯æ¸…æ™°ï¼Œé‡è¦–æ•¸æ“š"
        },
        "news_driven": {
            "name": "æ–°èçµäºº",
            "style": "æ•éŠ³ä¸”å³æ™‚", 
            "focus": "æ–°èå½±éŸ¿ã€æ”¿ç­–è®ŠåŒ–",
            "language": "ç”Ÿå‹•æ´»æ½‘ï¼Œæ™‚äº‹å°å‘"
        }
    }
    
    persona = kol_personas.get(kol_persona, kol_personas["technical"])
    
    # ç”Ÿæˆæ¨™é¡Œ - ç´”æ–‡å­—æ ¼å¼
    title = f"{stock_name} {persona['name']}è§€é»"
    
    # ç”Ÿæˆå…§å®¹ - ç´”æ–‡å­—æ ¼å¼
    content_md = f"""{stock_name}({stock_id}) æŠ€è¡“é¢åˆ†æå ±å‘Š

æ ¸å¿ƒè§€é»
{stock_name} ç›®å‰è™•æ–¼å¼·å‹¢çªç ´ç‹€æ…‹ï¼ŒæŠ€è¡“æŒ‡æ¨™é¡¯ç¤ºå¤šé ­è¨Šè™Ÿç¢ºèªã€‚

é—œéµæŠ€è¡“æŒ‡æ¨™
- MA5/MA20: é»ƒé‡‘äº¤å‰ç¢ºèªå¤šé ­è¶¨å‹¢
- RSI14: ä¸­æ€§åå¤šï¼Œä»æœ‰ä¸Šæ¼²ç©ºé–“
- MACDæŸ±ç‹€é«”: å¤šé ­è¨Šè™ŸæŒçºŒ

æŠ€è¡“è¨Šè™Ÿåˆ†æ
- åƒ¹æ¼²é‡å¢ï¼šè²·ç›¤åŠ›é“å¼·å‹ï¼Œå¾Œå¸‚çœ‹å¥½
- çªç ´å£“åŠ›ï¼šæˆåŠŸçªç ´é—œéµé˜»åŠ›ä½
- è¶¨å‹¢ç¢ºèªï¼šå¤šé ­æ’åˆ—å®Œæ•´

æŠ•è³‡å»ºè­°
åŸºæ–¼æŠ€è¡“åˆ†æï¼Œå»ºè­°é€¢ä½å¸ƒå±€ï¼Œç›®æ¨™åƒ¹ä½å¯æœŸå¾…10-15%æ¼²å¹…ã€‚

é¢¨éšªæé†’
- æ³¨æ„å¤§ç›¤ç’°å¢ƒè®ŠåŒ–
- è¨­å¥½åœæé»ä½
- åˆ†æ‰¹é€²å ´é™ä½é¢¨éšª

æ“ä½œç­–ç•¥
1. é€²å ´æ™‚æ©Ÿ: å›æ¸¬æ”¯æ’æ™‚åˆ†æ‰¹è²·é€²
2. åœæè¨­å®š: è·Œç ´é—œéµæ”¯æ’ä½
3. ç›®æ¨™åƒ¹ä½: æŠ€è¡“ç›®æ¨™åƒ¹ä½
4. æŒè‚¡æ¯”ä¾‹: å»ºè­°æ§åˆ¶åœ¨ç¸½è³‡ç”¢10%ä»¥å…§

ä»¥ä¸Šåˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°

æ•¸æ“šä¾†æº
æœ¬åˆ†ææ•´åˆäº†: æŠ€è¡“æŒ‡æ¨™æ•¸æ“š, å¸‚å ´æ‘˜è¦åˆ†æ, ç†±é–€è©±é¡Œæ•¸æ“š
"""
    
    return {
        "kol_id": f"kol_{persona['name']}",
        "kol_name": persona['name'],
        "stock_id": stock_id,
        "content_type": content_style,
        "title": title,
        "content_md": content_md,
        "key_points": [
            "æŠ€è¡“é¢å¼·å‹¢çªç ´",
            "å¤šé ­è¨Šè™Ÿç¢ºèª", 
            "åƒ¹æ¼²é‡å¢æ ¼å±€",
            "é€¢ä½å¸ƒå±€ç­–ç•¥"
        ],
        "investment_advice": {
            "recommendation": "buy",
            "confidence": 0.8,
            "target_price": "æŠ€è¡“ç›®æ¨™åƒ¹",
            "stop_loss": "é—œéµæ”¯æ’ä½"
        },
        "engagement_prediction": 0.75,
        "created_at": datetime.now().isoformat()
    }

def enhance_content_with_news(kol_content: Dict, topic: Dict, news_items: List[Dict]) -> Dict:
    """æ•´åˆæ–°èç´ æåˆ°KOLå…§å®¹ä¸­"""
    
    enhanced_content = kol_content.copy()
    
    # ç¢ºä¿ content_md å­˜åœ¨
    if "content_md" not in enhanced_content:
        enhanced_content["content_md"] = ""
    
    # åœ¨å…§å®¹ä¸­åŠ å…¥æ–°èç´ æ
    if news_items:
        news_section = "\n\nç›¸é—œæ–°èç´ æ\n"
        news_sources = []
        for i, news in enumerate(news_items[:5], 1):  # å–å‰5å‰‡æ–°è
            news_section += f"{news['title']}: {news['summary'][:100]}...\n\n"
            news_sources.append(f"{i}. {news['title']}\n   [é–±è®€æ›´å¤š]({news['url']})")
        
        # åœ¨å…§å®¹æœ«å°¾åŠ å…¥æ–°èç´ æ
        enhanced_content["content_md"] += news_section
        
        # æ·»åŠ æ–°èä¾†æºåˆ°æœ€å¾Œ
        if news_sources:
            sources_section = "\n\næ–°èä¾†æº:\n" + "\n".join(news_sources)
            enhanced_content["content_md"] += sources_section
        
        # æ›´æ–°é—œéµé»
        if "key_points" in enhanced_content:
            enhanced_content["key_points"].append("æ•´åˆæœ€æ–°æ–°èç´ æ")
        else:
            enhanced_content["key_points"] = ["æ•´åˆæœ€æ–°æ–°èç´ æ"]
    
    # åŠ å…¥è©±é¡Œæ¨™ç±¤
    if topic.get("title"):
        enhanced_content["content_md"] += f"\n\n---\n*å›æ‡‰ç†±é–€è©±é¡Œï¼š{topic['title']}*"
    
    return enhanced_content

async def post_to_platform(content: Dict, topic: Dict):
    """ç™¼æ–‡åˆ°æŒ‡å®šå¹³å° (æ¨¡æ“¬)"""
    
    # é€™è£¡å¯ä»¥æ•´åˆå¯¦éš›çš„ç™¼æ–‡å¹³å°API
    # ä¾‹å¦‚ï¼šTwitter API, LinkedIn API, æˆ–è‡ªå»ºå¹³å°
    
    post_data = {
        "content": content["content_md"],
        "title": content["title"],
        "stock_id": content["stock_id"],
        "kol_id": content["kol_id"],
        "topic_id": topic.get("id", "unknown"),
        "timestamp": datetime.now().isoformat()
    }
    
    # æ¨¡æ“¬ç™¼æ–‡æˆåŠŸ
    print(f"ğŸ“ ç™¼æ–‡æˆåŠŸ: {content['title']}")
    print(f"ğŸ“Š è‚¡ç¥¨: {content['stock_id']}")
    print(f"ğŸ‘¤ KOL: {content['kol_name']}")
    print(f"ğŸ”— è©±é¡Œ: {topic.get('title', 'N/A')}")
    
    # å¯¦éš›æ•´åˆæ™‚ï¼Œé€™è£¡æœƒèª¿ç”¨ç™¼æ–‡å¹³å°API
    # response = requests.post("https://api.twitter.com/2/tweets", json=post_data)
    
    return {"success": True, "post_id": f"post_{datetime.now().strftime('%Y%m%d_%H%M%S')}"}

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now(),
        "services": {
            "trending_api": "connected",
            "summary_api": "connected",
            "ohlc_api": "connected"
        }
    }

@app.get("/trending/preview")
async def preview_trending_content():
    """é è¦½ç†±é–€è©±é¡Œå…§å®¹"""
    
    try:
        # ç²å–ç†±é–€è©±é¡Œ
        trending_response = requests.get(f"{TRENDING_API_URL}/trending", params={"limit": 3})
        trending_response.raise_for_status()
        trending_topics = trending_response.json()
        
        # ç²å–ç†±é–€è‚¡ç¥¨
        stocks_response = requests.get(f"{TRENDING_API_URL}/trending/stocks", params={"limit": 5})
        stocks_response.raise_for_status()
        trending_stocks = stocks_response.json()
        
        return {
            "topics": trending_topics.get("topics", []),
            "stocks": trending_stocks.get("stocks", []),
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        return {"error": str(e), "timestamp": datetime.now()}

# ==================== KOLæ†‘è­‰ç®¡ç† ====================

class KOLCredentialManager:
    """KOLæ†‘è­‰ç®¡ç†å™¨"""
    
    def __init__(self):
        # ä½¿ç”¨ KOL æœå‹™è¼‰å…¥æ†‘è­‰
        self.kol_credentials = {}
        self.kol_tokens = {}
        self._load_kol_credentials()
        
        print("ğŸ” KOLæ†‘è­‰ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_kol_credentials(self):
        """å¾ KOL æœå‹™è¼‰å…¥æ†‘è­‰"""
        try:
            from kol_service import kol_service
            
            # ç²å–æ‰€æœ‰ KOL æ†‘è­‰
            for serial in kol_service.get_all_kol_serials():
                creds = kol_service.get_kol_credentials(serial)
                if creds:
                    self.kol_credentials[str(serial)] = {
                        "email": creds["email"],
                        "password": creds["password"],
                        "member_id": creds["member_id"]
                    }
                    print(f"è¼‰å…¥KOLæ†‘è­‰: {serial} - {creds['email']}")
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.kol_credentials)} å€‹KOLæ†‘è­‰")
            
        except Exception as e:
            print(f"âŒ å¾KOLæœå‹™è¼‰å…¥æ†‘è­‰å¤±æ•—: {e}")
            # ä½¿ç”¨é è¨­æ†‘è­‰ä½œç‚ºå‚™ç”¨
            self.kol_credentials = {
                "200": {"email": "forum_200@cmoney.com.tw", "password": "D8k9mN2p", "member_id": "9505546"},
                "201": {"email": "forum_201@cmoney.com.tw", "password": "D8k9mN2p", "member_id": "9505547"},
                "202": {"email": "forum_202@cmoney.com.tw", "password": "D8k9mN2p", "member_id": "9505548"},
                "203": {"email": "forum_203@cmoney.com.tw", "password": "D8k9mN2p", "member_id": "9505549"},
                "204": {"email": "forum_204@cmoney.com.tw", "password": "D8k9mN2p", "member_id": "9505550"},
                "205": {"email": "forum_205@cmoney.com.tw", "password": "Z5u6dL9o", "member_id": "9505551"},
                "206": {"email": "forum_206@cmoney.com.tw", "password": "T1t7kS9j", "member_id": "9505552"},
                "207": {"email": "forum_207@cmoney.com.tw", "password": "w2B3cF6l", "member_id": "9505553"},
                "208": {"email": "forum_208@cmoney.com.tw", "password": "q4N8eC7h", "member_id": "9505554"}
            }
            print("ä½¿ç”¨é è¨­KOLæ†‘è­‰é…ç½®")
    
    def get_kol_credentials(self, kol_serial: str) -> Optional[Dict[str, str]]:
        """ç²å–KOLæ†‘è­‰"""
        return self.kol_credentials.get(str(kol_serial))
    
    async def login_kol(self, kol_serial: str) -> Optional[str]:
        """ç™»å…¥KOLä¸¦è¿”å›access token"""
        try:
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰æœ‰æ•ˆtoken
            if kol_serial in self.kol_tokens:
                token_data = self.kol_tokens[kol_serial]
                if token_data.get('expires_at') and datetime.now() < token_data['expires_at']:
                    print(f"âœ… ä½¿ç”¨å¿«å–çš„KOL {kol_serial} token")
                    return token_data['token']
            
            # ç²å–æ†‘è­‰
            creds = self.get_kol_credentials(kol_serial)
            if not creds:
                print(f"âŒ æ‰¾ä¸åˆ°KOL {kol_serial} çš„æ†‘è­‰")
                return None
            
            print(f"ğŸ” é–‹å§‹ç™»å…¥KOL {kol_serial}...")
            
            # ä½¿ç”¨CMoney Clientç™»å…¥
            from src.clients.cmoney.cmoney_client import CMoneyClient, LoginCredentials
            cmoney_client = CMoneyClient()
            credentials = LoginCredentials(
                email=creds['email'],
                password=creds['password']
            )
            
            access_token = await cmoney_client.login(credentials)
            
            if access_token and access_token.token:
                # å¿«å–token
                self.kol_tokens[kol_serial] = {
                    'token': access_token.token,
                    'expires_at': access_token.expires_at
                }
                print(f"âœ… KOL {kol_serial} ç™»å…¥æˆåŠŸ")
                return access_token.token
            else:
                print(f"âŒ KOL {kol_serial} ç™»å…¥å¤±æ•—")
                return None
                
        except Exception as e:
            print(f"âŒ KOL {kol_serial} ç™»å…¥ç•°å¸¸: {e}")
            return None

# å…¨åŸŸKOLæ†‘è­‰ç®¡ç†å™¨
kol_credential_manager = KOLCredentialManager()


@app.get("/posts")
async def get_all_posts(skip: int = 0, limit: int = 100, status: Optional[str] = None):
    """ç²å–æ‰€æœ‰è²¼æ–‡"""
    try:
        posts = get_post_record_service().get_all_posts()
        
        # æ ¹æ“šç‹€æ…‹ç¯©é¸
        if status:
            posts = [post for post in posts if post.status == status]
        
        # åˆ†é 
        total = len(posts)
        posts = posts[skip:skip + limit]
        
        return {
            "posts": posts,
            "count": total,
            "skip": skip,
            "limit": limit
        }
    except Exception as e:
        print(f"ç²å–è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–è²¼æ–‡å¤±æ•—: {str(e)}")

@app.get("/posts/history-stats")
async def get_history_stats():
    """ç²å–æ­·å²ç”Ÿæˆè³‡æ–™çµ±è¨ˆ"""
    try:
        all_posts = get_post_record_service().get_all_posts()
        
        # æŒ‰ç‹€æ…‹åˆ†çµ„çµ±è¨ˆ
        status_stats = {}
        session_stats = {}
        kol_stats = {}
        stock_stats = {}
        
        for post in all_posts:
            # ç‹€æ…‹çµ±è¨ˆ
            status = post.status
            status_stats[status] = status_stats.get(status, 0) + 1
            
            # Session çµ±è¨ˆ
            session_id = post.session_id
            if session_id not in session_stats:
                session_stats[session_id] = {
                    'count': 0,
                    'statuses': {},
                    'kols': set(),
                    'stocks': set()
                }
            session_stats[session_id]['count'] += 1
            session_stats[session_id]['statuses'][status] = session_stats[session_id]['statuses'].get(status, 0) + 1
            session_stats[session_id]['kols'].add(post.kol_serial)
            session_stats[session_id]['stocks'].add(post.stock_code)
            
            # KOL çµ±è¨ˆ
            kol_key = f"KOL-{post.kol_serial}"
            if kol_key not in kol_stats:
                kol_stats[kol_key] = {
                    'count': 0,
                    'persona': post.kol_persona,
                    'stocks': set(),
                    'sessions': set()
                }
            kol_stats[kol_key]['count'] += 1
            kol_stats[kol_key]['stocks'].add(post.stock_code)
            kol_stats[kol_key]['sessions'].add(session_id)
            
            # è‚¡ç¥¨çµ±è¨ˆ
            stock_key = f"{post.stock_name}({post.stock_code})"
            if stock_key not in stock_stats:
                stock_stats[stock_key] = {
                    'count': 0,
                    'kols': set(),
                    'sessions': set()
                }
            stock_stats[stock_key]['count'] += 1
            stock_stats[stock_key]['kols'].add(post.kol_serial)
            stock_stats[stock_key]['sessions'].add(session_id)
        
        # è½‰æ› set ç‚º list
        for session_id, data in session_stats.items():
            data['kols'] = list(data['kols'])
            data['stocks'] = list(data['stocks'])
        
        for kol_key, data in kol_stats.items():
            data['stocks'] = list(data['stocks'])
            data['sessions'] = list(data['sessions'])
        
        for stock_key, data in stock_stats.items():
            data['kols'] = list(data['kols'])
            data['sessions'] = list(data['sessions'])
        
        # è‡ªæˆ‘å­¸ç¿’æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥
        learning_data_stats = {
            'total_posts': len(all_posts),
            'with_generation_params': sum(1 for post in all_posts if post.generation_params),
            'with_technical_analysis': sum(1 for post in all_posts if post.technical_analysis),
            'with_serper_data': sum(1 for post in all_posts if post.serper_data),
            'with_quality_scores': sum(1 for post in all_posts if post.quality_score is not None),
            'reconstruction_ready': sum(1 for post in all_posts 
                                       if post.generation_params and post.stock_code and post.kol_persona)
        }
        
        return {
            "success": True,
            "total_posts": len(all_posts),
            "status_stats": status_stats,
            "session_stats": session_stats,
            "kol_stats": kol_stats,
            "stock_stats": stock_stats,
            "learning_data_stats": learning_data_stats,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"ç²å–æ­·å²çµ±è¨ˆå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/posts/pending-review")
async def get_pending_review_posts():
    """ç²å–å¾…å¯©æ ¸çš„è²¼æ–‡åˆ—è¡¨"""
    try:
        posts = get_post_record_service().get_pending_review_posts()
        print(f"æ‰¾åˆ° {len(posts)} ç¯‡å¾…å¯©æ ¸è²¼æ–‡")
        for post in posts:
            print(f"  - {post.post_id}: {post.title} (ç‹€æ…‹: {post.status})")
        
        return {
            "success": True,
            "posts": posts,
            "count": len(posts),
            "timestamp": datetime.now()
        }
    except Exception as e:
        print(f"ç²å–å¾…å¯©æ ¸è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/posts/review-sidebar")
async def get_review_sidebar_data():
    """ç²å–ç™¼æ–‡å¯©æ ¸ sidebar é é¢æ‰€éœ€çš„æ•¸æ“š"""
    try:
        # ç²å–æ‰€æœ‰å¾…å¯©æ ¸è²¼æ–‡
        pending_posts = get_post_record_service().get_pending_review_posts()
        
        # æŒ‰ session åˆ†çµ„
        session_groups = {}
        for post in pending_posts:
            session_id = post.session_id
            if session_id not in session_groups:
                session_groups[session_id] = []
            session_groups[session_id].append(post)
        
        # çµ±è¨ˆæ•¸æ“š
        stats = {
            "total_pending": len(pending_posts),
            "sessions_count": len(session_groups),
            "latest_session": max(session_groups.keys()) if session_groups else None,
            "oldest_pending": min([post.created_at for post in pending_posts]) if pending_posts else None
        }
        
        # æº–å‚™ sidebar æ•¸æ“š
        sidebar_data = {
            "sessions": []
        }
        
        for session_id, posts in session_groups.items():
            session_info = {
                "session_id": session_id,
                "posts_count": len(posts),
                "latest_post": max([post.created_at for post in posts]),
                "kol_personas": list(set([post.kol_persona for post in posts])),
                "stock_codes": list(set([post.stock_code for post in posts if post.stock_code])),
                "posts": posts
            }
            sidebar_data["sessions"].append(session_info)
        
        # æŒ‰æœ€æ–°è²¼æ–‡æ™‚é–“æ’åº
        sidebar_data["sessions"].sort(key=lambda x: x["latest_post"], reverse=True)
        
        return {
            "success": True,
            "stats": stats,
            "sidebar_data": sidebar_data,
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        print(f"ç²å–å¯©æ ¸ sidebar æ•¸æ“šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/serper/test")
async def test_serper_api():
    """æ¸¬è©¦Serper APIé€£æ¥"""
    try:
        print("ğŸ” æ¸¬è©¦Serper APIé€£æ¥...")
        
        # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
        serper_api_key = os.getenv('SERPER_API_KEY')
        print(f"ğŸ”‘ SERPER_API_KEY ç‹€æ…‹: {'å·²è¨­å®š' if serper_api_key else 'æœªè¨­å®š'}")
        
        if not serper_api_key:
            return {
                "success": False,
                "error": "SERPER_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š",
                "timestamp": datetime.now().isoformat()
            }
        
        # æ¸¬è©¦APIé€£æ¥
        from serper_integration import serper_service
        
        # æ¸¬è©¦æœå°‹åŠŸèƒ½
        test_result = serper_service.search_stock_news("2330", "å°ç©é›»", limit=2, time_range="d2")
        
        return {
            "success": True,
            "api_key_configured": True,
            "test_query": "å°ç©é›» 2330 æ–°è æœ€æ–°",
            "results_count": len(test_result),
            "sample_results": test_result[:2] if test_result else [],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ Serper APIæ¸¬è©¦å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
            "api_key_configured": bool(os.getenv('SERPER_API_KEY')),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/posts/debug")
async def debug_posts():
    """èª¿è©¦ç«¯é»ï¼šæª¢æŸ¥æ‰€æœ‰è²¼æ–‡"""
    try:
        # ç²å–æ‰€æœ‰è²¼æ–‡
        all_posts = get_post_record_service().get_all_posts()
        print(f"è³‡æ–™åº«ä¸­å…±æœ‰ {len(all_posts)} ç¯‡è²¼æ–‡")
        
        # æŒ‰ç‹€æ…‹åˆ†çµ„
        status_groups = {}
        for post in all_posts:
            status = str(post.status)  # ç›´æ¥è½‰æ›ç‚ºå­—ç¬¦ä¸²
            if status not in status_groups:
                status_groups[status] = []
            status_groups[status].append(post)
        
        print("æŒ‰ç‹€æ…‹åˆ†çµ„:")
        for status, posts in status_groups.items():
            print(f"  {status}: {len(posts)} ç¯‡")
            for post in posts[:3]:  # åªé¡¯ç¤ºå‰3ç¯‡
                print(f"    - {post.post_id}: {post.title}")
        
        return {
            "success": True,
            "total_posts": len(all_posts),
            "posts_by_status": {status: len(posts) for status, posts in status_groups.items()},
            "posts": all_posts,
            "timestamp": datetime.now()
        }
    except Exception as e:
        print(f"èª¿è©¦è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/debug/data-source-assignment")
async def debug_data_source_assignment():
    """èª¿è©¦æ•¸æ“šæºåˆ†é…åŠŸèƒ½"""
    try:
        from smart_data_source_assigner import smart_assigner, KOLProfile, StockProfile
        
        # æ¸¬è©¦KOLé…ç½®
        test_kol = KOLProfile(
            serial=150,
            nickname="æ¸¬è©¦KOL",
            persona="technical",
            expertise_areas=["æŠ€è¡“åˆ†æ"],
            content_style="chart_analysis",
            target_audience="active_traders"
        )
        
        # æ¸¬è©¦è‚¡ç¥¨é…ç½®
        test_stock = StockProfile(
            stock_code="2208",
            stock_name="å°èˆ¹",
            industry="èˆªé‹",
            market_cap="medium",
            volatility="high",
            news_frequency="high"
        )
        
        # åŸ·è¡Œæ•¸æ“šæºåˆ†é…
        assignment = smart_assigner.assign_data_sources(
            kol_profile=test_kol,
            stock_profile=test_stock,
            batch_context={'trigger_type': 'after_hours_limit_up'}
        )
        
        return {
            "success": True,
            "kol_profile": {
                "serial": test_kol.serial,
                "nickname": test_kol.nickname,
                "persona": test_kol.persona
            },
            "stock_profile": {
                "stock_code": test_stock.stock_code,
                "stock_name": test_stock.stock_name,
                "market_cap": test_stock.market_cap,
                "volatility": test_stock.volatility
            },
            "data_source_assignment": {
                "primary_sources": [source.value for source in assignment.primary_sources],
                "secondary_sources": [source.value for source in assignment.secondary_sources],
                "excluded_sources": [source.value for source in assignment.excluded_sources],
                "assignment_reason": assignment.assignment_reason,
                "confidence_score": assignment.confidence_score
            }
        }
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šæºåˆ†é…èª¿è©¦å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/debug/data-source-usage")
async def debug_data_source_usage():
    """èª¿è©¦æ•¸æ“šæºå¯¦éš›ä½¿ç”¨æƒ…æ³"""
    try:
        # ç²å–æœ€è¿‘çš„è²¼æ–‡
        all_posts = get_post_record_service().get_all_posts()
        recent_posts = sorted(all_posts, key=lambda x: x.created_at, reverse=True)[:5]
        
        usage_analysis = []
        
        for post in recent_posts:
            # è§£æç”Ÿæˆåƒæ•¸
            generation_params = post.generation_params or {}
            if hasattr(generation_params, '__dict__'):
                generation_params = generation_params.__dict__
            
            data_sources = generation_params.get('data_sources', {})
            smart_assigned = generation_params.get('smart_assigned', [])
            assignment_reason = generation_params.get('assignment_reason', '')
            
            usage_analysis.append({
                "post_id": post.post_id,
                "title": post.title,
                "stock_code": post.stock_code,
                "kol_serial": post.kol_serial,
                "generation_params": {
                    "data_sources": data_sources,
                    "smart_assigned": smart_assigned,
                    "assignment_reason": assignment_reason
                },
                "content_preview": post.content[:200] + "..." if len(post.content) > 200 else post.content
            })
        
        return {
            "success": True,
            "total_posts": len(all_posts),
            "recent_posts_analysis": usage_analysis,
            "data_source_summary": {
                "smart_assignment_used": sum(1 for post in recent_posts 
                                           if post.generation_params and 
                                           hasattr(post.generation_params, 'smart_assigned')),
                "batch_data_sources_used": sum(1 for post in recent_posts 
                                              if post.generation_params and 
                                              hasattr(post.generation_params, 'data_sources')),
                "assignment_reasons_count": len(set(getattr(post.generation_params, 'assignment_reason', '') 
                                                   for post in recent_posts 
                                                   if post.generation_params))
            }
        }
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šæºä½¿ç”¨æƒ…æ³èª¿è©¦å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/posts/session/{session_id}")
async def get_session_posts(session_id: int, status: Optional[str] = None):
    """ç²å–æœƒè©±çš„æ‰€æœ‰è²¼æ–‡"""
    try:
        print(f"ğŸ” ç²å–æœƒè©±è²¼æ–‡: session_id={session_id}, status={status}")
        posts = get_post_record_service().get_session_posts(session_id, status)
        print(f"âœ… æ‰¾åˆ° {len(posts)} ç¯‡è²¼æ–‡")
        return {
            "success": True,
            "posts": posts,
            "count": len(posts),
            "timestamp": datetime.now()
        }
    except Exception as e:
        print(f"âŒ ç²å–æœƒè©±è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/post/batch-generate-stream")
async def batch_generate_posts_stream(request: BatchPostRequest):
    """
    æ‰¹é‡ç”Ÿæˆè²¼æ–‡ - ä½¿ç”¨Server-Sent Eventsä¸€å‰‡ä¸€å‰‡å›å‚³
    """
    print(f"ğŸš€ é–‹å§‹æ‰¹é‡ç™¼æ–‡ç”Ÿæˆ - æœƒè©±ID: {request.session_id}, è²¼æ–‡æ•¸é‡: {len(request.posts)}")
    
    async def generate_posts():
        total_posts = len(request.posts)
        successful_posts = 0
        failed_posts = 0
        
        print(f"ğŸ“Š æ‰¹é‡ç”Ÿæˆçµ±è¨ˆ: ç¸½æ•¸={total_posts}, æˆåŠŸ={successful_posts}, å¤±æ•—={failed_posts}")
        
        # ç”Ÿæˆ batch ç´šåˆ¥çš„å…±äº« commodity tags
        batch_commodity_tags = []
        
        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨ã€Œå…¨è²¼åŒç¾¤è‚¡æ¨™ã€
        should_use_shared_tags = False
        
        # å„ªå…ˆæª¢æŸ¥ tags_config ä¸­çš„ batch_shared_tags è¨­å®š
        if request.tags_config and request.tags_config.get('stock_tags', {}).get('batch_shared_tags', False):
            should_use_shared_tags = True
            print("ğŸ·ï¸ æ ¹æ“šå‰ç«¯æ¨™ç±¤é…ç½®å•Ÿç”¨å…¨è²¼åŒç¾¤è‚¡æ¨™")
        # å…¶æ¬¡æª¢æŸ¥ batch_config ä¸­çš„ shared_commodity_tags è¨­å®š
        elif request.batch_config.get('shared_commodity_tags', True):
            should_use_shared_tags = True
            print("ğŸ·ï¸ æ ¹æ“šæ‰¹é‡é…ç½®å•Ÿç”¨å…±äº«æ¨™ç±¤")
        
        if should_use_shared_tags:
            print("ğŸ·ï¸ ç”Ÿæˆ batch ç´šåˆ¥çš„å…±äº« commodity tags...")
            unique_stocks = set()
            for post_data in request.posts:
                stock_code = post_data.get('stock_code')
                if stock_code:
                    unique_stocks.add(stock_code)
            
            # æš«æ™‚ç¦ç”¨ commodity tag ç”Ÿæˆ
            print("âš ï¸ æ‰¹é‡ commodity tag ç”Ÿæˆæš«æ™‚ç¦ç”¨")
            
            print(f"âœ… ç”Ÿæˆ {len(batch_commodity_tags)} å€‹å…±äº« commodity tags: {[tag['key'] for tag in batch_commodity_tags]}")
        else:
            print("ğŸ·ï¸ æœªå•Ÿç”¨å…±äº«æ¨™ç±¤ï¼Œæ¯å€‹è²¼æ–‡å°‡ä½¿ç”¨ç¨ç«‹æ¨™ç±¤")
        
        # ç™¼é€é–‹å§‹äº‹ä»¶
        yield f"data: {json.dumps({'type': 'batch_start', 'total': total_posts, 'session_id': request.session_id, 'shared_tags_count': len(batch_commodity_tags)})}\n\n"
        
        for index, post_data in enumerate(request.posts):
            try:
                print(f"ğŸ“ é–‹å§‹ç”Ÿæˆç¬¬ {index + 1}/{total_posts} ç¯‡è²¼æ–‡...")
                
                # ç™¼é€é€²åº¦äº‹ä»¶
                progress = {
                    'type': 'progress',
                    'current': index + 1,
                    'total': total_posts,
                    'percentage': round((index + 1) / total_posts * 100, 1),
                    'successful': successful_posts,
                    'failed': failed_posts
                }
                yield f"data: {json.dumps(progress)}\n\n"
                
                # ç‚ºæ¯å€‹è²¼æ–‡æ™ºèƒ½åˆ†é…æ•¸æ“šæº
                print(f"ğŸ§  ç‚ºç¬¬ {index + 1} ç¯‡è²¼æ–‡æ™ºèƒ½åˆ†é…æ•¸æ“šæº...")
                
                # å‰µå»ºKOLå’Œè‚¡ç¥¨é…ç½®
                kol_profile = KOLProfile(
                    serial=int(post_data.get('kol_serial', 150)),
                    nickname=f"KOL-{post_data.get('kol_serial', 150)}",
                    persona=request.batch_config.get('kol_persona', 'technical'),
                    expertise_areas=[],
                    content_style=request.batch_config.get('content_style', 'chart_analysis'),
                    target_audience=request.batch_config.get('target_audience', 'active_traders')
                )
                
                stock_profile = StockProfile(
                    stock_code=post_data.get('stock_code'),
                    stock_name=post_data.get('stock_name'),
                    industry='unknown',
                    market_cap='medium',  # é è¨­ä¸­ç­‰å¸‚å€¼
                    volatility='medium',  # é è¨­ä¸­ç­‰æ³¢å‹•
                    news_frequency='medium'  # é è¨­ä¸­ç­‰æ–°èé »ç‡
                )
                
                # æ™ºèƒ½åˆ†é…æ•¸æ“šæº
                data_source_assignment = smart_assigner.assign_data_sources(
                    kol_profile=kol_profile,
                    stock_profile=stock_profile,
                    batch_context={'trigger_type': 'manual_batch'}
                )
                
                # åˆä½µæ™ºèƒ½åˆ†é…çš„æ•¸æ“šæºå’Œæ‰¹æ¬¡é…ç½®çš„æ•¸æ“šæº
                smart_sources = [source.value for source in data_source_assignment.primary_sources]
                batch_sources = request.data_sources or {}
                
                # å‰µå»ºæ··åˆæ•¸æ“šæºé…ç½® - å„ªå…ˆä½¿ç”¨æ™ºèƒ½åˆ†é…çš„æ•¸æ“šæº
                hybrid_data_sources = {
                    **batch_sources,  # æ‰¹æ¬¡é…ç½®çš„æ•¸æ“šæº
                    'smart_assigned': smart_sources,  # æ™ºèƒ½åˆ†é…çš„æ•¸æ“šæº
                    'assignment_reason': data_source_assignment.assignment_reason,
                    'confidence_score': data_source_assignment.confidence_score
                }
                
                # å¦‚æœæ™ºèƒ½åˆ†é…æœ‰æ•¸æ“šæºï¼Œå„ªå…ˆä½¿ç”¨æ™ºèƒ½åˆ†é…çš„
                if smart_sources:
                    # å°‡æ™ºèƒ½åˆ†é…çš„æ•¸æ“šæºè¨­ç‚ºä¸»è¦æ•¸æ“šæº
                    for source in smart_sources:
                        if source == 'ohlc_api':
                            hybrid_data_sources['stock_price_api'] = True
                        elif source == 'revenue_api':
                            hybrid_data_sources['monthly_revenue_api'] = True
                        elif source == 'fundamental_api':
                            hybrid_data_sources['fundamental_data'] = ['è²¡å ±']
                        elif source == 'serper_api':
                            hybrid_data_sources['news_sources'] = ['å·¥å•†æ™‚å ±', 'ç¶“æ¿Ÿæ—¥å ±', 'ä¸­å¤®ç¤¾']
                        elif source == 'summary_api':
                            hybrid_data_sources['technical_indicators'] = ['MACD', 'RSI', 'ç§»å‹•å¹³å‡ç·š']
                
                print(f"ğŸ“Š æ•¸æ“šæºåˆ†é…: æ™ºèƒ½={smart_sources}, æ‰¹æ¬¡={list(batch_sources.keys())}")
                
                # ç”Ÿæˆå–®å€‹è²¼æ–‡
                post_request = PostingRequest(
                    stock_code=post_data.get('stock_code'),
                    stock_name=post_data.get('stock_name'),
                    kol_serial=post_data.get('kol_serial'),
                    kol_persona=request.batch_config.get('kol_persona', 'technical'),
                    content_style=request.batch_config.get('content_style', 'chart_analysis'),
                    target_audience=request.batch_config.get('target_audience', 'active_traders'),
                    batch_mode=True,
                    session_id=request.session_id,
                    data_sources=hybrid_data_sources,  # ä½¿ç”¨æ··åˆæ•¸æ“šæº
                    explainability_config=request.explainability_config,
                    news_config=request.news_config,
                    tags_config=request.tags_config,  # å‚³éæ¨™ç±¤é…ç½®
                    shared_commodity_tags=batch_commodity_tags  # å‚³éå…±äº«çš„ commodity tags
                )
                
                print(f"âš™ï¸ èª¿ç”¨å–®å€‹è²¼æ–‡ç”ŸæˆAPI...")
                result = await manual_post_content(post_request)
                print(f"âœ… ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”Ÿæˆå®Œæˆ: {result.success}")
                
                # ç™¼é€è²¼æ–‡ç”Ÿæˆå®Œæˆäº‹ä»¶
                post_response = {
                    'type': 'post_generated',
                    'success': result.success,
                    'post_id': result.post_id,
                    'content': result.content,
                    'error': result.error,
                    'timestamp': result.timestamp.isoformat(),
                    'progress': {
                        'current': index + 1,
                        'total': total_posts,
                        'percentage': round((index + 1) / total_posts * 100, 1)
                    }
                }
                
                if result.success:
                    successful_posts += 1
                    print(f"âœ… ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”ŸæˆæˆåŠŸ: {result.post_id}")
                else:
                    failed_posts += 1
                    print(f"âŒ ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”Ÿæˆå¤±æ•—: {result.error}")
                
                yield f"data: {json.dumps(post_response)}\n\n"
                
                # æ·»åŠ å»¶é²ï¼Œé¿å…éæ–¼é »ç¹çš„è«‹æ±‚
                await asyncio.sleep(0.5)
                
            except Exception as e:
                failed_posts += 1
                print(f"âŒ ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”Ÿæˆç•°å¸¸: {e}")
                error_response = {
                    'type': 'post_error',
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat(),
                    'progress': {
                        'current': index + 1,
                        'total': total_posts,
                        'percentage': round((index + 1) / total_posts * 100, 1)
                    }
                }
                yield f"data: {json.dumps(error_response)}\n\n"
        
        # ç™¼é€å®Œæˆäº‹ä»¶
        print(f"ğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆ: ç¸½æ•¸={total_posts}, æˆåŠŸ={successful_posts}, å¤±æ•—={failed_posts}")
        final_result = {
            'type': 'batch_complete',
            'total': total_posts,
            'successful': successful_posts,
            'failed': failed_posts,
            'session_id': request.session_id,
            'timestamp': datetime.now().isoformat()
        }
        yield f"data: {json.dumps(final_result)}\n\n"
    
    return StreamingResponse(
        generate_posts(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

@app.post("/posts/{post_id}/approve")
async def approve_post(post_id: str, request: Request):
    """å¯©æ ¸é€šéè²¼æ–‡"""
    logger.info(f"ğŸ” é–‹å§‹è™•ç†è²¼æ–‡å¯©æ ¸è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        # è¨˜éŒ„è«‹æ±‚è©³æƒ…
        logger.info(f"ğŸ“ å¯©æ ¸è«‹æ±‚è©³æƒ… - Post ID: {post_id}")
        
        # æª¢æŸ¥è²¼æ–‡æ˜¯å¦å­˜åœ¨
        existing_post = get_post_record_service().get_post_record(post_id)
        if not existing_post:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            logger.info(f"ğŸ“Š ç›®å‰è³‡æ–™åº«ä¸­çš„è²¼æ–‡æ•¸é‡: {get_post_record_service().get_posts_count()}")
            logger.info(f"ğŸ“‹ è³‡æ–™åº«ä¸­çš„è²¼æ–‡ ID åˆ—è¡¨: ç„¡æ³•ç²å–ï¼ˆPostgreSQL æ¨¡å¼ï¼‰")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
        
        logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç•¶å‰ç‹€æ…‹: {existing_post.status}")
        
        # è§£æè«‹æ±‚å…§å®¹
        body = await request.json()
        reviewer_notes = body.get("reviewer_notes")
        approved_by = body.get("approved_by", "system")
        
        logger.info(f"ğŸ“ å¯©æ ¸åƒæ•¸ - å¯©æ ¸è€…: {approved_by}, å‚™è¨»: {reviewer_notes}")
        
        # å‰µå»ºæ›´æ–°è³‡æ–™
        update_data = {
            "status": "approved",
            "reviewer_notes": reviewer_notes,
            "approved_by": approved_by,
            "approved_at": datetime.now()
        }
        
        logger.info(f"ğŸ”„ é–‹å§‹æ›´æ–°è²¼æ–‡ç‹€æ…‹ - Post ID: {post_id}")
        
        # æ›´æ–°è²¼æ–‡è¨˜éŒ„
        post_record = get_post_record_service().update_post_record(post_id, update_data)
        
        if post_record:
            logger.info(f"âœ… è²¼æ–‡å¯©æ ¸æˆåŠŸ - Post ID: {post_id}, æ–°ç‹€æ…‹: {post_record.status}")
            logger.info(f"ğŸ“Š æ›´æ–°å¾Œè³‡æ–™åº«ç‹€æ…‹ - ç¸½è²¼æ–‡æ•¸: {get_post_record_service().get_posts_count()}")
            
            return {
                "success": True,
                "message": "è²¼æ–‡å¯©æ ¸é€šé",
                "post": {
                    "post_id": post_record.post_id,
                    "status": post_record.status,
                    "approved_by": post_record.approved_by,
                    "approved_at": post_record.approved_at.isoformat() if post_record.approved_at else None,
                    "reviewer_notes": post_record.reviewer_notes
                },
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ æ›´æ–°è²¼æ–‡å¤±æ•— - Post ID: {post_id}")
            raise HTTPException(status_code=500, detail="æ›´æ–°è²¼æ–‡å¤±æ•—")
            
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}, è©³æƒ…: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"âŒ å¯©æ ¸è²¼æ–‡æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        logger.error(f"ğŸ” éŒ¯èª¤é¡å‹: {type(e).__name__}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"å¯©æ ¸å¤±æ•—: {str(e)}")

@app.post("/posts/{post_id}/reject")
async def reject_post(post_id: str, request: Request):
    """æ‹’çµ•è²¼æ–‡"""
    logger.info(f"ğŸ” é–‹å§‹è™•ç†è²¼æ–‡æ‹’çµ•è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        # æª¢æŸ¥è²¼æ–‡æ˜¯å¦å­˜åœ¨
        existing_post = get_post_record_service().get_post_record(post_id)
        if not existing_post:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            logger.info(f"ğŸ“Š ç›®å‰è³‡æ–™åº«ä¸­çš„è²¼æ–‡æ•¸é‡: {get_post_record_service().get_posts_count()}")
            logger.info(f"ğŸ“‹ è³‡æ–™åº«ä¸­çš„è²¼æ–‡ ID åˆ—è¡¨: ç„¡æ³•ç²å–ï¼ˆPostgreSQL æ¨¡å¼ï¼‰")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
        
        logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç•¶å‰ç‹€æ…‹: {existing_post.status}")
        
        # è§£æè«‹æ±‚å…§å®¹
        body = await request.json()
        reviewer_notes = body.get("reviewer_notes", "æ‹’çµ•")
        
        logger.info(f"ğŸ“ æ‹’çµ•åƒæ•¸ - å‚™è¨»: {reviewer_notes}")
        
        # å‰µå»ºæ›´æ–°è³‡æ–™
        update_data = {
            "status": "rejected",
            "reviewer_notes": reviewer_notes,
            "approved_by": "system"
        }
        
        logger.info(f"ğŸ”„ é–‹å§‹æ›´æ–°è²¼æ–‡ç‹€æ…‹ç‚ºæ‹’çµ• - Post ID: {post_id}")
        
        # æ›´æ–°è²¼æ–‡è¨˜éŒ„
        post_record = get_post_record_service().update_post_record(post_id, update_data)
        
        if post_record:
            logger.info(f"âœ… è²¼æ–‡æ‹’çµ•æˆåŠŸ - Post ID: {post_id}, æ–°ç‹€æ…‹: {post_record.status}")
            return {
                "success": True,
                "message": "è²¼æ–‡å·²æ‹’çµ•",
                "post": {
                    "post_id": post_record.post_id,
                    "status": post_record.status,
                    "reviewer_notes": post_record.reviewer_notes
                },
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ æ›´æ–°è²¼æ–‡å¤±æ•— - Post ID: {post_id}")
            raise HTTPException(status_code=500, detail="æ›´æ–°è²¼æ–‡å¤±æ•—")
            
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}, è©³æƒ…: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"âŒ æ‹’çµ•è²¼æ–‡æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"æ‹’çµ•å¤±æ•—: {str(e)}")

@app.post("/posts/{post_id}/publish")
async def publish_post_to_cmoney(post_id: str, cmoney_config: Optional[Dict[str, Any]] = None):
    """ç™¼å¸ƒè²¼æ–‡åˆ°CMoney"""
    try:
        # ç²å–è²¼æ–‡è¨˜éŒ„
        post_record = get_post_record_service().get_post_record(post_id)
        if not post_record:
            raise HTTPException(status_code=404, detail="è²¼æ–‡ä¸å­˜åœ¨")
        
        if post_record.status != "approved":
            raise HTTPException(status_code=400, detail="åªæœ‰å·²å¯©æ ¸çš„è²¼æ–‡æ‰èƒ½ç™¼å¸ƒ")
        
        # ä½¿ç”¨ç™¼ä½ˆæœå‹™ç™¼ä½ˆè²¼æ–‡
        from publish_service import publish_service
        publish_result = await publish_service.publish_post(post_record)
        
        # æ›´æ–°è²¼æ–‡ç‹€æ…‹ç‚ºpublished
        update_data = {
            "status": "published",
            "published_at": datetime.now(),
            "cmoney_post_id": publish_result["post_id"],
            "cmoney_post_url": publish_result["post_url"]
        }
        
        updated_post = get_post_record_service().update_post_record(post_id, update_data)
        
        return publish_result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"ç™¼å¸ƒå¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
            "post_id": post_id,
            "timestamp": datetime.now().isoformat()
        }

@app.get("/posts/{post_id}")
async def get_post(post_id: str):
    """ç²å–å–®å€‹è²¼æ–‡è©³æƒ…"""
    logger.info(f"ğŸ” ç²å–è²¼æ–‡è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        post_record = get_post_record_service().get_post_record(post_id)
        if post_record:
            logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç‹€æ…‹: {post_record.status}")
            
            # å°‡è²¼æ–‡è¨˜éŒ„è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„å­—å…¸
            post_data = {
                "post_id": post_record.post_id,
                "session_id": post_record.session_id,
                "kol_serial": post_record.kol_serial,
                "kol_nickname": post_record.kol_nickname,
                "kol_persona": post_record.kol_persona,
                "stock_code": post_record.stock_code,
                "stock_name": post_record.stock_name,
                "title": post_record.title,
                "content": post_record.content,
                "content_md": post_record.content_md,
                "status": post_record.status,
                "quality_score": post_record.quality_score,
                "ai_detection_score": post_record.ai_detection_score,
                "risk_level": post_record.risk_level,
                "reviewer_notes": post_record.reviewer_notes,
                "approved_by": post_record.approved_by,
                "approved_at": post_record.approved_at.isoformat() if post_record.approved_at else None,
                "scheduled_at": post_record.scheduled_at.isoformat() if post_record.scheduled_at else None,
                "published_at": post_record.published_at.isoformat() if post_record.published_at else None,
                "cmoney_post_id": post_record.cmoney_post_id,
                "cmoney_post_url": post_record.cmoney_post_url,
                "publish_error": post_record.publish_error,
                "views": post_record.views,
                "likes": post_record.likes,
                "comments": post_record.comments,
                "shares": post_record.shares,
                "topic_id": post_record.topic_id,
                "topic_title": post_record.topic_title,
                "created_at": post_record.created_at.isoformat() if post_record.created_at else None,
                "updated_at": post_record.updated_at.isoformat() if post_record.updated_at else None
            }
            
            return {
                "success": True,
                "post": post_data,
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
            
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}")
        raise e
    except Exception as e:
        logger.error(f"âŒ ç²å–è²¼æ–‡æ™‚ç™¼ç”ŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"ç²å–è²¼æ–‡å¤±æ•—: {str(e)}")

@app.get("/posts/{post_id}/self-learning-data")
async def get_post_self_learning_data(post_id: str):
    """ç²å–è²¼æ–‡çš„è‡ªæˆ‘å­¸ç¿’æ•¸æ“š - ç”¨æ–¼é‡å»ºç›¸åŒå…§å®¹"""
    logger.info(f"ğŸ§  ç²å–è‡ªæˆ‘å­¸ç¿’æ•¸æ“š - Post ID: {post_id}")
    
    try:
        post_record = get_post_record_service().get_post_record(post_id)
        if not post_record:
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
        
        # æº–å‚™è‡ªæˆ‘å­¸ç¿’æ•¸æ“š
        self_learning_data = {
            "post_id": post_record.post_id,
            "session_id": post_record.session_id,
            "kol_serial": post_record.kol_serial,
            "kol_nickname": post_record.kol_nickname,
            "kol_persona": post_record.kol_persona,
            "stock_code": post_record.stock_code,
            "stock_name": post_record.stock_name,
            
            # ç”Ÿæˆåƒæ•¸ - ç”¨æ–¼é‡å»ºç›¸åŒå…§å®¹
            "generation_params": post_record.generation_params.model_dump() if post_record.generation_params else {},
            
            # æŠ€è¡“åˆ†ææ•¸æ“š
            "technical_analysis": post_record.technical_analysis,
            
            # Serper æ–°èæ•¸æ“š
            "serper_data": post_record.serper_data,
            
            # å•†å“æ¨™ç±¤
            "commodity_tags": [tag.model_dump() for tag in post_record.commodity_tags] if post_record.commodity_tags else [],
            
            # ç¤¾ç¾¤è©±é¡Œ
            "community_topic": post_record.community_topic.model_dump() if post_record.community_topic else None,
            
            # å“è³ªè©•ä¼°æ•¸æ“š
            "quality_score": post_record.quality_score,
            "ai_detection_score": post_record.ai_detection_score,
            "risk_level": post_record.risk_level,
            
            # æ™‚é–“æˆ³è¨˜
            "created_at": post_record.created_at.isoformat() if post_record.created_at else None,
            
            # é‡å»ºæ‰€éœ€çš„å…¶ä»–åƒæ•¸
            "content_length": post_record.generation_params.content_style if post_record.generation_params else "chart_analysis",
            "target_audience": post_record.generation_params.target_audience if post_record.generation_params else "active_traders",
            "data_sources": post_record.generation_params.data_sources if post_record.generation_params else [],
            "technical_indicators": post_record.generation_params.technical_indicators if post_record.generation_params else []
        }
        
        logger.info(f"âœ… è‡ªæˆ‘å­¸ç¿’æ•¸æ“šæº–å‚™å®Œæˆ - Post ID: {post_id}")
        logger.info(f"ğŸ“Š æ•¸æ“šåŒ…å«: generation_params={bool(self_learning_data['generation_params'])}, "
                   f"technical_analysis={bool(self_learning_data['technical_analysis'])}, "
                   f"serper_data={bool(self_learning_data['serper_data'])}")
        
        return {
            "success": True,
            "self_learning_data": self_learning_data,
            "reconstruction_ready": bool(
                self_learning_data['generation_params'] and 
                self_learning_data['stock_code'] and 
                self_learning_data['kol_persona']
            ),
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}")
        raise e
    except Exception as e:
        logger.error(f"âŒ ç²å–è‡ªæˆ‘å­¸ç¿’æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"ç²å–è‡ªæˆ‘å­¸ç¿’æ•¸æ“šå¤±æ•—: {str(e)}")

@app.post("/test/kol-login/{kol_serial}")
async def test_kol_login(kol_serial: str):
    """æ¸¬è©¦ KOL ç™»å…¥åŠŸèƒ½"""
    logger.info(f"ğŸ” æ¸¬è©¦ KOL ç™»å…¥ - Serial: {kol_serial}")
    
    try:
        # ä½¿ç”¨ç™¼ä½ˆæœå‹™æ¸¬è©¦ç™»å…¥
        from publish_service import publish_service
        
        # æ¸¬è©¦ç™»å…¥
        access_token = await publish_service.login_kol(kol_serial)
        
        if access_token:
            logger.info(f"âœ… KOL {kol_serial} ç™»å…¥æ¸¬è©¦æˆåŠŸ")
            return {
                "success": True,
                "message": f"KOL {kol_serial} ç™»å…¥æˆåŠŸ",
                "has_token": bool(access_token),
                "token_preview": access_token[:20] + "..." if access_token else None,
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ KOL {kol_serial} ç™»å…¥æ¸¬è©¦å¤±æ•—")
            return {
                "success": False,
                "message": f"KOL {kol_serial} ç™»å…¥å¤±æ•—",
                "error": "ç„¡æ³•ç²å– access token",
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"âŒ KOL ç™»å…¥æ¸¬è©¦ç•°å¸¸: {e}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        return {
            "success": False,
            "message": f"KOL {kol_serial} ç™»å…¥æ¸¬è©¦ç•°å¸¸",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# Delete API å·²ç§»è‡³ routes/cmoney_routes.py

# ==================== æ–°å¢çš„å…§å®¹ç”Ÿæˆå‡½æ•¸ ====================

def generate_kol_content_with_serper(stock_id: str, stock_name: str, kol_persona: str, 
                                    content_style: str, target_audience: str,
                                    serper_analysis: Dict[str, Any],
                                    data_sources: List[str]) -> Dict[str, Any]:
    """ä½¿ç”¨Serperæ•¸æ“šç”ŸæˆKOLå…§å®¹"""
    
    try:
        # æå–Serperæ•¸æ“š
        news_items = serper_analysis.get('news_items', [])
        limit_up_analysis = serper_analysis.get('limit_up_analysis', {})
        limit_up_reasons = limit_up_analysis.get('limit_up_reasons', [])
        key_events = limit_up_analysis.get('key_events', [])
        market_sentiment = limit_up_analysis.get('market_sentiment', 'neutral')
        
        # æ§‹å»ºå¢å¼·ç‰ˆPrompt
        prompt_parts = []
        
        # 1. åŸºæœ¬åˆ†ææ¡†æ¶ - ç´”æ–‡å­—æ ¼å¼
        prompt_parts.append(f"{stock_name}({stock_id}) æ·±åº¦åˆ†æå ±å‘Š")
        prompt_parts.append("")
        prompt_parts.append("æ ¸å¿ƒè§€é»")
        prompt_parts.append("")
        
        # 2. æ•´åˆæ¼²åœåŸå› åˆ†æ
        if limit_up_reasons:
            prompt_parts.append(f"åŸºæ–¼æœ€æ–°å¸‚å ´è³‡è¨Šï¼Œ{stock_name} ç›®å‰è™•æ–¼å¼·å‹¢ä¸Šæ¼²ç‹€æ…‹ï¼š")
            for reason in limit_up_reasons[:2]:  # å–å‰2å€‹åŸå› 
                prompt_parts.append(f"- {reason['title']}: {reason['snippet'][:150]}")
        else:
            prompt_parts.append(f"{stock_name} ç›®å‰è™•æ–¼æŠ€è¡“é¢å¼·å‹¢ç‹€æ…‹ï¼Œå¤šé …æŒ‡æ¨™é¡¯ç¤ºä¸Šæ¼²å‹•èƒ½ã€‚")
        
        prompt_parts.append("")
        
        # 3. æŠ€è¡“åˆ†æéƒ¨åˆ†
        if 'ohlc_api' in data_sources:
            prompt_parts.append("æŠ€è¡“é¢åˆ†æ")
            prompt_parts.append("- MA5/MA20: é»ƒé‡‘äº¤å‰ç¢ºèªå¤šé ­è¶¨å‹¢")
            prompt_parts.append("- RSI14: ä¸­æ€§åå¤šï¼Œä»æœ‰ä¸Šæ¼²ç©ºé–“")
            prompt_parts.append("- MACDæŸ±ç‹€é«”: å¤šé ­è¨Šè™ŸæŒçºŒ")
            prompt_parts.append("")
        
        # 4. åŸºæœ¬é¢åˆ†æéƒ¨åˆ†
        if 'fundamental_api' in data_sources:
            prompt_parts.append("åŸºæœ¬é¢åˆ†æ")
            if key_events:
                prompt_parts.append("é—œéµäº‹ä»¶åˆ†æ:")
                for event in key_events[:2]:
                    prompt_parts.append(f"- {event['event']}: {event['description'][:100]}")
            else:
                prompt_parts.append("- è²¡å‹™æŒ‡æ¨™ç©©å¥ï¼Œç‡Ÿæ”¶æˆé•·å‹•èƒ½å¼·å‹")
                prompt_parts.append("- ç”¢æ¥­å‰æ™¯çœ‹å¥½ï¼Œé•·æœŸæŠ•è³‡åƒ¹å€¼é¡¯ç¾")
            prompt_parts.append("")
        
        # 5. æ–°èæ•´åˆéƒ¨åˆ†
        if news_items and 'serper_api' in data_sources:
            prompt_parts.append("å¸‚å ´å‹•æ…‹")
            prompt_parts.append("æœ€æ–°å¸‚å ´è³‡è¨Š:")
            for news in news_items[:2]:  # å–å‰2å‰‡æ–°è
                prompt_parts.append(f"- {news['title']}: {news['snippet'][:150]}")
            prompt_parts.append("")
        
        # 6. æŠ•è³‡å»ºè­°
        prompt_parts.append("æŠ•è³‡å»ºè­°")
        if market_sentiment == 'positive':
            prompt_parts.append("åŸºæ–¼æŠ€è¡“é¢å’ŒåŸºæœ¬é¢åˆ†æï¼Œå»ºè­°ç©æ¥µå¸ƒå±€ï¼Œç›®æ¨™åƒ¹ä½å¯æœŸå¾…15-20%æ¼²å¹…ã€‚")
        elif market_sentiment == 'negative':
            prompt_parts.append("é›–ç„¶æŠ€è¡“é¢å¼·å‹¢ï¼Œä½†éœ€æ³¨æ„åŸºæœ¬é¢é¢¨éšªï¼Œå»ºè­°è¬¹æ…æ“ä½œï¼Œè¨­å¥½åœæé»ä½ã€‚")
        else:
            prompt_parts.append("åŸºæ–¼ç¶œåˆåˆ†æï¼Œå»ºè­°é€¢ä½å¸ƒå±€ï¼Œç›®æ¨™åƒ¹ä½å¯æœŸå¾…10-15%æ¼²å¹…ã€‚")
        prompt_parts.append("")
        
        # 7. é¢¨éšªæé†’
        prompt_parts.append("é¢¨éšªæé†’")
        prompt_parts.append("- æ³¨æ„å¤§ç›¤ç’°å¢ƒè®ŠåŒ–")
        prompt_parts.append("- è¨­å¥½åœæé»ä½")
        prompt_parts.append("- åˆ†æ‰¹é€²å ´é™ä½é¢¨éšª")
        prompt_parts.append("")
        
        # 8. æ“ä½œç­–ç•¥
        prompt_parts.append("æ“ä½œç­–ç•¥")
        prompt_parts.append("1. é€²å ´æ™‚æ©Ÿ: å›æ¸¬æ”¯æ’æ™‚åˆ†æ‰¹è²·é€²")
        prompt_parts.append("2. åœæè¨­å®š: è·Œç ´é—œéµæ”¯æ’ä½")
        prompt_parts.append("3. ç›®æ¨™åƒ¹ä½: æŠ€è¡“ç›®æ¨™åƒ¹ä½")
        prompt_parts.append("4. æŒè‚¡æ¯”ä¾‹: å»ºè­°æ§åˆ¶åœ¨ç¸½è³‡ç”¢10%ä»¥å…§")
        
        # 9. å…è²¬è²æ˜
        prompt_parts.append("")
        prompt_parts.append("ä»¥ä¸Šåˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°")
        prompt_parts.append("")
        
        # 10. æ•¸æ“šä¾†æºæ¨™è¨»
        prompt_parts.append("æ•¸æ“šä¾†æº")
        data_source_names = {
            'ohlc_api': 'æŠ€è¡“æŒ‡æ¨™æ•¸æ“š',
            'serper_api': 'æœ€æ–°æ–°èè³‡è¨Š',
            'fundamental_api': 'åŸºæœ¬é¢æ•¸æ“š',
            'summary_api': 'å¸‚å ´æ‘˜è¦åˆ†æ',
            'revenue_api': 'ç‡Ÿæ”¶æ•¸æ“š',
            'financial_api': 'è²¡å‹™æ•¸æ“š'
        }
        used_sources = [data_source_names.get(source, source) for source in data_sources]
        prompt_parts.append(f"æœ¬åˆ†ææ•´åˆäº†: {', '.join(used_sources)}")
        
        # çµ„åˆå®Œæ•´å…§å®¹
        content_md = "\n".join(prompt_parts)
        
        # ç”Ÿæˆæ¨™é¡Œ - ç´”æ–‡å­—æ ¼å¼
        title = f"{stock_name} æ·±åº¦åˆ†æ"
        
        return {
            "title": title,
            "content": content_md,
            "content_md": content_md,
            "stock_id": stock_id,
            "stock_name": stock_name,
            "kol_persona": kol_persona,
            "content_style": content_style,
            "target_audience": target_audience,
            "data_sources": data_sources,
            "serper_integration": True,
            "news_count": len(news_items),
            "market_sentiment": market_sentiment,
            "generation_timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"Serperå…§å®¹ç”Ÿæˆå¤±æ•—: {e}")
        # å›é€€åˆ°åŸºæœ¬å…§å®¹ç”Ÿæˆ
        return generate_kol_content_direct(stock_id, stock_name, kol_persona, content_style, target_audience)

def enhance_content_with_serper_data(kol_content: Dict[str, Any], 
                                   serper_analysis: Dict[str, Any],
                                   data_source_assignment) -> Dict[str, Any]:
    """ä½¿ç”¨Serperæ•¸æ“šå¢å¼·å…§å®¹"""
    
    try:
        enhanced_content = kol_content.copy()
        
        # ç²å–æ–°èæ•¸æ“š
        news_items = serper_analysis.get('news_items', [])
        limit_up_analysis = serper_analysis.get('limit_up_analysis', {})
        
        # å¦‚æœæœ‰æ–°èæ•¸æ“šï¼Œæ•´åˆåˆ°å…§å®¹ä¸­
        if news_items:
            print(f"ğŸ”— æ•´åˆ {len(news_items)} å‰‡æ–°èåˆ°å…§å®¹ä¸­")
            
            # æå–æ–°èæ‘˜è¦å’Œé€£çµ
            news_summary = []
            news_sources = []
            print(f"ğŸ” è™•ç† {len(news_items)} å‰‡æ–°è...")
            for i, news in enumerate(news_items[:5]):  # å–å‰5å‰‡æ–°è
                title = news.get('title', '')
                snippet = news.get('snippet', '')
                link = news.get('link', '')
                print(f"  æ–°è {i+1}: title='{title[:30]}...', snippet='{snippet[:30]}...', link='{link[:30]}...'")
                if title and snippet:
                    # æ–°èæ‘˜è¦ï¼ˆç°¡åŒ–ç‰ˆï¼Œä¸åŒ…å«emojiå’Œmarkdownï¼‰
                    news_summary.append(f"{title}: {snippet[:100]}...")
                    # æ–°èä¾†æºï¼ˆç”¨æ–¼æœ€å¾Œçš„ä¾†æºåˆ—è¡¨ï¼‰
                    if link:
                        news_sources.append(f"{i+1}. {title}\n   é€£çµ: {link}")
                        print(f"    âœ… æ·»åŠ æ–°èä¾†æº {i+1} (æœ‰é€£çµ): {link}")
                    else:
                        news_sources.append(f"{i+1}. {title}")
                        print(f"    âœ… æ·»åŠ æ–°èä¾†æº {i+1} (ç„¡é€£çµ)")
                else:
                    print(f"    âŒ è·³éæ–°è {i+1} (æ¨™é¡Œæˆ–æ‘˜è¦ç‚ºç©º)")
            
            # æ•´åˆæ–°èåˆ°å…§å®¹ä¸­
            original_content = enhanced_content.get('content', '')
            original_content_md = enhanced_content.get('content_md', '')
            
            # ä¸æ·»åŠ æ–°èæ‘˜è¦åˆ°å…§å®¹é–‹é ­ï¼Œåªä¿ç•™åŸå§‹å…§å®¹
            enhanced_content['content'] = original_content
            enhanced_content['content_md'] = original_content_md
            
            # åœ¨å…§å®¹æœ€å¾Œæ·»åŠ æ–°èä¾†æº
            print(f"ğŸ” æ–°èä¾†æºåˆ—è¡¨: {len(news_sources)} å€‹")
            for i, source in enumerate(news_sources):
                print(f"   {i+1}. {source[:50]}...")
            
            if news_sources:
                sources_section = "\n\næ–°èä¾†æº:\n" + "\n".join(news_sources)
                enhanced_content['content'] += sources_section
                enhanced_content['content_md'] += sources_section
                print(f"âœ… æ–°èä¾†æºå·²æ·»åŠ : {len(sources_section)} å­—")
            else:
                print("âš ï¸ æ²’æœ‰æ–°èä¾†æºå¯æ·»åŠ ")
            
            print(f"âœ… æ–°èæ•´åˆå®Œæˆï¼Œå…§å®¹é•·åº¦: {len(enhanced_content['content'])} å­—")
        
        # æ·»åŠ Serperæ•¸æ“šåˆ°å…§å®¹ä¸­
        enhanced_content.update({
            "serper_data": serper_analysis,
            "data_source_assignment": {
                "primary_sources": [source.value for source in data_source_assignment.primary_sources],
                "secondary_sources": [source.value for source in data_source_assignment.secondary_sources],
                "assignment_reason": data_source_assignment.assignment_reason,
                "confidence_score": data_source_assignment.confidence_score
            },
            "news_integration": True,
            "limit_up_analysis": limit_up_analysis,
            "market_sentiment": limit_up_analysis.get('market_sentiment', 'neutral')
        })
        
        return enhanced_content
        
    except Exception as e:
        print(f"Serperæ•¸æ“šå¢å¼·å¤±æ•—: {e}")
        return kol_content

print("ğŸ‰ æ‰€æœ‰æ¨¡çµ„è¼‰å…¥å®Œæˆï¼")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)

