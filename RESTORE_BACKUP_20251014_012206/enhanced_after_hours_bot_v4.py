#!/usr/bin/env python3
"""
ä¿®æ­£ç‰ˆç›¤å¾Œæ¼²åœæ©Ÿå™¨äºº V4
æ•´åˆæ‰€æœ‰ä¿®æ­£ï¼š
1. æ­£ç¢ºçš„ Google Sheets æ¬„ä½æ˜ å°„
2. Finlab æ•¸æ“šä½¿ç”¨å’Œè¨˜éŒ„
3. Serper API æ–°èæŠ“å–
4. Markdown æ ¼å¼æ”¯æ´
5. æ–°èä¾†æºé€£çµ
"""

import os
import sys
import asyncio
import requests
from datetime import datetime
from dotenv import load_dotenv
from typing import List, Dict, Any
import pandas as pd
import finlab
import finlab.data as fdata

load_dotenv()

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.sheets.enhanced_sheets_recorder import EnhancedSheetsRecorder, EnhancedPostRecord
from src.services.content.content_generator import ContentGenerator, ContentRequest
from src.clients.cmoney.cmoney_client import CMoneyClient, LoginCredentials
from smart_api_allocator import SmartAPIAllocator, StockAnalysis

# Serper API æ–°èæœå°‹å®¢æˆ¶ç«¯
class SerperNewsClient:
    """Serper API æ–°èæœå°‹å®¢æˆ¶ç«¯"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://google.serper.dev/search"
    
    def search_stock_news(self, stock_id: str, stock_name: str, num_results: int = 3) -> List[Dict[str, Any]]:
        """æœå°‹è‚¡ç¥¨ç›¸é—œæ–°è"""
        try:
            headers = {
                "X-API-KEY": self.api_key,
                "Content-Type": "application/json"
            }
            
            # æ›´ç²¾ç¢ºçš„æœå°‹æŸ¥è©¢ï¼ŒåŒ…å«è‚¡ç¥¨ä»£è™Ÿ
            search_query = f'"{stock_name}" "{stock_id}" æ¼²åœ ä»Šæ—¥ æ–°è'
            
            payload = {
                "q": search_query,
                "num": num_results,
                "gl": "tw",  # å°ç£åœ°å€
                "hl": "zh-tw"  # ç¹é«”ä¸­æ–‡
            }
            
            response = requests.post(self.base_url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            organic_results = data.get('organic', [])
            
            # éæ¿¾å‡ºç›¸é—œçš„æ–°è
            relevant_news = []
            for result in organic_results:
                title = result.get('title', '')
                snippet = result.get('snippet', '')
                link = result.get('link', '')
                
                # æ›´åš´æ ¼çš„ç›¸é—œæ€§æª¢æŸ¥
                title_lower = title.lower()
                snippet_lower = snippet.lower()
                
                # å¿…é ˆåŒ…å«è‚¡ç¥¨ä»£è™Ÿæˆ–è‚¡ç¥¨åç¨±
                has_stock_id = stock_id in title or stock_id in snippet
                has_stock_name = stock_name.lower() in title_lower or stock_name.lower() in snippet_lower
                has_limit_up = 'æ¼²åœ' in title or 'æ¼²åœ' in snippet
                
                if (has_stock_id or has_stock_name) and has_limit_up:
                    relevant_news.append({
                        'title': title,
                        'snippet': snippet,
                        'link': link,
                        'date': result.get('date', '')
                    })
            
            return relevant_news
            
        except Exception as e:
            print(f"âŒ Serper API æœå°‹å¤±æ•—: {e}")
            return []

# è‚¡ç¥¨åç¨±å°ç…§è¡¨ (ä½¿ç”¨æ­£ç¢ºçš„è‚¡ç¥¨ä»£è™Ÿ)
stock_name_mapping = {
    "1587": "ä»²ç¦",
    "2436": "å‰è©®é›»", 
    "2642": "æ±Ÿèˆˆé›",
    "2330": "å°ç©é›»",
    "2317": "é´»æµ·",
    "2454": "è¯ç™¼ç§‘",
    "2419": "ä»²ç¦",  # ä»²ç¦çš„æ­£ç¢ºä»£è™Ÿ
    "4528": "æ±Ÿèˆˆé›",  # æ±Ÿèˆˆé›çš„æ­£ç¢ºä»£è™Ÿ
    # ... å…¶ä»–è‚¡ç¥¨
}

def get_stock_name_from_id(stock_id: str) -> str:
    return stock_name_mapping.get(stock_id, f"è‚¡ç¥¨{stock_id}")

async def get_real_limit_up_stocks():
    """ç²å–çœŸå¯¦çš„ä»Šæ—¥æ¼²åœè‚¡ç¥¨æ•¸æ“š"""
    try:
        # ç™»å…¥ Finlab
        finlab_key = os.getenv('FINLAB_API_KEY')
        if not finlab_key:
            print("âš ï¸ æ²’æœ‰ FINLAB_API_KEYï¼Œç„¡æ³•ç²å–çœŸå¯¦æ•¸æ“š")
            return None
        
        finlab.login(finlab_key)
        
        # ç²å–æ”¶ç›¤åƒ¹å’Œæˆäº¤é‡‘é¡æ•¸æ“š
        close_price = fdata.get('price:æ”¶ç›¤åƒ¹')
        volume_amount = fdata.get('price:æˆäº¤é‡‘é¡')
        
        if close_price is None or volume_amount is None:
            print("âš ï¸ ç„¡æ³•ç²å– Finlab æ•¸æ“š")
            return None
        
        limit_up_stocks = []
        
        # ç²å–æœ€æ–°ä¸€å¤©æ•¸æ“š
        today_close = close_price.iloc[-1]
        today_volume = volume_amount.iloc[-1]
        
        # è¨ˆç®—å‰ä¸€æ—¥æ”¶ç›¤åƒ¹
        prev_close = close_price.iloc[-2] if len(close_price) > 1 else None
        
        if prev_close is not None:
            for stock_id in today_close.index:
                if pd.notna(today_close[stock_id]) and pd.notna(prev_close[stock_id]):
                    current_price = today_close[stock_id]
                    prev_price = prev_close[stock_id]
                    change_percent = ((current_price - prev_price) / prev_price) * 100
                    
                    # æª¢æŸ¥æ˜¯å¦æ¼²åœï¼ˆæ¼²å¹… >= 9.5%ï¼‰
                    if change_percent >= 9.5:
                        volume_val = today_volume[stock_id] if pd.notna(today_volume[stock_id]) else 0
                        volume_amount_billion = volume_val / 100000000  # è½‰æ›ç‚ºå„„
                        
                        stock_name = get_stock_name_from_id(stock_id)
                        
                        limit_up_stocks.append({
                            'stock_id': stock_id,
                            'stock_name': stock_name,
                            'change_percent': change_percent,
                            'volume_amount': volume_amount_billion,
                            'current_price': current_price,
                            'prev_price': prev_price,
                            'is_high_volume': volume_amount_billion >= 1.0
                        })
        
        print(f"ğŸ“Š Finlab æ•¸æ“šæª¢æŸ¥å®Œæˆï¼Œæ‰¾åˆ° {len(limit_up_stocks)} æª”æ¼²åœè‚¡ç¥¨")
        return limit_up_stocks
        
    except Exception as e:
        print(f"âŒ ç²å–çœŸå¯¦æ¼²åœè‚¡æ•¸æ“šå¤±æ•—: {e}")
        return None

def format_news_sources(news_list: List[Dict[str, Any]]) -> str:
    """æ ¼å¼åŒ–æ–°èä¾†æº"""
    if not news_list:
        return ""
    
    news_sources = "\n\nğŸ“° ç›¸é—œæ–°èä¾†æºï¼š\n"
    for i, news in enumerate(news_list, 1):
        news_sources += f"{i}. {news['title']}\n"
        news_sources += f"   {news['link']}\n"
        if news.get('snippet'):
            news_sources += f"   {news['snippet'][:100]}...\n"
        news_sources += "\n"
    
    return news_sources

async def test_enhanced_after_hours_bot():
    """æ¸¬è©¦å¢å¼·ç‰ˆç›¤å¾Œæ©Ÿå™¨äºº"""
    print("ğŸš€ å¢å¼·ç‰ˆç›¤å¾Œæ¼²åœæ©Ÿå™¨äºº V4 - å®Œæ•´åŠŸèƒ½æ¸¬è©¦")
    print("=" * 80)

    # 1. åˆå§‹åŒ–çµ„ä»¶
    print("\nğŸ“‹ æ­¥é©Ÿ 1: åˆå§‹åŒ–çµ„ä»¶...")
    sheets_recorder = EnhancedSheetsRecorder()
    content_generator = ContentGenerator()
    smart_allocator = SmartAPIAllocator()
    
    # åˆå§‹åŒ– Serper API
    serper_api_key = os.getenv('SERPER_API_KEY')
    if serper_api_key:
        serper_client = SerperNewsClient(serper_api_key)
        print("âœ… Serper API å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
    else:
        print("âš ï¸ æ²’æœ‰ SERPER_API_KEYï¼Œå°‡è·³éæ–°èæœå°‹")
        serper_client = None
    
    print("âœ… æ‰€æœ‰çµ„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    # 2. ç²å–çœŸå¯¦æ¼²åœè‚¡æ•¸æ“š
    print("\nğŸ“‹ æ­¥é©Ÿ 2: ç²å–çœŸå¯¦æ¼²åœè‚¡æ•¸æ“š...")
    real_limit_up_stocks = await get_real_limit_up_stocks()
    
    if real_limit_up_stocks and len(real_limit_up_stocks) > 0:
        print(f"âœ… ç²å–åˆ° {len(real_limit_up_stocks)} æª”æ¼²åœè‚¡ç¥¨")
        # åªå–å‰3æª”é€²è¡Œæ¸¬è©¦
        stocks_for_processing = real_limit_up_stocks[:3]
        for stock in stocks_for_processing:
            print(f"  - {stock['stock_name']}({stock['stock_id']}): æ¼²å¹… {stock['change_percent']:.2f}%, æˆäº¤é‡‘é¡ {stock['volume_amount']:.2f}å„„")
    else:
        print("âš ï¸ ä»Šæ—¥ç„¡æ¼²åœè‚¡ç¥¨æˆ–ç„¡æ³•ç²å–æ•¸æ“šï¼Œä½¿ç”¨æ¨£æœ¬æ•¸æ“š")
        stocks_for_processing = [
            {"stock_id": "2330", "stock_name": "å°ç©é›»", "change_percent": 9.8, "volume_amount": 15.2, "is_high_volume": True},
            {"stock_id": "2317", "stock_name": "é´»æµ·", "change_percent": 9.9, "volume_amount": 0.8, "is_high_volume": False},
            {"stock_id": "2454", "stock_name": "è¯ç™¼ç§‘", "change_percent": 9.7, "volume_amount": 2.1, "is_high_volume": True}
        ]
    
    # 3. æ™ºèƒ½APIèª¿é…
    print("\nğŸ“‹ æ­¥é©Ÿ 3: æ™ºèƒ½APIèª¿é…...")
    stock_analyses = []
    for stock in stocks_for_processing:
        stock_analyses.append(StockAnalysis(
            stock_id=stock['stock_id'],
            stock_name=stock['stock_name'],
            volume_rank=1, # ç°¡åŒ–è™•ç†
            change_percent=stock['change_percent'],
            volume_amount=stock['volume_amount'],
            rank_type='high_volume' if stock['is_high_volume'] else 'low_volume'
        ))
    
    allocated_stocks = smart_allocator.allocate_apis_for_stocks(stock_analyses)
    
    stocks_data = []
    for stock in allocated_stocks:
        stock_dict = {
            "stock_id": stock.stock_id,
            "stock_name": stock.stock_name,
            "change_percent": stock.change_percent,
            "volume_amount": stock.volume_amount,
            "is_high_volume": stock.volume_amount >= 1.0,
            "assigned_apis": stock.assigned_apis
        }
        stocks_data.append(stock_dict)
    
    # 4. æœå°‹æ–°èä¸¦ç”Ÿæˆå…§å®¹
    print("\nğŸ“‹ æ­¥é©Ÿ 4: æœå°‹æ–°èä¸¦ç”Ÿæˆå…§å®¹...")
    
    generated_posts = []
    for i, stock_data in enumerate(stocks_data):
        print(f"\nğŸ“ è™•ç†ç¬¬ {i+1} ç¯‡è²¼æ–‡: {stock_data['stock_name']}({stock_data['stock_id']})")
        
        # æœå°‹ç›¸é—œæ–°è
        news_sources = ""
        if serper_client:
            print(f"ğŸ” æœå°‹ {stock_data['stock_name']} ç›¸é—œæ–°è...")
            news_list = serper_client.search_stock_news(
                stock_data['stock_id'], 
                stock_data['stock_name'], 
                num_results=3
            )
            if news_list:
                print(f"âœ… æ‰¾åˆ° {len(news_list)} ç¯‡ç›¸é—œæ–°è")
                news_sources = format_news_sources(news_list)
            else:
                print("âš ï¸ æœªæ‰¾åˆ°ç›¸é—œæ–°è")
        
        # æ§‹å»ºå¢å¼·çš„å¸‚å ´æ•¸æ“šï¼ŒåŒ…å«è©³ç´°çš„ Finlab æ•¸æ“š
        enhanced_market_data = {
            "stock_id": stock_data['stock_id'],
            "stock_name": stock_data['stock_name'],
            "change_percent": stock_data['change_percent'],
            "volume_amount": stock_data['volume_amount'],
            "is_high_volume": stock_data['is_high_volume'],
            "assigned_apis": stock_data['assigned_apis'],
            "has_stock": True,
            "stock_data": {
                "change_percent": stock_data['change_percent'],
                "current_price": stock_data.get('current_price', 0),
                "prev_price": stock_data.get('prev_price', 0),
                "volume": stock_data['volume_amount'] * 100000000,  # è½‰æ›ç‚ºå¼µæ•¸
                "volume_amount_billion": stock_data['volume_amount']
            },
            "finlab_data": {
                "current_price": stock_data.get('current_price', 0),
                "prev_price": stock_data.get('prev_price', 0),
                "volume_amount_billion": stock_data['volume_amount'],
                "change_percent": stock_data['change_percent'],
                "is_limit_up": True,
                "volume_rank": "high" if stock_data['is_high_volume'] else "low"
            },
            "news_sources": news_sources
        }
        
        # æ§‹å»ºå…§å®¹è«‹æ±‚
        content_request = ContentRequest(
            topic_title=f"{stock_data['stock_name']}({stock_data['stock_id']}) æ¼²åœåˆ†æ",
            topic_keywords=f"{stock_data['stock_name']}, {stock_data['stock_id']}, æ¼²åœ, ç›¤å¾Œåˆ†æ, éš”æ—¥æ²–",
            kol_persona="éš”æ—¥æ²–çµäºº",
            kol_nickname="éš”æ—¥æ²–çµäºº",
            content_type="AFTER_HOURS_LIMIT_UP",
            target_audience="day_traders,swing_traders",
            market_data=enhanced_market_data
        )
        
        # ç”Ÿæˆå…§å®¹
        generated_content = content_generator.generate_complete_content(content_request)
        
        if generated_content.success:
            # æ·»åŠ æ–°èä¾†æºåˆ°å…§å®¹
            full_content = generated_content.content
            if news_sources:
                full_content += news_sources
            
            # ç§»é™¤ Markdown æ ¼å¼ï¼ˆ** ç­‰ï¼‰
            clean_content = full_content.replace('**', '').replace('*', '').replace('##', '').replace('#', '')
            
            post_data = {
                "post_id": f"after_hours_{stock_data['stock_id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "kol_serial": "150",
                "kol_nickname": "éš”æ—¥æ²–çµäºº",
                "kol_id": "9505496",
                "persona": "éš”æ—¥æ²–çµäºº",
                "content_type": "AFTER_HOURS_LIMIT_UP",
                "topic_id": f"after_hours_{stock_data['stock_id']}_{datetime.now().strftime('%Y%m%d')}",
                "topic_title": f"{stock_data['stock_name']}({stock_data['stock_id']}) æ¼²åœåˆ†æ",
                "content": clean_content,
                "status": "generated",
                "trigger_type": "AFTER_HOURS_LIMIT_UP",
                "trigger_event_id": f"event_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "data_sources": ", ".join(stock_data['assigned_apis']),
                "data_source_status": "success",
                "post_type": "after_hours_analysis",
                "content_length_type": "medium",
                "word_count": str(len(clean_content)),
                "content_length_category": "medium",
                "content_generation_time": datetime.now().isoformat(),
                "generated_title": generated_content.title,
                "stock_id": stock_data['stock_id'],
                "stock_name": stock_data['stock_name'],
                "generated_at": datetime.now().isoformat(),
                "preferred_data_sources": ", ".join(stock_data['assigned_apis']),
                "analysis_type": "finlab_technical_analysis",
                "analysis_type_detail": "finlab_price_volume_analysis",
                "is_stock_trigger": "true",
                "stock_trigger_type": "after_hours_limit_up",
                "topic_keywords": f"{stock_data['stock_name']}, {stock_data['stock_id']}, æ¼²åœ, ç›¤å¾Œåˆ†æ, éš”æ—¥æ²–",
                "topic_category": "stock_analysis",
                "topic_priority": "high",
                "topic_heat_score": "9.5",
                "writing_style": "éš”æ—¥æ²–çµäººé¢¨æ ¼",
                "tone": "å°ˆæ¥­åˆ†æ",
                "key_phrases": "æ¼²åœ, éš”æ—¥æ²–, æŠ€è¡“åˆ†æ, æˆäº¤é‡",
                "avoid_topics": "éåº¦æŠ•æ©Ÿ, å…§ç·šäº¤æ˜“",
                "kol_assignment_method": "fixed_pool",
                "kol_weight": "1.0",
                "kol_version": "v1.0",
                "kol_learning_score": "0.8"
            }
            
            # è¨˜éŒ„åˆ° Google Sheets
            await sheets_recorder.record_enhanced_post(post_data)
            
            generated_posts.append({
                'stock_name': stock_data['stock_name'],
                'stock_id': stock_data['stock_id'],
                'title': generated_content.title,
                'content': clean_content,
                'news_count': len(news_list) if serper_client and 'news_list' in locals() else 0
            })
            
            print(f"âœ… ç”Ÿæˆç¬¬ {i+1} ç¯‡è²¼æ–‡: {stock_data['stock_name']}({stock_data['stock_id']}) - éš”æ—¥æ²–çµäºº")
            print(f"  ğŸ“ æ¨™é¡Œ: {generated_content.title}")
            print(f"  ğŸ“„ å…§å®¹é•·åº¦: {len(clean_content)} å­—")
            print(f"  ğŸ”§ ä½¿ç”¨API: {', '.join(stock_data['assigned_apis'])}")
            if serper_client and 'news_list' in locals():
                print(f"  ğŸ“° æ–°èä¾†æº: {len(news_list)} ç¯‡")
        else:
            print(f"âŒ ç”Ÿæˆå¤±æ•—: {generated_content.error_message}")
    
    # 5. é¡¯ç¤ºçµæœ
    print(f"\nğŸ‰ å¢å¼·ç‰ˆç›¤å¾Œæ©Ÿå™¨äººæ¸¬è©¦å®Œæˆï¼")
    print("=" * 80)
    print(f"ğŸ“Š è™•ç†è‚¡ç¥¨: {len(stocks_for_processing)} æª”")
    print(f"ğŸ¤– ä½¿ç”¨KOL: éš”æ—¥æ²–çµäºº (åºè™Ÿ: 150)")
    print(f"ğŸ“ ç”Ÿæˆè²¼æ–‡: {len(generated_posts)} ç¯‡")
    print(f"ğŸ”§ æ™ºèƒ½èª¿é…: âœ… å®Œæˆ")
    print(f"ğŸ“° æ–°èæœå°‹: {'âœ… å®Œæˆ' if serper_client else 'âš ï¸ è·³é'}")
    print(f"ğŸ“„ å…§å®¹ç”Ÿæˆ: âœ… å®Œæˆ")
    print(f"ğŸ“Š è¨˜éŒ„ä¿å­˜: âœ… å®Œæˆ")
    
    # é¡¯ç¤ºç”Ÿæˆçš„å®Œæ•´è²¼æ–‡å…§å®¹
    print(f"\nğŸ“„ ç”Ÿæˆçš„å®Œæ•´è²¼æ–‡å…§å®¹:")
    print("=" * 80)
    
    for i, post in enumerate(generated_posts, 1):
        print(f"\nğŸ“ ç¬¬ {i} ç¯‡è²¼æ–‡:")
        print(f"æ¨™é¡Œ: {post['title']}")
        print(f"è‚¡ç¥¨: {post['stock_name']}({post['stock_id']})")
        print(f"æ–°èä¾†æº: {post['news_count']} ç¯‡")
        print(f"å…§å®¹:")
        print(post['content'])
        print("-" * 60)
    
    return generated_posts

async def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    await test_enhanced_after_hours_bot()

if __name__ == "__main__":
    asyncio.run(main())
