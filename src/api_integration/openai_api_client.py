#!/usr/bin/env python3
"""
OpenAI API å®¢æˆ¶ç«¯
ç”¨æ–¼å…§å®¹ç”Ÿæˆå’Œå€‹äººåŒ–æç¤ºè©è™•ç†
"""

import os
import aiohttp
import asyncio
import logging
import json
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class ContentGenerationRequest:
    """å…§å®¹ç”Ÿæˆè«‹æ±‚"""
    stock_id: str
    stock_name: str
    analysis_type: str
    kol_profile: Dict[str, Any]
    stock_data: Optional[Dict[str, Any]] = None
    news_data: Optional[Dict[str, Any]] = None
    target_length: int = 300
    content_style: str = "åˆ†æ"

@dataclass
class ContentGenerationResult:
    """å…§å®¹ç”Ÿæˆçµæœ"""
    title: str
    content: str
    tokens_used: int
    model_used: str
    generation_time: datetime
    quality_score: float
    personalization_score: float

class OpenAIAPIClient:
    """OpenAI API å®¢æˆ¶ç«¯"""
    
    def __init__(self):
        """åˆå§‹åŒ– OpenAI API å®¢æˆ¶ç«¯"""
        self.api_key = os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("ç¼ºå°‘ OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self.session = None
        self.default_model = "gpt-3.5-turbo"
        
        logger.info("OpenAI API å®¢æˆ¶ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    async def __aenter__(self):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
    
    def _get_title_guidance_by_style(self, title_style: str) -> str:
        """æ ¹æ“šæ¨™é¡Œé¢¨æ ¼ç²å–ç‰¹å®šçš„æ¨™é¡ŒæŒ‡å°"""
        title_guidances = {
            "question": """
æ¨™é¡Œé¢¨æ ¼ï¼šå•å¥é¡ï¼ˆ13.1%ï¼‰
- ä½¿ç”¨ç–‘å•å¥å½¢å¼ï¼Œå¢åŠ äº’å‹•æ€§
- ç¤ºä¾‹ï¼šã€Œé€™æ³¢æ¼²å‹¢èƒ½æŒçºŒå¤šä¹…ï¼Ÿã€ã€ŒèƒŒå¾ŒåŸå› ç©¶ç«Ÿæ˜¯ä»€éº¼ï¼Ÿã€ã€Œå¸‚å ´æƒ…ç·’ç‚ºä½•å¦‚æ­¤ç†±çƒˆï¼Ÿã€
- é¿å…é‡è¤‡ä½¿ç”¨ã€Œæ€éº¼äº†ï¼Ÿã€ã€Œç‚ºä»€éº¼ï¼Ÿã€ç­‰å¸¸è¦‹å•å¥
- å¯ä»¥å˜—è©¦ï¼šã€Œé€™æª”è‚¡ç¥¨åœ¨æä»€éº¼ï¼Ÿã€ã€Œå¸‚å ´ç˜‹äº†å—ï¼Ÿã€ã€ŒæŠ•è³‡äººåˆ°åº•åœ¨æƒ³ä»€éº¼ï¼Ÿã€
""",
            "exclamation": """
æ¨™é¡Œé¢¨æ ¼ï¼šæ„Ÿå˜†é¡ï¼ˆ5.1%ï¼‰
- ä½¿ç”¨æ„Ÿå˜†å¥å½¢å¼ï¼Œè¡¨é”å¼·çƒˆæƒ…ç·’
- ç¤ºä¾‹ï¼šã€Œå¤ªç˜‹ç‹‚äº†ï¼ã€ã€Œé€™æ³¢æ“ä½œå¤ªç¥äº†ï¼ã€ã€Œå¸‚å ´æƒ…ç·’ç‡ƒç‡’å¤©éš›ï¼ã€
- é¿å…é‡è¤‡ä½¿ç”¨ã€Œå¤ªçŒ›äº†ï¼ã€ã€Œå¥½æ£’ï¼ã€ç­‰å¸¸è¦‹æ„Ÿå˜†
- å¯ä»¥å˜—è©¦ï¼šã€Œé€™æª”è‚¡ç¥¨è¦èµ·é£›äº†ï¼ã€ã€Œå¸‚å ´æƒ…ç·’ç‚¸è£‚ï¼ã€ã€ŒæŠ•è³‡äººç˜‹ç‹‚äº†ï¼ã€
""",
            "command": """
æ¨™é¡Œé¢¨æ ¼ï¼šæŒ‡ä»¤é¡ï¼ˆ3.1%ï¼‰
- ä½¿ç”¨æŒ‡ä»¤å¥å½¢å¼ï¼Œæä¾›æ˜ç¢ºæŒ‡å¼•
- ç¤ºä¾‹ï¼šã€Œæ³¨æ„ï¼èˆªé‹è‚¡èµ·é£›ã€ã€Œå¿«çœ‹ï¼AIæ¦‚å¿µè‚¡ã€ã€Œæé†’ï¼å°ç©é›»çªç ´ã€
- é¿å…é‡è¤‡ä½¿ç”¨ã€Œæ³¨æ„ï¼ã€ã€Œæé†’ï¼ã€ç­‰å¸¸è¦‹æŒ‡ä»¤
- å¯ä»¥å˜—è©¦ï¼šã€Œå¿«çœ‹ï¼é€™æª”è‚¡ç¥¨è¦çˆ†ç™¼ã€ã€Œæ³¨æ„ï¼å¸‚å ´é¢¨å‘è½‰è®Šã€ã€Œæé†’ï¼æŠ€è¡“é¢çªç ´ã€
""",
            "professional": """
æ¨™é¡Œé¢¨æ ¼ï¼šå°ˆæ¥­é¡ï¼ˆ2.9%ï¼‰
- ä½¿ç”¨å°ˆæ¥­è¡“èªï¼Œçªå‡ºå°ˆæ¥­æ€§
- ç¤ºä¾‹ï¼šã€Œç‡Ÿæ”¶æˆé•·50%ã€ã€ŒæŠ€è¡“é¢çªç ´ã€ã€ŒåŸºæœ¬é¢è½‰å¥½ã€
- é¿å…é‡è¤‡ä½¿ç”¨ã€Œç‡Ÿæ”¶æˆé•·ã€ã€ŒåŸºæœ¬é¢è½‰å¥½ã€ç­‰å¸¸è¦‹å°ˆæ¥­è©
- å¯ä»¥å˜—è©¦ï¼šã€Œç²åˆ©èƒ½åŠ›å¤§å¹…æå‡ã€ã€ŒæŠ€è¡“æŒ‡æ¨™å…¨é¢è½‰å¼·ã€ã€Œç‡Ÿé‹æ•ˆç‡é¡¯è‘—æ”¹å–„ã€
""",
            "topic": """
æ¨™é¡Œé¢¨æ ¼ï¼šè©±é¡Œé¡ï¼ˆAI 1.3%ï¼‰
- é—œæ³¨ç†±é–€è©±é¡Œï¼Œç·Šè·Ÿæ™‚äº‹
- ç¤ºä¾‹ï¼šã€ŒAIæ¦‚å¿µè‚¡çˆ†ç™¼ã€ã€ŒåŠå°é«”ç†±æ½®ã€ã€Œé‡‘èè‚¡è½‰å¼·ã€
- é¿å…é‡è¤‡ä½¿ç”¨ã€Œå¸‚å ´æƒ…ç·’ã€ã€ŒæŠ€è¡“é¢ã€ç­‰å¸¸è¦‹è©±é¡Œ
- å¯ä»¥å˜—è©¦ï¼šã€Œç”¢æ¥­è¶¨å‹¢æ˜æœ—åŒ–ã€ã€Œæ”¿ç­–åˆ©å¤šç™¼é…µã€ã€Œè³‡é‡‘æµå‘æ˜ç¢ºã€
""",
            "emoji": """
æ¨™é¡Œé¢¨æ ¼ï¼šè¡¨æƒ…ç¬¦è™Ÿé¡ï¼ˆ3.5%ï¼‰
- é©åº¦ä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿï¼Œå¢åŠ è¦–è¦ºæ•ˆæœ
- ç¤ºä¾‹ï¼šã€ŒğŸ”¥ ç‡Ÿæ”¶çˆ†ç™¼ï¼ã€ã€ŒğŸ“ˆ æŠ€è¡“çªç ´ï¼ã€ã€Œâ¤ï¸ åŸºæœ¬é¢è½‰å¥½ï¼ã€
- é¿å…é‡è¤‡ä½¿ç”¨ã€ŒğŸ”¥ã€ã€ŒğŸ“ˆã€ç­‰å¸¸è¦‹è¡¨æƒ…
- å¯ä»¥å˜—è©¦ï¼šã€ŒğŸš€ è‚¡åƒ¹èµ·é£›ï¼ã€ã€ŒğŸ’ åƒ¹å€¼ç™¼ç¾ï¼ã€ã€Œâš¡ å‹•èƒ½çˆ†ç™¼ï¼ã€
""",
            "humorous": """
æ¨™é¡Œé¢¨æ ¼ï¼šå¹½é»˜é¡ï¼ˆæç¬‘æ¯”å–»ï¼‰
- ä½¿ç”¨æç¬‘æ¯”å–»å’Œå¹½é»˜è¡¨é”
- ç¤ºä¾‹ï¼šã€Œè‚¡åƒ¹åƒç«ç®­ä¸€æ¨£è¡ä¸Šå¤©ï¼ã€ã€Œé€™æª”è‚¡ç¥¨è¦èµ·é£›äº†ï¼ã€
- é¿å…é‡è¤‡ä½¿ç”¨ã€ŒéŸ­èœã€ã€Œç«ç®­ã€ç­‰å¸¸è¦‹æ¯”å–»
- å¯ä»¥å˜—è©¦ï¼šã€Œé€™æª”è‚¡ç¥¨è¦é–‹æ›äº†ï¼ã€ã€Œå¸‚å ´æƒ…ç·’åƒéå±±è»Šï¼ã€ã€ŒæŠ•è³‡äººç˜‹ç‹‚æ¶è³¼ï¼ã€
""",
            "alert": """
æ¨™é¡Œé¢¨æ ¼ï¼šæé†’é¡ï¼ˆæŒ‡ä»¤å¥ 3.1%ï¼‰
- ä½¿ç”¨æé†’å¥å½¢å¼ï¼Œæä¾›é¢¨éšªæé†’
- ç¤ºä¾‹ï¼šã€Œæ³¨æ„ï¼å¸‚å ´éœ‡ç›ªã€ã€Œæé†’ï¼æŠ€è¡“é¢è½‰å¼±ã€ã€Œé—œæ³¨ï¼è²¡å ±å…¬å¸ƒã€
- é¿å…é‡è¤‡ä½¿ç”¨ã€Œæ³¨æ„ï¼ã€ã€Œæé†’ï¼ã€ç­‰å¸¸è¦‹æé†’
- å¯ä»¥å˜—è©¦ï¼šã€Œå¿«çœ‹ï¼é€™æª”è‚¡ç¥¨è¦çˆ†ç™¼ã€ã€Œé—œæ³¨ï¼å¸‚å ´é¢¨å‘è½‰è®Šã€ã€Œç•™æ„ï¼æŠ€è¡“é¢çªç ´ã€
""",
            "concise": """
æ¨™é¡Œé¢¨æ ¼ï¼šç°¡æ½”é¡ï¼ˆâ‰¤15å­—ï¼‰
- ç°¡æ½”æ˜ç­ï¼Œé‡é»çªå‡º
- ç¤ºä¾‹ï¼šã€Œç‡Ÿæ”¶æˆé•·ã€ã€ŒæŠ€è¡“çªç ´ã€ã€ŒåŸºæœ¬é¢è½‰å¥½ã€
- é¿å…é‡è¤‡ä½¿ç”¨å¸¸è¦‹ç°¡æ½”è©å½™
- å¯ä»¥å˜—è©¦ï¼šã€Œç²åˆ©æå‡ã€ã€Œå‹•èƒ½å¢å¼·ã€ã€Œè¶¨å‹¢æ˜æœ—ã€
""",
            "balanced": """
æ¨™é¡Œé¢¨æ ¼ï¼šå¹³è¡¡é¡ï¼ˆç¶œåˆå‹ï¼‰
- ç¶œåˆå¤šç¨®é¢¨æ ¼ï¼Œä¿æŒå¹³è¡¡
- æ ¹æ“šå…§å®¹éˆæ´»é¸æ“‡å•å¥ã€æ„Ÿå˜†å¥ã€å°ˆæ¥­è¡“èª
- é¿å…éåº¦åå‘æŸä¸€é¢¨æ ¼
- å¯ä»¥å˜—è©¦ï¼šã€Œé€™æ³¢æ¼²å‹¢èƒŒå¾Œçš„åŸå› ã€ã€Œå¸‚å ´æƒ…ç·’ç‚ºä½•å¦‚æ­¤ç†±çƒˆã€ã€ŒæŠ€è¡“é¢çªç ´çš„æ„ç¾©ã€
"""
        }
        
    def _create_personalized_prompt(self, request: ContentGenerationRequest) -> str:
        """å‰µå»ºå€‹äººåŒ–æç¤ºè©ï¼ˆåŸºæ–¼çœŸå¯¦ UGC æ•¸æ“šåˆ†æï¼‰"""
        kol = request.kol_profile
        
        # ç²å– KOL çš„æ¨™é¡Œé¢¨æ ¼
        title_style = kol.get('title_style', 'balanced')
        
        # æ ¹æ“šæ¨™é¡Œé¢¨æ ¼ç”Ÿæˆç‰¹å®šçš„æ¨™é¡ŒæŒ‡å°
        title_guidance = self._get_title_guidance_by_style(title_style)
        
        # åŸºç¤æç¤ºè©æ¨¡æ¿
        base_prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è‚¡ç¥¨åˆ†æå¸«ï¼Œéœ€è¦ç‚º KOL "{kol.get('persona', 'å°ˆæ¥­åˆ†æå¸«')}" ç”Ÿæˆä¸€ç¯‡é—œæ–¼ {request.stock_name}({request.stock_id}) çš„è‚¡ç¥¨åˆ†ææ–‡ç« ã€‚

KOL å€‹äººåŒ–è¨­å®šï¼š
- äººè¨­ï¼š{kol.get('persona', 'å°ˆæ¥­åˆ†æå¸«')}
- å¯«ä½œé¢¨æ ¼ï¼š{kol.get('writing_style', 'å°ˆæ¥­åˆ†æ')}
- èªæ°£ï¼š{kol.get('tone', 'å°ˆæ¥­')}
- é—œéµè©ï¼š{', '.join(kol.get('key_phrases', []))}
- é¿å…è©±é¡Œï¼š{', '.join(kol.get('avoid_topics', []))}
- æ¨™é¡Œé¢¨æ ¼ï¼š{title_style}

åˆ†æé¡å‹ï¼š{request.analysis_type}
ç›®æ¨™é•·åº¦ï¼š{request.target_length} å­—
å…§å®¹é¢¨æ ¼ï¼š{request.content_style}

é‡è¦è¦æ±‚ï¼š
1. æ¨™é¡Œæ ¼å¼ï¼š
   - ä¸è¦æœ‰ã€Œæ¨™é¡Œï¼šã€å‰ç¶´
   - ä¸è¦æœ‰ ## æˆ– ### ç¬¦è™Ÿ
   - ä¸è¦æœ‰ã€ã€‘ç¬¦è™Ÿ
   - ä¸è¦æåˆ° KOL åå­—æˆ–æ´¾åˆ¥
   - ä¸è¦åŒ…å«è‚¡ç¥¨åç¨±ï¼ˆå› ç‚ºå·²ç¶“åœ¨è²¼æ–‡ä¸­ tag è‚¡ç¥¨ä»£è™Ÿï¼‰
   - ä¸è¦åŒ…å«è‚¡ç¥¨ä»£è™Ÿ
   - é•·åº¦åš´æ ¼æ§åˆ¶åœ¨ â‰¤15å­—ï¼ˆå¹³å‡ 11.0 å­—ï¼‰
   - é‡é»æè¿°æ¼²åœåŸå› ã€å¸‚å ´æƒ…ç·’æˆ–ç”¢æ¥­å‹•æ…‹

{title_guidance}

2. å…§å®¹è¦æ±‚ï¼š
   - ä¸è¦æœ‰ã€Œå…§å®¹ï¼šã€å‰ç¶´
   - é¿å…åˆ¶å¼åŒ–çš„ã€ŒæŠ•è³‡å»ºè­°ã€ã€ã€Œé¢¨éšªæé†’ã€
   - å…§å®¹è¦è‡ªç„¶æµæš¢ï¼Œç¬¦åˆ KOL é¢¨æ ¼
   - è‚¡ç¥¨åç¨±å’Œä»£è™Ÿåªæåˆ°å…¶ä¸­ä¸€å€‹
   - è‚¡ç¥¨ä»£è™Ÿä½¿ç”¨ç´”æ•¸å­—æ ¼å¼
   - é¿å…é‡è¤‡çš„æ ¼å¼å’Œç”¨è©

3. æ•¸æ“šæ ¼å¼ï¼š
   - æˆäº¤é‡ç”¨ã€Œå¼µæ•¸ã€è¡¨ç¤ºï¼ˆ1000è‚¡ = 1å¼µï¼‰
   - ç‡Ÿæ”¶ç”¨ã€Œç™¾è¬ã€æˆ–ã€Œå„„ã€ç‚ºå–®ä½
   - è²¡å ±æ•¸æ“šç”¨ã€Œå„„ã€ç‚ºå–®ä½
   - æŠ€è¡“æŒ‡æ¨™è¦å¯è§£é‡‹

4. æ–°èæ•´åˆï¼š
   - å¦‚æœæœ‰æ¼²åœç›¸é—œæ–°èï¼Œè¦åˆ†ææ¼²åœåŸå› 
   - æ•´åˆ Serper API æœå°‹åˆ°çš„ç›¸é—œæ–°è
   - åˆ†æä¸Šæ¼²å‹•èƒ½å’Œå¸‚å ´æƒ…ç·’
"""

        # æ ¹æ“šåˆ†æé¡å‹æ·»åŠ ç‰¹å®šè¦æ±‚
        if request.analysis_type == "revenue":
            base_prompt += """
ç‡Ÿæ”¶åˆ†æé‡é»ï¼š
- åˆ†ææœˆç‡Ÿæ”¶è¡¨ç¾ï¼ˆç”¨ç™¾è¬/å„„ç‚ºå–®ä½ï¼‰
- æ¯”è¼ƒå¹´å¢ç‡å’Œæœˆå¢ç‡
- åˆ†æç‡Ÿæ”¶è¶¨å‹¢å’Œå‹•èƒ½
- çµåˆæ¼²åœåŸå› åˆ†æ
- é¿å…åˆ¶å¼åŒ–æŠ•è³‡å»ºè­°
"""
        elif request.analysis_type == "earnings":
            base_prompt += """
è²¡å ±åˆ†æé‡é»ï¼š
- åˆ†æ EPS è¡¨ç¾ï¼ˆç”¨å…ƒç‚ºå–®ä½ï¼‰
- åˆ†ææ¯›åˆ©ç‡å’Œæ·¨åˆ©ç‡ï¼ˆç”¨%è¡¨ç¤ºï¼‰
- æ¯”è¼ƒç²åˆ©èƒ½åŠ›
- çµåˆæ¼²åœåŸå› åˆ†æ
- é¿å…åˆ¶å¼åŒ–æŠ•è³‡å»ºè­°
"""
        elif request.analysis_type in ["news_3", "news_2"]:
            base_prompt += """
æ–°èåˆ†æé‡é»ï¼š
- æ•´åˆ Serper API æœå°‹åˆ°çš„ç›¸é—œæ–°è
- åˆ†ææ¼²åœåŸå› å’Œå¸‚å ´æƒ…ç·’
- åˆ†æä¸Šæ¼²å‹•èƒ½å’Œç›¸é—œæ¶ˆæ¯
- é¿å…åˆ¶å¼åŒ–æŠ•è³‡å»ºè­°
- é‡é»åˆ†ææ–°èå°è‚¡åƒ¹çš„å½±éŸ¿
"""
        elif request.analysis_type == "price":
            base_prompt += """
æŠ€è¡“åˆ†æé‡é»ï¼š
- åˆ†æè‚¡åƒ¹èµ°å‹¢å’Œæ¼²åœåŸå› 
- åˆ†ææŠ€è¡“æŒ‡æ¨™ï¼ˆæˆäº¤é‡ç”¨å¼µæ•¸ï¼‰
- çµåˆ Serper API æ–°èåˆ†æ
- åˆ†æä¸Šæ¼²å‹•èƒ½å’Œå¸‚å ´æƒ…ç·’
- é¿å…åˆ¶å¼åŒ–æŠ•è³‡å»ºè­°
"""

        # æ·»åŠ è‚¡ç¥¨æ•¸æ“šï¼ˆå¦‚æœæœ‰ï¼‰
        if request.stock_data:
            # è½‰æ›æ•¸æ“šæ ¼å¼
            formatted_data = self._format_stock_data(request.stock_data)
            base_prompt += f"""
è‚¡ç¥¨æ•¸æ“šï¼ˆå·²æ ¼å¼åŒ–ï¼‰ï¼š
{json.dumps(formatted_data, ensure_ascii=False, indent=2)}
"""

        # æ·»åŠ æ–°èæ•¸æ“šï¼ˆå¦‚æœæœ‰ï¼‰
        if request.news_data and request.news_data.get('has_news', False):
            news_info = f"""
ç›¸é—œæ–°èï¼ˆ{request.news_data.get('news_count', 0)}å‰‡ï¼‰ï¼š
"""
            # æ·»åŠ æ–°èæ¨™é¡Œ
            if request.news_data.get('news_titles'):
                news_info += "æ–°èæ¨™é¡Œï¼š\n"
                for i, title in enumerate(request.news_data['news_titles'][:3], 1):
                    news_info += f"{i}. {title}\n"
            
            # æ·»åŠ æ–°èæ‘˜è¦
            if request.news_data.get('news_summaries'):
                news_info += "\næ–°èæ‘˜è¦ï¼š\n"
                for i, summary in enumerate(request.news_data['news_summaries'][:3], 1):
                    news_info += f"{i}. {summary[:100]}...\n"
            
            # æ·»åŠ æ¼²åœåŸå› 
            if request.news_data.get('limit_up_reason'):
                news_info += f"\næ¼²åœåŸå› åˆ†æï¼š{request.news_data['limit_up_reason']}\n"
            
            base_prompt += news_info + """
è«‹é‡é»åˆ†æï¼š
1. æ¼²åœåŸå› å’Œç›¸é—œæ–°è
2. ä¸Šæ¼²å‹•èƒ½å’Œå¸‚å ´æƒ…ç·’
3. ç›¸é—œç”¢æ¥­æ¶ˆæ¯
4. å°è‚¡åƒ¹çš„å½±éŸ¿
"""
        else:
            base_prompt += """
æ³¨æ„ï¼šç›®å‰æ²’æœ‰æ‰¾åˆ°ç›¸é—œæ–°èï¼Œè«‹åŸºæ–¼æŠ€è¡“é¢å’Œå¸‚å ´æƒ…ç·’é€²è¡Œåˆ†æã€‚
"""

        base_prompt += """
è«‹ç›´æ¥ç”Ÿæˆæ¨™é¡Œå’Œå…§å®¹ï¼Œä¸è¦æœ‰ä»»ä½•å‰ç¶´æ¨™è¨˜ã€‚

æ¨™é¡Œè¦æ±‚ï¼ˆåŸºæ–¼çœŸå¯¦ UGC æ•¸æ“šåˆ†æï¼‰ï¼š
- é•·åº¦ï¼šåš´æ ¼æ§åˆ¶åœ¨ â‰¤15å­—ï¼ˆå¹³å‡ 11.0 å­—ï¼‰
- çµ•å°ä¸è¦åŒ…å«è‚¡ç¥¨åç¨±æˆ–ä»£è™Ÿï¼ˆå› ç‚ºå·²ç¶“åœ¨è²¼æ–‡ä¸­ tagï¼‰
- ä¸è¦åŒ…å«åª’é«”åç¨±ã€å‰ç¶´ç¬¦è™Ÿï¼ˆ##ã€###ã€ã€ã€‘ç­‰ï¼‰

æ¨™é¡Œé¢¨æ ¼åˆ†å¸ƒï¼ˆåŸºæ–¼çœŸå¯¦ UGC æ•¸æ“šï¼‰ï¼š
1. å•å¥é¡ï¼ˆ13.1%ï¼‰ï¼š"æ€éº¼äº†ï¼Ÿ"ã€"è©²è²·å—ï¼Ÿ"ã€"æ€éº¼çœ‹ï¼Ÿ"
2. æ„Ÿå˜†é¡ï¼ˆ5.1%ï¼‰ï¼š"å¤ªçŒ›äº†ï¼"ã€"å¥½æ£’ï¼"ã€"èˆ’æœï¼"
3. æŒ‡ä»¤é¡ï¼ˆ3.1%ï¼‰ï¼š"æ³¨æ„ï¼"ã€"å¿«çœ‹ï¼"ã€"æé†’ï¼"
4. å°ˆæ¥­é¡ï¼ˆ2.9%ï¼‰ï¼š"ç‡Ÿæ”¶æˆé•·"ã€"æŠ€è¡“çªç ´"ã€"åŸºæœ¬é¢è½‰å¥½"

è¡¨æƒ…ç¬¦è™Ÿä½¿ç”¨ï¼ˆ3.5%ï¼‰ï¼šé©åº¦ä½¿ç”¨ ğŸ”¥ğŸ“ˆâ¤ï¸ ç­‰æŠ•è³‡ç›¸é—œè¡¨æƒ…

äº’å‹•æ€§è¦æ±‚ï¼š
- å•å¥æ¯”ä¾‹ï¼š13.1%ï¼ˆå¦‚ï¼š"å°ç©é›»æ€éº¼äº†ï¼Ÿ"ã€"AIæ¦‚å¿µè‚¡è©²è²·å—ï¼Ÿ"ï¼‰
- æ„Ÿå˜†å¥æ¯”ä¾‹ï¼š5.1%ï¼ˆå¦‚ï¼š"å¤ªçŒ›äº†ï¼"ã€"å¥½æ£’ï¼"ï¼‰
- æŒ‡ä»¤å¥æ¯”ä¾‹ï¼š3.1%ï¼ˆå¦‚ï¼š"æ³¨æ„ï¼èˆªé‹è‚¡èµ·é£›"ï¼‰

å°ˆæ¥­è¡“èªèå…¥ï¼š
- åŸºæœ¬é¢ï¼š2.9%ï¼ˆç‡Ÿæ”¶ã€è²¡å ±ã€EPSï¼‰
- ç±Œç¢¼é¢ï¼š2.8%ï¼ˆå¤–è³‡ã€ä¸»åŠ›ã€èè³‡ï¼‰
- æŠ€è¡“é¢ï¼š0.9%ï¼ˆçªç ´ã€æ”¯æ’ã€å‡ç·šï¼‰

ç†±é–€è©±é¡Œé—œæ³¨ï¼š
- AIï¼š1.3%ï¼ˆæœ€ç†±é–€è©±é¡Œï¼‰
- åŠå°é«”ï¼š0.9%
- é‡‘èï¼š0.7%

çœŸå¯¦ UGC æ¨™é¡Œç¤ºä¾‹ï¼š
å•å¥é¡ï¼šã€Œå°ç©é›»æ€éº¼äº†ï¼Ÿã€ã€ŒAIæ¦‚å¿µè‚¡è©²è²·å—ï¼Ÿã€ã€Œèˆªé‹è‚¡æ€éº¼çœ‹ï¼Ÿã€
æ„Ÿå˜†é¡ï¼šã€Œå¤ªçŒ›äº†ï¼ã€ã€Œå¥½æ£’ï¼ã€ã€Œèˆ’æœï¼ã€ã€Œç¥äº†ï¼ã€
å°ˆæ¥­é¡ï¼šã€Œç‡Ÿæ”¶æˆé•·50%ã€ã€ŒæŠ€è¡“é¢çªç ´ã€ã€ŒåŸºæœ¬é¢è½‰å¥½ã€
æŒ‡ä»¤é¡ï¼šã€Œæ³¨æ„ï¼èˆªé‹è‚¡èµ·é£›ã€ã€Œå¿«çœ‹ï¼AIæ¦‚å¿µè‚¡ã€ã€Œæé†’ï¼å°ç©é›»çªç ´ã€

å…§å®¹è¦æ±‚ï¼š
- è‡ªç„¶æµæš¢ï¼Œç¬¦åˆ KOL é¢¨æ ¼
- é¿å…åˆ¶å¼åŒ–èªè¨€
- ä¸è¦é‡è¤‡æ¨™é¡Œå…§å®¹
- ä½¿ç”¨ç¹é«”ä¸­æ–‡

è«‹ç›´æ¥è¼¸å‡ºï¼š
[æ¨™é¡Œ]
[å…§å®¹]
"""

        return base_prompt
    
    def _format_stock_data(self, stock_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–è‚¡ç¥¨æ•¸æ“š"""
        formatted = stock_data.copy()
        
        # è½‰æ›æˆäº¤é‡ç‚ºå¼µæ•¸
        if 'volume' in formatted:
            volume_shares = formatted['volume']
            volume_units = volume_shares / 1000  # 1000è‚¡ = 1å¼µ
            formatted['volume_units'] = f"{volume_units:,.0f}å¼µ"
        
        # è½‰æ›ç‡Ÿæ”¶ç‚ºç™¾è¬/å„„
        if 'revenue' in formatted:
            revenue = formatted['revenue']
            if revenue >= 100000000:  # 1å„„ä»¥ä¸Š
                formatted['revenue_formatted'] = f"{revenue/100000000:.2f}å„„å…ƒ"
            else:
                formatted['revenue_formatted'] = f"{revenue/1000000:.2f}ç™¾è¬å…ƒ"
        
        # è½‰æ› EPS ç‚ºå…ƒ
        if 'eps' in formatted:
            formatted['eps_formatted'] = f"{formatted['eps']:.2f}å…ƒ"
        
        # è½‰æ›æ¯›åˆ©ç‡å’Œæ·¨åˆ©ç‡ç‚ºç™¾åˆ†æ¯”
        if 'gross_margin' in formatted:
            formatted['gross_margin_formatted'] = f"{formatted['gross_margin']:.2f}%"
        if 'net_margin' in formatted:
            formatted['net_margin_formatted'] = f"{formatted['net_margin']:.2f}%"
        
        return formatted
    
    async def generate_content(self, request: ContentGenerationRequest) -> Optional[ContentGenerationResult]:
        """ç”Ÿæˆå…§å®¹"""
        try:
            prompt = self._create_personalized_prompt(request)
            
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            payload = {
                'model': self.default_model,
                'messages': [
                    {
                        'role': 'system',
                        'content': 'ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è‚¡ç¥¨åˆ†æå¸«ï¼Œæ“…é•·ç”Ÿæˆå€‹äººåŒ–çš„è‚¡ç¥¨åˆ†æå…§å®¹ã€‚é‡è¦ï¼šæ¨™é¡Œçµ•å°ä¸èƒ½åŒ…å«è‚¡ç¥¨åç¨±æˆ–ä»£è™Ÿï¼Œå› ç‚ºå·²ç¶“åœ¨è²¼æ–‡ä¸­ tag äº†ã€‚'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': request.target_length * 2,  # é ç•™è¶³å¤ çš„ token
                'temperature': 0.7,
                'top_p': 0.9,
                'frequency_penalty': 0.1,
                'presence_penalty': 0.1
            }
            
            async with self.session.post(self.base_url, json=payload, headers=headers) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    if 'choices' in data and len(data['choices']) > 0:
                        content = data['choices'][0]['message']['content']
                        
                        # è§£ææ¨™é¡Œå’Œå…§å®¹
                        title, content_text = self._parse_title_and_content(content)
                        
                        # è¨ˆç®—å“è³ªè©•åˆ†
                        quality_score = self._calculate_quality_score(title, content_text, request)
                        
                        # è¨ˆç®—å€‹äººåŒ–è©•åˆ†
                        personalization_score = self._calculate_personalization_score(content_text, request.kol_profile)
                        
                        return ContentGenerationResult(
                            title=title,
                            content=content_text,
                            tokens_used=data['usage']['total_tokens'],
                            model_used=self.default_model,
                            generation_time=datetime.now(),
                            quality_score=quality_score,
                            personalization_score=personalization_score
                        )
                
                logger.warning(f"OpenAI API ç”Ÿæˆå¤±æ•—: {response.status}")
                return None
                
        except Exception as e:
            logger.error(f"OpenAI API ç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def _parse_title_and_content(self, content: str) -> tuple[str, str]:
        """è§£ææ¨™é¡Œå’Œå…§å®¹"""
        lines = content.split('\n')
        title = ""
        content_text = ""
        
        # ç‰¹æ®Šè™•ç†ï¼šå¦‚æœå…§å®¹åŒ…å«åˆ¶è¡¨ç¬¦åˆ†éš”çš„æ ¼å¼
        if len(lines) == 1 and '\t' in lines[0]:
            parts = lines[0].split('\t')
            if len(parts) >= 2:
                # ç¬¬ä¸€éƒ¨åˆ†æ˜¯æ¨™è¨˜ï¼Œç¬¬äºŒéƒ¨åˆ†åŒ…å«æ¨™é¡Œå’Œå…§å®¹
                if parts[0].strip() == 'æ¨™é¡Œ':
                    title_content_part = parts[1].strip()
                    # åœ¨æ¨™é¡Œå…§å®¹éƒ¨åˆ†ä¸­å°‹æ‰¾ "å…§å®¹" çš„ä½ç½®
                    content_pos = title_content_part.find('å…§å®¹')
                    if content_pos > 0:
                        title = title_content_part[:content_pos].strip()
                        content_text = title_content_part[content_pos:].strip()
                        # ç§»é™¤å…§å®¹ä¸­çš„ "å…§å®¹" å‰ç¶´
                        if content_text.startswith('å…§å®¹'):
                            content_text = content_text[2:].strip()
                    else:
                        # å¦‚æœæ²’æœ‰æ‰¾åˆ° "å…§å®¹"ï¼Œæ•´å€‹ç¬¬äºŒéƒ¨åˆ†ä½œç‚ºæ¨™é¡Œ
                        title = title_content_part
                else:
                    # å¦‚æœä¸æ˜¯ "æ¨™é¡Œ" æ¨™è¨˜ï¼ŒæŒ‰æ­£å¸¸æµç¨‹è™•ç†
                    pass
            else:
                # å¦‚æœåˆ†å‰²å¾Œåªæœ‰ä¸€å€‹éƒ¨åˆ†ï¼ŒæŒ‰æ­£å¸¸æµç¨‹è™•ç†
                pass
        
        # å¦‚æœæ²’æœ‰é€šéç‰¹æ®Šè™•ç†å¾—åˆ°çµæœï¼Œä½¿ç”¨æ­£å¸¸æµç¨‹
        if not title and not content_text:
            # æ¸…ç†å…§å®¹ï¼Œç§»é™¤ä¸å¿…è¦çš„æ¨™è¨˜
            cleaned_lines = []
            for line in lines:
                line = line.strip()
                # ç§»é™¤æ¨™é¡Œï¼šã€å…§å®¹ï¼šç­‰å‰ç¶´
                if line.startswith('æ¨™é¡Œï¼š'):
                    line = line[3:].strip()
                elif line.startswith('å…§å®¹ï¼š'):
                    line = line[3:].strip()
                elif line.startswith('æ¨™é¡Œ\t'):
                    line = line[2:].strip()
                elif line.startswith('å…§å®¹\t'):
                    line = line[2:].strip()
                
                # ç§»é™¤åª’é«”åç¨±å‰ç¶´
                media_prefixes = ['è²¡è¨Šå¿«å ±ï¼š', 'é‰…äº¨ç¶²ï¼š', 'å¥‡æ‘©è‚¡å¸‚ï¼š', 'ç¶“æ¿Ÿæ—¥å ±ï¼š', 'å·¥å•†æ™‚å ±ï¼š']
                for prefix in media_prefixes:
                    if line.startswith(prefix):
                        line = line[len(prefix):].strip()
                
                if line:
                    cleaned_lines.append(line)
            
            # ç‰¹æ®Šè™•ç†ï¼šå¦‚æœç¬¬ä¸€è¡ŒåŒ…å« "æ¨™é¡Œ" å’Œ "å…§å®¹"ï¼Œéœ€è¦åˆ†é›¢
            if cleaned_lines and 'æ¨™é¡Œ' in cleaned_lines[0] and 'å…§å®¹' in cleaned_lines[0]:
                first_line = cleaned_lines[0]
                # å°‹æ‰¾ "å…§å®¹" çš„ä½ç½®
                content_pos = first_line.find('å…§å®¹')
                if content_pos > 0:
                    title_part = first_line[:content_pos].strip()
                    content_part = first_line[content_pos:].strip()
                    
                    # ç§»é™¤æ¨™é¡Œä¸­çš„ "æ¨™é¡Œ" å‰ç¶´
                    if title_part.startswith('æ¨™é¡Œ'):
                        title_part = title_part[2:].strip()
                    
                    # ç§»é™¤å…§å®¹ä¸­çš„ "å…§å®¹" å‰ç¶´
                    if content_part.startswith('å…§å®¹'):
                        content_part = content_part[2:].strip()
                    
                    cleaned_lines[0] = title_part
                    if content_part:
                        cleaned_lines.insert(1, content_part)
            
            # å°‹æ‰¾æ¨™é¡Œï¼ˆç¬¬ä¸€è¡Œæˆ–è¼ƒçŸ­çš„è¡Œï¼‰
            for i, line in enumerate(cleaned_lines):
                if not title and len(line) <= 30 and not line.startswith('â€¢') and not line.startswith('-'):
                    title = line
                else:
                    if content_text:
                        content_text += '\n' + line
                    else:
                        content_text = line
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™é¡Œï¼Œå¾å…§å®¹ä¸­æå–
            if not title and content_text:
                # å–ç¬¬ä¸€å¥ä½œç‚ºæ¨™é¡Œ
                sentences = content_text.split('ã€‚')
                if sentences:
                    first_sentence = sentences[0].strip()
                    if len(first_sentence) <= 25:
                        title = first_sentence
                    else:
                        title = first_sentence[:25] + "..."
        
        # ç¢ºä¿æ¨™é¡Œä¸åŒ…å«è‚¡ç¥¨ä»£è™Ÿå’Œå…¬å¸åç¨±
        if title:
            # ç§»é™¤æ¨™é¡Œä¸­çš„è‚¡ç¥¨ä»£è™Ÿæ ¼å¼
            import re
            title = re.sub(r'\([0-9]+\)', '', title)  # ç§»é™¤ (1234) æ ¼å¼
            title = re.sub(r'[0-9]{4}', '', title)   # ç§»é™¤ç´”æ•¸å­—ä»£è™Ÿ
            
            # ç§»é™¤å¸¸è¦‹çš„è‚¡ç¥¨åç¨±ï¼ˆæ ¹æ“šæ‚¨æä¾›çš„åˆ—è¡¨ï¼‰
            stock_names = [
                'æ˜‡é™½åŠå°é«”', 'æœ‹ç¨‹', 'é¾å¾·é€ èˆ¹', 'ç«‹ç©', 'æ˜‡é”ç§‘æŠ€', 'åº·éœˆç”ŸæŠ€', 
                'ä¸–ç´€é‹¼', 'æ‡·ç‰¹', 'å—èŒ‚', 'è¨ŠèˆŸ', 'é›·è™', 'å¯Œé‚¦é‡‘', 'æ˜‡ä½³é›»å­'
            ]
            for stock_name in stock_names:
                title = title.replace(stock_name, '').strip()
            
            # ç§»é™¤å¤šé¤˜çš„æ¨™é»ç¬¦è™Ÿ
            title = re.sub(r'^[ï¼š:]\s*', '', title)  # ç§»é™¤é–‹é ­çš„å†’è™Ÿ
            title = re.sub(r'\s+', ' ', title)  # å¤šå€‹ç©ºæ ¼è®Šå–®å€‹ç©ºæ ¼
            title = title.strip()
        
        # å¦‚æœæ¨™é¡Œå¤ªé•·ï¼Œæˆªæ–·
        if title and len(title) > 25:
            title = title[:25] + "..."
        
        # ç¢ºä¿å…§å®¹ä¸åŒ…å«æ¨™é¡Œ
        if content_text and title and content_text.startswith(title):
            content_text = content_text[len(title):].strip()
            if content_text.startswith('ã€‚'):
                content_text = content_text[1:].strip()
        
        return title, content_text
    
    def _calculate_quality_score(self, title: str, content: str, request: ContentGenerationRequest) -> float:
        """è¨ˆç®—å“è³ªè©•åˆ†"""
        score = 8.0  # åŸºç¤åˆ†æ•¸
        
        # æ¨™é¡Œæª¢æŸ¥
        if title:
            if 15 <= len(title) <= 25:
                score += 1.0
            if not any(keyword in title for keyword in ['##', '###', 'ã€', 'ã€‘', 'æ¨™é¡Œï¼š', 'KOL', 'æ´¾åˆ¥', 'åˆ†æå¸«']):
                score += 1.0
            if not any(keyword in title for keyword in ['æŠ•è³‡å»ºè­°', 'é¢¨éšªæé†’']):
                score += 0.5
        
        # å…§å®¹æª¢æŸ¥
        if content:
            if len(content) >= request.target_length * 0.8:
                score += 0.5
            if request.stock_name in content or request.stock_id in content:
                score += 0.5
            if not content.count(request.stock_name) > 3:  # é¿å…é‡è¤‡æåŠ
                score += 0.5
            if 'å¼µæ•¸' in content or 'ç™¾è¬' in content or 'å„„' in content:
                score += 0.5
        
        return min(score, 10.0)
    
    def _calculate_personalization_score(self, content: str, kol_profile: Dict[str, Any]) -> float:
        """è¨ˆç®—å€‹äººåŒ–è©•åˆ†"""
        score = 7.0  # åŸºç¤åˆ†æ•¸
        
        # æª¢æŸ¥é—œéµè©ä½¿ç”¨
        key_phrases = kol_profile.get('key_phrases', [])
        if key_phrases:
            used_phrases = sum(1 for phrase in key_phrases if phrase in content)
            score += min(used_phrases * 0.5, 2.0)
        
        # æª¢æŸ¥é¿å…è©±é¡Œ
        avoid_topics = kol_profile.get('avoid_topics', [])
        if avoid_topics:
            avoided_count = sum(1 for topic in avoid_topics if topic not in content)
            score += min(avoided_count * 0.3, 1.0)
        
        return min(score, 10.0)
    
    async def generate_multiple_content(self, requests: List[ContentGenerationRequest]) -> List[ContentGenerationResult]:
        """æ‰¹é‡ç”Ÿæˆå…§å®¹"""
        tasks = [self.generate_content(request) for request in requests]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # éæ¿¾æ‰éŒ¯èª¤çµæœ
        valid_results = []
        for result in results:
            if isinstance(result, ContentGenerationResult):
                valid_results.append(result)
            elif isinstance(result, Exception):
                logger.error(f"å…§å®¹ç”Ÿæˆå¤±æ•—: {result}")
        
        return valid_results
