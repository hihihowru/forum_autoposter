#!/usr/bin/env bash
# restore_all_files.sh
# å¾ Local History é‚„åŸ 8:59 git restore å½±éŸ¿çš„æ‰€æœ‰æª”æ¡ˆ

set -euo pipefail

PROJECT_ROOT="/Users/williamchen/Documents/n8n-migration-project"
HISTORY_DIR="/Users/williamchen/Library/Application Support/Cursor/User/History"
BACKUP_DIR="$PROJECT_ROOT/RESTORE_BACKUP_$(date +%Y%m%d_%H%M%S)"
LOG_FILE="$PROJECT_ROOT/restore_all_log.txt"

# é¡è‰²è¼¸å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log() {
    echo -e "${BLUE}[$(date '+%H:%M:%S')]${NC} $1" | tee -a "$LOG_FILE"
}

success() {
    echo -e "${GREEN}âœ… $1${NC}" | tee -a "$LOG_FILE"
}

warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}" | tee -a "$LOG_FILE"
}

error() {
    echo -e "${RED}âŒ $1${NC}" | tee -a "$LOG_FILE"
}

# æª¢æŸ¥æ˜¯å¦ç‚ºå¯åŸ·è¡Œçš„ç¨‹å¼ç¢¼æª”æ¡ˆ
is_valid_code_file() {
    local file="$1"
    local size=$(stat -f "%z" "$file" 2>/dev/null || echo 0)
    local first_line=$(head -1 "$file" 2>/dev/null || echo "")
    
    # æª¢æŸ¥æª”æ¡ˆå¤§å°ï¼ˆå¤ªå°å¯èƒ½æ˜¯æ—¥èªŒï¼Œå¤ªå¤§å¯èƒ½æ˜¯éŒ¯èª¤ï¼‰
    if [ "$size" -lt 50 ] || [ "$size" -gt 10000000 ]; then
        return 1
    fi
    
    # æª¢æŸ¥æ˜¯å¦åŒ…å«ç¨‹å¼ç¢¼ç‰¹å¾µ
    if echo "$first_line" | grep -qE "(import|from|def |class |interface |export|function|#!/)"; then
        return 0
    fi
    
    # æª¢æŸ¥æ˜¯å¦ç‚º TypeScript/React æª”æ¡ˆ
    if echo "$file" | grep -qE "\.(tsx?|jsx?)$" && head -5 "$file" | grep -qE "(React|import.*from)"; then
        return 0
    fi
    
    # æª¢æŸ¥æ˜¯å¦ç‚º Python æª”æ¡ˆ
    if echo "$file" | grep -qE "\.py$" && head -5 "$file" | grep -qE "(import|from|def |class )"; then
        return 0
    fi
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºé…ç½®æª”æ¡ˆ
    if echo "$file" | grep -qE "\.(yml|yaml|json|md|sh|txt)$"; then
        return 0
    fi
    
    return 1
}

# é‚„åŸå–®å€‹æª”æ¡ˆ
restore_file() {
    local history_file="$1"
    local target_path="$2"
    
    if ! is_valid_code_file "$history_file"; then
        warning "è·³éç„¡æ•ˆæª”æ¡ˆ: $history_file"
        return 1
    fi
    
    # å‚™ä»½ç¾æœ‰æª”æ¡ˆ
    if [ -f "$target_path" ]; then
        mkdir -p "$BACKUP_DIR/$(dirname "$target_path")"
        cp "$target_path" "$BACKUP_DIR/$target_path"
        log "å‚™ä»½ç¾æœ‰æª”æ¡ˆ: $target_path"
    fi
    
    # é‚„åŸæª”æ¡ˆ
    mkdir -p "$(dirname "$target_path")"
    cp "$history_file" "$target_path"
    success "é‚„åŸ: $target_path"
    return 0
}

# ä¸»å‡½æ•¸
main() {
    log "é–‹å§‹é‚„åŸ 8:59 git restore å½±éŸ¿çš„æ‰€æœ‰æª”æ¡ˆ"
    log "å°ˆæ¡ˆç›®éŒ„: $PROJECT_ROOT"
    log "æ­·å²ç›®éŒ„: $HISTORY_DIR"
    log "å‚™ä»½ç›®éŒ„: $BACKUP_DIR"
    
    # æª¢æŸ¥å¿…è¦ç›®éŒ„
    if [ ! -d "$HISTORY_DIR" ]; then
        error "æ‰¾ä¸åˆ° Local History ç›®éŒ„: $HISTORY_DIR"
        exit 1
    fi
    
    # å»ºç«‹å‚™ä»½ç›®éŒ„
    mkdir -p "$BACKUP_DIR"
    
    # çµ±è¨ˆè®Šæ•¸
    local total_found=0
    local total_restored=0
    local total_skipped=0
    
    # æƒææ‰€æœ‰æ­·å²æª”æ¡ˆ
    log "æƒæ Local History æª”æ¡ˆ..."
    
    # ä½¿ç”¨ Python è…³æœ¬ä¾†æ‰¾å‡ºæ‰€æœ‰éœ€è¦é‚„åŸçš„æª”æ¡ˆ
    python3 << 'EOF'
import json
import datetime
import os
import urllib.parse
import subprocess
import sys

PROJECT_ROOT = "/Users/williamchen/Documents/n8n-migration-project"
HISTORY_DIR = "/Users/williamchen/Library/Application Support/Cursor/User/History"
target_date = datetime.date(2025, 10, 13)

# 8:59 é™„è¿‘çš„æ™‚é–“ç¯„åœ
start_time = datetime.time(8, 55)
end_time = datetime.time(9, 5)

restore_files = []

print("æƒæ Local History...")
for root, dirs, files in os.walk(HISTORY_DIR):
    if 'entries.json' in files:
        try:
            with open(os.path.join(root, 'entries.json'), 'r') as f:
                data = json.load(f)
            
            file_path = urllib.parse.unquote(data['resource'].replace('file://', ''))
            
            # æª¢æŸ¥ 8:55-9:05 ä¹‹é–“çš„è¨˜éŒ„
            for entry in data['entries']:
                timestamp = entry['timestamp'] / 1000
                dt = datetime.datetime.fromtimestamp(timestamp)
                
                if dt.date() == target_date and start_time <= dt.time() <= end_time:
                    restore_files.append({
                        'file': file_path,
                        'entry_id': entry['id'],
                        'timestamp': dt,
                        'source': entry.get('source', 'Unknown'),
                        'history_dir': root
                    })
        except Exception as e:
            continue

# æŒ‰æª”æ¡ˆåˆ†çµ„ï¼Œå–æœ€æ–°çš„ç‰ˆæœ¬
file_groups = {}
for item in restore_files:
    file_name = os.path.basename(item['file'])
    if file_name not in file_groups:
        file_groups[file_name] = []
    file_groups[file_name].append(item)

# ç‚ºæ¯å€‹æª”æ¡ˆæ‰¾å‡ºæœ€æ–°ç‰ˆæœ¬
latest_versions = []
for file_name, versions in file_groups.items():
    # æŒ‰æ™‚é–“æ’åºï¼Œå–æœ€æ–°çš„
    latest = max(versions, key=lambda x: x['timestamp'])
    latest_versions.append(latest)

# æŒ‰æ™‚é–“æ’åº
latest_versions.sort(key=lambda x: x['timestamp'])

print(f"æ‰¾åˆ° {len(latest_versions)} å€‹æª”æ¡ˆéœ€è¦é‚„åŸ")

# è¼¸å‡ºé‚„åŸæŒ‡ä»¤
for item in latest_versions:
    history_file = os.path.join(item['history_dir'], item['entry_id'])
    target_path = item['file']
    
    # è½‰æ›ç‚ºç›¸å°è·¯å¾‘
    if target_path.startswith(PROJECT_ROOT):
        target_path = os.path.relpath(target_path, PROJECT_ROOT)
    
    print(f"restore_file \"{history_file}\" \"{target_path}\"")
EOF
    
    # åŸ·è¡Œé‚„åŸ
    log "é–‹å§‹åŸ·è¡Œé‚„åŸ..."
    
    # é‡æ–°æƒæä¸¦é‚„åŸ
    python3 << 'EOF'
import json
import datetime
import os
import urllib.parse
import shutil

PROJECT_ROOT = "/Users/williamchen/Documents/n8n-migration-project"
HISTORY_DIR = "/Users/williamchen/Library/Application Support/Cursor/User/History"
BACKUP_DIR = f"{PROJECT_ROOT}/RESTORE_BACKUP_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
target_date = datetime.date(2025, 10, 13)

# 8:59 é™„è¿‘çš„æ™‚é–“ç¯„åœ
start_time = datetime.time(8, 55)
end_time = datetime.time(9, 5)

restore_files = []

print("æƒæ Local History...")
for root, dirs, files in os.walk(HISTORY_DIR):
    if 'entries.json' in files:
        try:
            with open(os.path.join(root, 'entries.json'), 'r') as f:
                data = json.load(f)
            
            file_path = urllib.parse.unquote(data['resource'].replace('file://', ''))
            
            # æª¢æŸ¥ 8:55-9:05 ä¹‹é–“çš„è¨˜éŒ„
            for entry in data['entries']:
                timestamp = entry['timestamp'] / 1000
                dt = datetime.datetime.fromtimestamp(timestamp)
                
                if dt.date() == target_date and start_time <= dt.time() <= end_time:
                    restore_files.append({
                        'file': file_path,
                        'entry_id': entry['id'],
                        'timestamp': dt,
                        'source': entry.get('source', 'Unknown'),
                        'history_dir': root
                    })
        except Exception as e:
            continue

# æŒ‰æª”æ¡ˆåˆ†çµ„ï¼Œå–æœ€æ–°çš„ç‰ˆæœ¬
file_groups = {}
for item in restore_files:
    file_name = os.path.basename(item['file'])
    if file_name not in file_groups:
        file_groups[file_name] = []
    file_groups[file_name].append(item)

# ç‚ºæ¯å€‹æª”æ¡ˆæ‰¾å‡ºæœ€æ–°ç‰ˆæœ¬
latest_versions = []
for file_name, versions in file_groups.items():
    # æŒ‰æ™‚é–“æ’åºï¼Œå–æœ€æ–°çš„
    latest = max(versions, key=lambda x: x['timestamp'])
    latest_versions.append(latest)

# æŒ‰æ™‚é–“æ’åº
latest_versions.sort(key=lambda x: x['timestamp'])

print(f"æ‰¾åˆ° {len(latest_versions)} å€‹æª”æ¡ˆéœ€è¦é‚„åŸ")

# å»ºç«‹å‚™ä»½ç›®éŒ„
os.makedirs(BACKUP_DIR, exist_ok=True)

# åŸ·è¡Œé‚„åŸ
restored_count = 0
skipped_count = 0

for item in latest_versions:
    history_file = os.path.join(item['history_dir'], item['entry_id'])
    target_path = item['file']
    
    try:
        # æª¢æŸ¥æ­·å²æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(history_file):
            print(f"âš ï¸  è·³é: æ­·å²æª”æ¡ˆä¸å­˜åœ¨ {history_file}")
            skipped_count += 1
            continue
        
        # æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_size = os.path.getsize(history_file)
        if file_size < 50 or file_size > 10000000:
            print(f"âš ï¸  è·³é: æª”æ¡ˆå¤§å°ç•°å¸¸ {history_file} ({file_size} bytes)")
            skipped_count += 1
            continue
        
        # å‚™ä»½ç¾æœ‰æª”æ¡ˆ
        if os.path.exists(target_path):
            backup_path = os.path.join(BACKUP_DIR, os.path.relpath(target_path, PROJECT_ROOT))
            os.makedirs(os.path.dirname(backup_path), exist_ok=True)
            shutil.copy2(target_path, backup_path)
            print(f"ğŸ“ å‚™ä»½: {target_path}")
        
        # é‚„åŸæª”æ¡ˆ
        os.makedirs(os.path.dirname(target_path), exist_ok=True)
        shutil.copy2(history_file, target_path)
        print(f"âœ… é‚„åŸ: {target_path} ({item['timestamp']})")
        restored_count += 1
        
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {target_path} - {e}")
        skipped_count += 1

print(f"\nğŸ‰ é‚„åŸå®Œæˆ!")
print(f"âœ… æˆåŠŸé‚„åŸ: {restored_count} å€‹æª”æ¡ˆ")
print(f"âš ï¸  è·³é: {skipped_count} å€‹æª”æ¡ˆ")
print(f"ğŸ“ å‚™ä»½ä½ç½®: {BACKUP_DIR}")
EOF
    
    log "é‚„åŸå®Œæˆ!"
    success "è©³ç´°æ—¥èªŒ: $LOG_FILE"
    
    echo
    echo "ğŸ‰ é‚„åŸå®Œæˆ! è«‹æª¢æŸ¥å°ˆæ¡ˆç‹€æ…‹ã€‚"
    echo "ğŸ“ å‚™ä»½ä½ç½®: $BACKUP_DIR"
    echo "ğŸ“‹ è©³ç´°æ—¥èªŒ: $LOG_FILE"
}

# åŸ·è¡Œä¸»å‡½æ•¸
main "$@"



