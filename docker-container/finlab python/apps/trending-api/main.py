import os
import requests
import json
from fastapi import FastAPI, Query
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import asyncio
import aiohttp
import sys
sys.path.append('/app')

# å°å…¥ CMoney å®¢æˆ¶ç«¯
from src.clients.cmoney.cmoney_client import CMoneyClient, LoginCredentials

# å°å…¥æ™ºèƒ½ Agent
from src.agents.intelligent_topic_analyzer import IntelligentTopicAnalyzer
from src.agents.multi_level_search_strategy import MultiLevelSearchStrategy
from src.agents.smart_content_generator import SmartContentGenerator

app = FastAPI(title="Trending API", description="ç†±é–€è©±é¡Œå’Œæ–°èç´ æAPI")

# é…ç½®
CMONEY_API_KEY = os.getenv("CMONEY_API_KEY", "demo_key")
ALPHA_VANTAGE_API_KEY = os.getenv("ALPHA_VANTAGE_API_KEY", "demo_key")
NEWS_API_KEY = os.getenv("NEWS_API_KEY", "demo_key")

# åˆå§‹åŒ–æ™ºèƒ½ Agent
topic_analyzer = IntelligentTopicAnalyzer()
search_strategy = MultiLevelSearchStrategy(topic_analyzer)
content_generator = SmartContentGenerator()

class TrendingTopic(BaseModel):
    id: str
    title: str
    content: str
    stock_ids: List[str]
    category: str
    created_at: datetime
    engagement_score: float

class NewsItem(BaseModel):
    title: str
    summary: str
    url: str
    published_at: datetime
    relevance_score: float
    stock_ids: List[str]

class TrendingResponse(BaseModel):
    topics: List[TrendingTopic]
    timestamp: datetime
    total_count: int

class NewsResponse(BaseModel):
    news: List[NewsItem]
    query: str
    timestamp: datetime

@app.get("/trending", response_model=TrendingResponse)
async def get_trending_topics(
    limit: int = Query(10, description="ç²å–è©±é¡Œæ•¸é‡"),
    category: str = Query(None, description="è©±é¡Œåˆ†é¡")
):
    """ç²å– Cmoney ç†±é–€è©±é¡Œ"""
    
    try:
        # ä½¿ç”¨çœŸå¯¦çš„ CMoney API
        cmoney_client = CMoneyClient()
        
        # ä½¿ç”¨å·å·å“¥çš„æ†‘è­‰
        credentials = LoginCredentials(
            email='forum_200@cmoney.com.tw',
            password='N9t1kY3x'
        )
        
        # ç™»å…¥ä¸¦ç²å–ç†±é–€è©±é¡Œ
        token = await cmoney_client.login(credentials)
        cmoney_topics = await cmoney_client.get_trending_topics(token.token)
        
        # è½‰æ›ç‚º API æ ¼å¼
        trending_topics = []
        print(f"ğŸ”¥ é–‹å§‹è™•ç† {len(cmoney_topics)} å€‹ CMoney ç†±é–€è©±é¡Œ")
        
        for topic in cmoney_topics[:limit]:
            print(f"ğŸ“ è™•ç†è©±é¡Œ - Topic ID: {topic.id}, æ¨™é¡Œ: {topic.title}")
            
            # ç²å–è©±é¡Œè©³ç´°è³‡è¨Šï¼ˆåŒ…å«è‚¡ç¥¨è³‡è¨Šï¼‰
            try:
                topic_detail = await cmoney_client.get_topic_detail(token.token, topic.id)
                
                # æå–è‚¡ç¥¨æ¨™ç±¤
                stock_ids = []
                if 'relatedStockSymbols' in topic_detail:
                    stock_symbols = topic_detail['relatedStockSymbols']
                    stock_ids = [stock['key'] for stock in stock_symbols if stock.get('type') == 'Stock']
                
                # æå–è©±é¡Œæè¿°
                description = topic_detail.get('description', topic.name)
                
                trending_topic = {
                    "id": topic.id,
                    "title": topic.title,
                    "content": description,
                    "stock_ids": stock_ids,
                    "category": "trending",
                    "created_at": datetime.now() - timedelta(hours=1),
                    "engagement_score": 0.8  # å¯ä»¥æ ¹æ“šå¯¦éš›æ•¸æ“šè¨ˆç®—
                }
                trending_topics.append(trending_topic)
                
                print(f"âœ… è©±é¡Œè™•ç†å®Œæˆ - Topic ID: {topic.id}, è‚¡ç¥¨IDs: {stock_ids}")
                
            except Exception as detail_error:
                print(f"ç²å–è©±é¡Œ {topic.id} è©³ç´°è³‡è¨Šå¤±æ•—: {detail_error}")
                # å¦‚æœç²å–è©³ç´°è³‡è¨Šå¤±æ•—ï¼Œä½¿ç”¨åŸºæœ¬è³‡è¨Š
                trending_topic = {
                    "id": topic.id,
                    "title": topic.title,
                    "content": topic.name,
                    "stock_ids": [],
                    "category": "trending",
                    "created_at": datetime.now() - timedelta(hours=1),
                    "engagement_score": 0.8
                }
                trending_topics.append(trending_topic)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è©±é¡Œï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨ fallback
        if not trending_topics:
            print("CMoney API è¿”å›ç©ºè©±é¡Œåˆ—è¡¨ï¼Œä½¿ç”¨æ¨¡æ“¬æ•¸æ“šä½œç‚º fallback")
            print("ğŸ”¥ é–‹å§‹ä½¿ç”¨æ¨¡æ“¬ç†±é–€è©±é¡Œæ•¸æ“š")
            trending_topics = [
                {
                    "id": "mock_topic_001",
                    "title": "å°è‚¡é«˜æª”éœ‡ç›ªï¼Œé–‹é«˜èµ°å¹³èƒŒå¾Œçš„çœŸç›¸ï¼Ÿ",
                    "content": "å°è‚¡ä»Šæ—¥é–‹é«˜å¾Œèµ°å¹³ï¼Œå¸‚å ´é—œæ³¨å¾ŒçºŒèµ°å‹¢ã€‚å¾æŠ€è¡“é¢ä¾†çœ‹ï¼Œå¤§ç›¤åœ¨é—œéµé˜»åŠ›ä½é™„è¿‘éœ‡ç›ªï¼ŒæŠ•è³‡äººéœ€å¯†åˆ‡é—œæ³¨æˆäº¤é‡è®ŠåŒ–ã€‚",
                    "stock_ids": ["2330", "2454", "2317"],
                    "category": "market_analysis",
                    "created_at": datetime.now() - timedelta(hours=1),
                    "engagement_score": 0.85
                },
                {
                    "id": "mock_topic_002",
                    "title": "AIæ¦‚å¿µè‚¡å¼·å‹¢ï¼Œå°ç©é›»é ˜è»ä¸Šæ”»",
                    "content": "AIæ¦‚å¿µè‚¡è¡¨ç¾å¼·å‹¢ï¼Œå°ç©é›»é ˜è»ç§‘æŠ€è‚¡ä¸Šæ”»ã€‚éš¨è‘—AIæ‡‰ç”¨éœ€æ±‚æŒçºŒå¢é•·ï¼Œç›¸é—œä¾›æ‡‰éˆå…¬å¸è‚¡åƒ¹è¡¨ç¾äº®çœ¼ã€‚",
                    "stock_ids": ["2330", "2454", "2379"],
                    "category": "technology",
                    "created_at": datetime.now() - timedelta(hours=2),
                    "engagement_score": 0.92
                },
                {
                    "id": "mock_topic_003",
                    "title": "é€šè†¨æ•¸æ“šå‡ºçˆï¼Œå¤®è¡Œæ”¿ç­–èµ°å‘å¼•é—œæ³¨",
                    "content": "æœ€æ–°é€šè†¨æ•¸æ“šå…¬å¸ƒï¼Œå¸‚å ´é—œæ³¨å¤®è¡Œæ”¿ç­–å‹•å‘ã€‚é€šè†¨å£“åŠ›æ˜¯å¦æœƒå½±éŸ¿åˆ©ç‡æ”¿ç­–ï¼Œæˆç‚ºæŠ•è³‡äººé—œæ³¨ç„¦é»ã€‚",
                    "stock_ids": ["2881", "2882", "2886"],
                    "category": "macro_economics",
                    "created_at": datetime.now() - timedelta(hours=3),
                    "engagement_score": 0.78
                },
                {
                    "id": "mock_topic_004",
                    "title": "ç”ŸæŠ€è‚¡ç•°è»çªèµ·ï¼Œæ¸›é‡è—¥é¡Œæç™¼é…µ",
                    "content": "ç”ŸæŠ€è‚¡ç•°è»çªèµ·ï¼Œæ¸›é‡è—¥é¡ŒææŒçºŒç™¼é…µã€‚éš¨è‘—æ¸›é‡è—¥å¸‚å ´éœ€æ±‚å¢é•·ï¼Œç›¸é—œç”ŸæŠ€å…¬å¸è‚¡åƒ¹è¡¨ç¾å¼·å‹¢ã€‚",
                    "stock_ids": ["6919", "4743", "6547"],
                    "category": "biotech",
                    "created_at": datetime.now() - timedelta(hours=4),
                    "engagement_score": 0.88
                },
                {
                    "id": "mock_topic_005",
                    "title": "é›»å‹•è»Šæ¦‚å¿µè‚¡å›æº«ï¼Œå……é›»æ¨å»ºè¨­åŠ é€Ÿ",
                    "content": "é›»å‹•è»Šæ¦‚å¿µè‚¡å›æº«ï¼Œå……é›»æ¨å»ºè¨­åŠ é€Ÿé€²è¡Œã€‚éš¨è‘—é›»å‹•è»Šæ™®åŠç‡æå‡ï¼Œå……é›»åŸºç¤è¨­æ–½éœ€æ±‚æŒçºŒå¢é•·ã€‚",
                    "stock_ids": ["3661", "2308", "2377"],
                    "category": "green_energy",
                    "created_at": datetime.now() - timedelta(hours=5),
                    "engagement_score": 0.82
                }
            ]
        
        # æ ¹æ“šåˆ†é¡ç¯©é¸
        if category:
            trending_topics = [t for t in trending_topics if t["category"] == category]
        
        return TrendingResponse(
            topics=trending_topics,
            timestamp=datetime.now(),
            total_count=len(trending_topics)
        )
        
    except Exception as e:
        # å¦‚æœçœŸå¯¦ API å¤±æ•—ï¼Œå›é€€åˆ°æ¨¡æ“¬æ•¸æ“š
        print(f"CMoney API éŒ¯èª¤: {e}")
        
        # æ¨¡æ“¬æ•¸æ“šä½œç‚ºå‚™ç”¨
        trending_topics = [
            {
                "id": "topic_001",
                "title": "å°ç©é›»æ³•èªªæœƒäº®çœ¼ï¼ŒAIéœ€æ±‚å¼·å‹",
                "content": "å°ç©é›»æœ€æ–°æ³•èªªæœƒé¡¯ç¤ºAIéœ€æ±‚æŒçºŒå¼·å‹ï¼Œç‡Ÿæ”¶å±•æœ›æ¨‚è§€...",
                "stock_ids": ["2330", "2454", "3034"],
                "category": "earnings",
                "created_at": datetime.now() - timedelta(hours=2),
                "engagement_score": 0.85
            },
            {
                "id": "topic_002", 
                "title": "è¯ç™¼ç§‘5Gæ™¶ç‰‡å¸‚å ç‡æå‡",
                "content": "è¯ç™¼ç§‘åœ¨5Gæ™¶ç‰‡å¸‚å ´è¡¨ç¾äº®çœ¼ï¼Œå¸‚å ç‡æŒçºŒæå‡...",
                "stock_ids": ["2454", "2379"],
                "category": "technology",
                "created_at": datetime.now() - timedelta(hours=4),
                "engagement_score": 0.72
            }
        ]
        
        # æ ¹æ“šåˆ†é¡ç¯©é¸
        if category:
            trending_topics = [t for t in trending_topics if t["category"] == category]
        
        # é™åˆ¶æ•¸é‡
        trending_topics = trending_topics[:limit]
        
        return TrendingResponse(
            topics=trending_topics,
            timestamp=datetime.now(),
            total_count=len(trending_topics)
        )

@app.get("/news/search", response_model=NewsResponse)
async def search_news(
    query: str = Query(..., description="æœå°‹é—œéµå­—"),
    stock_id: str = Query(None, description="è‚¡ç¥¨ä»£è™Ÿ"),
    limit: int = Query(10, description="æ–°èæ•¸é‡")
):
    """æœå°‹ç›¸é—œæ–°èç´ æ"""
    
    # æ¨¡æ“¬æ–°èAPIå›æ‡‰ (å¯¦éš›æ•´åˆæ™‚æ›¿æ›)
    news_items = [
        {
            "title": f"{query}ç›¸é—œæ–°èæ¨™é¡Œ1",
            "summary": f"é€™æ˜¯é—œæ–¼{query}çš„æ–°èæ‘˜è¦ï¼ŒåŒ…å«é‡è¦è³‡è¨Š...",
            "url": "https://example.com/news1",
            "published_at": datetime.now() - timedelta(hours=1),
            "relevance_score": 0.92,
            "stock_ids": [stock_id] if stock_id else []
        },
        {
            "title": f"{query}ç”¢æ¥­åˆ†æå ±å‘Š",
            "summary": f"æ·±å…¥åˆ†æ{query}ç”¢æ¥­ç™¼å±•è¶¨å‹¢å’ŒæŠ•è³‡æ©Ÿæœƒ...",
            "url": "https://example.com/news2", 
            "published_at": datetime.now() - timedelta(hours=3),
            "relevance_score": 0.87,
            "stock_ids": [stock_id] if stock_id else []
        }
    ]
    
    # é™åˆ¶æ•¸é‡
    news_items = news_items[:limit]
    
    return NewsResponse(
        news=news_items,
        query=query,
        timestamp=datetime.now()
    )

@app.get("/news/stock/{stock_id}", response_model=NewsResponse)
async def get_stock_news(
    stock_id: str,
    limit: int = Query(10, description="æ–°èæ•¸é‡"),
    days_back: int = Query(7, description="å›æº¯å¤©æ•¸")
):
    """æ ¹æ“šè‚¡ç¥¨ä»£è™Ÿç²å–ç›¸é—œæ–°è"""
    
    # æ¨¡æ“¬è‚¡ç¥¨ç›¸é—œæ–°è (å¯¦éš›æ•´åˆæ™‚æ›¿æ›)
    stock_news = [
        {
            "title": f"{stock_id}æœ€æ–°è²¡å ±åˆ†æ",
            "summary": f"{stock_id}ç™¼å¸ƒæœ€æ–°è²¡å ±ï¼Œç‡Ÿæ”¶æˆé•·è¡¨ç¾äº®çœ¼...",
            "url": f"https://example.com/stock/{stock_id}/earnings",
            "published_at": datetime.now() - timedelta(hours=2),
            "relevance_score": 0.95,
            "stock_ids": [stock_id]
        },
        {
            "title": f"{stock_id}ç”¢æ¥­è¶¨å‹¢åˆ†æ",
            "summary": f"åˆ†æ{stock_id}æ‰€å±¬ç”¢æ¥­çš„ç™¼å±•è¶¨å‹¢å’ŒæŠ•è³‡æ©Ÿæœƒ...",
            "url": f"https://example.com/stock/{stock_id}/industry",
            "published_at": datetime.now() - timedelta(hours=6),
            "relevance_score": 0.88,
            "stock_ids": [stock_id]
        }
    ]
    
    # é™åˆ¶æ•¸é‡å’Œæ™‚é–“ç¯„åœ
    cutoff_date = datetime.now() - timedelta(days=days_back)
    stock_news = [n for n in stock_news if n["published_at"] >= cutoff_date]
    stock_news = stock_news[:limit]
    
    return NewsResponse(
        news=stock_news,
        query=f"stock:{stock_id}",
        timestamp=datetime.now()
    )

@app.get("/trending/stocks")
async def get_trending_stocks(
    limit: int = Query(20, description="è‚¡ç¥¨æ•¸é‡")
):
    """ç²å–ç†±é–€è‚¡ç¥¨åˆ—è¡¨"""
    
    # æ¨¡æ“¬ç†±é–€è‚¡ç¥¨æ•¸æ“š (å¯¦éš›æ•´åˆæ™‚æ›¿æ›)
    trending_stocks = [
        {"stock_id": "2330", "name": "å°ç©é›»", "trend_score": 0.95, "volume_change": 0.15},
        {"stock_id": "2454", "name": "è¯ç™¼ç§‘", "trend_score": 0.87, "volume_change": 0.12},
        {"stock_id": "2317", "name": "é´»æµ·", "trend_score": 0.82, "volume_change": 0.08},
        {"stock_id": "3008", "name": "å¤§ç«‹å…‰", "trend_score": 0.78, "volume_change": 0.06},
        {"stock_id": "2412", "name": "ä¸­è¯é›»", "trend_score": 0.75, "volume_change": 0.05}
    ]
    
    # æŒ‰ç†±é–€åº¦æ’åº
    trending_stocks.sort(key=lambda x: x["trend_score"], reverse=True)
    
    return {
        "stocks": trending_stocks[:limit],
        "timestamp": datetime.now(),
        "total_count": len(trending_stocks)
    }

@app.get("/extract-keywords")
async def extract_keywords_from_topic(
    topic_id: str = Query(..., description="ç†±é–€è©±é¡ŒID"),
    max_keywords: int = Query(5, description="æœ€å¤§é—œéµå­—æ•¸é‡")
):
    """å¾ç†±é–€è©±é¡Œä¸­æå–é—œéµå­—"""
    try:
        cmoney_client = CMoneyClient()
        credentials = LoginCredentials(email='forum_200@cmoney.com.tw', password='N9t1kY3x')
        token = await cmoney_client.login(credentials)
        
        # ç²å–è©±é¡Œè©³ç´°è³‡è¨Š
        topic_detail = await cmoney_client.get_topic_detail(token.token, topic_id)
        
        # æå–é—œéµå­—çš„é‚è¼¯ - è¿”å›å®Œæ•´è©±é¡Œå…§å®¹
        keywords = []
        
        # çµ„åˆæ¨™é¡Œå’Œå…§å®¹ä½œç‚ºå®Œæ•´çš„è©±é¡Œæè¿°
        title = topic_detail.get('title', '')
        content = topic_detail.get('description', '')
        
        # å°‡æ¨™é¡Œå’Œå…§å®¹çµ„åˆæˆå®Œæ•´çš„è©±é¡Œæè¿°
        full_topic_content = f"{title} {content}".strip()
        
        if full_topic_content:
            # æ¸…ç†ä¸¦æˆªå–å…§å®¹
            cleaned_content = extract_keywords_from_text(full_topic_content)
            keywords.extend(cleaned_content)
        
        # ç¢ºä¿è‡³å°‘æœ‰ä¸€å€‹é—œéµå­—
        if not keywords:
            keywords = [title if title else "ç†±é–€è©±é¡Œå…§å®¹"]
        
        return {
            "topic_id": topic_id,
            "title": title,
            "keywords": keywords,
            "extraction_method": "complete_topic_content",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"æå–é—œéµå­—å¤±æ•—: {e}")
        return {"error": f"æå–é—œéµå­—å¤±æ•—: {str(e)}"}

def extract_keywords_from_text(text: str) -> list:
    """å¾æ–‡æœ¬ä¸­æå–é—œéµå­— - è¿”å›å®Œæ•´å…§å®¹è€Œä¸æ˜¯æ‹†åˆ†"""
    import re
    
    # æ¸…ç†æ–‡æœ¬ï¼Œä½†ä¿æŒå®Œæ•´æ€§
    cleaned_text = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', text)
    
    # ç§»é™¤å¤šé¤˜ç©ºæ ¼
    cleaned_text = ' '.join(cleaned_text.split())
    
    # å¦‚æœæ–‡æœ¬å¤ªé•·ï¼Œæˆªå–å‰100å€‹å­—ç¬¦
    if len(cleaned_text) > 100:
        cleaned_text = cleaned_text[:100] + '...'
    
    # è¿”å›å®Œæ•´å…§å®¹ä½œç‚ºä¸€å€‹é—œéµå­—
    return [cleaned_text] if cleaned_text.strip() else []

@app.get("/search-stocks-by-keywords")
async def search_stocks_by_keywords(
    keywords: str = Query(..., description="é—œéµå­—åˆ—è¡¨ï¼Œç”¨é€—è™Ÿåˆ†éš”"),
    limit: int = Query(10, description="å›å‚³è‚¡ç¥¨æ•¸é‡é™åˆ¶")
):
    """ä½¿ç”¨é—œéµå­—æœå°‹ç›¸é—œè‚¡ç¥¨"""
    try:
        keyword_list = [k.strip() for k in keywords.split(',') if k.strip()]
        
        # é€™è£¡å¯ä»¥æ•´åˆè‚¡ç¥¨æœå°‹é‚è¼¯
        # ç›®å‰å…ˆå›å‚³æ¨¡æ“¬æ•¸æ“šï¼Œå¾ŒçºŒå¯ä»¥æ•´åˆ FinLab API æˆ–å…¶ä»–è‚¡ç¥¨æœå°‹æœå‹™
        matched_stocks = []
        
        for keyword in keyword_list:
            # æ¨¡æ“¬è‚¡ç¥¨æœå°‹çµæœ
            # å¯¦éš›å¯¦ç¾æ™‚ï¼Œé€™è£¡æœƒèª¿ç”¨è‚¡ç¥¨æœå°‹ API
            if 'å°ç©é›»' in keyword or 'TSMC' in keyword or 'åŠå°é«”' in keyword:
                matched_stocks.append({
                    "code": "2330",
                    "name": "å°ç©é›»",
                    "industry": "åŠå°é«”æ¥­",
                    "match_keyword": keyword,
                    "match_score": 0.9
                })
            elif 'é´»æµ·' in keyword or 'Foxconn' in keyword or 'é›»å­' in keyword:
                matched_stocks.append({
                    "code": "2317", 
                    "name": "é´»æµ·",
                    "industry": "å…¶ä»–é›»å­æ¥­",
                    "match_keyword": keyword,
                    "match_score": 0.8
                })
            elif 'è¯ç™¼ç§‘' in keyword or 'MTK' in keyword or 'ICè¨­è¨ˆ' in keyword:
                matched_stocks.append({
                    "code": "2454",
                    "name": "è¯ç™¼ç§‘", 
                    "industry": "åŠå°é«”æ¥­",
                    "match_keyword": keyword,
                    "match_score": 0.85
                })
            elif 'å°æŒ‡' in keyword or 'å¤§ç›¤' in keyword or 'æŒ‡æ•¸' in keyword:
                matched_stocks.append({
                    "code": "TWA00",
                    "name": "å°æŒ‡æœŸ",
                    "industry": "æœŸè²¨",
                    "match_keyword": keyword,
                    "match_score": 0.95
                })
        
        # å»é‡ä¸¦æŒ‰åŒ¹é…åˆ†æ•¸æ’åº
        unique_stocks = {}
        for stock in matched_stocks:
            if stock["code"] not in unique_stocks or stock["match_score"] > unique_stocks[stock["code"]]["match_score"]:
                unique_stocks[stock["code"]] = stock
        
        sorted_stocks = sorted(unique_stocks.values(), key=lambda x: x["match_score"], reverse=True)[:limit]
        
        return {
            "keywords": keyword_list,
            "matched_stocks": sorted_stocks,
            "total_matches": len(sorted_stocks),
            "search_method": "keyword_matching",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"é—œéµå­—æœå°‹è‚¡ç¥¨å¤±æ•—: {e}")
        return {"error": f"é—œéµå­—æœå°‹è‚¡ç¥¨å¤±æ•—: {str(e)}"}

@app.get("/extract-and-search")
async def extract_keywords_and_search_stocks(
    topic_id: str = Query(..., description="ç†±é–€è©±é¡ŒID"),
    max_keywords: int = Query(5, description="æœ€å¤§é—œéµå­—æ•¸é‡"),
    stock_limit: int = Query(10, description="å›å‚³è‚¡ç¥¨æ•¸é‡é™åˆ¶")
):
    """å¾ç†±é–€è©±é¡Œæå–é—œéµå­—ä¸¦æœå°‹ç›¸é—œè‚¡ç¥¨"""
    try:
        # æ­¥é©Ÿ1ï¼šæå–é—œéµå­—
        keywords_result = await extract_keywords_from_topic(topic_id, max_keywords)
        
        if "error" in keywords_result:
            return keywords_result
        
        keywords = keywords_result["keywords"]
        
        # æ­¥é©Ÿ2ï¼šä½¿ç”¨é—œéµå­—æœå°‹è‚¡ç¥¨
        keywords_str = ",".join(keywords)
        stocks_result = await search_stocks_by_keywords(keywords_str, stock_limit)
        
        if "error" in stocks_result:
            return stocks_result
        
        # æ•´åˆçµæœ
        return {
            "topic_id": topic_id,
            "topic_title": keywords_result["title"],
            "extracted_keywords": keywords,
            "matched_stocks": stocks_result["matched_stocks"],
            "total_matches": stocks_result["total_matches"],
            "extraction_method": keywords_result["extraction_method"],
            "search_method": stocks_result["search_method"],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"æå–é—œéµå­—ä¸¦æœå°‹è‚¡ç¥¨å¤±æ•—: {e}")
        return {"error": f"æå–é—œéµå­—ä¸¦æœå°‹è‚¡ç¥¨å¤±æ•—: {str(e)}"}

# ==================== æ™ºèƒ½ Agent ç«¯é» ====================

@app.get("/analyze-topic")
async def analyze_topic_intelligently(
    topic_id: str = Query(..., description="ç†±é–€è©±é¡ŒID")
):
    """æ™ºèƒ½åˆ†æç†±é–€è©±é¡Œ"""
    try:
        # ç²å–è©±é¡Œè©³æƒ…
        cmoney_client = CMoneyClient()
        credentials = LoginCredentials(email='forum_200@cmoney.com.tw', password='N9t1kY3x')
        token = await cmoney_client.login(credentials)
        
        topic_detail = await cmoney_client.get_topic_detail(token.token, topic_id)
        
        if not topic_detail:
            return {"error": "ç„¡æ³•ç²å–è©±é¡Œè©³æƒ…"}
        
        # æ™ºèƒ½åˆ†æè©±é¡Œ
        topic_analysis = await topic_analyzer.analyze_topic(topic_detail)
        
        return {
            "topic_id": topic_id,
            "topic_title": topic_detail.get('title', ''),
            "analysis": {
                "topic_type": topic_analysis.topic_type,
                "sentiment": topic_analysis.sentiment,
                "market_impact": topic_analysis.market_impact,
                "confidence": topic_analysis.confidence,
                "entities": [
                    {
                        "text": entity.text,
                        "type": entity.type,
                        "confidence": entity.confidence
                    } for entity in topic_analysis.entities
                ]
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"æ™ºèƒ½åˆ†æè©±é¡Œå¤±æ•—: {e}")
        return {"error": f"æ™ºèƒ½åˆ†æè©±é¡Œå¤±æ•—: {str(e)}"}

@app.get("/generate-search-strategy")
async def generate_intelligent_search_strategy(
    topic_id: str = Query(..., description="ç†±é–€è©±é¡ŒID"),
    stock_code: str = Query(..., description="è‚¡ç¥¨ä»£è™Ÿ")
):
    """ç‚ºç‰¹å®šè‚¡ç¥¨ç”Ÿæˆæ™ºèƒ½æœå°‹ç­–ç•¥"""
    try:
        # ç²å–è©±é¡Œè©³æƒ…
        cmoney_client = CMoneyClient()
        credentials = LoginCredentials(email='forum_200@cmoney.com.tw', password='N9t1kY3x')
        token = await cmoney_client.login(credentials)
        
        topic_detail = await cmoney_client.get_topic_detail(token.token, topic_id)
        
        if not topic_detail:
            return {"error": "ç„¡æ³•ç²å–è©±é¡Œè©³æƒ…"}
        
        # ç”Ÿæˆæœå°‹ç­–ç•¥
        search_strategy_result = await search_strategy.generate_search_strategy(topic_detail, stock_code)
        
        return {
            "topic_id": topic_id,
            "stock_code": stock_code,
            "search_strategy": {
                "recommended_strategy": search_strategy_result.recommended_strategy,
                "overall_confidence": search_strategy_result.overall_confidence,
                "queries": [
                    {
                        "level": query.level,
                        "query": query.query,
                        "priority": query.priority,
                        "weight": query.weight,
                        "strategy": query.strategy,
                        "confidence": query.confidence
                    } for query in search_strategy_result.queries
                ]
            },
            "news_search_keywords": search_strategy.get_search_keywords_for_news(search_strategy_result),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"ç”Ÿæˆæœå°‹ç­–ç•¥å¤±æ•—: {e}")
        return {"error": f"ç”Ÿæˆæœå°‹ç­–ç•¥å¤±æ•—: {str(e)}"}

@app.post("/generate-content")
async def generate_intelligent_content(
    topic_id: str = Query(..., description="ç†±é–€è©±é¡ŒID"),
    stock_code: str = Query(..., description="è‚¡ç¥¨ä»£è™Ÿ"),
    stock_data: dict = None,
    news_results: list = None
):
    """ç”Ÿæˆæ™ºèƒ½å…§å®¹"""
    try:
        # ç²å–è©±é¡Œè©³æƒ…
        cmoney_client = CMoneyClient()
        credentials = LoginCredentials(email='forum_200@cmoney.com.tw', password='N9t1kY3x')
        token = await cmoney_client.login(credentials)
        
        topic_detail = await cmoney_client.get_topic_detail(token.token, topic_id)
        
        if not topic_detail:
            return {"error": "ç„¡æ³•ç²å–è©±é¡Œè©³æƒ…"}
        
        # åˆ†æè©±é¡Œ
        topic_analysis = await topic_analyzer.analyze_topic(topic_detail)
        
        # ç”Ÿæˆæœå°‹ç­–ç•¥
        search_strategy_result = await search_strategy.generate_search_strategy(topic_detail, stock_code)
        
        # æº–å‚™å…§å®¹ä¸Šä¸‹æ–‡
        from src.agents.smart_content_generator import ContentContext
        context = ContentContext(
            topic=topic_detail,
            stock_data=stock_data or {},
            news_results=news_results or [],
            topic_analysis=topic_analysis,
            search_strategy=search_strategy_result,
            timestamp=datetime.now()
        )
        
        # ç”Ÿæˆå…§å®¹
        generated_content = await content_generator.generate_contextual_content(context)
        
        return {
            "topic_id": topic_id,
            "stock_code": stock_code,
            "generated_content": {
                "content": generated_content.content,
                "style": generated_content.style,
                "confidence": generated_content.confidence,
                "data_sources": generated_content.data_sources,
                "news_sources": generated_content.news_sources,
                "metadata": generated_content.metadata
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"ç”Ÿæˆæ™ºèƒ½å…§å®¹å¤±æ•—: {e}")
        return {"error": f"ç”Ÿæˆæ™ºèƒ½å…§å®¹å¤±æ•—: {str(e)}"}

@app.get("/intelligent-extract-keywords")
async def intelligent_extract_keywords(
    topic_id: str = Query(..., description="ç†±é–€è©±é¡ŒID"),
    stock_code: str = Query(None, description="è‚¡ç¥¨ä»£è™Ÿï¼ˆå¯é¸ï¼‰")
):
    """æ™ºèƒ½æå–é—œéµå­—ï¼ˆæ•´åˆæ‰€æœ‰ Agentï¼‰"""
    try:
        # ç²å–è©±é¡Œè©³æƒ…
        cmoney_client = CMoneyClient()
        credentials = LoginCredentials(email='forum_200@cmoney.com.tw', password='N9t1kY3x')
        token = await cmoney_client.login(credentials)
        
        topic_detail = await cmoney_client.get_topic_detail(token.token, topic_id)
        
        if not topic_detail:
            return {"error": "ç„¡æ³•ç²å–è©±é¡Œè©³æƒ…"}
        
        # æ™ºèƒ½åˆ†æè©±é¡Œ
        topic_analysis = await topic_analyzer.analyze_topic(topic_detail)
        
        # å¦‚æœæœ‰è‚¡ç¥¨ä»£è™Ÿï¼Œç”Ÿæˆæœå°‹ç­–ç•¥
        search_keywords = []
        if stock_code:
            search_strategy_result = await search_strategy.generate_search_strategy(topic_detail, stock_code)
            search_keywords = search_strategy.get_search_keywords_for_news(search_strategy_result)
        
        # æå–å‚³çµ±é—œéµå­—ï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰
        traditional_keywords = extract_keywords_from_text(f"{topic_detail.get('title', '')} {topic_detail.get('description', '')}")
        
        return {
            "topic_id": topic_id,
            "topic_title": topic_detail.get('title', ''),
            "intelligent_analysis": {
                "topic_type": topic_analysis.topic_type,
                "sentiment": topic_analysis.sentiment,
                "market_impact": topic_analysis.market_impact,
                "confidence": topic_analysis.confidence
            },
            "keywords": {
                "traditional": traditional_keywords,
                "intelligent_search": search_keywords,
                "recommended": search_keywords if search_keywords else traditional_keywords
            },
            "extraction_method": "intelligent_analysis",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"æ™ºèƒ½æå–é—œéµå­—å¤±æ•—: {e}")
        return {"error": f"æ™ºèƒ½æå–é—œéµå­—å¤±æ•—: {str(e)}"}

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now(),
        "services": {
            "cmoney_api": "connected" if CMONEY_API_KEY != "demo_key" else "demo_mode",
            "news_api": "connected" if ALPHA_VANTAGE_API_KEY != "demo_key" else "demo_mode"
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

