"""
å…§å®¹å“è³ªæª¢æŸ¥å™¨
æª¢æŸ¥ç”Ÿæˆå…§å®¹çš„å“è³ªï¼ŒåŒ…æ‹¬ç›¸ä¼¼åº¦ã€é•·åº¦ã€å€‹äººåŒ–ç‰¹å¾µç­‰
"""

import re
import json
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
from openai import OpenAI
import os

logger = logging.getLogger(__name__)

@dataclass
class QualityIssue:
    """å“è³ªå•é¡Œ"""
    post_id: str
    issue_type: str
    severity: str  # high, medium, low
    description: str
    suggestion: str
    score: float = 0.0
    similar_to: Optional[str] = None

@dataclass
class QualityCheckResult:
    """å“è³ªæª¢æŸ¥çµæœ"""
    passed: bool
    overall_score: float
    issues: List[QualityIssue]
    posts_to_regenerate: List[str]
    check_timestamp: datetime
    detailed_scores: Dict[str, Dict[str, float]]

@dataclass
class GeneratedPost:
    """ç”Ÿæˆçš„è²¼æ–‡"""
    post_id: str
    kol_serial: str
    kol_nickname: str
    persona: str
    title: str
    content: str
    topic_title: str
    topic_id: str  # å®Œæ•´çš„ topic ID
    generation_params: Dict[str, Any]
    created_at: datetime

class ContentQualityChecker:
    """å…§å®¹å“è³ªæª¢æŸ¥å™¨"""
    
    def __init__(self):
        self.llm_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # å“è³ªé–¾å€¼è¨­å®š
        self.similarity_threshold = 0.75
        self.min_length_threshold = 50
        self.max_length_threshold = 600
        self.personalization_threshold = 0.6
        self.overall_quality_threshold = 6.0
        
        # æª¢æŸ¥æ¬Šé‡
        self.check_weights = {
            'length': 0.2,
            'similarity': 0.3,
            'personalization': 0.3,
            'content_quality': 0.2
        }
    
    async def check_batch_quality(self, posts: List[GeneratedPost]) -> QualityCheckResult:
        """æª¢æŸ¥ä¸€æ‰¹è²¼æ–‡çš„æ•´é«”å“è³ª"""
        
        print(f"\nğŸ” é–‹å§‹å“è³ªæª¢æŸ¥ ({len(posts)} ç¯‡è²¼æ–‡)...")
        
        all_issues = []
        posts_to_regenerate = []
        detailed_scores = {}
        
        # 1. å€‹åˆ¥è²¼æ–‡æª¢æŸ¥
        for post in posts:
            post_issues, post_scores = await self.check_individual_post(post)
            all_issues.extend(post_issues)
            detailed_scores[post.post_id] = post_scores
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ç”Ÿæˆ
            if post_scores['overall'] < self.overall_quality_threshold:
                posts_to_regenerate.append(post.post_id)
        
        # 2. æ‰¹æ¬¡ç›¸ä¼¼åº¦æª¢æŸ¥
        similarity_issues = await self.check_batch_similarity(posts)
        all_issues.extend(similarity_issues)
        
        # æ›´æ–°éœ€è¦é‡æ–°ç”Ÿæˆçš„è²¼æ–‡
        for issue in similarity_issues:
            if issue.post_id not in posts_to_regenerate:
                posts_to_regenerate.append(issue.post_id)
            if issue.similar_to and issue.similar_to not in posts_to_regenerate:
                posts_to_regenerate.append(issue.similar_to)
        
        # 3. è¨ˆç®—æ•´é«”å“è³ªåˆ†æ•¸
        overall_score = self.calculate_overall_score(detailed_scores, len(all_issues))
        
        # 4. ç”Ÿæˆæª¢æŸ¥çµæœ
        result = QualityCheckResult(
            passed=len(posts_to_regenerate) == 0,
            overall_score=overall_score,
            issues=all_issues,
            posts_to_regenerate=list(set(posts_to_regenerate)),  # å»é‡
            check_timestamp=datetime.now(),
            detailed_scores=detailed_scores
        )
        
        # 5. é¡¯ç¤ºæª¢æŸ¥çµæœ
        self.display_check_results(result, posts)
        
        return result
    
    async def check_individual_post(self, post: GeneratedPost) -> tuple[List[QualityIssue], Dict[str, float]]:
        """æª¢æŸ¥å–®ç¯‡è²¼æ–‡å“è³ª"""
        
        issues = []
        scores = {}
        
        # 1. é•·åº¦æª¢æŸ¥
        length_score, length_issues = self.check_content_length(post)
        scores['length'] = length_score
        issues.extend(length_issues)
        
        # 2. å€‹äººåŒ–ç‰¹å¾µæª¢æŸ¥
        personalization_score, personalization_issues = await self.check_personalization_features(post)
        scores['personalization'] = personalization_score
        issues.extend(personalization_issues)
        
        # 3. å…§å®¹å“è³ªæª¢æŸ¥
        content_score, content_issues = await self.check_content_quality(post)
        scores['content_quality'] = content_score
        issues.extend(content_issues)
        
        # 4. è¨ˆç®—ç¸½åˆ†
        overall_score = (
            length_score * self.check_weights['length'] +
            personalization_score * self.check_weights['personalization'] +
            content_score * self.check_weights['content_quality']
        )
        scores['overall'] = overall_score
        
        return issues, scores
    
    def check_content_length(self, post: GeneratedPost) -> tuple[float, List[QualityIssue]]:
        """æª¢æŸ¥å…§å®¹é•·åº¦"""
        
        content_length = len(post.content)
        issues = []
        
        # åŸºç¤é•·åº¦æª¢æŸ¥
        if content_length < self.min_length_threshold:
            issues.append(QualityIssue(
                post_id=post.post_id,
                issue_type='content_too_short',
                severity='high',
                description=f'å…§å®¹éçŸ­ï¼š{content_length} å­— (æœ€å°‘éœ€è¦ {self.min_length_threshold} å­—)',
                suggestion='å¢åŠ åˆ†ææ·±åº¦å’Œå…·é«”è§€é»',
                score=content_length / self.min_length_threshold * 10
            ))
            return content_length / self.min_length_threshold * 10, issues
        
        if content_length > self.max_length_threshold:
            issues.append(QualityIssue(
                post_id=post.post_id,
                issue_type='content_too_long',
                severity='medium',
                description=f'å…§å®¹éé•·ï¼š{content_length} å­— (å»ºè­°ä¸è¶…é {self.max_length_threshold} å­—)',
                suggestion='ç²¾ç°¡è¡¨é”ï¼Œçªå‡ºé‡é»',
                score=8.0
            ))
            return 8.0, issues
        
        # æ ¹æ“šé æœŸé•·åº¦è¨ˆç®—åˆ†æ•¸
        if 100 <= content_length <= 400:
            return 10.0, issues
        else:
            return 8.0, issues
    
    async def check_personalization_features(self, post: GeneratedPost) -> tuple[float, List[QualityIssue]]:
        """æª¢æŸ¥å€‹äººåŒ–ç‰¹å¾µ"""
        
        # ä½¿ç”¨ LLM åˆ†æå€‹äººåŒ–ç¨‹åº¦
        personalization_prompt = f"""
è«‹è©•ä¼°ä»¥ä¸‹è²¼æ–‡çš„å€‹äººåŒ–ç¨‹åº¦ï¼š

KOL: {post.kol_nickname} ({post.persona})
æ¨™é¡Œ: {post.title}
å…§å®¹: {post.content}

è©•ä¼°ç¶­åº¦ï¼ˆ1-10åˆ†ï¼‰ï¼š
1. èªæ°£é¢¨æ ¼æ˜¯å¦ç¬¦åˆ {post.persona} ç‰¹è‰²
2. ç”¨è©æ˜¯å¦å…·æœ‰å€‹äººç‰¹è‰²
3. è¡¨é”æ–¹å¼æ˜¯å¦è‡ªç„¶ä¸åšä½œ
4. å°ˆæ¥­è§’åº¦æ˜¯å¦çªå‡º
5. æ•´é«”æ˜¯å¦åƒçœŸäººç™¼æ–‡

è«‹å›å‚³ JSON æ ¼å¼ï¼š
{{
  "style_score": 8,
  "vocabulary_score": 7,
  "naturalness_score": 9,
  "expertise_score": 8,
  "authenticity_score": 7,
  "overall_score": 7.8,
  "issues": ["èªæ°£å¯ä»¥æ›´å£èªåŒ–", "ç¼ºå°‘å°ˆæ¥­è¡“èª"],
  "strengths": ["è§€é»æ˜ç¢º", "é‚è¼¯æ¸…æ™°"]
}}
"""
        
        try:
            response = self.llm_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„å…§å®¹åˆ†æå¸«ï¼Œæ“…é•·è©•ä¼°æ–‡ç« çš„å€‹äººåŒ–ç¨‹åº¦ã€‚"},
                    {"role": "user", "content": personalization_prompt}
                ],
                temperature=0.1
            )
            
            analysis = json.loads(response.choices[0].message.content)
            overall_score = analysis.get('overall_score', 5.0)
            
            issues = []
            if overall_score < self.personalization_threshold * 10:
                issues.append(QualityIssue(
                    post_id=post.post_id,
                    issue_type='insufficient_personalization',
                    severity='high' if overall_score < 5.0 else 'medium',
                    description=f'å€‹äººåŒ–ç¨‹åº¦ä¸è¶³ï¼š{overall_score}/10',
                    suggestion=f"æ”¹é€²å»ºè­°ï¼š{', '.join(analysis.get('issues', []))}",
                    score=overall_score
                ))
            
            return overall_score, issues
            
        except Exception as e:
            logger.error(f"å€‹äººåŒ–æª¢æŸ¥å¤±æ•—: {e}")
            return 5.0, []
    
    async def check_content_quality(self, post: GeneratedPost) -> tuple[float, List[QualityIssue]]:
        """æª¢æŸ¥å…§å®¹å“è³ª"""
        
        quality_prompt = f"""
è«‹è©•ä¼°ä»¥ä¸‹æŠ•è³‡åˆ†ææ–‡ç« çš„å“è³ªï¼š

æ¨™é¡Œ: {post.title}
å…§å®¹: {post.content}

è©•ä¼°æ¨™æº–ï¼ˆ1-10åˆ†ï¼‰ï¼š
1. å…§å®¹æ˜¯å¦æœ‰å¯¦è³ªåˆ†æåƒ¹å€¼
2. è§€é»æ˜¯å¦æ˜ç¢ºä¸”æœ‰é‚è¼¯
3. æ˜¯å¦é©åˆæŠ•è³‡è¨è«–
4. èªè¨€è¡¨é”æ˜¯å¦æµæš¢
5. æ˜¯å¦æœ‰æ˜é¡¯çš„ AI ç”Ÿæˆç—•è·¡

è«‹å›å‚³ JSON æ ¼å¼ï¼š
{{
  "analysis_value": 8,
  "logical_coherence": 7,
  "investment_relevance": 9,
  "language_fluency": 8,
  "human_like": 6,
  "overall_score": 7.6,
  "major_issues": ["éæ–¼æ¨¡æ¿åŒ–", "ç¼ºä¹å…·é«”æ•¸æ“š"],
  "improvement_suggestions": ["å¢åŠ å…·é«”æ¡ˆä¾‹", "ä½¿ç”¨æ›´å¤šå°ˆæ¥­è¡“èª"]
}}
"""
        
        try:
            print(f"    ğŸ¤– èª¿ç”¨ LLM é€²è¡Œå“è³ªè©•ä¼°...")
            response = self.llm_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„æŠ•è³‡å…§å®¹è©•å¯©å¸«ã€‚"},
                    {"role": "user", "content": quality_prompt}
                ],
                temperature=0.1,
                timeout=20.0  # å¢åŠ è¶…æ™‚è¨­å®š
            )
            
            response_content = response.choices[0].message.content
            print(f"    ğŸ“ LLM å›æ‡‰é•·åº¦: {len(response_content)} å­—ç¬¦")
            
            try:
                analysis = json.loads(response_content)
                overall_score = analysis.get('overall_score', 5.0)
                print(f"    âœ… JSON è§£ææˆåŠŸï¼Œè©•åˆ†: {overall_score}")
            except json.JSONDecodeError as je:
                print(f"    âš ï¸ JSON è§£æå¤±æ•—: {je}")
                print(f"    ğŸ“„ åŸå§‹å›æ‡‰: {response_content[:200]}...")
                # å˜—è©¦å¾æ–‡å­—ä¸­æå–åˆ†æ•¸
                score_match = re.search(r'overall_score[\'\"]*:\s*([0-9.]+)', response_content)
                overall_score = float(score_match.group(1)) if score_match else 5.0
                analysis = {'overall_score': overall_score, 'improvement_suggestions': []}
            
            issues = []
            if overall_score < 6.0:
                issues.append(QualityIssue(
                    post_id=post.post_id,
                    issue_type='poor_content_quality',
                    severity='high' if overall_score < 4.0 else 'medium',
                    description=f'å…§å®¹å“è³ªä¸ä½³ï¼š{overall_score}/10',
                    suggestion=f"æ”¹é€²å»ºè­°ï¼š{', '.join(analysis.get('improvement_suggestions', []))}",
                    score=overall_score
                ))
            
            return overall_score, issues
            
        except Exception as e:
            logger.error(f"å…§å®¹å“è³ªæª¢æŸ¥å¤±æ•—: {e}")
            return 5.0, []
    
    async def check_batch_similarity(self, posts: List[GeneratedPost]) -> List[QualityIssue]:
        """æª¢æŸ¥æ‰¹æ¬¡ç›¸ä¼¼åº¦"""
        
        similarity_issues = []
        
        for i, post1 in enumerate(posts):
            for j, post2 in enumerate(posts[i+1:], i+1):
                similarity_score = await self.calculate_content_similarity(post1, post2)
                
                if similarity_score > self.similarity_threshold:
                    similarity_issues.append(QualityIssue(
                        post_id=post1.post_id,
                        issue_type='content_too_similar',
                        severity='high',
                        description=f'èˆ‡ {post2.kol_nickname} å…§å®¹éæ–¼ç›¸ä¼¼ï¼š{similarity_score:.2f}',
                        suggestion=f'é‡æ–°ç”Ÿæˆä»¥å¢åŠ å·®ç•°åŒ–ï¼Œé¿å…é‡è¤‡è¡¨é”',
                        score=similarity_score,
                        similar_to=post2.post_id
                    ))
        
        return similarity_issues
    
    async def calculate_content_similarity(self, post1: GeneratedPost, post2: GeneratedPost) -> float:
        """è¨ˆç®—å…§å®¹ç›¸ä¼¼åº¦"""
        
        # ç°¡å–®çš„è©å½™é‡ç–Šè¨ˆç®—
        words1 = set(re.findall(r'\w+', post1.content.lower()))
        words2 = set(re.findall(r'\w+', post2.content.lower()))
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        jaccard_similarity = len(intersection) / len(union)
        
        # çµæ§‹ç›¸ä¼¼åº¦æª¢æŸ¥
        structure_similarity = self.check_structure_similarity(post1, post2)
        
        # ç¶œåˆç›¸ä¼¼åº¦
        overall_similarity = (jaccard_similarity * 0.7 + structure_similarity * 0.3)
        
        return overall_similarity
    
    def check_structure_similarity(self, post1: GeneratedPost, post2: GeneratedPost) -> float:
        """æª¢æŸ¥çµæ§‹ç›¸ä¼¼åº¦"""
        
        # æª¢æŸ¥å¥å­æ•¸é‡ç›¸ä¼¼åº¦
        sentences1 = len(re.findall(r'[ã€‚ï¼ï¼Ÿ]', post1.content))
        sentences2 = len(re.findall(r'[ã€‚ï¼ï¼Ÿ]', post2.content))
        
        sentence_similarity = 1 - abs(sentences1 - sentences2) / max(sentences1, sentences2, 1)
        
        # æª¢æŸ¥æ®µè½çµæ§‹
        paragraphs1 = len(post1.content.split('\n\n'))
        paragraphs2 = len(post2.content.split('\n\n'))
        
        paragraph_similarity = 1 - abs(paragraphs1 - paragraphs2) / max(paragraphs1, paragraphs2, 1)
        
        # æª¢æŸ¥æ¨™é¡Œæ¨¡å¼
        title_pattern_similarity = 0.0
        if post1.title.startswith('ã€') and post2.title.startswith('ã€'):
            title_pattern_similarity = 0.5
        
        return (sentence_similarity + paragraph_similarity + title_pattern_similarity) / 3
    
    def calculate_overall_score(self, detailed_scores: Dict[str, Dict[str, float]], 
                               issue_count: int) -> float:
        """è¨ˆç®—æ•´é«”å“è³ªåˆ†æ•¸"""
        
        if not detailed_scores:
            return 0.0
        
        # è¨ˆç®—å¹³å‡åˆ†æ•¸
        total_score = 0
        valid_posts = 0
        
        for post_id, scores in detailed_scores.items():
            if 'overall' in scores:
                total_score += scores['overall']
                valid_posts += 1
        
        if valid_posts == 0:
            return 0.0
        
        average_score = total_score / valid_posts
        
        # æ ¹æ“šå•é¡Œæ•¸é‡èª¿æ•´åˆ†æ•¸
        issue_penalty = min(issue_count * 0.5, 3.0)
        final_score = max(0.0, average_score - issue_penalty)
        
        return final_score
    
    def display_check_results(self, result: QualityCheckResult, posts: List[GeneratedPost]):
        """é¡¯ç¤ºæª¢æŸ¥çµæœ"""
        
        print(f"\nğŸ“Š å“è³ªæª¢æŸ¥çµæœ:")
        print(f"  æ•´é«”è©•åˆ†: {result.overall_score:.1f}/10")
        print(f"  æª¢æŸ¥ç‹€æ…‹: {'âœ… é€šé' if result.passed else 'âŒ æœªé€šé'}")
        print(f"  ç™¼ç¾å•é¡Œ: {len(result.issues)} å€‹")
        print(f"  éœ€è¦é‡æ–°ç”Ÿæˆ: {len(result.posts_to_regenerate)} ç¯‡")
        
        if result.issues:
            print("\nğŸ” å•é¡Œè©³æƒ…:")
            for issue in result.issues:
                severity_icon = "ğŸ”´" if issue.severity == "high" else "ğŸŸ¡" if issue.severity == "medium" else "ğŸŸ¢"
                post_name = next((p.kol_nickname for p in posts if p.post_id == issue.post_id), issue.post_id)
                print(f"  {severity_icon} {post_name}: {issue.description}")
                if issue.suggestion:
                    print(f"    ğŸ’¡ å»ºè­°: {issue.suggestion}")
        
        if result.detailed_scores:
            print("\nğŸ“ˆ è©³ç´°è©•åˆ†:")
            for post_id, scores in result.detailed_scores.items():
                post_name = next((p.kol_nickname for p in posts if p.post_id == post_id), post_id)
                print(f"  {post_name}: æ•´é«” {scores.get('overall', 0):.1f} "
                      f"(é•·åº¦ {scores.get('length', 0):.1f}, "
                      f"å€‹äººåŒ– {scores.get('personalization', 0):.1f}, "
                      f"å“è³ª {scores.get('content_quality', 0):.1f})")
    
    def get_regeneration_guidance(self, post_id: str, issues: List[QualityIssue]) -> Dict[str, Any]:
        """ç²å–é‡æ–°ç”ŸæˆæŒ‡å°"""
        
        post_issues = [issue for issue in issues if issue.post_id == post_id]
        
        guidance = {
            'priority_fixes': [],
            'suggested_changes': [],
            'parameter_adjustments': {}
        }
        
        for issue in post_issues:
            if issue.severity == 'high':
                guidance['priority_fixes'].append(issue.description)
                guidance['suggested_changes'].append(issue.suggestion)
            
            # æ ¹æ“šå•é¡Œé¡å‹èª¿æ•´åƒæ•¸
            if issue.issue_type == 'content_too_similar':
                guidance['parameter_adjustments']['temperature'] = 0.8
                guidance['parameter_adjustments']['diversity_boost'] = True
            elif issue.issue_type == 'insufficient_personalization':
                guidance['parameter_adjustments']['persona_emphasis'] = True
            elif issue.issue_type == 'content_too_short':
                guidance['parameter_adjustments']['min_length_boost'] = True
        
        return guidance
