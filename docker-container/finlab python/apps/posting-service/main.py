import os
import requests
import json
from fastapi import FastAPI, BackgroundTasks, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncio
import sys
import json
from dotenv import load_dotenv
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

print("ğŸš€ é–‹å§‹è¼‰å…¥æ¨¡çµ„...")

# å°å…¥æ”¹é€²çš„å…§å®¹ç”Ÿæˆå™¨
from improved_content_generator import generate_improved_kol_content
# å°å…¥GPTå…§å®¹ç”Ÿæˆå™¨
from gpt_content_generator import gpt_generator

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
print("ğŸ“ è¼‰å…¥ç’°å¢ƒè®Šæ•¸...")
load_dotenv(os.path.join(os.path.dirname(__file__), '../../../../.env'))
print("âœ… ç’°å¢ƒè®Šæ•¸è¼‰å…¥å®Œæˆ")

# ä½¿ç”¨æœ¬åœ°çš„post_record_service
print("ğŸ“¦ å°å…¥post_record_service...")
from post_record_service import PostRecordCreate, CommodityTag, CommunityTopic, GenerationParams, PostRecordService, PostRecordUpdate
print("âœ… post_record_serviceå°å…¥å®Œæˆ")

print("ğŸ—ï¸ å‰µå»ºFastAPIæ‡‰ç”¨...")
app = FastAPI(title="Posting Service", description="è™›æ“¬KOLè‡ªå‹•ç™¼æ–‡æœå‹™")
print("âœ… FastAPIæ‡‰ç”¨å‰µå»ºå®Œæˆ")

# æ·»åŠ  CORS ä¸­é–“ä»¶
print("ğŸŒ æ·»åŠ CORSä¸­é–“ä»¶...")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒæ‡‰è©²é™åˆ¶ç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
print("âœ… CORSä¸­é–“ä»¶æ·»åŠ å®Œæˆ")

# API ç«¯é»é…ç½®
print("âš™ï¸ é…ç½®APIç«¯é»...")
TRENDING_API_URL = os.getenv("TRENDING_API_URL", "http://localhost:8004")
SUMMARY_API_URL = os.getenv("SUMMARY_API_URL", "http://summary-api:8003")
OHLC_API_URL = os.getenv("OHLC_API_URL", "http://ohlc-api:8001")
print("âœ… APIç«¯é»é…ç½®å®Œæˆ")

# åˆå§‹åŒ–æ•¸æ“šåº«æœå‹™
print("ğŸ’¾ åˆå§‹åŒ–æ•¸æ“šåº«æœå‹™...")
post_record_service = PostRecordService()
print("âœ… æ•¸æ“šåº«æœå‹™åˆå§‹åŒ–å®Œæˆ")

class PostingRequest(BaseModel):
    stock_code: Optional[str] = None
    stock_name: Optional[str] = None
    kol_serial: Optional[str] = None
    kol_persona: str = "technical"
    content_style: str = "chart_analysis"
    target_audience: str = "active_traders"
    auto_post: bool = True
    post_to_thread: Optional[str] = None
    batch_mode: bool = False
    session_id: Optional[int] = None
    # å…§å®¹é•·åº¦è¨­å®š
    content_length: str = "medium"
    max_words: int = 200
    # æ–°å¢æ•¸æ“šæºç›¸é—œæ¬„ä½
    data_sources: Optional[Dict[str, Any]] = None
    explainability_config: Optional[Dict[str, Any]] = None
    news_config: Optional[Dict[str, Any]] = None

class PostingResult(BaseModel):
    success: bool
    post_id: Optional[str] = None
    content: Optional[Dict] = None
    error: Optional[str] = None
    timestamp: datetime

class BatchPostRequest(BaseModel):
    session_id: int
    posts: List[Dict[str, Any]]
    batch_config: Dict[str, Any]
    data_sources: Optional[Dict[str, Any]] = None
    explainability_config: Optional[Dict[str, Any]] = None
    news_config: Optional[Dict[str, Any]] = None

class BatchPostResponse(BaseModel):
    success: bool
    post_id: Optional[str] = None
    content: Optional[Dict] = None
    error: Optional[str] = None
    timestamp: str
    progress: Optional[Dict[str, Any]] = None

class AutoPostingConfig(BaseModel):
    enabled: bool = True
    interval_minutes: int = 60
    max_posts_per_day: int = 10
    kol_personas: List[str] = ["technical", "fundamental", "news_driven"]

@app.post("/post/auto", response_model=PostingResult)
async def auto_post_content(background_tasks: BackgroundTasks, config: AutoPostingConfig):
    """è‡ªå‹•ç™¼æ–‡ - æ ¹æ“šç†±é–€è©±é¡Œè‡ªå‹•ç”Ÿæˆå…§å®¹ä¸¦ç™¼æ–‡"""
    
    try:
        # 1. ç²å–ç†±é–€è©±é¡Œ
        trending_response = requests.get(f"{TRENDING_API_URL}/trending", params={"limit": 5})
        trending_response.raise_for_status()
        trending_topics = trending_response.json()
        
        if not trending_topics.get("topics"):
            return PostingResult(
                success=False,
                error="æ²’æœ‰æ‰¾åˆ°ç†±é–€è©±é¡Œ",
                timestamp=datetime.now()
            )
        
        # 2. é¸æ“‡ç¬¬ä¸€å€‹ç†±é–€è©±é¡Œ
        topic = trending_topics["topics"][0]
        stock_id = topic["stock_ids"][0] if topic["stock_ids"] else "2330"
        
        # 3. ç²å–ç›¸é—œæ–°èç´ æ
        news_response = requests.get(f"{TRENDING_API_URL}/news/stock/{stock_id}", params={"limit": 3})
        news_items = []
        if news_response.status_code == 200:
            news_items = news_response.json().get("news", [])
        
        # 4. ç”ŸæˆKOLå…§å®¹
        content_request = {
            "stock_id": stock_id,
            "kol_persona": config.kol_personas[0],
            "content_style": "chart_analysis",
            "target_audience": "active_traders"
        }
        
        summary_response = requests.post(f"{SUMMARY_API_URL}/generate-kol-content", json=content_request)
        summary_response.raise_for_status()
        kol_content = summary_response.json()
        
        # 5. æ•´åˆæ–°èç´ æåˆ°å…§å®¹ä¸­
        enhanced_content = enhance_content_with_news(kol_content, topic, news_items)
        
        # 6. ç™¼æ–‡åˆ°æŒ‡å®šå¹³å°
        if config.enabled:
            background_tasks.add_task(post_to_platform, enhanced_content, topic)
        
        return PostingResult(
            success=True,
            post_id=f"post_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            content=enhanced_content,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        return PostingResult(
            success=False,
            error=str(e),
            timestamp=datetime.now()
        )

@app.post("/post/manual", response_model=PostingResult)
async def manual_post_content(request: PostingRequest):
    """æ‰‹å‹•ç™¼æ–‡ - æŒ‡å®šè‚¡ç¥¨å’ŒKOLé¢¨æ ¼"""
    
    print(f"ğŸš€ é–‹å§‹æ‰‹å‹•ç™¼æ–‡ç”Ÿæˆ - è«‹æ±‚åƒæ•¸: {request}")
    print(f"ğŸ“ å…§å®¹é•·åº¦è¨­å®š: content_length={request.content_length}, max_words={request.max_words}")
    
    try:
        # å¦‚æœå‰ç«¯æŒ‡å®šäº†è‚¡ç¥¨ä»£è™Ÿï¼Œä½¿ç”¨æŒ‡å®šçš„è‚¡ç¥¨
        if request.stock_code:
            stock_id = request.stock_code
            stock_name = request.stock_name or f"è‚¡ç¥¨{stock_id}"
            print(f"ğŸ“Š ä½¿ç”¨æŒ‡å®šè‚¡ç¥¨: {stock_name}({stock_id})")
        else:
            # å¦å‰‡ç²å–ç†±é–€è‚¡ç¥¨
            print("ğŸ“ˆ ç²å–ç†±é–€è‚¡ç¥¨...")
            try:
                trending_stocks_response = requests.get(f"{TRENDING_API_URL}/trending/stocks", params={"limit": 10})
                trending_stocks_response.raise_for_status()
                trending_stocks = trending_stocks_response.json()
                
                if not trending_stocks.get("stocks"):
                    print("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç†±é–€è‚¡ç¥¨")
                    return PostingResult(
                        success=False,
                        error="æ²’æœ‰æ‰¾åˆ°ç†±é–€è‚¡ç¥¨",
                        timestamp=datetime.now()
                    )
                
                # é¸æ“‡ç¬¬ä¸€å€‹ç†±é–€è‚¡ç¥¨
                stock = trending_stocks["stocks"][0]
                stock_id = stock["stock_id"]
                stock_name = stock.get("stock_name", f"è‚¡ç¥¨{stock_id}")
                print(f"ğŸ“ˆ é¸æ“‡ç†±é–€è‚¡ç¥¨: {stock_name}({stock_id})")
            except Exception as e:
                print(f"âš ï¸ ç²å–ç†±é–€è‚¡ç¥¨å¤±æ•—: {e}")
                stock_id = "2330"
                stock_name = "å°ç©é›»"
                print(f"ğŸ“ˆ ä½¿ç”¨é è¨­è‚¡ç¥¨: {stock_name}({stock_id})")
        
        print(f"âœ… è‚¡ç¥¨ç¢ºå®š: {stock_name}({stock_id})")
        
        # å°å…¥æ–°çš„æœå‹™
        print("ğŸ”§ å°å…¥æœå‹™æ¨¡çµ„...")
        try:
            from serper_integration import serper_service
            from smart_data_source_assigner import smart_assigner, KOLProfile, StockProfile
            from publish_service import publish_service
            print("âœ… æœå‹™æ¨¡çµ„å°å…¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æœå‹™æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
            raise
        
        # 1. æ™ºèƒ½æ•¸æ“šæºåˆ†é…
        print(f"ğŸ¯ é–‹å§‹æ™ºèƒ½æ•¸æ“šæºåˆ†é…: {stock_id}, {request.kol_persona}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å‰ç«¯å‚³ä¾†çš„æ•¸æ“šæºé…ç½®
        if request.data_sources:
            print(f"ğŸ“Š ä½¿ç”¨å‰ç«¯æ•¸æ“šæºé…ç½®: {request.data_sources}")
            # ä½¿ç”¨å‰ç«¯é…ç½®çš„æ•¸æ“šæº
            primary_sources = []
            if request.data_sources.get('stock_price_api'):
                primary_sources.append('ohlc_api')
            if request.data_sources.get('monthly_revenue_api'):
                primary_sources.append('revenue_api')
            if request.data_sources.get('financial_report_api'):
                primary_sources.append('financial_api')
            if request.data_sources.get('news_sources', []):
                primary_sources.append('serper_api')
            
            # å‰µå»ºæ¨¡æ“¬çš„æ•¸æ“šæºåˆ†é…çµæœ
            from smart_data_source_assigner import DataSourceAssignment, DataSourceType
            data_source_assignment = DataSourceAssignment(
                primary_sources=[DataSourceType(source) for source in primary_sources if hasattr(DataSourceType, source)],
                secondary_sources=[],
                excluded_sources=[],
                assignment_reason=f"åŸºæ–¼å‰ç«¯é…ç½®: {', '.join(primary_sources)}",
                confidence_score=0.9
            )
        else:
            # ä½¿ç”¨æ™ºèƒ½åˆ†é…é‚è¼¯
            kol_profile = KOLProfile(
                serial=int(request.kol_serial) if request.kol_serial else 1,
                nickname=f"KOL-{request.kol_serial or '1'}",
                persona=request.kol_persona,
                expertise_areas=[request.kol_persona],
                content_style=request.content_style,
                target_audience=request.target_audience
            )
            
            stock_profile = StockProfile(
                stock_code=stock_id,
                stock_name=stock_name,
                industry="ç§‘æŠ€",  # å¯ä»¥å¾APIç²å–
                market_cap="medium",  # å¯ä»¥å¾APIç²å–
                volatility="medium",  # å¯ä»¥å¾APIç²å–
                news_frequency="medium"  # å¯ä»¥å¾APIç²å–
            )
            
            # åˆ†é…æ•¸æ“šæº
            data_source_assignment = smart_assigner.assign_data_sources(kol_profile, stock_profile)
        
        print(f"âœ… æ•¸æ“šæºåˆ†é…å®Œæˆ: {data_source_assignment.assignment_reason}")
        print(f"ğŸ“Š ä¸»è¦æ•¸æ“šæº: {[s.value for s in data_source_assignment.primary_sources]}")
        
        # 2. ç²å–Serperæ–°èæ•¸æ“š - ä½¿ç”¨å‰ç«¯é…ç½®çš„é—œéµå­—
        print(f"ğŸ” é–‹å§‹ç²å–Serperæ–°èæ•¸æ“š: {stock_id}")
        try:
            # æå–æ–°èæœå°‹é—œéµå­—é…ç½®
            search_keywords = None
            if request.news_config and request.news_config.get('search_keywords'):
                search_keywords = request.news_config.get('search_keywords')
                print(f"ğŸ“ ä½¿ç”¨å‰ç«¯æ–°èé—œéµå­—é…ç½®: {len(search_keywords)} å€‹é—œéµå­—")
                for kw in search_keywords:
                    print(f"   - {kw.get('type', 'custom')}: {kw.get('keyword', '')}")
            else:
                print("ğŸ“ ä½¿ç”¨é è¨­æ–°èæœå°‹é—œéµå­—")
            
            serper_analysis = serper_service.get_comprehensive_stock_analysis(
                stock_id, 
                stock_name, 
                search_keywords=search_keywords
            )
            news_items = serper_analysis.get('news_items', [])
            limit_up_analysis = serper_analysis.get('limit_up_analysis', {})
            print(f"âœ… Serperåˆ†æå®Œæˆ: æ‰¾åˆ° {len(news_items)} å‰‡æ–°è")
        except Exception as e:
            print(f"âš ï¸ Serperåˆ†æå¤±æ•—: {e}")
            serper_analysis = {'news_items': [], 'limit_up_analysis': {}}
            news_items = []
            limit_up_analysis = {}
        
        # 3. ç”ŸæˆKOLå…§å®¹ - å¼·åˆ¶ä½¿ç”¨æ–°èåˆ†æAgent
        print(f"âœï¸ é–‹å§‹ç”ŸæˆKOLå…§å®¹: {stock_id}, {request.kol_persona}")
        
        try:
            # å¼·åˆ¶ä½¿ç”¨æ–°èåˆ†æAgent
            if news_items:
                print(f"ğŸ¤– å¼·åˆ¶ä½¿ç”¨æ–°èåˆ†æAgentåˆ†æ {len(news_items)} å‰‡æ–°è")
                from news_analysis_agent import NewsAnalysisAgent
                # å‰µå»ºæ–°çš„å¯¦ä¾‹ä»¥ç¢ºä¿API Keyæ­£ç¢ºè¼‰å…¥
                news_agent = NewsAnalysisAgent()
                kol_content = news_agent.analyze_stock_news(
                    stock_id, stock_name, news_items, request.kol_persona, 
                    request.content_length, request.max_words
                )
                print(f"âœ… Agentå…§å®¹ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
            else:
                print("âš ï¸ æ²’æœ‰æ–°èæ•¸æ“šï¼Œä½¿ç”¨GPTç”Ÿæˆå™¨")
                kol_content = gpt_generator.generate_stock_analysis(
                    stock_id=stock_id,
                    stock_name=stock_name,
                    kol_persona=request.kol_persona,
                    serper_analysis=serper_analysis,
                    data_sources=[source.value for source in data_source_assignment.primary_sources],
                    content_length=request.content_length,
                    max_words=request.max_words
                )
                print(f"âœ… GPTå…§å®¹ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
        except Exception as e:
            print(f"âŒ Agentå…§å®¹ç”Ÿæˆå¤±æ•—: {e}")
            # å›é€€åˆ°æ”¹é€²çš„å…§å®¹ç”Ÿæˆå™¨
            kol_content = generate_improved_kol_content(
                stock_id=stock_id,
                stock_name=stock_name,
                kol_persona=request.kol_persona,
                content_style=request.content_style,
                target_audience=request.target_audience,
                serper_analysis=serper_analysis,
                data_sources=[source.value for source in data_source_assignment.primary_sources]
            )
            print(f"âœ… å›é€€å…§å®¹ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
        
        # 4. æ•´åˆæ–°èç´ æå’Œæ•¸æ“šæºè³‡è¨Š
        print("ğŸ”— æ•´åˆæ–°èç´ æå’Œæ•¸æ“šæºè³‡è¨Š...")
        try:
            enhanced_content = enhance_content_with_serper_data(
                kol_content, 
                serper_analysis, 
                data_source_assignment
            )
            print("âœ… å…§å®¹æ•´åˆå®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ å…§å®¹æ•´åˆå¤±æ•—: {e}")
            enhanced_content = kol_content
        
        # æ·»åŠ é¡å¤–çš„æ¬„ä½ä»¥ç¬¦åˆå‰ç«¯æœŸæœ›
        enhanced_content.update({
            "stock_code": stock_id,
            "stock_name": stock_name,
            "kol_serial": request.kol_serial or "1",
            "session_id": request.session_id,
            "batch_mode": request.batch_mode
        })
        
        # æº–å‚™å•†å“æ¨™ç±¤
        print("ğŸ·ï¸ æº–å‚™å•†å“æ¨™ç±¤...")
        commodity_tags = []
        if stock_id:
            commodity_tag = CommodityTag(
                type="Stock",
                key=stock_id,
                bullOrBear=0  # ä¸­æ€§ï¼Œå¯æ ¹æ“šæŠ€è¡“åˆ†æèª¿æ•´
            )
            commodity_tags.append(commodity_tag.model_dump())
        
        print(f"âœ… ç”Ÿæˆçš„å•†å“æ¨™ç±¤: {commodity_tags}")
        print(f"ğŸ“Š è‚¡ç¥¨ä»£è™Ÿ: {stock_id}, è‚¡ç¥¨åç¨±: {stock_name}")
        print(f"ğŸ‘¤ KOLåºè™Ÿ: {request.kol_serial}")
        
        # æº–å‚™ç¤¾ç¾¤è©±é¡Œ
        community_topic = None
        if request.post_to_thread:
            community_topic = CommunityTopic(id=request.post_to_thread)
            print(f"ğŸ’¬ ç¤¾ç¾¤è©±é¡Œ: {request.post_to_thread}")
        
        # æº–å‚™ç”Ÿæˆåƒæ•¸ - æ•´åˆæ•¸æ“šæºè³‡è¨Š
        print("âš™ï¸ æº–å‚™ç”Ÿæˆåƒæ•¸...")
        generation_params = GenerationParams(
            kol_persona=request.kol_persona,
            content_style=request.content_style,
            target_audience=request.target_audience,
            batch_mode=request.batch_mode,
            data_sources=[source.value for source in data_source_assignment.primary_sources],
            session_id=request.session_id,
            technical_indicators=[]
        )
        print("âœ… ç”Ÿæˆåƒæ•¸æº–å‚™å®Œæˆ")
        
        # å‰µå»ºè²¼æ–‡è¨˜éŒ„
        print("ğŸ’¾ é–‹å§‹ä¿å­˜è²¼æ–‡è¨˜éŒ„åˆ°è³‡æ–™åº«...")
        try:
            # è½‰æ› commodity_tags ç‚º Pydantic æ¨¡å‹åˆ—è¡¨
            commodity_tag_models = []
            for tag_dict in commodity_tags:
                commodity_tag_models.append(CommodityTag(**tag_dict))
            
            post_record_data = PostRecordCreate(
                session_id=request.session_id or 0,
                kol_serial=int(request.kol_serial or "1"),
                kol_nickname=f"KOL-{request.kol_serial or '1'}",
                kol_persona=request.kol_persona,
                stock_code=stock_id,
                stock_name=stock_name,
                title=enhanced_content.get("title", f"{stock_name}åˆ†æ"),
                content=enhanced_content.get("content_md", enhanced_content.get("content", "")),
                content_md=enhanced_content.get("content_md"),
                commodity_tags=commodity_tag_models,
                community_topic=community_topic,
                status="pending_review",  # æ·»åŠ ç‹€æ…‹
                generation_params=generation_params,
                topic_id=None,
                topic_title=None
            )
            
            print(f"ğŸ“ è²¼æ–‡è¨˜éŒ„æ•¸æ“šæº–å‚™å®Œæˆ: {post_record_data.title}")
            print(f"ğŸ” è²¼æ–‡è¨˜éŒ„æ•¸æ“šè©³æƒ…: session_id={post_record_data.session_id}, stock_code={post_record_data.stock_code}")
            
            # ä¿å­˜åˆ°æ•¸æ“šåº«
            post_record = post_record_service.create_post_record(post_record_data)
            print(f"âœ… è²¼æ–‡è¨˜éŒ„ä¿å­˜æˆåŠŸ: {post_record.post_id}")
            print(f"ğŸ” æ•¸æ“šåº«ä¸­è²¼æ–‡ç¸½æ•¸: {len(post_record_service.db)}")
            
            # æ›´æ–°enhanced_contentåŒ…å«post_id
            enhanced_content["post_id"] = post_record.post_id
            enhanced_content["status"] = "pending_review"
            
        except Exception as e:
            print(f"âŒ ä¿å­˜è²¼æ–‡è¨˜éŒ„å¤±æ•—: {e}")
            # å³ä½¿ä¿å­˜å¤±æ•—ä¹Ÿç¹¼çºŒè¿”å›çµæœ
            enhanced_content["post_id"] = f"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            enhanced_content["status"] = "error"
        
        # ç™¼æ–‡
        if request.auto_post:
            print("ğŸš€ æº–å‚™è‡ªå‹•ç™¼æ–‡...")
            background_tasks = BackgroundTasks()
            background_tasks.add_task(post_to_platform, enhanced_content, {"id": request.post_to_thread})
            print("âœ… è‡ªå‹•ç™¼æ–‡ä»»å‹™å·²åŠ å…¥èƒŒæ™¯ä»»å‹™")
        
        print(f"ğŸ‰ ç™¼æ–‡ç”Ÿæˆå®Œæˆ: {enhanced_content.get('post_id')}")
        
        return PostingResult(
            success=True,
            post_id=enhanced_content.get("post_id", f"post_{datetime.now().strftime('%Y%m%d_%H%M%S')}"),
            content=enhanced_content,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        return PostingResult(
            success=False,
            error=str(e),
            timestamp=datetime.now()
        )

def generate_kol_content_direct(stock_id: str, stock_name: str, kol_persona: str, content_style: str, target_audience: str) -> Dict:
    """ç›´æ¥ç”ŸæˆKOLå…§å®¹ - åŸºæ–¼åŸæœ¬çš„ç›¤å¾Œæ¼²åœè…³æœ¬æ¶æ§‹"""
    
    # KOLäººè¨­é…ç½®
    kol_personas = {
        "technical": {
            "name": "æŠ€è¡“å¤§å¸«",
            "style": "å°ˆæ¥­ä¸”è‡ªä¿¡",
            "focus": "åœ–è¡¨åˆ†æã€æŠ€è¡“æŒ‡æ¨™",
            "language": "æŠ€è¡“è¡“èªè±å¯Œï¼Œæ•¸æ“šå°å‘"
        },
        "fundamental": {
            "name": "åƒ¹å€¼æŠ•è³‡å¤§å¸«", 
            "style": "ç©©é‡ä¸”æ·±æ€ç†Ÿæ…®",
            "focus": "åŸºæœ¬é¢åˆ†æã€è²¡å ±è§£è®€",
            "language": "é‚è¼¯æ¸…æ™°ï¼Œé‡è¦–æ•¸æ“š"
        },
        "news_driven": {
            "name": "æ–°èçµäºº",
            "style": "æ•éŠ³ä¸”å³æ™‚", 
            "focus": "æ–°èå½±éŸ¿ã€æ”¿ç­–è®ŠåŒ–",
            "language": "ç”Ÿå‹•æ´»æ½‘ï¼Œæ™‚äº‹å°å‘"
        }
    }
    
    persona = kol_personas.get(kol_persona, kol_personas["technical"])
    
    # ç”Ÿæˆæ¨™é¡Œ - ç´”æ–‡å­—æ ¼å¼
    title = f"{stock_name}({stock_id}) {persona['name']}è§€é» - æŠ€è¡“é¢æ·±åº¦è§£æ"
    
    # ç”Ÿæˆå…§å®¹ - ç´”æ–‡å­—æ ¼å¼
    content_md = f"""{stock_name}({stock_id}) æŠ€è¡“é¢åˆ†æå ±å‘Š

æ ¸å¿ƒè§€é»
{stock_name} ç›®å‰è™•æ–¼å¼·å‹¢çªç ´ç‹€æ…‹ï¼ŒæŠ€è¡“æŒ‡æ¨™é¡¯ç¤ºå¤šé ­è¨Šè™Ÿç¢ºèªã€‚

é—œéµæŠ€è¡“æŒ‡æ¨™
- MA5/MA20: é»ƒé‡‘äº¤å‰ç¢ºèªå¤šé ­è¶¨å‹¢
- RSI14: ä¸­æ€§åå¤šï¼Œä»æœ‰ä¸Šæ¼²ç©ºé–“
- MACDæŸ±ç‹€é«”: å¤šé ­è¨Šè™ŸæŒçºŒ

æŠ€è¡“è¨Šè™Ÿåˆ†æ
- åƒ¹æ¼²é‡å¢ï¼šè²·ç›¤åŠ›é“å¼·å‹ï¼Œå¾Œå¸‚çœ‹å¥½
- çªç ´å£“åŠ›ï¼šæˆåŠŸçªç ´é—œéµé˜»åŠ›ä½
- è¶¨å‹¢ç¢ºèªï¼šå¤šé ­æ’åˆ—å®Œæ•´

æŠ•è³‡å»ºè­°
åŸºæ–¼æŠ€è¡“åˆ†æï¼Œå»ºè­°é€¢ä½å¸ƒå±€ï¼Œç›®æ¨™åƒ¹ä½å¯æœŸå¾…10-15%æ¼²å¹…ã€‚

é¢¨éšªæé†’
- æ³¨æ„å¤§ç›¤ç’°å¢ƒè®ŠåŒ–
- è¨­å¥½åœæé»ä½
- åˆ†æ‰¹é€²å ´é™ä½é¢¨éšª

æ“ä½œç­–ç•¥
1. é€²å ´æ™‚æ©Ÿ: å›æ¸¬æ”¯æ’æ™‚åˆ†æ‰¹è²·é€²
2. åœæè¨­å®š: è·Œç ´é—œéµæ”¯æ’ä½
3. ç›®æ¨™åƒ¹ä½: æŠ€è¡“ç›®æ¨™åƒ¹ä½
4. æŒè‚¡æ¯”ä¾‹: å»ºè­°æ§åˆ¶åœ¨ç¸½è³‡ç”¢10%ä»¥å…§

ä»¥ä¸Šåˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°

æ•¸æ“šä¾†æº
æœ¬åˆ†ææ•´åˆäº†: æŠ€è¡“æŒ‡æ¨™æ•¸æ“š, å¸‚å ´æ‘˜è¦åˆ†æ, ç†±é–€è©±é¡Œæ•¸æ“š
"""
    
    return {
        "kol_id": f"kol_{persona['name']}",
        "kol_name": persona['name'],
        "stock_id": stock_id,
        "content_type": content_style,
        "title": title,
        "content_md": content_md,
        "key_points": [
            "æŠ€è¡“é¢å¼·å‹¢çªç ´",
            "å¤šé ­è¨Šè™Ÿç¢ºèª", 
            "åƒ¹æ¼²é‡å¢æ ¼å±€",
            "é€¢ä½å¸ƒå±€ç­–ç•¥"
        ],
        "investment_advice": {
            "recommendation": "buy",
            "confidence": 0.8,
            "target_price": "æŠ€è¡“ç›®æ¨™åƒ¹",
            "stop_loss": "é—œéµæ”¯æ’ä½"
        },
        "engagement_prediction": 0.75,
        "created_at": datetime.now().isoformat()
    }

def enhance_content_with_news(kol_content: Dict, topic: Dict, news_items: List[Dict]) -> Dict:
    """æ•´åˆæ–°èç´ æåˆ°KOLå…§å®¹ä¸­"""
    
    enhanced_content = kol_content.copy()
    
    # ç¢ºä¿ content_md å­˜åœ¨
    if "content_md" not in enhanced_content:
        enhanced_content["content_md"] = ""
    
    # åœ¨å…§å®¹ä¸­åŠ å…¥æ–°èç´ æ
    if news_items:
        news_section = "\n\n### ğŸ“° ç›¸é—œæ–°èç´ æ\n"
        for i, news in enumerate(news_items[:3], 1):
            news_section += f"{i}. **{news['title']}**\n"
            news_section += f"   {news['summary'][:100]}...\n"
            news_section += f"   [é–±è®€æ›´å¤š]({news['url']})\n\n"
        
        # åœ¨å…§å®¹æœ«å°¾åŠ å…¥æ–°èç´ æ
        enhanced_content["content_md"] += news_section
        
        # æ›´æ–°é—œéµé»
        if "key_points" in enhanced_content:
            enhanced_content["key_points"].append("æ•´åˆæœ€æ–°æ–°èç´ æ")
        else:
            enhanced_content["key_points"] = ["æ•´åˆæœ€æ–°æ–°èç´ æ"]
    
    # åŠ å…¥è©±é¡Œæ¨™ç±¤
    if topic.get("title"):
        enhanced_content["content_md"] += f"\n\n---\n*å›æ‡‰ç†±é–€è©±é¡Œï¼š{topic['title']}*"
    
    return enhanced_content

async def post_to_platform(content: Dict, topic: Dict):
    """ç™¼æ–‡åˆ°æŒ‡å®šå¹³å° (æ¨¡æ“¬)"""
    
    # é€™è£¡å¯ä»¥æ•´åˆå¯¦éš›çš„ç™¼æ–‡å¹³å°API
    # ä¾‹å¦‚ï¼šTwitter API, LinkedIn API, æˆ–è‡ªå»ºå¹³å°
    
    post_data = {
        "content": content["content_md"],
        "title": content["title"],
        "stock_id": content["stock_id"],
        "kol_id": content["kol_id"],
        "topic_id": topic.get("id", "unknown"),
        "timestamp": datetime.now().isoformat()
    }
    
    # æ¨¡æ“¬ç™¼æ–‡æˆåŠŸ
    print(f"ğŸ“ ç™¼æ–‡æˆåŠŸ: {content['title']}")
    print(f"ğŸ“Š è‚¡ç¥¨: {content['stock_id']}")
    print(f"ğŸ‘¤ KOL: {content['kol_name']}")
    print(f"ğŸ”— è©±é¡Œ: {topic.get('title', 'N/A')}")
    
    # å¯¦éš›æ•´åˆæ™‚ï¼Œé€™è£¡æœƒèª¿ç”¨ç™¼æ–‡å¹³å°API
    # response = requests.post("https://api.twitter.com/2/tweets", json=post_data)
    
    return {"success": True, "post_id": f"post_{datetime.now().strftime('%Y%m%d_%H%M%S')}"}

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now(),
        "services": {
            "trending_api": "connected",
            "summary_api": "connected",
            "ohlc_api": "connected"
        }
    }

@app.get("/trending/preview")
async def preview_trending_content():
    """é è¦½ç†±é–€è©±é¡Œå…§å®¹"""
    
    try:
        # ç²å–ç†±é–€è©±é¡Œ
        trending_response = requests.get(f"{TRENDING_API_URL}/trending", params={"limit": 3})
        trending_response.raise_for_status()
        trending_topics = trending_response.json()
        
        # ç²å–ç†±é–€è‚¡ç¥¨
        stocks_response = requests.get(f"{TRENDING_API_URL}/trending/stocks", params={"limit": 5})
        stocks_response.raise_for_status()
        trending_stocks = stocks_response.json()
        
        return {
            "topics": trending_topics.get("topics", []),
            "stocks": trending_stocks.get("stocks", []),
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        return {"error": str(e), "timestamp": datetime.now()}

# ==================== KOLæ†‘è­‰ç®¡ç† ====================

class KOLCredentialManager:
    """KOLæ†‘è­‰ç®¡ç†å™¨"""
    
    def __init__(self):
        # KOLæ†‘è­‰é…ç½® (å¯¦éš›ä½¿ç”¨æ™‚æ‡‰è©²å¾ç’°å¢ƒè®Šé‡æˆ–æ•¸æ“šåº«è®€å–)
        self.kol_credentials = {
            "150": {"email": "forum_150@cmoney.com.tw", "password": "N9t1kY3x", "member_id": "150"},
            "151": {"email": "forum_151@cmoney.com.tw", "password": "m7C1lR4t", "member_id": "151"},
            "152": {"email": "forum_152@cmoney.com.tw", "password": "x2U9nW5p", "member_id": "152"},
            "153": {"email": "forum_153@cmoney.com.tw", "password": "y7O3cL9k", "member_id": "153"},
            "154": {"email": "forum_154@cmoney.com.tw", "password": "f4E9sC8w", "member_id": "154"},
            "155": {"email": "forum_155@cmoney.com.tw", "password": "Z5u6dL9o", "member_id": "155"},
            "156": {"email": "forum_156@cmoney.com.tw", "password": "T1t7kS9j", "member_id": "156"},
            "157": {"email": "forum_157@cmoney.com.tw", "password": "w2B3cF6l", "member_id": "157"},
            "158": {"email": "forum_158@cmoney.com.tw", "password": "q4N8eC7h", "member_id": "158"},
            "159": {"email": "forum_159@cmoney.com.tw", "password": "V5n6hK0f", "member_id": "159"},
            "160": {"email": "forum_160@cmoney.com.tw", "password": "D8k9mN2p", "member_id": "160"}
        }
        
        # Tokenå¿«å–
        self.kol_tokens = {}
        
        print("ğŸ” KOLæ†‘è­‰ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def get_kol_credentials(self, kol_serial: str) -> Optional[Dict[str, str]]:
        """ç²å–KOLæ†‘è­‰"""
        return self.kol_credentials.get(str(kol_serial))
    
    async def login_kol(self, kol_serial: str) -> Optional[str]:
        """ç™»å…¥KOLä¸¦è¿”å›access token"""
        try:
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰æœ‰æ•ˆtoken
            if kol_serial in self.kol_tokens:
                token_data = self.kol_tokens[kol_serial]
                if token_data.get('expires_at') and datetime.now() < token_data['expires_at']:
                    print(f"âœ… ä½¿ç”¨å¿«å–çš„KOL {kol_serial} token")
                    return token_data['token']
            
            # ç²å–æ†‘è­‰
            creds = self.get_kol_credentials(kol_serial)
            if not creds:
                print(f"âŒ æ‰¾ä¸åˆ°KOL {kol_serial} çš„æ†‘è­‰")
                return None
            
            print(f"ğŸ” é–‹å§‹ç™»å…¥KOL {kol_serial}...")
            
            # ä½¿ç”¨CMoney Clientç™»å…¥
            from serper_integration import serper_service
            if hasattr(serper_service, 'cmoney_client'):
                cmoney_client = serper_service.cmoney_client
            else:
                # å¦‚æœæ²’æœ‰CMoney clientï¼Œå‰µå»ºä¸€å€‹
                from src.clients.cmoney.cmoney_client import CMoneyClient, LoginCredentials
                cmoney_client = CMoneyClient()
            
            from src.clients.cmoney.cmoney_client import LoginCredentials
            credentials = LoginCredentials(
                email=creds['email'],
                password=creds['password']
            )
            
            access_token = await cmoney_client.login(credentials)
            
            if access_token and access_token.token:
                # å¿«å–token
                self.kol_tokens[kol_serial] = {
                    'token': access_token.token,
                    'expires_at': access_token.expires_at
                }
                print(f"âœ… KOL {kol_serial} ç™»å…¥æˆåŠŸ")
                return access_token.token
            else:
                print(f"âŒ KOL {kol_serial} ç™»å…¥å¤±æ•—")
                return None
                
        except Exception as e:
            print(f"âŒ KOL {kol_serial} ç™»å…¥ç•°å¸¸: {e}")
            return None

# å…¨åŸŸKOLæ†‘è­‰ç®¡ç†å™¨
kol_credential_manager = KOLCredentialManager()


@app.get("/posts")
async def get_all_posts(skip: int = 0, limit: int = 100, status: Optional[str] = None):
    """ç²å–æ‰€æœ‰è²¼æ–‡"""
    try:
        posts = post_record_service.get_all_posts()
        
        # æ ¹æ“šç‹€æ…‹ç¯©é¸
        if status:
            posts = [post for post in posts if post.status == status]
        
        # åˆ†é 
        total = len(posts)
        posts = posts[skip:skip + limit]
        
        return {
            "posts": posts,
            "count": total,
            "skip": skip,
            "limit": limit
        }
    except Exception as e:
        print(f"ç²å–è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–è²¼æ–‡å¤±æ•—: {str(e)}")

@app.get("/posts/pending-review")
async def get_pending_review_posts():
    """ç²å–å¾…å¯©æ ¸çš„è²¼æ–‡åˆ—è¡¨"""
    try:
        posts = post_record_service.get_pending_review_posts()
        print(f"æ‰¾åˆ° {len(posts)} ç¯‡å¾…å¯©æ ¸è²¼æ–‡")
        for post in posts:
            print(f"  - {post.post_id}: {post.title} (ç‹€æ…‹: {post.status})")
        
        return {
            "success": True,
            "posts": posts,
            "count": len(posts),
            "timestamp": datetime.now()
        }
    except Exception as e:
        print(f"ç²å–å¾…å¯©æ ¸è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/serper/test")
async def test_serper_api():
    """æ¸¬è©¦Serper APIé€£æ¥"""
    try:
        print("ğŸ” æ¸¬è©¦Serper APIé€£æ¥...")
        
        # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
        serper_api_key = os.getenv('SERPER_API_KEY')
        print(f"ğŸ”‘ SERPER_API_KEY ç‹€æ…‹: {'å·²è¨­å®š' if serper_api_key else 'æœªè¨­å®š'}")
        
        if not serper_api_key:
            return {
                "success": False,
                "error": "SERPER_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š",
                "timestamp": datetime.now().isoformat()
            }
        
        # æ¸¬è©¦APIé€£æ¥
        from serper_integration import serper_service
        
        # æ¸¬è©¦æœå°‹åŠŸèƒ½
        test_result = serper_service.search_stock_news("2330", "å°ç©é›»", limit=2)
        
        return {
            "success": True,
            "api_key_configured": True,
            "test_query": "å°ç©é›» 2330 æ–°è æœ€æ–°",
            "results_count": len(test_result),
            "sample_results": test_result[:2] if test_result else [],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ Serper APIæ¸¬è©¦å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
            "api_key_configured": bool(os.getenv('SERPER_API_KEY')),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/posts/debug")
async def debug_posts():
    """èª¿è©¦ç«¯é»ï¼šæª¢æŸ¥æ‰€æœ‰è²¼æ–‡"""
    try:
        # ç²å–æ‰€æœ‰è²¼æ–‡
        all_posts = post_record_service.get_all_posts()
        print(f"è³‡æ–™åº«ä¸­å…±æœ‰ {len(all_posts)} ç¯‡è²¼æ–‡")
        
        # æŒ‰ç‹€æ…‹åˆ†çµ„
        status_groups = {}
        for post in all_posts:
            status = str(post.status)  # ç›´æ¥è½‰æ›ç‚ºå­—ç¬¦ä¸²
            if status not in status_groups:
                status_groups[status] = []
            status_groups[status].append(post)
        
        print("æŒ‰ç‹€æ…‹åˆ†çµ„:")
        for status, posts in status_groups.items():
            print(f"  {status}: {len(posts)} ç¯‡")
            for post in posts[:3]:  # åªé¡¯ç¤ºå‰3ç¯‡
                print(f"    - {post.post_id}: {post.title}")
        
        return {
            "success": True,
            "total_posts": len(all_posts),
            "posts_by_status": {status: len(posts) for status, posts in status_groups.items()},
            "posts": all_posts,
            "timestamp": datetime.now()
        }
    except Exception as e:
        print(f"èª¿è©¦è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/debug/data-source-assignment")
async def debug_data_source_assignment():
    """èª¿è©¦æ•¸æ“šæºåˆ†é…åŠŸèƒ½"""
    try:
        from smart_data_source_assigner import smart_assigner, KOLProfile, StockProfile
        
        # æ¸¬è©¦KOLé…ç½®
        test_kol = KOLProfile(
            serial=150,
            nickname="æ¸¬è©¦KOL",
            persona="technical",
            expertise_areas=["æŠ€è¡“åˆ†æ"],
            content_style="chart_analysis",
            target_audience="active_traders"
        )
        
        # æ¸¬è©¦è‚¡ç¥¨é…ç½®
        test_stock = StockProfile(
            stock_code="2208",
            stock_name="å°èˆ¹",
            industry="èˆªé‹",
            market_cap="medium",
            volatility="high",
            news_frequency="high"
        )
        
        # åŸ·è¡Œæ•¸æ“šæºåˆ†é…
        assignment = smart_assigner.assign_data_sources(
            kol_profile=test_kol,
            stock_profile=test_stock,
            batch_context={'trigger_type': 'after_hours_limit_up'}
        )
        
        return {
            "success": True,
            "kol_profile": {
                "serial": test_kol.serial,
                "nickname": test_kol.nickname,
                "persona": test_kol.persona
            },
            "stock_profile": {
                "stock_code": test_stock.stock_code,
                "stock_name": test_stock.stock_name,
                "market_cap": test_stock.market_cap,
                "volatility": test_stock.volatility
            },
            "data_source_assignment": {
                "primary_sources": [source.value for source in assignment.primary_sources],
                "secondary_sources": [source.value for source in assignment.secondary_sources],
                "excluded_sources": [source.value for source in assignment.excluded_sources],
                "assignment_reason": assignment.assignment_reason,
                "confidence_score": assignment.confidence_score
            }
        }
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šæºåˆ†é…èª¿è©¦å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/debug/data-source-usage")
async def debug_data_source_usage():
    """èª¿è©¦æ•¸æ“šæºå¯¦éš›ä½¿ç”¨æƒ…æ³"""
    try:
        # ç²å–æœ€è¿‘çš„è²¼æ–‡
        all_posts = post_record_service.get_all_posts()
        recent_posts = sorted(all_posts, key=lambda x: x.created_at, reverse=True)[:5]
        
        usage_analysis = []
        
        for post in recent_posts:
            # è§£æç”Ÿæˆåƒæ•¸
            generation_params = post.generation_params or {}
            if hasattr(generation_params, '__dict__'):
                generation_params = generation_params.__dict__
            
            data_sources = generation_params.get('data_sources', {})
            smart_assigned = generation_params.get('smart_assigned', [])
            assignment_reason = generation_params.get('assignment_reason', '')
            
            usage_analysis.append({
                "post_id": post.post_id,
                "title": post.title,
                "stock_code": post.stock_code,
                "kol_serial": post.kol_serial,
                "generation_params": {
                    "data_sources": data_sources,
                    "smart_assigned": smart_assigned,
                    "assignment_reason": assignment_reason
                },
                "content_preview": post.content[:200] + "..." if len(post.content) > 200 else post.content
            })
        
        return {
            "success": True,
            "total_posts": len(all_posts),
            "recent_posts_analysis": usage_analysis,
            "data_source_summary": {
                "smart_assignment_used": sum(1 for post in recent_posts 
                                           if post.generation_params and 
                                           hasattr(post.generation_params, 'smart_assigned')),
                "batch_data_sources_used": sum(1 for post in recent_posts 
                                              if post.generation_params and 
                                              hasattr(post.generation_params, 'data_sources')),
                "assignment_reasons_count": len(set(getattr(post.generation_params, 'assignment_reason', '') 
                                                   for post in recent_posts 
                                                   if post.generation_params))
            }
        }
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šæºä½¿ç”¨æƒ…æ³èª¿è©¦å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/posts/session/{session_id}")
async def get_session_posts(session_id: int, status: Optional[str] = None):
    """ç²å–æœƒè©±çš„æ‰€æœ‰è²¼æ–‡"""
    try:
        print(f"ğŸ” ç²å–æœƒè©±è²¼æ–‡: session_id={session_id}, status={status}")
        posts = post_record_service.get_session_posts(session_id, status)
        print(f"âœ… æ‰¾åˆ° {len(posts)} ç¯‡è²¼æ–‡")
        return {
            "success": True,
            "posts": posts,
            "count": len(posts),
            "timestamp": datetime.now()
        }
    except Exception as e:
        print(f"âŒ ç²å–æœƒè©±è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/post/batch-generate-stream")
async def batch_generate_posts_stream(request: BatchPostRequest):
    """
    æ‰¹é‡ç”Ÿæˆè²¼æ–‡ - ä½¿ç”¨Server-Sent Eventsä¸€å‰‡ä¸€å‰‡å›å‚³
    """
    print(f"ğŸš€ é–‹å§‹æ‰¹é‡ç™¼æ–‡ç”Ÿæˆ - æœƒè©±ID: {request.session_id}, è²¼æ–‡æ•¸é‡: {len(request.posts)}")
    
    async def generate_posts():
        total_posts = len(request.posts)
        successful_posts = 0
        failed_posts = 0
        
        print(f"ğŸ“Š æ‰¹é‡ç”Ÿæˆçµ±è¨ˆ: ç¸½æ•¸={total_posts}, æˆåŠŸ={successful_posts}, å¤±æ•—={failed_posts}")
        
        # ç™¼é€é–‹å§‹äº‹ä»¶
        yield f"data: {json.dumps({'type': 'batch_start', 'total': total_posts, 'session_id': request.session_id})}\n\n"
        
        for index, post_data in enumerate(request.posts):
            try:
                print(f"ğŸ“ é–‹å§‹ç”Ÿæˆç¬¬ {index + 1}/{total_posts} ç¯‡è²¼æ–‡...")
                
                # ç™¼é€é€²åº¦äº‹ä»¶
                progress = {
                    'type': 'progress',
                    'current': index + 1,
                    'total': total_posts,
                    'percentage': round((index + 1) / total_posts * 100, 1),
                    'successful': successful_posts,
                    'failed': failed_posts
                }
                yield f"data: {json.dumps(progress)}\n\n"
                
                # ç‚ºæ¯å€‹è²¼æ–‡æ™ºèƒ½åˆ†é…æ•¸æ“šæº
                print(f"ğŸ§  ç‚ºç¬¬ {index + 1} ç¯‡è²¼æ–‡æ™ºèƒ½åˆ†é…æ•¸æ“šæº...")
                
                # å‰µå»ºKOLå’Œè‚¡ç¥¨é…ç½®
                kol_profile = KOLProfile(
                    serial=int(post_data.get('kol_serial', 150)),
                    nickname=f"KOL-{post_data.get('kol_serial', 150)}",
                    persona=request.batch_config.get('kol_persona', 'technical'),
                    expertise_areas=[],
                    content_style=request.batch_config.get('content_style', 'chart_analysis'),
                    target_audience=request.batch_config.get('target_audience', 'active_traders')
                )
                
                stock_profile = StockProfile(
                    stock_code=post_data.get('stock_code'),
                    stock_name=post_data.get('stock_name'),
                    industry='unknown',
                    market_cap='medium',  # é è¨­ä¸­ç­‰å¸‚å€¼
                    volatility='medium',  # é è¨­ä¸­ç­‰æ³¢å‹•
                    news_frequency='medium'  # é è¨­ä¸­ç­‰æ–°èé »ç‡
                )
                
                # æ™ºèƒ½åˆ†é…æ•¸æ“šæº
                data_source_assignment = smart_assigner.assign_data_sources(
                    kol_profile=kol_profile,
                    stock_profile=stock_profile,
                    batch_context={'trigger_type': 'manual_batch'}
                )
                
                # åˆä½µæ™ºèƒ½åˆ†é…çš„æ•¸æ“šæºå’Œæ‰¹æ¬¡é…ç½®çš„æ•¸æ“šæº
                smart_sources = [source.value for source in data_source_assignment.primary_sources]
                batch_sources = request.data_sources or {}
                
                # å‰µå»ºæ··åˆæ•¸æ“šæºé…ç½® - å„ªå…ˆä½¿ç”¨æ™ºèƒ½åˆ†é…çš„æ•¸æ“šæº
                hybrid_data_sources = {
                    **batch_sources,  # æ‰¹æ¬¡é…ç½®çš„æ•¸æ“šæº
                    'smart_assigned': smart_sources,  # æ™ºèƒ½åˆ†é…çš„æ•¸æ“šæº
                    'assignment_reason': data_source_assignment.assignment_reason,
                    'confidence_score': data_source_assignment.confidence_score
                }
                
                # å¦‚æœæ™ºèƒ½åˆ†é…æœ‰æ•¸æ“šæºï¼Œå„ªå…ˆä½¿ç”¨æ™ºèƒ½åˆ†é…çš„
                if smart_sources:
                    # å°‡æ™ºèƒ½åˆ†é…çš„æ•¸æ“šæºè¨­ç‚ºä¸»è¦æ•¸æ“šæº
                    for source in smart_sources:
                        if source == 'ohlc_api':
                            hybrid_data_sources['stock_price_api'] = True
                        elif source == 'revenue_api':
                            hybrid_data_sources['monthly_revenue_api'] = True
                        elif source == 'fundamental_api':
                            hybrid_data_sources['fundamental_data'] = ['è²¡å ±']
                        elif source == 'serper_api':
                            hybrid_data_sources['news_sources'] = ['å·¥å•†æ™‚å ±', 'ç¶“æ¿Ÿæ—¥å ±', 'ä¸­å¤®ç¤¾']
                        elif source == 'summary_api':
                            hybrid_data_sources['technical_indicators'] = ['MACD', 'RSI', 'ç§»å‹•å¹³å‡ç·š']
                
                print(f"ğŸ“Š æ•¸æ“šæºåˆ†é…: æ™ºèƒ½={smart_sources}, æ‰¹æ¬¡={list(batch_sources.keys())}")
                
                # ç”Ÿæˆå–®å€‹è²¼æ–‡
                post_request = PostingRequest(
                    stock_code=post_data.get('stock_code'),
                    stock_name=post_data.get('stock_name'),
                    kol_serial=post_data.get('kol_serial'),
                    kol_persona=request.batch_config.get('kol_persona', 'technical'),
                    content_style=request.batch_config.get('content_style', 'chart_analysis'),
                    target_audience=request.batch_config.get('target_audience', 'active_traders'),
                    batch_mode=True,
                    session_id=request.session_id,
                    data_sources=hybrid_data_sources,  # ä½¿ç”¨æ··åˆæ•¸æ“šæº
                    explainability_config=request.explainability_config,
                    news_config=request.news_config
                )
                
                print(f"âš™ï¸ èª¿ç”¨å–®å€‹è²¼æ–‡ç”ŸæˆAPI...")
                result = await manual_post_content(post_request)
                print(f"âœ… ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”Ÿæˆå®Œæˆ: {result.success}")
                
                # ç™¼é€è²¼æ–‡ç”Ÿæˆå®Œæˆäº‹ä»¶
                post_response = {
                    'type': 'post_generated',
                    'success': result.success,
                    'post_id': result.post_id,
                    'content': result.content,
                    'error': result.error,
                    'timestamp': result.timestamp.isoformat(),
                    'progress': {
                        'current': index + 1,
                        'total': total_posts,
                        'percentage': round((index + 1) / total_posts * 100, 1)
                    }
                }
                
                if result.success:
                    successful_posts += 1
                    print(f"âœ… ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”ŸæˆæˆåŠŸ: {result.post_id}")
                else:
                    failed_posts += 1
                    print(f"âŒ ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”Ÿæˆå¤±æ•—: {result.error}")
                
                yield f"data: {json.dumps(post_response)}\n\n"
                
                # æ·»åŠ å»¶é²ï¼Œé¿å…éæ–¼é »ç¹çš„è«‹æ±‚
                await asyncio.sleep(0.5)
                
            except Exception as e:
                failed_posts += 1
                print(f"âŒ ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”Ÿæˆç•°å¸¸: {e}")
                error_response = {
                    'type': 'post_error',
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat(),
                    'progress': {
                        'current': index + 1,
                        'total': total_posts,
                        'percentage': round((index + 1) / total_posts * 100, 1)
                    }
                }
                yield f"data: {json.dumps(error_response)}\n\n"
        
        # ç™¼é€å®Œæˆäº‹ä»¶
        print(f"ğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆ: ç¸½æ•¸={total_posts}, æˆåŠŸ={successful_posts}, å¤±æ•—={failed_posts}")
        final_result = {
            'type': 'batch_complete',
            'total': total_posts,
            'successful': successful_posts,
            'failed': failed_posts,
            'session_id': request.session_id,
            'timestamp': datetime.now().isoformat()
        }
        yield f"data: {json.dumps(final_result)}\n\n"
    
    return StreamingResponse(
        generate_posts(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

@app.post("/posts/{post_id}/approve")
async def approve_post(post_id: str, request: Request):
    """å¯©æ ¸é€šéè²¼æ–‡"""
    logger.info(f"ğŸ” é–‹å§‹è™•ç†è²¼æ–‡å¯©æ ¸è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        # è¨˜éŒ„è«‹æ±‚è©³æƒ…
        logger.info(f"ğŸ“ å¯©æ ¸è«‹æ±‚è©³æƒ… - Post ID: {post_id}")
        
        # æª¢æŸ¥è²¼æ–‡æ˜¯å¦å­˜åœ¨
        existing_post = post_record_service.get_post_record(post_id)
        if not existing_post:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            logger.info(f"ğŸ“Š ç›®å‰è³‡æ–™åº«ä¸­çš„è²¼æ–‡æ•¸é‡: {len(post_record_service.db)}")
            logger.info(f"ğŸ“‹ è³‡æ–™åº«ä¸­çš„è²¼æ–‡ ID åˆ—è¡¨: {list(post_record_service.db.keys())}")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
        
        logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç•¶å‰ç‹€æ…‹: {existing_post.status}")
        
        # è§£æè«‹æ±‚å…§å®¹
        body = await request.json()
        reviewer_notes = body.get("reviewer_notes")
        approved_by = body.get("approved_by", "system")
        
        logger.info(f"ğŸ“ å¯©æ ¸åƒæ•¸ - å¯©æ ¸è€…: {approved_by}, å‚™è¨»: {reviewer_notes}")
        
        # å‰µå»ºæ›´æ–°è³‡æ–™
        update_data = PostRecordUpdate(
            status="approved",
            reviewer_notes=reviewer_notes,
            approved_by=approved_by,
            approved_at=datetime.now()
        )
        
        logger.info(f"ğŸ”„ é–‹å§‹æ›´æ–°è²¼æ–‡ç‹€æ…‹ - Post ID: {post_id}")
        
        # æ›´æ–°è²¼æ–‡è¨˜éŒ„
        post_record = post_record_service.update_post_record(post_id, update_data)
        
        if post_record:
            logger.info(f"âœ… è²¼æ–‡å¯©æ ¸æˆåŠŸ - Post ID: {post_id}, æ–°ç‹€æ…‹: {post_record.status}")
            logger.info(f"ğŸ“Š æ›´æ–°å¾Œè³‡æ–™åº«ç‹€æ…‹ - ç¸½è²¼æ–‡æ•¸: {len(post_record_service.db)}")
            
            return {
                "success": True,
                "message": "è²¼æ–‡å¯©æ ¸é€šé",
                "post": {
                    "post_id": post_record.post_id,
                    "status": post_record.status,
                    "approved_by": post_record.approved_by,
                    "approved_at": post_record.approved_at.isoformat() if post_record.approved_at else None,
                    "reviewer_notes": post_record.reviewer_notes
                },
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ æ›´æ–°è²¼æ–‡å¤±æ•— - Post ID: {post_id}")
            raise HTTPException(status_code=500, detail="æ›´æ–°è²¼æ–‡å¤±æ•—")
            
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}, è©³æƒ…: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"âŒ å¯©æ ¸è²¼æ–‡æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        logger.error(f"ğŸ” éŒ¯èª¤é¡å‹: {type(e).__name__}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"å¯©æ ¸å¤±æ•—: {str(e)}")

@app.post("/posts/{post_id}/reject")
async def reject_post(post_id: str, request: Request):
    """æ‹’çµ•è²¼æ–‡"""
    logger.info(f"ğŸ” é–‹å§‹è™•ç†è²¼æ–‡æ‹’çµ•è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        # æª¢æŸ¥è²¼æ–‡æ˜¯å¦å­˜åœ¨
        existing_post = post_record_service.get_post_record(post_id)
        if not existing_post:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            logger.info(f"ğŸ“Š ç›®å‰è³‡æ–™åº«ä¸­çš„è²¼æ–‡æ•¸é‡: {len(post_record_service.db)}")
            logger.info(f"ğŸ“‹ è³‡æ–™åº«ä¸­çš„è²¼æ–‡ ID åˆ—è¡¨: {list(post_record_service.db.keys())}")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
        
        logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç•¶å‰ç‹€æ…‹: {existing_post.status}")
        
        # è§£æè«‹æ±‚å…§å®¹
        body = await request.json()
        reviewer_notes = body.get("reviewer_notes", "æ‹’çµ•")
        
        logger.info(f"ğŸ“ æ‹’çµ•åƒæ•¸ - å‚™è¨»: {reviewer_notes}")
        
        # å‰µå»ºæ›´æ–°è³‡æ–™
        update_data = PostRecordUpdate(
            status="rejected",
            reviewer_notes=reviewer_notes,
            approved_by="system"
        )
        
        logger.info(f"ğŸ”„ é–‹å§‹æ›´æ–°è²¼æ–‡ç‹€æ…‹ç‚ºæ‹’çµ• - Post ID: {post_id}")
        
        # æ›´æ–°è²¼æ–‡è¨˜éŒ„
        post_record = post_record_service.update_post_record(post_id, update_data)
        
        if post_record:
            logger.info(f"âœ… è²¼æ–‡æ‹’çµ•æˆåŠŸ - Post ID: {post_id}, æ–°ç‹€æ…‹: {post_record.status}")
            return {
                "success": True,
                "message": "è²¼æ–‡å·²æ‹’çµ•",
                "post": {
                    "post_id": post_record.post_id,
                    "status": post_record.status,
                    "reviewer_notes": post_record.reviewer_notes
                },
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ æ›´æ–°è²¼æ–‡å¤±æ•— - Post ID: {post_id}")
            raise HTTPException(status_code=500, detail="æ›´æ–°è²¼æ–‡å¤±æ•—")
            
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}, è©³æƒ…: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"âŒ æ‹’çµ•è²¼æ–‡æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"æ‹’çµ•å¤±æ•—: {str(e)}")

@app.post("/posts/{post_id}/publish")
async def publish_post_to_cmoney(post_id: str, cmoney_config: Optional[Dict[str, Any]] = None):
    """ç™¼å¸ƒè²¼æ–‡åˆ°CMoney"""
    try:
        # ç²å–è²¼æ–‡è¨˜éŒ„
        post_record = post_record_service.get_post_record(post_id)
        if not post_record:
            raise HTTPException(status_code=404, detail="è²¼æ–‡ä¸å­˜åœ¨")
        
        if post_record.status != "approved":
            raise HTTPException(status_code=400, detail="åªæœ‰å·²å¯©æ ¸çš„è²¼æ–‡æ‰èƒ½ç™¼å¸ƒ")
        
        # ä½¿ç”¨ç™¼ä½ˆæœå‹™ç™¼ä½ˆè²¼æ–‡
        from publish_service import publish_service
        publish_result = await publish_service.publish_post(post_record)
        
        # æ›´æ–°è²¼æ–‡ç‹€æ…‹ç‚ºpublished
        update_data = PostRecordUpdate(
            status="published",
            published_at=datetime.now(),
            cmoney_post_id=publish_result["post_id"],
            cmoney_post_url=publish_result["post_url"]
        )
        
        updated_post = post_record_service.update_post_record(post_id, update_data)
        
        return publish_result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"ç™¼å¸ƒå¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
            "post_id": post_id,
            "timestamp": datetime.now().isoformat()
        }

@app.get("/posts/{post_id}")
async def get_post(post_id: str):
    """ç²å–å–®å€‹è²¼æ–‡è©³æƒ…"""
    logger.info(f"ğŸ” ç²å–è²¼æ–‡è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        post_record = post_record_service.get_post_record(post_id)
        if post_record:
            logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç‹€æ…‹: {post_record.status}")
            
            # å°‡è²¼æ–‡è¨˜éŒ„è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„å­—å…¸
            post_data = {
                "post_id": post_record.post_id,
                "session_id": post_record.session_id,
                "kol_serial": post_record.kol_serial,
                "kol_nickname": post_record.kol_nickname,
                "kol_persona": post_record.kol_persona,
                "stock_code": post_record.stock_code,
                "stock_name": post_record.stock_name,
                "title": post_record.title,
                "content": post_record.content,
                "content_md": post_record.content_md,
                "status": post_record.status,
                "quality_score": post_record.quality_score,
                "ai_detection_score": post_record.ai_detection_score,
                "risk_level": post_record.risk_level,
                "reviewer_notes": post_record.reviewer_notes,
                "approved_by": post_record.approved_by,
                "approved_at": post_record.approved_at.isoformat() if post_record.approved_at else None,
                "scheduled_at": post_record.scheduled_at.isoformat() if post_record.scheduled_at else None,
                "published_at": post_record.published_at.isoformat() if post_record.published_at else None,
                "cmoney_post_id": post_record.cmoney_post_id,
                "cmoney_post_url": post_record.cmoney_post_url,
                "publish_error": post_record.publish_error,
                "views": post_record.views,
                "likes": post_record.likes,
                "comments": post_record.comments,
                "shares": post_record.shares,
                "topic_id": post_record.topic_id,
                "topic_title": post_record.topic_title,
                "created_at": post_record.created_at.isoformat() if post_record.created_at else None,
                "updated_at": post_record.updated_at.isoformat() if post_record.updated_at else None
            }
            
            return {
                "success": True,
                "post": post_data,
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
            
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}")
        raise e
    except Exception as e:
        logger.error(f"âŒ ç²å–è²¼æ–‡æ™‚ç™¼ç”ŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"ç²å–è²¼æ–‡å¤±æ•—: {str(e)}")

# ==================== æ–°å¢çš„å…§å®¹ç”Ÿæˆå‡½æ•¸ ====================

def generate_kol_content_with_serper(stock_id: str, stock_name: str, kol_persona: str, 
                                    content_style: str, target_audience: str,
                                    serper_analysis: Dict[str, Any],
                                    data_sources: List[str]) -> Dict[str, Any]:
    """ä½¿ç”¨Serperæ•¸æ“šç”ŸæˆKOLå…§å®¹"""
    
    try:
        # æå–Serperæ•¸æ“š
        news_items = serper_analysis.get('news_items', [])
        limit_up_analysis = serper_analysis.get('limit_up_analysis', {})
        limit_up_reasons = limit_up_analysis.get('limit_up_reasons', [])
        key_events = limit_up_analysis.get('key_events', [])
        market_sentiment = limit_up_analysis.get('market_sentiment', 'neutral')
        
        # æ§‹å»ºå¢å¼·ç‰ˆPrompt
        prompt_parts = []
        
        # 1. åŸºæœ¬åˆ†ææ¡†æ¶ - ç´”æ–‡å­—æ ¼å¼
        prompt_parts.append(f"{stock_name}({stock_id}) æ·±åº¦åˆ†æå ±å‘Š")
        prompt_parts.append("")
        prompt_parts.append("æ ¸å¿ƒè§€é»")
        prompt_parts.append("")
        
        # 2. æ•´åˆæ¼²åœåŸå› åˆ†æ
        if limit_up_reasons:
            prompt_parts.append(f"åŸºæ–¼æœ€æ–°å¸‚å ´è³‡è¨Šï¼Œ{stock_name} ç›®å‰è™•æ–¼å¼·å‹¢ä¸Šæ¼²ç‹€æ…‹ï¼š")
            for reason in limit_up_reasons[:2]:  # å–å‰2å€‹åŸå› 
                prompt_parts.append(f"- {reason['title']}: {reason['snippet'][:150]}")
        else:
            prompt_parts.append(f"{stock_name} ç›®å‰è™•æ–¼æŠ€è¡“é¢å¼·å‹¢ç‹€æ…‹ï¼Œå¤šé …æŒ‡æ¨™é¡¯ç¤ºä¸Šæ¼²å‹•èƒ½ã€‚")
        
        prompt_parts.append("")
        
        # 3. æŠ€è¡“åˆ†æéƒ¨åˆ†
        if 'ohlc_api' in data_sources:
            prompt_parts.append("æŠ€è¡“é¢åˆ†æ")
            prompt_parts.append("- MA5/MA20: é»ƒé‡‘äº¤å‰ç¢ºèªå¤šé ­è¶¨å‹¢")
            prompt_parts.append("- RSI14: ä¸­æ€§åå¤šï¼Œä»æœ‰ä¸Šæ¼²ç©ºé–“")
            prompt_parts.append("- MACDæŸ±ç‹€é«”: å¤šé ­è¨Šè™ŸæŒçºŒ")
            prompt_parts.append("")
        
        # 4. åŸºæœ¬é¢åˆ†æéƒ¨åˆ†
        if 'fundamental_api' in data_sources:
            prompt_parts.append("åŸºæœ¬é¢åˆ†æ")
            if key_events:
                prompt_parts.append("é—œéµäº‹ä»¶åˆ†æ:")
                for event in key_events[:2]:
                    prompt_parts.append(f"- {event['event']}: {event['description'][:100]}")
            else:
                prompt_parts.append("- è²¡å‹™æŒ‡æ¨™ç©©å¥ï¼Œç‡Ÿæ”¶æˆé•·å‹•èƒ½å¼·å‹")
                prompt_parts.append("- ç”¢æ¥­å‰æ™¯çœ‹å¥½ï¼Œé•·æœŸæŠ•è³‡åƒ¹å€¼é¡¯ç¾")
            prompt_parts.append("")
        
        # 5. æ–°èæ•´åˆéƒ¨åˆ†
        if news_items and 'serper_api' in data_sources:
            prompt_parts.append("å¸‚å ´å‹•æ…‹")
            prompt_parts.append("æœ€æ–°å¸‚å ´è³‡è¨Š:")
            for news in news_items[:2]:  # å–å‰2å‰‡æ–°è
                prompt_parts.append(f"- {news['title']}: {news['snippet'][:150]}")
            prompt_parts.append("")
        
        # 6. æŠ•è³‡å»ºè­°
        prompt_parts.append("æŠ•è³‡å»ºè­°")
        if market_sentiment == 'positive':
            prompt_parts.append("åŸºæ–¼æŠ€è¡“é¢å’ŒåŸºæœ¬é¢åˆ†æï¼Œå»ºè­°ç©æ¥µå¸ƒå±€ï¼Œç›®æ¨™åƒ¹ä½å¯æœŸå¾…15-20%æ¼²å¹…ã€‚")
        elif market_sentiment == 'negative':
            prompt_parts.append("é›–ç„¶æŠ€è¡“é¢å¼·å‹¢ï¼Œä½†éœ€æ³¨æ„åŸºæœ¬é¢é¢¨éšªï¼Œå»ºè­°è¬¹æ…æ“ä½œï¼Œè¨­å¥½åœæé»ä½ã€‚")
        else:
            prompt_parts.append("åŸºæ–¼ç¶œåˆåˆ†æï¼Œå»ºè­°é€¢ä½å¸ƒå±€ï¼Œç›®æ¨™åƒ¹ä½å¯æœŸå¾…10-15%æ¼²å¹…ã€‚")
        prompt_parts.append("")
        
        # 7. é¢¨éšªæé†’
        prompt_parts.append("é¢¨éšªæé†’")
        prompt_parts.append("- æ³¨æ„å¤§ç›¤ç’°å¢ƒè®ŠåŒ–")
        prompt_parts.append("- è¨­å¥½åœæé»ä½")
        prompt_parts.append("- åˆ†æ‰¹é€²å ´é™ä½é¢¨éšª")
        prompt_parts.append("")
        
        # 8. æ“ä½œç­–ç•¥
        prompt_parts.append("æ“ä½œç­–ç•¥")
        prompt_parts.append("1. é€²å ´æ™‚æ©Ÿ: å›æ¸¬æ”¯æ’æ™‚åˆ†æ‰¹è²·é€²")
        prompt_parts.append("2. åœæè¨­å®š: è·Œç ´é—œéµæ”¯æ’ä½")
        prompt_parts.append("3. ç›®æ¨™åƒ¹ä½: æŠ€è¡“ç›®æ¨™åƒ¹ä½")
        prompt_parts.append("4. æŒè‚¡æ¯”ä¾‹: å»ºè­°æ§åˆ¶åœ¨ç¸½è³‡ç”¢10%ä»¥å…§")
        
        # 9. å…è²¬è²æ˜
        prompt_parts.append("")
        prompt_parts.append("ä»¥ä¸Šåˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°")
        prompt_parts.append("")
        
        # 10. æ•¸æ“šä¾†æºæ¨™è¨»
        prompt_parts.append("æ•¸æ“šä¾†æº")
        data_source_names = {
            'ohlc_api': 'æŠ€è¡“æŒ‡æ¨™æ•¸æ“š',
            'serper_api': 'æœ€æ–°æ–°èè³‡è¨Š',
            'fundamental_api': 'åŸºæœ¬é¢æ•¸æ“š',
            'summary_api': 'å¸‚å ´æ‘˜è¦åˆ†æ',
            'revenue_api': 'ç‡Ÿæ”¶æ•¸æ“š',
            'financial_api': 'è²¡å‹™æ•¸æ“š'
        }
        used_sources = [data_source_names.get(source, source) for source in data_sources]
        prompt_parts.append(f"æœ¬åˆ†ææ•´åˆäº†: {', '.join(used_sources)}")
        
        # çµ„åˆå®Œæ•´å…§å®¹
        content_md = "\n".join(prompt_parts)
        
        # ç”Ÿæˆæ¨™é¡Œ - ç´”æ–‡å­—æ ¼å¼
        title = f"{stock_name}({stock_id}) {kol_persona.title()}è§€é» - æ·±åº¦å¸‚å ´è§£æ"
        
        return {
            "title": title,
            "content": content_md,
            "content_md": content_md,
            "stock_id": stock_id,
            "stock_name": stock_name,
            "kol_persona": kol_persona,
            "content_style": content_style,
            "target_audience": target_audience,
            "data_sources": data_sources,
            "serper_integration": True,
            "news_count": len(news_items),
            "market_sentiment": market_sentiment,
            "generation_timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"Serperå…§å®¹ç”Ÿæˆå¤±æ•—: {e}")
        # å›é€€åˆ°åŸºæœ¬å…§å®¹ç”Ÿæˆ
        return generate_kol_content_direct(stock_id, stock_name, kol_persona, content_style, target_audience)

def enhance_content_with_serper_data(kol_content: Dict[str, Any], 
                                   serper_analysis: Dict[str, Any],
                                   data_source_assignment) -> Dict[str, Any]:
    """ä½¿ç”¨Serperæ•¸æ“šå¢å¼·å…§å®¹"""
    
    try:
        enhanced_content = kol_content.copy()
        
        # ç²å–æ–°èæ•¸æ“š
        news_items = serper_analysis.get('news_items', [])
        limit_up_analysis = serper_analysis.get('limit_up_analysis', {})
        
        # å¦‚æœæœ‰æ–°èæ•¸æ“šï¼Œæ•´åˆåˆ°å…§å®¹ä¸­
        if news_items:
            print(f"ğŸ”— æ•´åˆ {len(news_items)} å‰‡æ–°èåˆ°å…§å®¹ä¸­")
            
            # æå–æ–°èæ‘˜è¦å’Œé€£çµ
            news_summary = []
            for i, news in enumerate(news_items[:3]):  # åªå–å‰3å‰‡æ–°è
                title = news.get('title', '')
                snippet = news.get('snippet', '')
                link = news.get('link', '')
                if title and snippet:
                    if link:
                        news_summary.append(f"ğŸ“° {title}: {snippet[:100]}...\n   [é–±è®€æ›´å¤š]({link})")
                    else:
                        news_summary.append(f"ğŸ“° {title}: {snippet[:100]}...")
            
            # æ•´åˆæ–°èåˆ°å…§å®¹ä¸­
            original_content = enhanced_content.get('content', '')
            original_content_md = enhanced_content.get('content_md', '')
            
            # æ·»åŠ æ–°èè³‡è¨Šåˆ°å…§å®¹é–‹é ­
            news_section = ""
            if news_summary:
                news_section = "ğŸ“° **æœ€æ–°æ¶ˆæ¯**\n\n" + "\n".join(news_summary) + "\n\n"
            
            # å¦‚æœæœ‰æ¼²åœåˆ†æï¼Œä¹ŸåŠ å…¥
            if limit_up_analysis:
                analysis_section = ""
                if limit_up_analysis.get('market_sentiment'):
                    sentiment = limit_up_analysis.get('market_sentiment', 'neutral')
                    analysis_section += f"ğŸ“Š **å¸‚å ´æƒ…ç·’**: {sentiment}\n\n"
                
                if limit_up_analysis.get('key_factors'):
                    factors = limit_up_analysis.get('key_factors', [])
                    if factors:
                        analysis_section += f"ğŸ” **é—œéµå› ç´ **: {', '.join(factors[:3])}\n\n"
                
                news_section += analysis_section
            
            # æ›´æ–°å…§å®¹
            enhanced_content['content'] = news_section + original_content
            enhanced_content['content_md'] = news_section + original_content_md
            
            print(f"âœ… æ–°èæ•´åˆå®Œæˆï¼Œå…§å®¹é•·åº¦: {len(enhanced_content['content'])} å­—")
        
        # æ·»åŠ Serperæ•¸æ“šåˆ°å…§å®¹ä¸­
        enhanced_content.update({
            "serper_data": serper_analysis,
            "data_source_assignment": {
                "primary_sources": [source.value for source in data_source_assignment.primary_sources],
                "secondary_sources": [source.value for source in data_source_assignment.secondary_sources],
                "assignment_reason": data_source_assignment.assignment_reason,
                "confidence_score": data_source_assignment.confidence_score
            },
            "news_integration": True,
            "limit_up_analysis": limit_up_analysis,
            "market_sentiment": limit_up_analysis.get('market_sentiment', 'neutral')
        })
        
        return enhanced_content
        
    except Exception as e:
        print(f"Serperæ•¸æ“šå¢å¼·å¤±æ•—: {e}")
        return kol_content

print("ğŸ‰ æ‰€æœ‰æ¨¡çµ„è¼‰å…¥å®Œæˆï¼")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

