import os
import requests
import json
from fastapi import FastAPI, BackgroundTasks, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, validator
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncio
import sys
import json
from dotenv import load_dotenv
import logging
import pytz

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# è¨­ç½®æ—¥èªŒ - å…è¨± INFO ç´šåˆ¥ä»¥é¡¯ç¤ºæ’ç¨‹å•Ÿå‹•æ—¥èªŒ
# å¼·åˆ¶è¦†è“‹ç’°å¢ƒè®Šæ•¸ LOG_LEVEL=INFO
import os
os.environ['LOG_LEVEL'] = 'INFO'

logging.basicConfig(level=logging.INFO, force=True)
logger = logging.getLogger(__name__)

# å¼·åˆ¶é—œé–‰ SQLAlchemy çš„ SQL æŸ¥è©¢æ—¥èªŒ
logging.getLogger('sqlalchemy.engine').setLevel(logging.CRITICAL)
logging.getLogger('sqlalchemy.dialects').setLevel(logging.CRITICAL)
logging.getLogger('sqlalchemy.pool').setLevel(logging.CRITICAL)
logging.getLogger('sqlalchemy.orm').setLevel(logging.CRITICAL)
logging.getLogger('sqlalchemy').setLevel(logging.CRITICAL)

# å¼·åˆ¶è¨­ç½®æ ¹æ—¥èªŒç´šåˆ¥
logging.getLogger().setLevel(logging.WARNING)

# å°å…¥æ”¹é€²çš„å…§å®¹ç”Ÿæˆå™¨
from improved_content_generator import generate_improved_kol_content
# å°å…¥GPTå…§å®¹ç”Ÿæˆå™¨
from gpt_content_generator import gpt_generator
# å°å…¥äº’å‹•å…§å®¹ç”Ÿæˆå™¨
# from interaction_content_generator import generate_interaction_content  # æš«æ™‚è¨»è§£ï¼Œæ¨¡çµ„ä¸å­˜åœ¨

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv(os.path.join(os.path.dirname(__file__), '../../../../.env'))

# ä½¿ç”¨PostgreSQLæœå‹™
from postgresql_service import PostgreSQLPostRecordService
# å°å…¥æ•¸æ“šæ¨¡å‹ (CommodityTag å°‡åœ¨éœ€è¦æ™‚å‹•æ…‹å°å…¥)
try:
    from post_record_service import CommunityTopic, GenerationParams, PostRecordCreate, PostRecordUpdate
except ImportError as e:
    print(f"âŒ æ•¸æ“šæ¨¡å‹å°å…¥å¤±æ•—: {e}")

# å°å…¥ asyncio æ¨¡çµ„
import asyncio

app = FastAPI(
    title="Posting Service", 
    description="è™›æ“¬KOLè‡ªå‹•ç™¼æ–‡æœå‹™"
)

# ğŸ”¥ ä½¿ç”¨èˆŠç‰ˆæœ¬çš„å•Ÿå‹•äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """æ‡‰ç”¨å•Ÿå‹•äº‹ä»¶"""
    print("ğŸš€ğŸš€ğŸš€ STARTUP äº‹ä»¶è¢«èª¿ç”¨ï¼ğŸš€ğŸš€ğŸš€")
    print("ğŸš€ğŸš€ğŸš€ FastAPI æ‡‰ç”¨é–‹å§‹å•Ÿç”¨ ğŸš€ğŸš€ğŸš€")
    
    # å•Ÿå‹•æ™‚çš„é‚è¼¯
    logger.info("ğŸš€ğŸš€ğŸš€ FastAPI æ‡‰ç”¨é–‹å§‹å•Ÿç”¨ ğŸš€ğŸš€ğŸš€")
    logger.info("ğŸ“‹ æ­£åœ¨åˆå§‹åŒ–å„é …æœå‹™...")
    print("ğŸ“‹ æ­£åœ¨åˆå§‹åŒ–å„é …æœå‹™...")
    
    # ğŸ”¥ TEMPORARILY DISABLED: posting-service background scheduler
    # TODO: Fix time check logic before re-enabling
    # The background scheduler was executing all active schedules continuously
    # Disabled to prevent infinite loop execution
    logger.warning("âš ï¸  æ’ç¨‹æœå‹™èƒŒæ™¯ä»»å‹™å·²æš«æ™‚åœç”¨ - éœ€ä¿®å¾©æ™‚é–“æª¢æŸ¥é‚è¼¯")
    print("âš ï¸  æ’ç¨‹æœå‹™èƒŒæ™¯ä»»å‹™å·²æš«æ™‚åœç”¨ - éœ€ä¿®å¾©æ™‚é–“æª¢æŸ¥é‚è¼¯")

    # try:
    #     # ğŸ”¥ é‡æ–°å•Ÿç”¨æ’ç¨‹æœå‹™
    #     logger.info("ğŸš€ğŸš€ğŸš€ é–‹å§‹å•Ÿå‹•æ’ç¨‹æœå‹™èƒŒæ™¯ä»»å‹™ ğŸš€ğŸš€ğŸš€")
    #     logger.info("ğŸ“‹ æ­£åœ¨å°å…¥æ’ç¨‹æœå‹™æ¨¡çµ„...")
    #     print("ğŸš€ğŸš€ğŸš€ é–‹å§‹å•Ÿå‹•æ’ç¨‹æœå‹™èƒŒæ™¯ä»»å‹™ ğŸš€ğŸš€ğŸš€")
    #
    #     try:
    #         from schedule_service import schedule_service
    #         logger.info("âœ… æ’ç¨‹æœå‹™æ¨¡çµ„å°å…¥æˆåŠŸ")
    #         print("âœ… æ’ç¨‹æœå‹™æ¨¡çµ„å°å…¥æˆåŠŸ")
    #
    #         logger.info("ğŸ”„ æ­£åœ¨å‰µå»ºèƒŒæ™¯æ’ç¨‹ä»»å‹™...")
    #         print("ğŸ”„ æ­£åœ¨å‰µå»ºèƒŒæ™¯æ’ç¨‹ä»»å‹™...")
    #         background_task = asyncio.create_task(schedule_service.start_background_scheduler())
    #         app.state.background_scheduler_task = background_task
    #         logger.info("âœ… èƒŒæ™¯æ’ç¨‹ä»»å‹™å‰µå»ºæˆåŠŸ")
    #         print("âœ… èƒŒæ™¯æ’ç¨‹ä»»å‹™å‰µå»ºæˆåŠŸ")
    #
    #         logger.info("âœ… âœ… âœ… æ’ç¨‹æœå‹™å·²å•Ÿå‹•ï¼ŒAPI æœå‹™å·²å•Ÿå‹• âœ… âœ… âœ…")
    #         print("âœ… âœ… âœ… æ’ç¨‹æœå‹™å·²å•Ÿå‹•ï¼ŒAPI æœå‹™å·²å•Ÿå‹• âœ… âœ… âœ…")
    #
    #     except Exception as import_error:
    #         logger.error(f"âŒ æ’ç¨‹æœå‹™æ¨¡çµ„å°å…¥æˆ–å•Ÿå‹•å¤±æ•—: {import_error}")
    #         logger.error(f"ğŸ” å°å…¥éŒ¯èª¤è©³æƒ…: {str(import_error)}")
    #         print(f"âŒ æ’ç¨‹æœå‹™æ¨¡çµ„å°å…¥æˆ–å•Ÿå‹•å¤±æ•—: {import_error}")
    #         import traceback
    #         logger.error(f"ğŸ” å°å…¥éŒ¯èª¤å †ç–Š:\n{traceback.format_exc()}")
    #         print(f"ğŸ” å°å…¥éŒ¯èª¤å †ç–Š:\n{traceback.format_exc()}")
    #         raise
    #
    # except Exception as e:
    #     logger.error(f"âŒ æ’ç¨‹æœå‹™å•Ÿå‹•å¤±æ•—: {e}")
    #     logger.error(f"ğŸ” éŒ¯èª¤è©³æƒ…: {str(e)}")
    #     print(f"âŒ æ’ç¨‹æœå‹™å•Ÿå‹•å¤±æ•—: {e}")
    #     import traceback
    #     traceback.print_exc()

    logger.info("ğŸ‰ æ‰€æœ‰æœå‹™åˆå§‹åŒ–å®Œæˆï¼æ‡‰ç”¨é–‹å§‹é‹è¡Œ...")
    print("ğŸ‰ æ‰€æœ‰æœå‹™åˆå§‹åŒ–å®Œæˆï¼æ‡‰ç”¨é–‹å§‹é‹è¡Œ...")

@app.on_event("shutdown")
async def shutdown_event():
    """æ‡‰ç”¨é—œé–‰äº‹ä»¶"""
    print("ğŸ›‘ æ‡‰ç”¨æ­£åœ¨é—œé–‰...")
    logger.info("ğŸ›‘ æ‡‰ç”¨æ­£åœ¨é—œé–‰...")
    try:
        # æ¸…ç†èƒŒæ™¯ä»»å‹™
        if hasattr(app.state, 'background_scheduler_task'):
            logger.info("ğŸ”„ æ­£åœ¨åœæ­¢èƒŒæ™¯æ’ç¨‹å™¨...")
            print("ğŸ”„ æ­£åœ¨åœæ­¢èƒŒæ™¯æ’ç¨‹å™¨...")
            app.state.background_scheduler_task.cancel()
            try:
                await app.state.background_scheduler_task
            except asyncio.CancelledError:
                logger.info("âœ… èƒŒæ™¯æ’ç¨‹å™¨å·²åœæ­¢")
                print("âœ… èƒŒæ™¯æ’ç¨‹å™¨å·²åœæ­¢")
    except Exception as e:
        logger.error(f"âŒ é—œé–‰æœå‹™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        print(f"âŒ é—œé–‰æœå‹™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    logger.info("ğŸ æ‡‰ç”¨é—œé–‰å®Œæˆ")
    print("ğŸ æ‡‰ç”¨é—œé–‰å®Œæˆ")

# æ·»åŠ  CORS ä¸­é–“ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒæ‡‰è©²é™åˆ¶ç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åŒ…å«è·¯ç”±æ¨¡çµ„
from routes import main_router
from routes.schedule_routes_simple import router as schedule_router
app.include_router(main_router)
app.include_router(schedule_router, prefix="/api/schedule")

# API ç«¯é»é…ç½®
TRENDING_API_URL = os.getenv("TRENDING_API_URL", "http://localhost:8004")
SUMMARY_API_URL = os.getenv("SUMMARY_API_URL", "http://summary-api:8003")
OHLC_API_URL = os.getenv("OHLC_API_URL", "http://ohlc-api:8001")

# åˆå§‹åŒ–PostgreSQLæ•¸æ“šåº«æœå‹™
# å»¶é²åˆå§‹åŒ–ï¼Œé¿å…å•Ÿå‹•æ™‚é€£æ¥æ•¸æ“šåº«
post_record_service = None

def get_post_record_service():
    """ç²å–PostgreSQLæœå‹™å¯¦ä¾‹ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰"""
    global post_record_service
    if post_record_service is None:
        post_record_service = PostgreSQLPostRecordService()
    return post_record_service

def _extract_stock_from_keywords(keywords: str) -> dict:
    """å¾é—œéµè©ä¸­æå–è‚¡ç¥¨ä¿¡æ¯"""
    if not keywords:
        return None
    
    # è‚¡ç¥¨åç¨±åˆ°ä»£ç¢¼çš„æ˜ å°„
    stock_mapping = {
        "æ­£é”": "3149",
        "èŒ‚çŸ½": "2342", 
        "ç’°çƒæ™¶": "6488",
        "ä¸­ç¾æ™¶": "5483",
        "åˆæ™¶": "6182",
        "å˜‰æ™¶": "3016",
        "æ¼¢ç£Š": "3707",
        "ä¸–ç•Œ": "5347",
        "åŠ›ç©é›»": "6770",
        "å—äºç§‘": "2408",
        "è¯é‚¦é›»": "2344",
        "æ—ºå®": "2337",
        "ç¾¤è¯": "8299",
        "æ…§æ¦®": "2379",
        "ç‘æ˜±": "2379",
        "è¯è© ": "3034",
        "çŸ½åŠ›": "6415",
        "è­œç‘": "4966",
        "ç¥¥ç¢©": "5269",
        "ä¿¡é©Š": "5274",
        "å‰µæ„": "3443",
        "ä¸–èŠ¯": "3661",
        "æ™ºåŸ": "3035",
        "åŠ›æ—º": "3529",
        "å°å‹ç§‘": "3532",
        "å°ç©é›»": "2330",
        "è¯ç™¼ç§‘": "2454", 
        "é´»æµ·": "2317",
        "ä¸­è¯é›»": "2412",
        "å°å¡‘": "1301",
        "ä¸­é‹¼": "2002",
        "é•·æ¦®": "2603",
        "é™½æ˜": "2609",
        "è¬æµ·": "2615",
        "å¯Œé‚¦é‡‘": "2881"
    }
    
    # æª¢æŸ¥é—œéµè©ä¸­æ˜¯å¦åŒ…å«è‚¡ç¥¨åç¨±
    for stock_name, stock_code in stock_mapping.items():
        if stock_name in keywords:
            logger.info(f"ğŸ¯ åœ¨é—œéµè©ä¸­æ‰¾åˆ°è‚¡ç¥¨: {stock_name}({stock_code})")
            return {
                "name": stock_name,
                "code": stock_code
            }
    
    logger.info(f"âš ï¸ åœ¨é—œéµè©ä¸­æœªæ‰¾åˆ°å·²çŸ¥è‚¡ç¥¨: {keywords}")
    return None

class PostingRequest(BaseModel):
    stock_code: Optional[str] = None
    stock_name: Optional[str] = None
    
    @validator('stock_name', pre=True)
    def validate_stock_name(cls, v):
        """é©—è­‰ stock_name å­—æ®µï¼Œå¦‚æœæ˜¯å°è±¡å‰‡æå– company_name"""
        if isinstance(v, dict):
            # å¦‚æœæ˜¯å°è±¡ï¼Œæå– company_name å­—æ®µ
            company_name = v.get('company_name')
            if company_name:
                return company_name
            # å¦‚æœæ²’æœ‰ company_nameï¼Œå˜—è©¦å…¶ä»–å¯èƒ½çš„å­—æ®µ
            return v.get('name', v.get('stock_name', str(v)))
        return v
    kol_serial: Optional[str] = None
    kol_persona: str = "technical"
    content_style: str = "chart_analysis"
    target_audience: str = "active_traders"
    auto_post: bool = True
    post_to_thread: Optional[str] = None
    batch_mode: bool = False
    session_id: Optional[int] = None
    # å…§å®¹é•·åº¦è¨­å®š
    content_length: str = "medium"
    max_words: int = 1000
    # æ–°å¢æ•¸æ“šæºç›¸é—œæ¬„ä½
    data_sources: Optional[Dict[str, Any]] = None
    # æ–°èæ™‚é–“ç¯„åœè¨­å®š
    news_time_range: Optional[str] = "d2"
    explainability_config: Optional[Dict[str, Any]] = None
    news_config: Optional[Dict[str, Any]] = None
    # æ–°å¢è©±é¡Œç›¸é—œæ¬„ä½
    topic_title: Optional[str] = None
    topic_keywords: Optional[str] = None
    kol_nickname: Optional[str] = None
    # æ¨™ç±¤é…ç½®
    tags_config: Optional[Dict[str, Any]] = None
    # å…±äº« commodity tags (ç”¨æ–¼æ‰¹é‡ç”Ÿæˆ)
    shared_commodity_tags: Optional[List[Dict[str, Any]]] = None
    # ç†±é–€è©±é¡Œç›¸é—œæ¬„ä½
    topic_id: Optional[str] = None
    topic_title: Optional[str] = None
    # ç™¼æ–‡é¡å‹
    posting_type: Optional[str] = 'analysis'  # analysis/interaction
    # è§¸ç™¼å™¨é¡å‹
    trigger_type: Optional[str] = None
    
    # æ–°å¢ï¼šç™¾åˆ†æ¯”é…ç½®æ¬„ä½
    article_type_distribution: Optional[Dict[str, int]] = None
    content_length_distribution: Optional[Dict[str, int]] = None
    content_style_distribution: Optional[Dict[str, int]] = None
    analysis_depth_distribution: Optional[Dict[str, int]] = None
    include_charts: Optional[bool] = None
    include_risk_warning: Optional[bool] = None
    
    # æ–°å¢ï¼šç”Ÿæˆæ¨¡å¼å’Œå»¢æ–‡æƒ…æ„Ÿå‚¾å‘
    generation_mode: Optional[str] = "high_quality"
    trash_sentiment: Optional[str] = "positive"
    
    # æ–°å¢ï¼šæ–°èé€£çµé…ç½®
    enable_news_links: Optional[bool] = True
    news_max_links: Optional[int] = 5
    # æ–°å¢ï¼šç™¼æ–‡é¡å‹ (analysis/interaction)
    posting_type: Optional[str] = 'analysis'

class PostingResult(BaseModel):
    success: bool
    post_id: Optional[str] = None
    content: Optional[Dict] = None
    error: Optional[str] = None
    timestamp: datetime

class BatchPostRequest(BaseModel):
    session_id: int
    posts: List[Dict[str, Any]]
    batch_config: Dict[str, Any]
    data_sources: Optional[Dict[str, Any]] = None
    explainability_config: Optional[Dict[str, Any]] = None
    news_config: Optional[Dict[str, Any]] = None
    tags_config: Optional[Dict[str, Any]] = None  # æ–°å¢ï¼šæ¨™ç±¤é…ç½®
    posting_type: Optional[str] = 'analysis'  # æ–°å¢ï¼šç™¼æ–‡é¡å‹ (analysis/interaction)

class BatchPostResponse(BaseModel):
    success: bool
    post_id: Optional[str] = None
    content: Optional[Dict] = None
    error: Optional[str] = None
    timestamp: str
    progress: Optional[Dict[str, Any]] = None

class AutoPostingConfig(BaseModel):
    enabled: bool = True
    interval_minutes: int = 60
    max_posts_per_day: int = 10
    kol_personas: List[str] = ["technical", "fundamental", "news_driven"]

@app.post("/post/auto", response_model=PostingResult)
async def auto_post_content(background_tasks: BackgroundTasks, config: AutoPostingConfig):
    """è‡ªå‹•ç™¼æ–‡ - æ ¹æ“šç†±é–€è©±é¡Œè‡ªå‹•ç”Ÿæˆå…§å®¹ä¸¦ç™¼æ–‡"""
    
    try:
        # 1. ç²å–ç†±é–€è©±é¡Œ
        trending_response = requests.get(f"{TRENDING_API_URL}/trending", params={"limit": 5})
        trending_response.raise_for_status()
        trending_topics = trending_response.json()
        
        if not trending_topics.get("topics"):
            return PostingResult(
                success=False,
                error="æ²’æœ‰æ‰¾åˆ°ç†±é–€è©±é¡Œ",
                timestamp=datetime.now()
            )
        
        # 2. é¸æ“‡ç¬¬ä¸€å€‹ç†±é–€è©±é¡Œ
        topic = trending_topics["topics"][0]
        stock_id = topic["stock_ids"][0] if topic["stock_ids"] else "2330"
        
        # 3. ç²å–ç›¸é—œæ–°èç´ æ
        news_response = requests.get(f"{TRENDING_API_URL}/news/stock/{stock_id}", params={"limit": 3})
        news_items = []
        if news_response.status_code == 200:
            news_items = news_response.json().get("news", [])
        
        # 4. ç”ŸæˆKOLå…§å®¹
        content_request = {
            "stock_id": stock_id,
            "kol_persona": config.kol_personas[0],
            "content_style": "chart_analysis",
            "target_audience": "active_traders"
        }
        
        summary_response = requests.post(f"{SUMMARY_API_URL}/generate-kol-content", json=content_request)
        summary_response.raise_for_status()
        kol_content = summary_response.json()
        
        # 5. æ•´åˆæ–°èç´ æåˆ°å…§å®¹ä¸­
        enhanced_content = enhance_content_with_news(kol_content, topic, news_items)
        
        # 6. ç™¼æ–‡åˆ°æŒ‡å®šå¹³å°
        if config.enabled:
            background_tasks.add_task(post_to_platform, enhanced_content, topic)
        
        return PostingResult(
            success=True,
            post_id=f"post_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            content=enhanced_content,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        return PostingResult(
            success=False,
            error=str(e),
            timestamp=datetime.now()
        )

@app.post("/api/simple-mode/generate-batch")
async def simple_mode_generate_batch(request: dict):
    """ç°¡æ˜“æ¨¡å¼/å»¢æ–‡æ¨¡å¼æ‰¹æ¬¡ç”Ÿæˆ"""
    try:
        print(f"ğŸ² ç°¡æ˜“æ¨¡å¼æ‰¹æ¬¡ç”Ÿæˆé–‹å§‹: {request}")
        
        stock_codes = request.get('stock_codes', [])
        stock_names = request.get('stock_names', [])
        session_id = request.get('session_id')
        use_random_kol = request.get('use_random_kol', False)
        trash_mode = request.get('trash_mode', False)
        trash_sentiment = request.get('trash_sentiment', 'positive')
        
        if not stock_codes:
            return {"success": False, "error": "æ²’æœ‰è‚¡ç¥¨ä»£ç¢¼"}
        
        results = []
        
        for i, stock_code in enumerate(stock_codes):
            stock_name = stock_names[i] if i < len(stock_names) else stock_code
            
            # éš¨æ©Ÿé¸æ“‡KOL
            if use_random_kol:
                kol_serial = random.choice(['200', '201', '202', '203', '204', '205', '206', '207', '208'])
            else:
                kol_serial = '200'  # é è¨­KOL
            
            # ç”Ÿæˆå…§å®¹
            if trash_mode:
                # å»¢æ–‡æ¨¡å¼
                title = f"{stock_name} {random.choice(['çˆ†äº†', 'å™´äº†', 'å´©äº†', 'ç©©äº†'])}ï¼"
                content = f"{stock_name}ä»Šå¤©{random.choice(['è¶…å¼·', 'è¶…å¼±', 'è¶…ç©©', 'è¶…çŒ›'])}ï¼Œ{random.choice(['è²·çˆ†', 'è³£çˆ†', 'è§€æœ›', 'åŠ ç¢¼'])}å°±å°äº†ï¼"
            else:
                # ç°¡æ˜“æ¨¡å¼
                title = f"{stock_name} æŠ€è¡“åˆ†æ"
                content = f"{stock_name}è¿‘æœŸè¡¨ç¾{random.choice(['å¼·å‹¢', 'å¼±å‹¢', 'ç©©å®š'])}ï¼ŒæŠ€è¡“é¢é¡¯ç¤º{random.choice(['çªç ´', 'å›èª¿', 'æ•´ç†'])}ï¼Œå»ºè­°{random.choice(['é€¢ä½å¸ƒå±€', 'è§€æœ›', 'æ¸›ç¢¼'])}ã€‚"
            
            results.append({
                "stock_code": stock_code,
                "stock_name": stock_name,
                "kol_serial": kol_serial,
                "title": title,
                "content": content,
                "session_id": session_id
            })
        
        return {
            "success": True,
            "data": {
                "posts": results,
                "total_count": len(results),
                "mode": "trash" if trash_mode else "simple"
            }
        }
        
    except Exception as e:
        print(f"âŒ ç°¡æ˜“æ¨¡å¼æ‰¹æ¬¡ç”Ÿæˆå¤±æ•—: {e}")
        return {"success": False, "error": str(e)}

@app.post("/post/simple")
async def simple_post_content(request: PostingRequest):
    """ç°¡åŒ–ç‰ˆè²¼æ–‡ç”Ÿæˆï¼Œä½¿ç”¨ä¿®å¾©å¾Œçš„ ContentGenerator"""
    try:
        logger.info(f"ğŸš€ ç°¡åŒ–æ¨¡å¼ï¼šé–‹å§‹ç”Ÿæˆè²¼æ–‡")
        logger.info(f"ğŸ“ è«‹æ±‚åƒæ•¸: topic_title={request.topic_title}, topic_keywords={request.topic_keywords}, kol_serial={request.kol_serial}")
        
        # åŸºæœ¬åƒæ•¸
        stock_id = request.stock_code or "2330"
        stock_name = request.stock_name or "å°ç©é›»"
        kol_serial = int(request.kol_serial) if request.kol_serial else 200
        session_id = request.session_id or 1  # ä½¿ç”¨ç°¡å–®æ•¸å­— 1, 2, 3...
        
        logger.info(f"ğŸ“Š åŸºæœ¬åƒæ•¸: stock_id={stock_id}, stock_name={stock_name}, kol_serial={kol_serial}")
        
        # ä½¿ç”¨ä¿®å¾©å¾Œçš„ ContentGenerator
        try:
            logger.info(f"ğŸ”§ å˜—è©¦å°å…¥ ContentGenerator...")
            from src.services.content.content_generator import ContentGenerator, ContentRequest
            logger.info(f"âœ… ContentGenerator å°å…¥æˆåŠŸ")
            
            # å‰µå»ºå…§å®¹ç”Ÿæˆå™¨
            logger.info(f"ğŸ”§ å‰µå»º ContentGenerator å¯¦ä¾‹...")
            content_generator = ContentGenerator()
            logger.info(f"âœ… ContentGenerator å¯¦ä¾‹å‰µå»ºæˆåŠŸ")
            
            # ğŸ” æª¢æŸ¥KOLå€‹äººåŒ–ç®¡ç†å™¨æ˜¯å¦è¼‰å…¥
            if hasattr(content_generator, 'kol_personalization_manager') and content_generator.kol_personalization_manager:
                logger.info(f"âœ… KOLå€‹äººåŒ–ç®¡ç†å™¨å·²è¼‰å…¥")
                # æ¸¬è©¦KOLå€‹äººåŒ–ç®¡ç†å™¨
                try:
                    test_nickname = content_generator.kol_personalization_manager.get_kol_nickname(str(kol_serial))
                    test_persona = content_generator.kol_personalization_manager.get_kol_persona(str(kol_serial))
                    logger.info(f"ğŸ¯ KOL {kol_serial} çœŸå¯¦è³‡æ–™: æš±ç¨±={test_nickname}, äººè¨­={test_persona}")
                except Exception as e:
                    logger.warning(f"âš ï¸ KOLå€‹äººåŒ–ç®¡ç†å™¨æ¸¬è©¦å¤±æ•—: {e}")
            else:
                logger.warning(f"âŒ KOLå€‹äººåŒ–ç®¡ç†å™¨æœªè¼‰å…¥æˆ–ä¸å¯ç”¨")
            
            # å¾ topic_keywords ä¸­æå–è‚¡ç¥¨ä¿¡æ¯
            extracted_stock_info = _extract_stock_from_keywords(request.topic_keywords)
            if extracted_stock_info:
                stock_name = extracted_stock_info['name']
                stock_id = extracted_stock_info['code']
                logger.info(f"ğŸ¯ å¾é—œéµè©æå–è‚¡ç¥¨ä¿¡æ¯: {stock_name}({stock_id})")
            
            # å‰µå»ºå…§å®¹è«‹æ±‚
            content_request = ContentRequest(
                topic_title=request.topic_title or f"{stock_name}ç›¤å¾Œåˆ†æ",
                topic_keywords=request.topic_keywords or f"{stock_name}, æŠ€è¡“åˆ†æ",
                kol_persona=request.kol_persona or "æŠ€è¡“æ´¾",
                kol_nickname=request.kol_nickname or f"KOL-{kol_serial}",
                content_type=request.content_style or "investment",
                target_audience=request.target_audience or "active_traders"
            )
            
            logger.info(f"ğŸ“ å…§å®¹è«‹æ±‚: topic_title={content_request.topic_title}, topic_keywords={content_request.topic_keywords}")
            
            # ç”Ÿæˆå…§å®¹
            logger.info(f"ğŸ”„ é–‹å§‹ç”Ÿæˆå…§å®¹...")
            generated_content = content_generator.generate_complete_content(content_request)
            
            if generated_content.success:
                simple_content = {
                    "title": generated_content.title,
                    "content": generated_content.content,
                    "stock_code": stock_id,
                    "stock_name": stock_name,
                    "kol_serial": kol_serial,
                    "session_id": session_id,
                    "post_id": f"simple_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "status": "draft",
                    "created_at": datetime.now().isoformat()
                }
                logger.info(f"âœ… ä½¿ç”¨ ContentGenerator ç”Ÿæˆå…§å®¹æˆåŠŸ")
                logger.info(f"ğŸ“ ç”Ÿæˆæ¨™é¡Œ: {generated_content.title}")
            else:
                raise Exception(f"ContentGenerator ç”Ÿæˆå¤±æ•—: {generated_content.error_message}")
                
        except Exception as gen_error:
            logger.warning(f"âš ï¸ ContentGenerator å¤±æ•—ï¼Œä½¿ç”¨ç°¡åŒ–é‚è¼¯: {gen_error}")
            logger.error(f"âŒ ContentGenerator éŒ¯èª¤è©³æƒ…: {str(gen_error)}")
            import traceback
            logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
            
            # Fallback åˆ°ç°¡åŒ–é‚è¼¯
            simple_content = {
                "title": f"{stock_name}({stock_id}) - æŠ€è¡“åˆ†æ",
                "content": f"ä»Šæ—¥{stock_name}è¡¨ç¾å¦‚ä½•ï¼Ÿè®“æˆ‘å€‘ä¾†çœ‹çœ‹æŠ€è¡“é¢çš„ç‹€æ³...",
                "stock_code": stock_id,
                "stock_name": stock_name,
                "kol_serial": kol_serial,
                "session_id": session_id,
                "post_id": f"simple_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "status": "pending_review",
                "created_at": datetime.now().isoformat()
            }
            logger.info(f"ğŸ”„ ä½¿ç”¨ç°¡åŒ–é‚è¼¯ç”Ÿæˆå…§å®¹")
        
        # å˜—è©¦ä¿å­˜åˆ°æ•¸æ“šåº«ï¼ˆä¸ä½¿ç”¨ CommodityTagï¼‰
        try:
            logger.info(f"ğŸ’¾ é–‹å§‹ä¿å­˜åˆ°æ•¸æ“šåº«...")
            from postgresql_service import PostgreSQLPostRecordService
            post_service = PostgreSQLPostRecordService()
            
            # ç²å– KOL æš±ç¨±
            kol_nickname = f"KOL-{kol_serial}"  # é»˜èªåç¨±
            try:
                from kol_service import kol_service
                kol_data = kol_service.get_kol_info(str(kol_serial))
                if kol_data and 'nickname' in kol_data:
                    kol_nickname = kol_data['nickname']
                    logger.info(f"ğŸ‘¤ ç²å– KOL æš±ç¨±: {kol_nickname}")
            except Exception as kol_error:
                logger.warning(f"âš ï¸ ç²å– KOL ä¿¡æ¯å¤±æ•—ï¼Œä½¿ç”¨é»˜èªåç¨±: {kol_error}")
            
            # å‰µå»ºç°¡åŒ–çš„è²¼æ–‡è¨˜éŒ„ï¼Œä¸åŒ…å« commodity_tags
            logger.info(f"ğŸ“ å‰µå»ºè²¼æ–‡è¨˜éŒ„: stock_code={stock_id}, stock_name={stock_name}, kol_serial={kol_serial}")
            post_record = post_service.create_post_record_simple(
                stock_code=stock_id,
                stock_name=stock_name,
                kol_serial=str(kol_serial),
                kol_nickname=kol_nickname,
                session_id=session_id
            )
            
            simple_content["database_saved"] = True
            simple_content["database_post_id"] = post_record.id if post_record else None
            logger.info(f"âœ… ç°¡åŒ–è²¼æ–‡å·²ä¿å­˜åˆ°æ•¸æ“šåº«: {simple_content['database_post_id']}")
            
        except Exception as db_error:
            logger.error(f"âš ï¸ æ•¸æ“šåº«ä¿å­˜å¤±æ•—ï¼Œä½†å…§å®¹ç”ŸæˆæˆåŠŸ: {db_error}")
            logger.error(f"âŒ æ•¸æ“šåº«éŒ¯èª¤è©³æƒ…: {str(db_error)}")
            import traceback
            logger.error(f"ğŸ“‹ æ•¸æ“šåº«éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
            simple_content["database_saved"] = False
            simple_content["database_error"] = str(db_error)
        
        logger.info(f"âœ… ç°¡åŒ–è²¼æ–‡ç”Ÿæˆå®Œæˆ")
        logger.info(f"ğŸ“Š æœ€çµ‚çµæœ: title={simple_content.get('title', 'N/A')}, stock_name={simple_content.get('stock_name', 'N/A')}")
        
        return {
            "success": True,
            "post_id": simple_content["post_id"],
            "content": simple_content,
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        import traceback
        logger.error(f"âŒ ç°¡åŒ–æ¨¡å¼éŒ¯èª¤: {e}")
        logger.error(f"âŒ éŒ¯èª¤è©³æƒ…: {str(e)}")
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now()
        }

@app.post("/post/manual", response_model=PostingResult)
async def manual_post_content(request: PostingRequest):
    """æ‰‹å‹•ç™¼æ–‡ - æŒ‡å®šè‚¡ç¥¨å’ŒKOLé¢¨æ ¼"""
    print("ğŸš€ğŸš€ğŸš€ manual_post_content å‡½æ•¸è¢«èª¿ç”¨ï¼")
    print(f"ğŸš€ğŸš€ğŸš€ è«‹æ±‚åƒæ•¸: stock_code={request.stock_code}, kol_serial={request.kol_serial}")
    print(f"ğŸš€ğŸš€ğŸš€ è«‹æ±‚æ™‚é–“: {datetime.now()}")
    
    # åˆå§‹åŒ– topic_id å’Œ topic_title è®Šé‡
    topic_id = request.topic_id or None
    topic_title = request.topic_title or None
    
    print(f"ğŸš€ é–‹å§‹æ‰‹å‹•ç™¼æ–‡ç”Ÿæˆ - è«‹æ±‚åƒæ•¸: {request}")
    print(f"ğŸ“ å…§å®¹é•·åº¦è¨­å®š: content_length={request.content_length}, max_words={request.max_words}")
    
    # æ·»åŠ èª¿è©¦ä¿¡æ¯
    print(f"ğŸ” å¾Œç«¯èª¿è©¦ - æ¥æ”¶åˆ°çš„åƒæ•¸:")
    print(f"  - tags_config: {request.tags_config}")
    print(f"  - topic_tags: {request.tags_config.get('topic_tags', {}) if request.tags_config else {}}")
    print(f"  - mixed_mode: {request.tags_config.get('topic_tags', {}).get('mixed_mode', False) if request.tags_config else False}")
    print(f"  - topic_id: {topic_id}")
    print(f"  - topic_title: {topic_title}")
    
    try:
        # å¦‚æœå‰ç«¯æŒ‡å®šäº†è‚¡ç¥¨ä»£è™Ÿï¼Œä½¿ç”¨æŒ‡å®šçš„è‚¡ç¥¨
        if request.stock_code:
            stock_id = request.stock_code
            # ä½¿ç”¨å‰ç«¯å‚³éçš„è‚¡ç¥¨åç¨±ï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨é»˜èªæ ¼å¼
            stock_name = request.stock_name or f"è‚¡ç¥¨{stock_id}"
            print(f"ğŸ“Š ä½¿ç”¨æŒ‡å®šè‚¡ç¥¨: {stock_name}({stock_id})")
        else:
            # å¦å‰‡ç²å–ç†±é–€è‚¡ç¥¨
            print("ğŸ“ˆ ç²å–ç†±é–€è‚¡ç¥¨...")
            try:
                trending_stocks_response = requests.get(f"{TRENDING_API_URL}/trending/stocks", params={"limit": 10})
                trending_stocks_response.raise_for_status()
                trending_stocks = trending_stocks_response.json()
                
                if not trending_stocks.get("stocks"):
                    print("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç†±é–€è‚¡ç¥¨")
                    return PostingResult(
                        success=False,
                        error="æ²’æœ‰æ‰¾åˆ°ç†±é–€è‚¡ç¥¨",
                        timestamp=datetime.now()
                    )
                
                # é¸æ“‡ç¬¬ä¸€å€‹ç†±é–€è‚¡ç¥¨
                stock = trending_stocks["stocks"][0]
                stock_id = stock["stock_id"]
                stock_name = stock.get("stock_name", f"è‚¡ç¥¨{stock_id}")
                print(f"ğŸ“ˆ é¸æ“‡ç†±é–€è‚¡ç¥¨: {stock_name}({stock_id})")
            except Exception as e:
                print(f"âš ï¸ ç²å–ç†±é–€è‚¡ç¥¨å¤±æ•—: {e}")
                stock_id = "2330"
                stock_name = "å°ç©é›»"
                print(f"ğŸ“ˆ ä½¿ç”¨é è¨­è‚¡ç¥¨: {stock_name}({stock_id})")
        
        # print(f"âœ… è‚¡ç¥¨ç¢ºå®š: {stock_name}({stock_id})")
        
        # å°å…¥æ–°çš„æœå‹™
        print("ğŸ”§ å°å…¥æœå‹™æ¨¡çµ„...")
        try:
            from serper_integration import serper_service
            from smart_data_source_assigner import smart_assigner, KOLProfile, StockProfile
            from publish_service import publish_service
            # print("âœ… æœå‹™æ¨¡çµ„å°å…¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æœå‹™æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
            raise
        
        # 1. æ™ºèƒ½æ•¸æ“šæºåˆ†é…
        # print(f"ğŸ¯ é–‹å§‹æ™ºèƒ½æ•¸æ“šæºåˆ†é…: {stock_id}, {request.kol_persona}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å‰ç«¯å‚³ä¾†çš„æ•¸æ“šæºé…ç½®
        if request.data_sources:
            print(f"ğŸ“Š ä½¿ç”¨å‰ç«¯æ•¸æ“šæºé…ç½®: {request.data_sources}")
            # ä½¿ç”¨å‰ç«¯é…ç½®çš„æ•¸æ“šæº
            primary_sources = []
            if request.data_sources.get('stock_price_api'):
                primary_sources.append('ohlc_api')
            if request.data_sources.get('monthly_revenue_api'):
                primary_sources.append('revenue_api')
            if request.data_sources.get('financial_report_api'):
                primary_sources.append('financial_api')
            if request.data_sources.get('news_sources', []):
                primary_sources.append('serper_api')
            
            # å‰µå»ºæ¨¡æ“¬çš„æ•¸æ“šæºåˆ†é…çµæœ
            from smart_data_source_assigner import DataSourceAssignment, DataSourceType
            data_source_assignment = DataSourceAssignment(
                primary_sources=[DataSourceType(source) for source in primary_sources if hasattr(DataSourceType, source)],
                secondary_sources=[],
                excluded_sources=[],
                assignment_reason=f"åŸºæ–¼å‰ç«¯é…ç½®: {', '.join(primary_sources)}",
                confidence_score=0.9
            )
        else:
            # ä½¿ç”¨æ™ºèƒ½åˆ†é…é‚è¼¯
            kol_profile = KOLProfile(
                serial=int(request.kol_serial) if request.kol_serial else 1,
                nickname=f"KOL-{request.kol_serial or '1'}",
                persona=request.kol_persona,
                expertise_areas=[request.kol_persona],
                content_style=request.content_style,
                target_audience=request.target_audience
            )
            
            stock_profile = StockProfile(
                stock_code=stock_id,
                stock_name=stock_name,
                industry="ç§‘æŠ€",  # å¯ä»¥å¾APIç²å–
                market_cap="medium",  # å¯ä»¥å¾APIç²å–
                volatility="medium",  # å¯ä»¥å¾APIç²å–
                news_frequency="medium"  # å¯ä»¥å¾APIç²å–
            )
            
            # åˆ†é…æ•¸æ“šæº
            data_source_assignment = smart_assigner.assign_data_sources(kol_profile, stock_profile)
        
        # print(f"âœ… æ•¸æ“šæºåˆ†é…å®Œæˆ: {data_source_assignment.assignment_reason}")
        print(f"ğŸ“Š ä¸»è¦æ•¸æ“šæº: {[s.value for s in data_source_assignment.primary_sources]}")
        
        # 2. ç²å–å³æ™‚è‚¡åƒ¹æ•¸æ“šå’Œé©—è­‰è§¸ç™¼å™¨é¡å‹
        print(f"ğŸ” é–‹å§‹ç²å–å³æ™‚è‚¡åƒ¹æ•¸æ“š: {stock_id}")
        actual_price_data = None
        
        try:
            # ğŸ”¥ ä½¿ç”¨ç›¤ä¸­è§¸ç™¼å™¨ç²å–å³æ™‚è‚¡åƒ¹æ•¸æ“š
            print(f"ğŸ“Š èª¿ç”¨ç›¤ä¸­è§¸ç™¼å™¨ç²å–å³æ™‚è‚¡åƒ¹æ•¸æ“š...")
            
            # æ§‹å»ºç›¤ä¸­è§¸ç™¼å™¨è«‹æ±‚ - ä½¿ç”¨æ­£ç¢ºçš„ StockCalculation endpoint
            trigger_config = {
                "endpoint": "https://asterisk-chipsapi.cmoney.tw/AdditionInformationRevisit/api/GetAll/StockCalculation",
                "processing": [
                    {"ParameterJson": f'{{"TargetPropertyNamePath": ["CommKey"], "Value": "{stock_id}"}}', "ProcessType": "EqualValueFilter"},
                    {"ProcessType": "TakeCount", "ParameterJson": "{\"Count\":1}"}
                ]
            }
            
            # ç›´æ¥èª¿ç”¨ CMoney API ç²å–å³æ™‚è‚¡åƒ¹æ•¸æ“š
            import httpx
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    "https://asterisk-chipsapi.cmoney.tw/AdditionInformationRevisit/api/GetAll/StockCalculation",
                    json=trigger_config
                )
                
                if response.status_code == 200:
                    trigger_data = response.json()
                    if trigger_data and len(trigger_data) > 0:
                        # è§£æå³æ™‚è‚¡åƒ¹æ•¸æ“š
                        price_data = trigger_data
                        if price_data and len(price_data) > 0:
                            # æ•¸æ“šæ ¼å¼: [äº¤æ˜“æ™‚é–“,å‚³è¼¸åºè™Ÿ,å…§å¤–ç›¤æ——æ¨™,å³æ™‚æˆäº¤åƒ¹,å³æ™‚æˆäº¤é‡,æœ€ä½åƒ¹,æœ€é«˜åƒ¹,æ¨™çš„,æ¼²è·Œ,æ¼²è·Œå¹…,ç´¯è¨ˆæˆäº¤ç¸½é¡,ç´¯è¨ˆæˆäº¤é‡,é–‹ç›¤åƒ¹]
                            stock_data = price_data[0]  # å–ç¬¬ä¸€ç­†æ•¸æ“š
                            
                            actual_price_data = {
                                'current_price': float(stock_data[3]) if len(stock_data) > 3 else 0,  # å³æ™‚æˆäº¤åƒ¹
                                'change_amount': float(stock_data[8]) if len(stock_data) > 8 else 0,  # æ¼²è·Œ
                                'change_percentage': float(stock_data[9]) if len(stock_data) > 9 else 0,  # æ¼²è·Œå¹…
                                'current_volume': int(stock_data[4]) if len(stock_data) > 4 else 0,  # å³æ™‚æˆäº¤é‡
                                'total_volume': int(stock_data[11]) if len(stock_data) > 11 else 0,  # ç´¯è¨ˆæˆäº¤é‡
                                'high_price': float(stock_data[5]) if len(stock_data) > 5 else 0,  # æœ€é«˜åƒ¹
                                'low_price': float(stock_data[6]) if len(stock_data) > 6 else 0,  # æœ€ä½åƒ¹
                                'open_price': float(stock_data[12]) if len(stock_data) > 12 else 0,  # é–‹ç›¤åƒ¹
                                'is_limit_up': abs(float(stock_data[9])) >= 9.5 and float(stock_data[9]) > 0 if len(stock_data) > 9 else False,
                                'is_limit_down': abs(float(stock_data[9])) >= 9.5 and float(stock_data[9]) < 0 if len(stock_data) > 9 else False,
                                'volume_ratio': 1.0,  # éœ€è¦è¨ˆç®—
                                'raw_data': stock_data,  # ğŸ”¥ ä¿å­˜åŸå§‹ JSON æ•¸æ“š
                                'column_names': ['äº¤æ˜“æ™‚é–“', 'å‚³è¼¸åºè™Ÿ', 'å…§å¤–ç›¤æ——æ¨™', 'å³æ™‚æˆäº¤åƒ¹', 'å³æ™‚æˆäº¤é‡', 'æœ€ä½åƒ¹', 'æœ€é«˜åƒ¹', 'æ¨™çš„', 'æ¼²è·Œ', 'æ¼²è·Œå¹…', 'ç´¯è¨ˆæˆäº¤ç¸½é¡', 'ç´¯è¨ˆæˆäº¤é‡', 'é–‹ç›¤åƒ¹'],  # æ–°å¢ï¼šcolumn names
                                'avg_volume': 0  # éœ€è¦å¾å…¶ä»–APIç²å–
                            }
                            
                            print(f"âœ… ç²å–å³æ™‚è‚¡åƒ¹æ•¸æ“šæˆåŠŸ:")
                            print(f"   - ç•¶å‰åƒ¹æ ¼: {actual_price_data['current_price']}")
                            print(f"   - æ¼²è·Œ: {actual_price_data['change_amount']}")
                            print(f"   - æ¼²è·Œå¹…: {actual_price_data['change_percentage']}%")
                            print(f"   - æ˜¯å¦æ¼²åœ: {actual_price_data['is_limit_up']}")
                            print(f"   - æ˜¯å¦è·Œåœ: {actual_price_data['is_limit_down']}")
                        else:
                            print(f"âš ï¸ CMoney API è¿”å›ç©ºæ•¸æ“š")
                    else:
                        print(f"âš ï¸ CMoney API è«‹æ±‚å¤±æ•—: {trigger_data}")
                else:
                    print(f"âš ï¸ CMoney API èª¿ç”¨å¤±æ•—: HTTP {response.status_code}")
                    
        except Exception as e:
            print(f"âš ï¸ ç²å–å³æ™‚è‚¡åƒ¹æ•¸æ“šå¤±æ•—: {e}")
            import traceback
            print(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        
        # 3. è‚¡åƒ¹é©—è­‰å’Œæ–°èé—œéµå­—ä¿®æ­£
        corrected_keywords = None
        if actual_price_data:
            try:
                # å°å…¥è‚¡åƒ¹é©—è­‰å™¨
                from stock_price_validator import stock_price_validator
                
                # é©—è­‰è§¸ç™¼å™¨é¡å‹
                trigger_type = getattr(request, 'trigger_type', 'intraday_limit_up')
                is_valid, validation_message, suggested_trigger = stock_price_validator.validate_trigger_type(
                    stock_code=stock_id,
                    stock_name=stock_name,
                    trigger_type=trigger_type,
                    actual_price_data=actual_price_data
                )
                
                print(f"ğŸ” è§¸ç™¼å™¨é©—è­‰çµæœ: {validation_message}")
                if not is_valid and suggested_trigger:
                    print(f"âš ï¸ å»ºè­°ä½¿ç”¨è§¸ç™¼å™¨é¡å‹: {suggested_trigger}")
                    # å¯ä»¥é¸æ“‡æ˜¯å¦è‡ªå‹•ä¿®æ­£è§¸ç™¼å™¨é¡å‹
                    # trigger_type = suggested_trigger
                
                # æ ¹æ“šå¯¦éš›è‚¡åƒ¹è¡¨ç¾ç²å–æ­£ç¢ºçš„æ–°èé—œéµå­—
                corrected_keywords = stock_price_validator.get_corrected_news_keywords(
                    stock_code=stock_id,
                    stock_name=stock_name,
                    trigger_type=trigger_type,
                    actual_price_data=actual_price_data
                )
                
            except Exception as e:
                print(f"âš ï¸ è‚¡åƒ¹é©—è­‰å¤±æ•—ï¼Œä½¿ç”¨é è¨­è¨­å®š: {e}")
                corrected_keywords = None
        else:
            print(f"âš ï¸ ç„¡æ³•ç²å–å³æ™‚è‚¡åƒ¹æ•¸æ“šï¼Œè·³éé©—è­‰")
        
        # 4. ç²å–Serperæ–°èæ•¸æ“š - ä½¿ç”¨ä¿®æ­£å¾Œçš„é—œéµå­—
        print(f"ğŸ” é–‹å§‹ç²å–Serperæ–°èæ•¸æ“š: {stock_id}")
        try:
            # æå–æ–°èæœå°‹é—œéµå­—é…ç½®
            search_keywords = None
            time_range = "d2"  # é è¨­æ™‚é–“ç¯„åœ
            
            # å„ªå…ˆä½¿ç”¨ä¿®æ­£å¾Œçš„é—œéµå­—
            if corrected_keywords:
                search_keywords = corrected_keywords
                print(f"ğŸ“ ä½¿ç”¨ä¿®æ­£å¾Œçš„æ–°èé—œéµå­—: {len(search_keywords)} å€‹é—œéµå­—")
                for kw in search_keywords:
                    print(f"   - {kw.get('type', 'custom')}: {kw.get('keyword', '')}")
            elif request.news_config:
                # æå–æœå°‹é—œéµå­—
                if request.news_config.get('search_keywords'):
                    search_keywords = request.news_config.get('search_keywords')
                    print(f"ğŸ“ ä½¿ç”¨å‰ç«¯æ–°èé—œéµå­—é…ç½®: {len(search_keywords)} å€‹é—œéµå­—")
                    for kw in search_keywords:
                        print(f"   - {kw.get('type', 'custom')}: {kw.get('keyword', '')}")
                
                # æå–æ™‚é–“ç¯„åœè¨­å®š
                if request.news_config.get('time_range'):
                    time_range = request.news_config.get('time_range')
                    print(f"â° ä½¿ç”¨å‰ç«¯æ™‚é–“ç¯„åœè¨­å®š: {time_range}")
                elif request.news_time_range:
                    time_range = request.news_time_range
                    print(f"â° ä½¿ç”¨è«‹æ±‚æ™‚é–“ç¯„åœè¨­å®š: {time_range}")
                
                # ğŸ”¥ ä¿®å¾©ï¼šæå–æ–°èé€£çµè¨­å®š
                if 'enable_news_links' in request.news_config:
                    request.enable_news_links = request.news_config.get('enable_news_links', True)
                    print(f"ğŸ”— ä½¿ç”¨å‰ç«¯æ–°èé€£çµè¨­å®š: {request.enable_news_links}")
                
                # ğŸ”¥ ä¿®å¾©ï¼šæå–æ–°èæ•¸é‡è¨­å®š
                if 'max_links' in request.news_config:
                    request.news_max_links = request.news_config.get('max_links', 5)
                    print(f"ğŸ“Š ä½¿ç”¨å‰ç«¯æ–°èæ•¸é‡è¨­å®š: {request.news_max_links}")
            else:
                print("ğŸ“ ä½¿ç”¨é è¨­æ–°èæœå°‹é—œéµå­—")
            
            serper_analysis = serper_service.get_comprehensive_stock_analysis(
                stock_id, 
                stock_name, 
                search_keywords=search_keywords,
                time_range=time_range,
                trigger_type=request.trigger_type
            )
            news_items = serper_analysis.get('news_items', [])
            limit_up_analysis = serper_analysis.get('limit_up_analysis', {})
            # print(f"âœ… Serperåˆ†æå®Œæˆ: æ‰¾åˆ° {len(news_items)} å‰‡æ–°è")
        except Exception as e:
            print(f"âš ï¸ Serperåˆ†æå¤±æ•—: {e}")
            serper_analysis = {'news_items': [], 'limit_up_analysis': {}}
            news_items = []
            limit_up_analysis = {}
        
        # 3. ç”ŸæˆKOLå…§å®¹ - æª¢æŸ¥ç™¼æ–‡é¡å‹
        print(f"âœï¸ é–‹å§‹ç”ŸæˆKOLå…§å®¹: {stock_id}, {request.kol_persona}")
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºäº’å‹•ç™¼å•é¡å‹
        posting_type = getattr(request, 'posting_type', 'analysis')
        print(f"ğŸ“ ç™¼æ–‡é¡å‹: {posting_type}")
        
        if posting_type == 'interaction':
            print("ğŸ¯ ä½¿ç”¨äº’å‹•ç™¼å•æ·å¾‘ç”Ÿæˆå…§å®¹ï¼ˆè·³éå€‹äººåŒ–æ¨¡çµ„ï¼‰")
            
            # ä½¿ç”¨äº’å‹•å…§å®¹ç”Ÿæˆå™¨
            kol_content = generate_interaction_content(
                stock_id=stock_id,
                stock_name=stock_name,
                include_questions=True,
                include_emoji=True,
                include_hashtag=True
            )
            
            print(f"âœ… äº’å‹•ç™¼å•å…§å®¹ç”Ÿæˆå®Œæˆ: {kol_content['title']} - {kol_content['content']}")
            print(f"ğŸ“Š å…§å®¹é•·åº¦: {kol_content['content_length']} å­—")
            print(f"ğŸš« è·³éå€‹äººåŒ–æ¨¡çµ„: {kol_content['skipped_personalization']}")
            
        else:
            print("ğŸ“Š ä½¿ç”¨æ­£å¸¸åˆ†ææµç¨‹ç”Ÿæˆå…§å®¹")
            
            try:
                # å¼·åˆ¶ä½¿ç”¨æ–°èåˆ†æAgent
                if news_items:
                    print(f"ğŸ¤– å¼·åˆ¶ä½¿ç”¨æ–°èåˆ†æAgentåˆ†æ {len(news_items)} å‰‡æ–°è")
                from news_analysis_agent import NewsAnalysisAgent
                
                # ç²å–KOLé…ç½®ä¿¡æ¯
                kol_nickname = f"KOL-{request.kol_serial}" if request.kol_serial else "åˆ†æå¸«"
                kol_persona = request.kol_persona or "technical"  # åˆå§‹åŒ– kol_persona
                kol_config = {}
                
                # å˜—è©¦å¾KOLæœå‹™ç²å–è©³ç´°é…ç½®
                try:
                    print(f"ğŸ” é–‹å§‹ç²å–KOLé…ç½®: serial={request.kol_serial}")
                    from kol_service import kol_service
                    kol_data = kol_service.get_kol_info(str(request.kol_serial)) if request.kol_serial else None
                    print(f"ğŸ” KOLæ•¸æ“šæŸ¥è©¢çµæœ: {kol_data is not None}")
                    if kol_data:
                        print(f"ğŸ” KOLæ•¸æ“šå…§å®¹: {list(kol_data.keys())}")
                        kol_nickname = kol_data.get('nickname', kol_nickname)
                        # æ§‹å»ºKOLé…ç½®å­—å…¸
                        kol_config = {
                            'tone_style': kol_data.get('tone_style', 'å°ˆæ¥­å‹å–„'),
                            'common_words': kol_data.get('common_terms', ''),
                            'casual_words': kol_data.get('colloquial_terms', ''),
                            'typing_habit': kol_data.get('typing_habit', 'æ­£å¸¸æ¨™é»'),
                            'background_story': kol_data.get('backstory', ''),
                            'expertise': kol_data.get('expertise', ''),
                            'ending_style': kol_data.get('signature', 'æ„Ÿè¬é–±è®€ï¼Œæ­¡è¿è¨è«–')
                        }
                        print(f"ğŸ‘¤ ç²å–KOLé…ç½®: {kol_nickname}")
                        print(f"ğŸ‘¤ KOLé…ç½®å…§å®¹: {kol_config}")
                        print(f"ğŸ‘¤ KOLé…ç½®è©³ç´°: tone_style={kol_config.get('tone_style')}, common_words={kol_config.get('common_words')}, casual_words={kol_config.get('casual_words')}")
                    else:
                        print(f"âš ï¸ æœªæ‰¾åˆ°KOLæ•¸æ“š: serial={request.kol_serial}")
                except Exception as kol_error:
                    print(f"âš ï¸ ç²å–KOLé…ç½®å¤±æ•—ï¼Œä½¿ç”¨é»˜èªè¨­å®š: {kol_error}")
                    import traceback
                    print(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
                
                # å‰µå»ºæ–°çš„å¯¦ä¾‹ä»¥ç¢ºä¿API Keyæ­£ç¢ºè¼‰å…¥
                news_agent = NewsAnalysisAgent()
                
                # æ ¹æ“šç”Ÿæˆæ¨¡å¼é¸æ“‡ä¸åŒçš„å…§å®¹ç”Ÿæˆé‚è¼¯
                # ğŸ”¥ ä¿®å¾©ï¼šå¼·åˆ¶ä½¿ç”¨é«˜å“è³ªæ¨¡å¼ï¼Œå¿½ç•¥å‰ç«¯çš„éŒ¯èª¤åƒæ•¸
                generation_mode = 'high_quality'  # å¼·åˆ¶ä½¿ç”¨é«˜å“è³ªæ¨¡å¼
                print(f"ğŸ¯ å¼·åˆ¶ä½¿ç”¨é«˜å“è³ªæ¨¡å¼ï¼Œå¿½ç•¥å‰ç«¯åƒæ•¸: {request.generation_mode}")
                
                if generation_mode == 'trash':
                    # å»¢æ–‡æ¨¡å¼ - ä½¿ç”¨ç°¡æ˜“å…§å®¹ç”Ÿæˆå™¨
                    print("ğŸ—‘ï¸ ä½¿ç”¨å»¢æ–‡æ¨¡å¼ç”Ÿæˆå…§å®¹")
                    from simple_content_generator import SimpleContentGenerator
                    simple_generator = SimpleContentGenerator()
                    
                    kol_content = simple_generator.generate_content(
                        stock_codes=[stock_id],
                        stock_names=[stock_name],
                        kol_nickname=kol_nickname,
                        kol_persona=request.kol_persona,
                        session_id=request.session_id,
                        trash_mode=True,
                        trash_sentiment=request.trash_sentiment or 'positive'
                    )
                    # print(f"âœ… å»¢æ–‡æ¨¡å¼ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
                    
                elif generation_mode == 'simple':
                    # ç°¡æ˜“æ¨¡å¼ - ä½¿ç”¨ä¿®å¾©å¾Œçš„ContentGeneratorï¼ˆèˆ‡é«˜å“è³ªæ¨¡å¼ç›¸åŒï¼‰
                    print("ğŸ² ä½¿ç”¨ç°¡æ˜“æ¨¡å¼ç”Ÿæˆå…§å®¹ï¼ˆä½¿ç”¨ContentGeneratorï¼‰")
                    
                    # ğŸ”§ ä½¿ç”¨ä¿®å¾©å¾Œçš„ContentGenerator
                    try:
                        print("ğŸ”§ å˜—è©¦ä½¿ç”¨ä¿®å¾©å¾Œçš„ContentGenerator...")
                        from src.services.content.content_generator import ContentGenerator, ContentRequest
                        content_generator = ContentGenerator()
                        
                        # ğŸ” æª¢æŸ¥KOLå€‹äººåŒ–ç®¡ç†å™¨
                        if hasattr(content_generator, 'kol_personalization_manager') and content_generator.kol_personalization_manager:
                            # print("âœ… KOLå€‹äººåŒ–ç®¡ç†å™¨å·²è¼‰å…¥")
                            # ç²å–çœŸå¯¦KOLè³‡æ–™
                            real_nickname = content_generator.kol_personalization_manager.get_kol_nickname(str(kol_serial))
                            real_persona = content_generator.kol_personalization_manager.get_kol_persona(str(kol_serial))
                            # print(f"ğŸ¯ KOL {kol_serial} çœŸå¯¦è³‡æ–™: æš±ç¨±={real_nickname}, äººè¨­={real_persona}")
                            
                            # ä½¿ç”¨çœŸå¯¦KOLè³‡æ–™
                            kol_nickname = real_nickname
                            if real_persona:
                                request.kol_persona = real_persona
                        else:
                            print("âš ï¸ KOLå€‹äººåŒ–ç®¡ç†å™¨æœªè¼‰å…¥ï¼Œä½¿ç”¨é è¨­è³‡æ–™")
                        
                        # æ§‹å»ºContentRequest
                        content_request = ContentRequest(
                            stock_code=stock_id,
                            stock_name=stock_name,
                            kol_serial=kol_serial,
                            kol_nickname=kol_nickname,
                            kol_persona=request.kol_persona,
                            content_style=request.content_style,
                            target_audience=request.target_audience,
                            content_length=request.content_length,
                            max_words=request.max_words,
                            data_sources=request.data_sources,
                            serper_analysis=serper_analysis,
                            trigger_type=request.trigger_type
                        )
                        
                        # ç”Ÿæˆå…§å®¹
                        generated_content = content_generator.generate_content(content_request)
                        
                        if generated_content.success:
                            kol_content = {
                                "title": generated_content.title,
                                "content": generated_content.content,
                                "content_md": generated_content.content_md,
                                "commodity_tags": generated_content.commodity_tags,
                                "community_topic": generated_content.community_topic
                            }
                            print(f"âœ… ç°¡æ˜“æ¨¡å¼ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
                        else:
                            raise Exception(f"ContentGeneratorç”Ÿæˆå¤±æ•—: {generated_content.error}")
                            
                    except Exception as e:
                        print(f"âŒ ContentGeneratorå¤±æ•—: {e}")
                        # Fallback åˆ°åŸºæœ¬å…§å®¹
                        kol_content = {
                            "title": f"{stock_name} åˆ†æ",
                            "content": f"é—œæ–¼ {stock_name} çš„æŠ€è¡“åˆ†æï¼Œå»ºè­°è¬¹æ…æ“ä½œã€‚",
                            "content_md": f"é—œæ–¼ {stock_name} çš„æŠ€è¡“åˆ†æï¼Œå»ºè­°è¬¹æ…æ“ä½œã€‚",
                            "commodity_tags": [{"type": "Stock", "key": stock_id, "bullOrBear": 0}],
                            "community_topic": None
                        }
                    
                else:
                    # é«˜å“è³ªæ¨¡å¼ - ä½¿ç”¨ä¿®å¾©å¾Œçš„ContentGenerator
                    print("âœ¨ ä½¿ç”¨é«˜å“è³ªæ¨¡å¼ç”Ÿæˆå…§å®¹")
                    
                    # ğŸ”§ ä½¿ç”¨ä¿®å¾©å¾Œçš„ContentGenerator
                    try:
                        print("ğŸ”§ å˜—è©¦ä½¿ç”¨ä¿®å¾©å¾Œçš„ContentGenerator...")
                        from src.services.content.content_generator import ContentGenerator, ContentRequest
                        content_generator = ContentGenerator()
                        
                        # ğŸ” æª¢æŸ¥KOLå€‹äººåŒ–ç®¡ç†å™¨
                        if hasattr(content_generator, 'kol_personalization_manager') and content_generator.kol_personalization_manager:
                            # print("âœ… KOLå€‹äººåŒ–ç®¡ç†å™¨å·²è¼‰å…¥")
                            # ç²å–çœŸå¯¦KOLè³‡æ–™
                            real_nickname = content_generator.kol_personalization_manager.get_kol_nickname(str(kol_serial))
                            real_persona = content_generator.kol_personalization_manager.get_kol_persona(str(kol_serial))
                            # print(f"ğŸ¯ KOL {kol_serial} çœŸå¯¦è³‡æ–™: æš±ç¨±={real_nickname}, äººè¨­={real_persona}")
                            
                            # ä½¿ç”¨çœŸå¯¦KOLè³‡æ–™
                            kol_nickname = real_nickname
                            kol_persona = real_persona
                        else:
                            print("âš ï¸ KOLå€‹äººåŒ–ç®¡ç†å™¨æœªè¼‰å…¥ï¼Œä½¿ç”¨é è¨­è³‡æ–™")
                        
                        # å‰µå»ºå…§å®¹è«‹æ±‚
                        content_request = ContentRequest(
                            topic_title=request.topic_title or f"{stock_name}ç›¤å¾Œåˆ†æ",
                            topic_keywords=request.topic_keywords or f"{stock_name}, æŠ€è¡“åˆ†æ",
                            kol_persona=kol_persona,
                            kol_nickname=kol_nickname,
                            content_type=request.content_style or "investment",
                            target_audience=request.target_audience or "active_traders"
                        )
                        
                        # ç”Ÿæˆå…§å®¹ - æ•´åˆæ–°èæ•¸æ“š
                        generated_content = content_generator.generate_complete_content(
                            content_request,
                            serper_analysis=serper_analysis,
                            data_sources=[source.value for source in data_source_assignment.primary_sources] if data_source_assignment else None
                        )
                        
                        if generated_content.success:
                            kol_content = {
                                "title": generated_content.title,
                                "content": generated_content.content,
                                "stock_code": stock_id,
                                "stock_name": stock_name,
                                "kol_serial": kol_serial,
                                "kol_nickname": kol_nickname,
                                "kol_persona": kol_persona
                            }
                            # print(f"âœ… ContentGeneratorç”ŸæˆæˆåŠŸ: {len(generated_content.content)} å­—")
                        else:
                            raise Exception(f"ContentGeneratorç”Ÿæˆå¤±æ•—: {generated_content.error_message}")
                            
                    except Exception as e:
                        print(f"âš ï¸ ContentGeneratorå¤±æ•—ï¼Œå›é€€åˆ°åŸæœ‰é‚è¼¯: {e}")
                        # å›é€€åˆ°åŸæœ‰é‚è¼¯
                        # æª¢æŸ¥æ˜¯å¦ç‚ºç†±é–€è©±é¡Œ
                        if topic_id and topic_title:
                            print(f"ğŸ”¥ æª¢æ¸¬åˆ°ç†±é–€è©±é¡Œï¼Œä½¿ç”¨å°ˆç”¨åˆ†ææ–¹æ³•: {topic_title}")
                        # ç²å–è©±é¡Œå…§å®¹
                        topic_content = ""
                        try:
                            from src.services.triggers.trending_topic_trigger_system import get_trending_topic_trigger_system
                            trending_system = get_trending_topic_trigger_system()
                            topic_data = trending_system.get_topic_details(topic_id)
                            if topic_data:
                                topic_content = topic_data.get("content", "")
                                print(f"ğŸ“ ç²å–è©±é¡Œå…§å®¹: {len(topic_content)} å­—")
                        except Exception as e:
                            print(f"âš ï¸ ç²å–è©±é¡Œå…§å®¹å¤±æ•—: {e}")
                        
                        kol_content = news_agent.analyze_stock_news(
                            stock_code=stock_id,
                            stock_name=stock_name,
                            news_items=news_items,
                            kol_persona=request.kol_persona,
                            content_length=request.content_length,
                            max_words=request.max_words
                        )
                        # print(f"âœ… ç†±é–€è©±é¡Œåˆ†æå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
                    else:
                        # æ ¹æ“šè§¸ç™¼å™¨é¡å‹é¸æ“‡ä¸åŒçš„åˆ†ææ–¹æ³•
                        trigger_type = request.trigger_type or 'default'
                        print(f"ğŸ“ˆ ä½¿ç”¨è‚¡ç¥¨åˆ†ææ–¹æ³•: {stock_name}({stock_id}), è§¸ç™¼å™¨é¡å‹: {trigger_type}")
                        print(f"ğŸ” DEBUG: request.trigger_type = {request.trigger_type}")
                        print(f"ğŸ” DEBUG: trigger_type = {trigger_type}")
                        
                        if trigger_type == 'volume_low':
                            # æˆäº¤é‡ä½è¿·è§¸ç™¼å™¨ - ä½¿ç”¨ä¸‹è·Œåˆ†æ
                            kol_content = news_agent.analyze_volume_low_stock(
                                stock_id, stock_name, news_items, request.kol_persona, 
                                kol_nickname, kol_config, request.content_length, request.max_words
                            )
                            # print(f"âœ… æˆäº¤é‡ä½è¿·åˆ†æå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
                        elif trigger_type == 'limit_down_after_hours':
                            # ç›¤å¾Œä¸‹è·Œè§¸ç™¼å™¨ - ä½¿ç”¨ä¸‹è·Œåˆ†æ
                            kol_content = news_agent.analyze_limit_down_stock(
                                stock_id, stock_name, news_items, request.kol_persona, 
                                kol_nickname, kol_config, request.content_length, request.max_words
                            )
                            # print(f"âœ… ç›¤å¾Œä¸‹è·Œåˆ†æå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
                        else:
                            # é»˜èªä½¿ç”¨é€šç”¨è‚¡ç¥¨åˆ†æ
                            kol_content = news_agent.analyze_stock_news(
                                stock_id, stock_name, news_items, request.kol_persona, 
                                kol_nickname, kol_config, request.content_length, request.max_words, trigger_type
                            )
                            # print(f"âœ… é€šç”¨è‚¡ç¥¨åˆ†æå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
                        
                        # å¦‚æœæ²’æœ‰æ–°èæ•¸æ“šï¼Œä½¿ç”¨GPTç”Ÿæˆå™¨
                        if not news_items:
                            print("âš ï¸ æ²’æœ‰æ–°èæ•¸æ“šï¼Œä½¿ç”¨GPTç”Ÿæˆå™¨")
                            kol_content = gpt_generator.generate_stock_analysis(
                                stock_id=stock_id,
                                stock_name=stock_name,
                                kol_persona=request.kol_persona,
                                serper_analysis=serper_analysis,
                                data_sources=[source.value for source in data_source_assignment.primary_sources],
                                content_length=request.content_length,
                                max_words=request.max_words
                            )
                            # print(f"âœ… GPTå…§å®¹ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
                    
            except Exception as e:
                print(f"âŒ Agentå…§å®¹ç”Ÿæˆå¤±æ•—: {e}")
                # å›é€€åˆ°æ”¹é€²çš„å…§å®¹ç”Ÿæˆå™¨
                kol_content = generate_improved_kol_content(
                    stock_id=stock_id,
                    stock_name=stock_name,
                    kol_persona=request.kol_persona,
                    content_style=request.content_style,
                    target_audience=request.target_audience,
                    serper_analysis=serper_analysis,
                    data_sources=[source.value for source in data_source_assignment.primary_sources]
                )
                # print(f"âœ… å›é€€å…§å®¹ç”Ÿæˆå®Œæˆ: {len(kol_content.get('content', ''))} å­—")
        
        # 4. æ•´åˆæ–°èç´ æå’Œæ•¸æ“šæºè³‡è¨Š
        print("ğŸ”— æ•´åˆæ–°èç´ æå’Œæ•¸æ“šæºè³‡è¨Š...")
        try:
            enhanced_content = enhance_content_with_serper_data(
                kol_content, 
                serper_analysis, 
                data_source_assignment
            )
            # print("âœ… å…§å®¹æ•´åˆå®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ å…§å®¹æ•´åˆå¤±æ•—: {e}")
            enhanced_content = kol_content
        
        # å®šç¾©ç™¾åˆ†æ¯”é…ç½®è®Šæ•¸ï¼ˆé¿å…èªæ³•éŒ¯èª¤ï¼‰
        article_type_distribution = getattr(request, 'article_type_distribution', None)
        content_length_distribution = getattr(request, 'content_length_distribution', None)
        content_style_distribution = getattr(request, 'content_style_distribution', None)
        analysis_depth_distribution = getattr(request, 'analysis_depth_distribution', None)
        max_words = getattr(request, 'max_words', None)
        include_charts = getattr(request, 'include_charts', None)
        include_risk_warning = getattr(request, 'include_risk_warning', None)
        
        # ğŸ¯ å€‹äººåŒ–æ­¥é©Ÿ - åœ¨å…§å®¹æ•´åˆå®Œæˆå¾Œï¼Œä¿å­˜åˆ°æ•¸æ“šåº«å‰
        print("ğŸ¯ é–‹å§‹å€‹äººåŒ–è™•ç†...")
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºäº’å‹•ç™¼å•é¡å‹ï¼Œå¦‚æœæ˜¯å‰‡è·³éå€‹äººåŒ–è™•ç†
        if posting_type == 'interaction':
            print("ğŸš« äº’å‹•ç™¼å•é¡å‹è·³éå€‹äººåŒ–è™•ç†")
            enhanced_content = kol_content  # ç›´æ¥ä½¿ç”¨äº’å‹•å…§å®¹
        else:
            print("ğŸ¯ æ­£å¸¸é¡å‹é€²è¡Œå€‹äººåŒ–è™•ç†")
        
        # ğŸ”” æ’ç¨‹ç”Ÿæˆæª¢æ¸¬æ¨™è¨˜
        batch_mode = getattr(request, 'batch_mode', False)
        session_id = getattr(request, 'session_id', None)
        schedule_task_id = os.environ.get('CURRENT_SCHEDULE_TASK_ID', None)
        
        # ğŸ”¥ ä¿®å¾©ï¼šåªæœ‰ç•¶CURRENT_SCHEDULE_TASK_IDå­˜åœ¨æ™‚æ‰æ˜¯çœŸæ­£çš„æ’ç¨‹æ¨¡å¼
        if schedule_task_id:
            print(f"ğŸ””ğŸ””ğŸ”” æª¢æ¸¬åˆ°æ’ç¨‹ç”Ÿæˆæ¨¡å¼ï¼é€™æ˜¯æ’ç¨‹ç³»çµ±è‡ªå‹•è§¸ç™¼çš„è²¼æ–‡ï¼ğŸ””ğŸ””ğŸ””")
            print(f"ğŸ”” Task ID: {schedule_task_id}, Stock: {request.stock_code}, KOL: KOL-{request.kol_serial}")
        elif batch_mode:
            print("ğŸ“¦ğŸ“¦ğŸ“¦ æª¢æ¸¬åˆ°æ‰‹å‹•æ‰¹æ¬¡æ¨¡å¼ï¼é€™æ˜¯ç”¨æˆ¶æ‰‹å‹•è§¸ç™¼çš„æ‰¹æ¬¡è²¼æ–‡ï¼ğŸ“¦ğŸ“¦ğŸ“¦")
            print(f"ğŸ“¦ Stock: {request.stock_code}, Session: {session_id}")
        else:
            print("ğŸ‘¤ğŸ‘¤ğŸ‘¤ æª¢æ¸¬åˆ°æ‰‹å‹•å–®ç¯‡æ¨¡å¼ï¼é€™æ˜¯ç”¨æˆ¶æ‰‹å‹•è§¸ç™¼çš„å–®ç¯‡è²¼æ–‡ï¼ğŸ‘¤ğŸ‘¤ğŸ‘¤")
            print(f"ğŸ‘¤ Stock: {request.stock_code}, Session: {session_id}")
        
        print(f"ğŸ” èª¿è©¦ï¼šenhanced_content keys: {list(enhanced_content.keys()) if enhanced_content else 'None'}")
        print(f"ğŸ” èª¿è©¦ï¼šenhanced_content title: {enhanced_content.get('title', 'None') if enhanced_content else 'None'}")
        print(f"ğŸ” èª¿è©¦ï¼šenhanced_content content length: {len(enhanced_content.get('content', '')) if enhanced_content else 0}")
        
        # å®šç¾© kol_serial è®Šæ•¸ - å¦‚æœæ²’æœ‰æŒ‡å®šå‰‡éš¨æ©Ÿé¸æ“‡
        if request.kol_serial:
            kol_serial = request.kol_serial
            print(f"ğŸ¯ ä½¿ç”¨æŒ‡å®šçš„KOLåºåˆ—è™Ÿ: {kol_serial}")
        else:
            # éš¨æ©Ÿé¸æ“‡KOL - å¾è³‡æ–™åº«å‹•æ…‹ç²å–æ‰€æœ‰å¯ç”¨KOL
            import random
            import time
            try:
                # å¾è³‡æ–™åº«ç²å–æ‰€æœ‰å¯ç”¨çš„KOL
                from kol_database_service import KOLDatabaseService
                kol_service = KOLDatabaseService()
                all_kols = kol_service.get_all_kols()
                available_kols = [str(kol.serial) for kol in all_kols if kol.status == 'active']
                
                if not available_kols:
                    # å¦‚æœè³‡æ–™åº«æ²’æœ‰KOLï¼Œä½¿ç”¨é è¨­çš„9å€‹
                    available_kols = ['200', '201', '202', '203', '204', '205', '206', '207', '208']
                    print(f"âš ï¸ è³‡æ–™åº«æ²’æœ‰å¯ç”¨KOLï¼Œä½¿ç”¨é è¨­æ± å­: {len(available_kols)} å€‹")
                else:
                    print(f"ğŸ“Š å¾è³‡æ–™åº«ç²å–åˆ° {len(available_kols)} å€‹å¯ç”¨KOL")
                
                # ä½¿ç”¨ç•¶å‰æ™‚é–“ä½œç‚ºéš¨æ©Ÿç¨®å­çš„ä¸€éƒ¨åˆ†ï¼Œå¢åŠ éš¨æ©Ÿæ€§
                random.seed(int(time.time() * 1000) % 1000000)
                # æ‰“äº‚é †åºå¾Œé¸æ“‡
                random.shuffle(available_kols)
                kol_serial = random.choice(available_kols)
                print(f"ğŸ² éš¨æ©Ÿé¸æ“‡KOLåºåˆ—è™Ÿ: {kol_serial} (å¾ {len(available_kols)} å€‹KOLä¸­é¸æ“‡)")
                
            except Exception as e:
                print(f"âŒ ç²å–KOLåˆ—è¡¨å¤±æ•—: {e}ï¼Œä½¿ç”¨é è¨­KOL")
                # å›é€€åˆ°é è¨­çš„9å€‹KOL
                available_kols = ['200', '201', '202', '203', '204', '205', '206', '207', '208']
                random.seed(int(time.time() * 1000) % 1000000)
                random.shuffle(available_kols)
                kol_serial = random.choice(available_kols)
                print(f"ğŸ² éš¨æ©Ÿé¸æ“‡KOLåºåˆ—è™Ÿ: {kol_serial} (å¾é è¨­æ± å­ä¸­é¸æ“‡)")
        print(f"ğŸ¯ è«‹æ±‚ä¸­çš„ kol_persona: {request.kol_persona}")
        
        # ğŸ¯ èˆŠç‰ˆå€‹äººåŒ–æ¨¡çµ„å·²ç§»é™¤ï¼Œä½¿ç”¨å¢å¼·ç‰ˆå€‹äººåŒ–æ¨¡çµ„
        print("ğŸ¯ è·³éèˆŠç‰ˆå€‹äººåŒ–æ¨¡çµ„ï¼Œç­‰å¾…å¢å¼·ç‰ˆå€‹äººåŒ–è™•ç†...")
        
        # 5. å…§å®¹æª¢æŸ¥å’Œä¿®å¾©ï¼ˆåœ¨æ–°èæ•´åˆå¾Œé€²è¡Œï¼‰
        print("ğŸ” é–‹å§‹å…§å®¹æª¢æŸ¥å’Œä¿®å¾©...")
        print("âš ï¸ æš«æ™‚ç¦ç”¨ ContentChecker ä»¥æ¸¬è©¦å€‹äººåŒ–åŠŸèƒ½")
        # try:
        #     from content_checker import ContentChecker
        #     content_checker = ContentChecker()
        #     
        #     # æª¢æŸ¥ä¸¦ä¿®å¾©å…§å®¹ï¼ˆæª¢æŸ¥ content_md å­—æ®µï¼‰
        #     content_to_check = enhanced_content.get('content_md', enhanced_content.get('content', ''))
        #     check_result = content_checker.check_and_fix_content(
        #         content_to_check,
        #         stock_name,
        #         stock_id,
        #         request.kol_persona,
        #         request.kol_serial,
        #         # æ–°å¢ï¼šå‚³éç™¾åˆ†æ¯”é…ç½®
        #         article_type_distribution=article_type_distribution,
        #         content_length_distribution=content_length_distribution,
        #         content_style_distribution=content_style_distribution,
        #         analysis_depth_distribution=analysis_depth_distribution,
        #         max_words=max_words,
        #         include_charts=include_charts,
        #         include_risk_warning=include_risk_warning,
        #         # æ–°å¢ï¼šå‚³éè§¸ç™¼å™¨é¡å‹
        #         trigger_type=request.trigger_type
        #     )
        #     
        #     if check_result['success']:
        #         print(f"âœ… å…§å®¹æª¢æŸ¥å®Œæˆ: {check_result['fix_method']} ä¿®å¾©")
        #         if check_result['issues_found']:
        #             print(f"ğŸ”§ ç™¼ç¾å•é¡Œ: {', '.join(check_result['issues_found'])}")
        #         
        #         # ä½¿ç”¨ä¿®å¾©å¾Œçš„å…§å®¹ï¼Œä½†ä¿ç•™å€‹äººåŒ–æ¨™ç±¤å’Œæ–°èä¾†æº
        #         # æª¢æŸ¥æ˜¯å¦æœ‰å€‹äººåŒ–æ¨™ç±¤éœ€è¦ä¿ç•™
        #         personalization_tag = ""
        #         if enhanced_content['content'].startswith(f"ã€{real_nickname}ã€‘"):
        #             personalization_tag = f"ã€{real_nickname}ã€‘"
        #             print(f"ğŸ” ä¿ç•™å€‹äººåŒ–æ¨™ç±¤: {personalization_tag}")
        #         
        #         # æª¢æŸ¥æ˜¯å¦æœ‰æ–°èä¾†æºéœ€è¦ä¿ç•™
        #         news_sources_section = ""
        #         if "æ–°èä¾†æº:" in enhanced_content['content']:
        #             news_sources_start = enhanced_content['content'].find("æ–°èä¾†æº:")
        #             news_sources_section = enhanced_content['content'][news_sources_start:]
        #             print(f"ğŸ” ä¿ç•™æ–°èä¾†æº: {len(news_sources_section)} å­—")
        #         
        #         # æ‡‰ç”¨ä¿®å¾©å¾Œçš„å…§å®¹
        #         enhanced_content['content'] = check_result['fixed_content']
        #         enhanced_content['content_md'] = check_result['fixed_content']
        #         
        #         # é‡æ–°æ·»åŠ å€‹äººåŒ–æ¨™ç±¤
        #         if personalization_tag:
        #             enhanced_content['content'] = personalization_tag + enhanced_content['content']
        #             enhanced_content['content_md'] = personalization_tag + enhanced_content['content_md']
        #             print(f"âœ… å€‹äººåŒ–æ¨™ç±¤å·²é‡æ–°æ·»åŠ : {personalization_tag}")
        #         
        #         # é‡æ–°æ·»åŠ æ–°èä¾†æº
        #         if news_sources_section:
        #             enhanced_content['content'] += "\n\n" + news_sources_section
        #             enhanced_content['content_md'] += "\n\n" + news_sources_section
        #             print(f"âœ… æ–°èä¾†æºå·²é‡æ–°æ·»åŠ : {len(news_sources_section)} å­—")
        #         
        #         enhanced_content['content_check'] = check_result
        #     else:
        #         print(f"âš ï¸ å…§å®¹æª¢æŸ¥å¤±æ•—: {check_result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
        #         
        # except Exception as e:
        #     print(f"âš ï¸ å…§å®¹æª¢æŸ¥å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
        
        # æ·»åŠ é¡å¤–çš„æ¬„ä½ä»¥ç¬¦åˆå‰ç«¯æœŸæœ›
        enhanced_content.update({
            "stock_code": stock_id,
            "stock_name": stock_name,
            "kol_serial": request.kol_serial or "1",
            "session_id": request.session_id,
            "batch_mode": request.batch_mode
        })
        
        # æº–å‚™å•†å“æ¨™ç±¤
        print("ğŸ·ï¸ æº–å‚™å•†å“æ¨™ç±¤...")
        
        # è™•ç† commodity tags
        commodity_tags = []
        
        # é»˜èªæ·»åŠ  TWA00 æ¨™ç±¤ï¼ˆå°è‚¡å¤§ç›¤ï¼‰
        commodity_tags.append({
            "type": "Market",
            "key": "TWA00",
            "bullOrBear": 0  # é è¨­ä¸­æ€§
        })
        print(f"ğŸ·ï¸ æ·»åŠ é»˜èª TWA00 æ¨™ç±¤")
        
        # å¦‚æœæœ‰å…±äº«çš„ commodity tagsï¼ˆä¾†è‡ªæ‰¹é‡ç”Ÿæˆï¼‰ï¼Œå„ªå…ˆä½¿ç”¨
        if request.shared_commodity_tags:
            commodity_tags.extend(request.shared_commodity_tags)
            print(f"ğŸ·ï¸ ä½¿ç”¨å…±äº« commodity tags: {len(request.shared_commodity_tags)} å€‹")
            for tag in request.shared_commodity_tags:
                print(f"  - {tag.get('type')}: {tag.get('key')}")
        else:
            # æª¢æŸ¥æ˜¯å¦ç‚ºç†±é–€è©±é¡Œ
            if topic_id and topic_title:
                # ç†±é–€è©±é¡Œç”Ÿæˆå°ˆç”¨æ¨™ç±¤ - ä½¿ç”¨ topic_id ä½œç‚º key
                commodity_tags.append({
                    "type": "TrendingTopic",
                    "key": topic_id,  # ä½¿ç”¨ topic_id (UUID) è€Œä¸æ˜¯ topic_title
                    "bullOrBear": 0  # é è¨­ä¸­æ€§ï¼Œå¾ŒçºŒå¯ä»¥æ ¹æ“šå…§å®¹åˆ†æèª¿æ•´
                })
                print(f"ğŸ·ï¸ ç”Ÿæˆç†±é–€è©±é¡Œ commodity tag: {topic_id} - {topic_title}")
            else:
                # å¦å‰‡æ ¹æ“šè‚¡ç¥¨ä¿¡æ¯ç”Ÿæˆ commodity tags
                commodity_tags.append({
                    "type": "Stock",
                    "key": stock_id,
                    "bullOrBear": 0  # é è¨­ä¸­æ€§
                })
                print(f"ğŸ·ï¸ ç”Ÿæˆå–®å€‹è‚¡ç¥¨ commodity tag: {stock_id}")
        
        print(f"âœ… æœ€çµ‚ commodity tags: {len(commodity_tags)} å€‹")
        print(f"ğŸ“Š è‚¡ç¥¨ä»£è™Ÿ: {stock_id}, è‚¡ç¥¨åç¨±: {stock_name}")
        print(f"ğŸ‘¤ KOLåºè™Ÿ: {request.kol_serial}")
        
        # æº–å‚™ç¤¾ç¾¤è©±é¡Œ
        community_topic = None
        if request.post_to_thread:
            community_topic = CommunityTopic(id=request.post_to_thread, title=request.post_to_thread)
            print(f"ğŸ’¬ ç¤¾ç¾¤è©±é¡Œ: {request.post_to_thread}")
        elif topic_id and topic_title:
            # å¦‚æœæ˜¯ç†±é–€è©±é¡Œï¼Œä½¿ç”¨ topic_id ä½œç‚ºç¤¾ç¾¤è©±é¡Œ ID
            community_topic = CommunityTopic(id=topic_id, title=topic_title)
            print(f"ğŸ’¬ ç†±é–€è©±é¡Œç¤¾ç¾¤è©±é¡Œ: {topic_id} - {topic_title}")
        
        # æº–å‚™ç”Ÿæˆåƒæ•¸ - æ•´åˆæ•¸æ“šæºè³‡è¨Š
        print("âš™ï¸ æº–å‚™ç”Ÿæˆåƒæ•¸...")
        
        generation_params = GenerationParams(
            kol_persona=request.kol_persona,
            content_style=request.content_style,
            target_audience=request.target_audience,
            batch_mode=request.batch_mode,
            data_sources=[source.value for source in data_source_assignment.primary_sources],
            session_id=request.session_id,
            technical_indicators=[],
            # æ–°å¢ï¼šç™¾åˆ†æ¯”é…ç½®åƒæ•¸
            article_type_distribution=article_type_distribution,
            content_length_distribution=content_length_distribution,
            content_style_distribution=content_style_distribution,
            analysis_depth_distribution=analysis_depth_distribution,
            max_words=max_words,
            include_charts=include_charts,
            include_risk_warning=include_risk_warning
        )
        print("âœ… ç”Ÿæˆåƒæ•¸æº–å‚™å®Œæˆ")
        
        # å‰µå»ºè²¼æ–‡è¨˜éŒ„
        print("ğŸ’¾ é–‹å§‹ä¿å­˜è²¼æ–‡è¨˜éŒ„åˆ°è³‡æ–™åº«...")
        try:
            # è™•ç† commodity tags æ¨¡å‹è½‰æ›
            commodity_tag_models = []
            if commodity_tags:
                try:
                    # å‹•æ…‹å°å…¥ CommodityTag æ¨¡å‹
                    from post_record_service import CommodityTag
                    for tag_data in commodity_tags:
                        commodity_tag_models.append(CommodityTag(
                            type=tag_data.get("type", "Stock"),
                            key=tag_data.get("key", ""),
                            bullOrBear=tag_data.get("bullOrBear", 0)
                        ))
                    print(f"âœ… æˆåŠŸè½‰æ› {len(commodity_tag_models)} å€‹ commodity tags")
                except ImportError as e:
                    print(f"âš ï¸ CommodityTag æ¨¡å‹å°å…¥å¤±æ•—ï¼Œè·³é commodity tags: {e}")
                    commodity_tag_models = []
            else:
                print("â„¹ï¸ æ²’æœ‰ commodity tags éœ€è¦è™•ç†")
            
            # ç¢ºä¿ä½¿ç”¨å­˜åœ¨çš„ KOL
            from kol_service import kol_service
            available_kol_ids = list(kol_service.kol_credentials.keys())
            if request.kol_serial and str(request.kol_serial) in available_kol_ids:
                kol_serial = int(request.kol_serial)
            else:
                # ä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨çš„ KOL
                kol_serial = int(available_kol_ids[0])
                print(f"âš ï¸ KOL {request.kol_serial} ä¸å­˜åœ¨ï¼Œä½¿ç”¨ KOL {kol_serial}")
            
            # æº–å‚™è²¼æ–‡è¨˜éŒ„æ•¸æ“š
            print(f"ğŸ“ æº–å‚™è²¼æ–‡è¨˜éŒ„æ•¸æ“š: {enhanced_content.get('title', 'æœªå‘½åè²¼æ–‡')}")
            print(f"ğŸ” è²¼æ–‡è¨˜éŒ„æ•¸æ“šè©³æƒ…: session_id={request.session_id}, stock_code={stock_id}")
            
        except Exception as e:
            print(f"âŒ æº–å‚™è²¼æ–‡è¨˜éŒ„æ•¸æ“šå¤±æ•—: {e}")
            # ä¸è¨­ç½® error ç‹€æ…‹ï¼Œç¹¼çºŒå˜—è©¦ä¿å­˜åˆ°æ•¸æ“šåº«
        
        # è™•ç†ç†±é–€è©±é¡Œ IDï¼ˆæ··å’Œæ¨¡å¼ï¼‰- åœ¨ä¿å­˜åˆ°æ•¸æ“šåº«ä¹‹å‰åŸ·è¡Œ
        print("ğŸ” é–‹å§‹è™•ç†ç†±é–€è©±é¡Œ IDï¼ˆæ··å’Œæ¨¡å¼ï¼‰")
        # èª¿è©¦æ—¥èªŒ
        print(f"ğŸ” èª¿è©¦æ¨™ç±¤æ¨¡å¼æ¢ä»¶:")
        print(f"  - topic_id: {topic_id}")
        print(f"  - topic_title: {topic_title}")
        print(f"  - tags_config: {request.tags_config}")
        print(f"  - tag_mode: {request.tags_config.get('tag_mode', 'stock_tags') if request.tags_config else 'stock_tags'}")
        print(f"  - topic_tags: {request.tags_config.get('topic_tags', {}) if request.tags_config else {}}")
        print(f"  - mixed_mode: {request.tags_config.get('topic_tags', {}).get('mixed_mode', False) if request.tags_config else False}")
        
        # æª¢æŸ¥æ¨™ç±¤æ¨¡å¼æ¢ä»¶
        tag_mode = request.tags_config.get('tag_mode', 'stock_tags') if request.tags_config else 'stock_tags'
        mixed_mode_enabled = request.tags_config and request.tags_config.get('topic_tags', {}).get('mixed_mode', False)
        topic_tags_enabled = request.tags_config and request.tags_config.get('topic_tags', {}).get('enabled', False)
        
        print(f"ğŸ” æ¨™ç±¤æ¨¡å¼æ¢ä»¶æª¢æŸ¥:")
        print(f"  - request.tags_config å­˜åœ¨: {bool(request.tags_config)}")
        print(f"  - tag_mode: {tag_mode}")
        print(f"  - mixed_mode_enabled: {mixed_mode_enabled}")
        print(f"  - topic_id ç‚ºç©º: {not topic_id}")
        
        # åˆ¤æ–·æ˜¯å¦éœ€è¦è‡ªå‹•ç²å–ç†±é–€è©±é¡Œ
        should_auto_fetch_topic = (
            (not topic_id or topic_id == 'auto_fetch') and  # æ²’æœ‰æä¾› topic_id æˆ–æ˜ç¢ºè¦æ±‚è‡ªå‹•ç²å–
            (
                tag_mode == 'topic_tags' or  # ç´”ç†±é–€è©±é¡Œæ¨¡å¼
                tag_mode == 'both' or  # æ··åˆæ¨¡å¼
                mixed_mode_enabled or  # æˆ–è€…å•Ÿç”¨äº†æ··å’Œæ¨¡å¼
                topic_id == 'auto_fetch'  # æˆ–è€…æ˜ç¢ºè¦æ±‚è‡ªå‹•ç²å–
            )
        )
        
        print(f"  - æ‡‰è©²è‡ªå‹•ç²å–ç†±é–€è©±é¡Œ: {should_auto_fetch_topic}")
        
        # å¦‚æœæ²’æœ‰æä¾› topic_id ä½†éœ€è¦ç†±é–€è©±é¡Œæ¨™ç±¤ï¼Œè‡ªå‹•å¾ trending API ç²å–
        if should_auto_fetch_topic:
            try:
                print("ğŸ”„ è‡ªå‹•ç²å–ç†±é–€è©±é¡Œï¼ˆåŸºæ–¼æ¨™ç±¤æ¨¡å¼ï¼‰...")
                print(f"ğŸ” èª¿ç”¨ trending API: {TRENDING_API_URL}/trending")
                trending_response = requests.get(f"{TRENDING_API_URL}/trending", params={"limit": 1})
                print(f"ğŸ” trending API éŸ¿æ‡‰ç‹€æ…‹: {trending_response.status_code}")
                trending_response.raise_for_status()
                trending_data = trending_response.json()
                print(f"ğŸ” trending API éŸ¿æ‡‰æ•¸æ“š: {trending_data}")
                
                if trending_data.get("topics") and len(trending_data["topics"]) > 0:
                    trending_topic = trending_data["topics"][0]
                    topic_id = trending_topic.get("id")
                    topic_title = trending_topic.get("title")
                    print(f"âœ… è‡ªå‹•ç²å–åˆ°ç†±é–€è©±é¡Œ - ID: {topic_id}, æ¨™é¡Œ: {topic_title}")
                    print(f"ğŸ” å®Œæ•´è©±é¡Œæ•¸æ“š: {trending_topic}")
                else:
                    print("âš ï¸ æœªç²å–åˆ°ç†±é–€è©±é¡Œæ•¸æ“š")
                    print(f"ğŸ” éŸ¿æ‡‰æ•¸æ“šçµæ§‹: {trending_data}")
                    # ç¢ºä¿è®Šé‡æœ‰é»˜èªå€¼
                    if not topic_id:
                        topic_id = None
                    if not topic_title:
                        topic_title = None
            except Exception as e:
                print(f"âŒ ç²å–ç†±é–€è©±é¡Œå¤±æ•—: {e}")
                import traceback
                print(f"ğŸ” éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
                # ç¢ºä¿è®Šé‡æœ‰é»˜èªå€¼
                if not topic_id:
                    topic_id = None
                if not topic_title:
                    topic_title = None
        
        # ğŸ¯ å¢å¼·ç‰ˆå€‹äººåŒ–ç¯€é» - åœ¨ä¿å­˜åˆ°æ•¸æ“šåº«ä¹‹å‰é€²è¡Œå€‹äººåŒ–è™•ç†
        print("ğŸ¯ é–‹å§‹å¢å¼·ç‰ˆå€‹äººåŒ–ç¯€é»è™•ç†...")
        try:
            from personalization_module import enhanced_personalization_processor
            
            # ç²å–KOLåºè™Ÿ - ä½¿ç”¨ä¹‹å‰ç¢ºå®šçš„kol_serial
            print(f"ğŸ¯ ä½¿ç”¨å¢å¼·ç‰ˆå€‹äººåŒ–è™•ç†å™¨ - KOL: {kol_serial}")
            
            # æº–å‚™å€‹äººåŒ–åƒæ•¸
            original_title = enhanced_content.get('title', f"{stock_name} åˆ†æ")
            original_content = enhanced_content.get('content', '')
            batch_config = {}  # å¯ä»¥å¾requestä¸­ç²å–
            serper_analysis = enhanced_content.get('serper_data', {})
            trigger_type = request.trigger_type or 'manual'
            
            print(f"ğŸ¯ å€‹äººåŒ–è¼¸å…¥ - æ¨™é¡Œ: {original_title}")
            print(f"ğŸ¯ å€‹äººåŒ–è¼¸å…¥ - å…§å®¹é•·åº¦: {len(original_content)} å­—")
            print(f"ğŸ¯ å€‹äººåŒ–è¼¸å…¥ - è§¸ç™¼å™¨é¡å‹: {trigger_type}")
            
            # å°‡æ–°èé€£çµé…ç½®æ·»åŠ åˆ° serper_analysis ä¸­
            if serper_analysis:
                serper_analysis['enable_news_links'] = getattr(request, 'enable_news_links', True)
                serper_analysis['news_max_links'] = getattr(request, 'news_max_links', 5) if getattr(request, 'enable_news_links', True) else 0
            
            # ä½¿ç”¨å¢å¼·ç‰ˆå€‹äººåŒ–è™•ç†å™¨ - æ•´åˆéš¨æ©ŸåŒ–ç”Ÿæˆ
            try:
                personalized_title, personalized_content, random_metadata = enhanced_personalization_processor.personalize_content(
                    standard_title=original_title,
                    standard_content=original_content,
                    kol_serial=kol_serial,
                    batch_config=batch_config,
                    serper_analysis=serper_analysis,
                    trigger_type=trigger_type,
                    real_time_price_data=actual_price_data or {},  # ğŸ”¥ æ–°å¢ï¼šå‚³å…¥å³æ™‚è‚¡åƒ¹æ•¸æ“šï¼Œå¦‚æœç‚º None å‰‡å‚³å…¥ç©ºå­—å…¸
                    posting_type=posting_type  # ğŸ² æ–°å¢ï¼šå‚³å…¥ç™¼æ–‡é¡å‹
                )
                
                # ğŸ² æ–°å¢ï¼šè™•ç†éš¨æ©ŸåŒ–å…ƒæ•¸æ“š
                if random_metadata:
                    alternative_versions = random_metadata.get('alternative_versions', [])
                    generation_metadata = random_metadata.get('generation_metadata', {})
                    
                    print(f"ğŸ² éš¨æ©ŸåŒ–ç”Ÿæˆå®Œæˆ - é¸ä¸­ç‰ˆæœ¬: {generation_metadata.get('selected_index', 'Unknown') + 1}")
                    print(f"ğŸ“ å…¶ä»–ç‰ˆæœ¬æ•¸é‡: {len(alternative_versions)}")
                    
                    # è©³ç´°è¨˜éŒ„æ¯å€‹ alternative_versions çš„å…§å®¹
                    for i, version in enumerate(alternative_versions):
                        print(f"ğŸ“ ç‰ˆæœ¬ {i+1}: {version.get('title', 'No title')}")
                        print(f"   è§’åº¦: {version.get('angle', 'No angle')}")
                        print(f"   å…§å®¹é•·åº¦: {len(version.get('content', ''))} å­—ç¬¦")
                    
                    # å°‡å…¶ä»–ç‰ˆæœ¬å­˜å„²åˆ° enhanced_content ä¸­ï¼Œç¨å¾Œä¿å­˜åˆ°æ•¸æ“šåº«
                    enhanced_content['alternative_versions'] = alternative_versions
                    enhanced_content['generation_metadata'] = generation_metadata
                    
                    print(f"ğŸ’¾ alternative_versions å·²å­˜å„²åˆ° enhanced_contentï¼Œæ•¸é‡: {len(enhanced_content.get('alternative_versions', []))}")
                    
            except Exception as e:
                print(f"âš ï¸ å¢å¼·ç‰ˆå€‹äººåŒ–ç¯€é»å¤±æ•—: {e}")
                # å›é€€åˆ°åŸºæœ¬å€‹äººåŒ–è™•ç†
                personalized_title = original_title
                personalized_content = original_content
                enhanced_content['alternative_versions'] = []
                enhanced_content['generation_metadata'] = {}
            
            # ç§»é™¤Markdownæ ¼å¼ï¼ˆç”¨æ–¼ç¤¾äº¤åª’é«”ç™¼å¸ƒï¼‰
            import re
            def remove_markdown(text):
                """ç§»é™¤Markdownæ ¼å¼ç¬¦è™Ÿ"""
                # ç§»é™¤æ¨™é¡Œç¬¦è™Ÿ ##
                text = re.sub(r'^#{1,6}\s*', '', text, flags=re.MULTILINE)
                # ç§»é™¤ç²—é«” **text**
                text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
                # ç§»é™¤æ–œé«” *text*
                text = re.sub(r'\*(.*?)\*', r'\1', text)
                # ç§»é™¤ç¨‹å¼ç¢¼å€å¡Š ```
                text = re.sub(r'```[^`]*```', '', text, flags=re.DOTALL)
                # ç§»é™¤è¡Œå…§ç¨‹å¼ç¢¼ `code`
                text = re.sub(r'`([^`]*)`', r'\1', text)
                # ç§»é™¤æ°´å¹³åˆ†éš”ç·š ---
                text = re.sub(r'^[\-*_]{3,}\s*$', '', text, flags=re.MULTILINE)
                # ç§»é™¤é€£çµ [text](url) ä½†ä¿ç•™æ–‡å­—
                text = re.sub(r'\[([^\]]*)\]\([^)]*\)', r'\1', text)
                # ç§»é™¤åœ–ç‰‡ ![alt](url)
                text = re.sub(r'!\[([^\]]*)\]\([^)]*\)', '', text)
                # æ¸…ç†å¤šé¤˜çš„ç©ºè¡Œï¼ˆæœ€å¤šä¿ç•™å…©å€‹ï¼‰
                text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
                return text.strip()
            
            # æ›´æ–°enhanced_content
            personalized_content_no_md = remove_markdown(personalized_content)
            enhanced_content['title'] = personalized_title
            enhanced_content['content'] = personalized_content_no_md
            enhanced_content['content_md'] = personalized_content_no_md
            
            print(f"âœ… å¢å¼·ç‰ˆå€‹äººåŒ–å®Œæˆ")
            print(f"âœ… å€‹äººåŒ–æ¨™é¡Œ: {original_title} â†’ {personalized_title}")
            print(f"âœ… å€‹äººåŒ–å…§å®¹é•·åº¦: {len(original_content)} â†’ {len(personalized_content_no_md)} å­—")
            print(f"âœ… Markdownæ ¼å¼å·²ç§»é™¤")
            print(f"âœ… å€‹äººåŒ–å…§å®¹å‰100å­—: {personalized_content_no_md[:100]}...")
            
        except Exception as e:
            print(f"âš ï¸ å¢å¼·ç‰ˆå€‹äººåŒ–ç¯€é»å¤±æ•—: {e}")
            # å¦‚æœå€‹äººåŒ–å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹å…§å®¹

        # ä¿å­˜åˆ°æ•¸æ“šåº« - ä½¿ç”¨å€‹äººåŒ–å¾Œçš„ enhanced_content
        try:
            post_service = get_post_record_service()
            
            # æº–å‚™å®Œæ•´çš„è²¼æ–‡æ•¸æ“š
            print(f"ğŸ” æº–å‚™ä¿å­˜åˆ°æ•¸æ“šåº«çš„ topic_id: {topic_id}")
            print(f"ğŸ” æº–å‚™ä¿å­˜åˆ°æ•¸æ“šåº«çš„ topic_title: {topic_title}")
            
            # å®‰å…¨è™•ç† kol_serial
            # ä½¿ç”¨ä¹‹å‰ç¢ºå®šçš„kol_serial
            try:
                kol_serial_int = int(kol_serial)
                kol_nickname = f"KOL-{kol_serial}"
            except (ValueError, TypeError):
                kol_serial_int = 200
                kol_nickname = "KOL-200"
            
            # ç²å–æ­£ç¢ºçš„ KOL persona
            actual_kol_persona = request.kol_persona
            try:
                # å˜—è©¦å¾ KOL æœå‹™ç²å–æ­£ç¢ºçš„ persona
                from kol_service import KOLService
                kol_service = KOLService()
                kol_profile = kol_service.get_kol_info(str(kol_serial_int))
                if kol_profile and kol_profile.get('persona'):
                    actual_kol_persona = kol_profile['persona']
                    print(f"ğŸ¯ ä½¿ç”¨ KOL æ•¸æ“šåº«ä¸­çš„ persona: {actual_kol_persona}")
                else:
                    print(f"âš ï¸ ç„¡æ³•ç²å– KOL {kol_serial_int} çš„ personaï¼Œä½¿ç”¨é è¨­å€¼: {actual_kol_persona}")
            except Exception as e:
                print(f"âš ï¸ ç²å– KOL persona å¤±æ•—: {e}ï¼Œä½¿ç”¨é è¨­å€¼: {actual_kol_persona}")
            
            post_data = {
                'session_id': request.session_id or 1,
                'kol_serial': kol_serial_int,
                'kol_nickname': kol_nickname,
                'kol_persona': actual_kol_persona,
                'stock_code': request.stock_code or "2330",
                'stock_name': stock_name,  # ä½¿ç”¨å¾ stock_mapping ç²å–çš„æ­£ç¢ºåç¨±
                'title': enhanced_content.get("title", f"ã€{kol_nickname}ã€‘{request.stock_name or 'å°ç©é›»'}({request.stock_code or '2330'}) ç›¤å¾Œåˆ†æ"),
                'content': enhanced_content.get("content", ""),
                'content_md': enhanced_content.get("content_md", ""),
                'status': 'draft',
                'technical_analysis': enhanced_content.get("technical_analysis"),
                'serper_data': enhanced_content.get("serper_data"),
                'quality_score': enhanced_content.get("quality_score"),
                'ai_detection_score': enhanced_content.get("ai_detection_score"),
                'risk_level': enhanced_content.get("risk_level"),
                'topic_id': topic_id,  # ä½¿ç”¨è™•ç†å¾Œçš„ topic_id
                'topic_title': topic_title,  # ä½¿ç”¨è™•ç†å¾Œçš„ topic_title
                'trigger_type': request.trigger_type or 'manual',  # æ·»åŠ è§¸ç™¼å™¨é¡å‹
                'commodity_tags': [tag.model_dump() for tag in commodity_tag_models] if commodity_tag_models else [],
                'generation_params': json.dumps({
                    "method": "manual",  # æ‰‹å‹•ç™¼æ–‡ç”Ÿæˆï¼ˆæ­¥é©Ÿ1-9ï¼‰
                    "kol_persona": request.kol_persona,
                    "content_style": request.content_style,
                    "target_audience": request.target_audience,
                    "topic_id": topic_id,
                    "topic_title": topic_title,
                    "tag_mode": tag_mode,
                    "topic_tags_enabled": topic_tags_enabled,
                    "mixed_mode": mixed_mode_enabled,
                    "shared_commodity_tags": len(commodity_tags) if request.shared_commodity_tags else 0,
                    "trigger_type": request.trigger_type or 'manual',  # åœ¨ generation_params ä¸­ä¹Ÿæ·»åŠ 
                    "posting_type": posting_type,  # ğŸ² æ–°å¢ï¼šç™¼æ–‡é¡å‹
                    "created_at": datetime.now(pytz.timezone('Asia/Taipei')).replace(tzinfo=None).isoformat()
                }),
                'alternative_versions': json.dumps(enhanced_content.get('alternative_versions', []))  # ğŸ² æ–°å¢ï¼šå…¶ä»–ç‰ˆæœ¬
            }
            
            print(f"ğŸ” å®Œæ•´çš„ post_data: {post_data}")
            print(f"ğŸ’¾ æº–å‚™ä¿å­˜åˆ°æ•¸æ“šåº«çš„ alternative_versions: {len(enhanced_content.get('alternative_versions', []))} å€‹ç‰ˆæœ¬")
            
            # å‰µå»ºå®Œæ•´çš„è²¼æ–‡è¨˜éŒ„
            post_record = post_service.create_post_record(post_data)
            
            print(f"âœ… è²¼æ–‡è¨˜éŒ„ä¿å­˜æˆåŠŸ: {post_record.post_id}")
            enhanced_content["post_id"] = post_record.post_id
            enhanced_content["status"] = "draft"  # è¨­ç½®ç‚º draft ç‹€æ…‹ï¼Œç­‰å¾…å¯©æ ¸
            
            # å°‡ topic_id å’Œ topic_title æ·»åŠ åˆ° enhanced_content ä¸­
            if topic_id:
                enhanced_content["topic_id"] = topic_id
                enhanced_content["topic_title"] = topic_title
                print(f"âœ… å·²æ›´æ–° enhanced_content ä¸­çš„è©±é¡Œä¿¡æ¯: {topic_id} - {topic_title}")
            
        except Exception as db_error:
            print(f"âŒ ä¿å­˜è²¼æ–‡è¨˜éŒ„å¤±æ•—: {db_error}")
            enhanced_content["post_id"] = f"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            enhanced_content["status"] = "error"
            # å¦‚æœæ•¸æ“šåº«ä¿å­˜å¤±æ•—ï¼Œè¿”å›éŒ¯èª¤
            return PostingResult(
                success=False,
                error=f"æ•¸æ“šåº«ä¿å­˜å¤±æ•—: {str(db_error)}",
                timestamp=datetime.now()
            )
        
        # ç™¼æ–‡
        if request.auto_post:
            print("ğŸš€ æº–å‚™è‡ªå‹•ç™¼æ–‡...")
            background_tasks = BackgroundTasks()
            background_tasks.add_task(post_to_platform, enhanced_content, {"id": request.post_to_thread})
            print("âœ… è‡ªå‹•ç™¼æ–‡ä»»å‹™å·²åŠ å…¥èƒŒæ™¯ä»»å‹™")
        
        print(f"ğŸ‰ ç™¼æ–‡ç”Ÿæˆå®Œæˆ: {enhanced_content.get('post_id')}")
        
        # å°‡ commodity_tags å’Œ community_topic æ·»åŠ åˆ° enhanced_content ä¸­
        enhanced_content["commodity_tags"] = [tag.model_dump() for tag in commodity_tag_models] if commodity_tag_models else []
        enhanced_content["community_topic"] = community_topic.model_dump() if community_topic else None
        
        print(f"âœ… å·²æ·»åŠ  commodity_tags: {len(enhanced_content['commodity_tags'])} å€‹")
        print(f"âœ… å·²æ·»åŠ  community_topic: {enhanced_content['community_topic']}")
        
        
        return PostingResult(
            success=True,
            post_id=enhanced_content.get("post_id", f"post_{datetime.now().strftime('%Y%m%d_%H%M%S')}"),
            content=enhanced_content,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        import traceback
        print(f"âŒ manual_post_content å‡½æ•¸ç™¼ç”ŸéŒ¯èª¤: {e}")
        print(f"âŒ éŒ¯èª¤è©³æƒ…: {str(e)}")
        print(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        return PostingResult(
            success=False,
            error=str(e),
            timestamp=datetime.now()
        )

def generate_kol_content_direct(stock_id: str, stock_name: str, kol_persona: str, content_style: str, target_audience: str) -> Dict:
    """ç›´æ¥ç”ŸæˆKOLå…§å®¹ - åŸºæ–¼åŸæœ¬çš„ç›¤å¾Œæ¼²åœè…³æœ¬æ¶æ§‹"""
    
    # KOLäººè¨­é…ç½®
    kol_personas = {
        "technical": {
            "name": "æŠ€è¡“å¤§å¸«",
            "style": "å°ˆæ¥­ä¸”è‡ªä¿¡",
            "focus": "åœ–è¡¨åˆ†æã€æŠ€è¡“æŒ‡æ¨™",
            "language": "æŠ€è¡“è¡“èªè±å¯Œï¼Œæ•¸æ“šå°å‘"
        },
        "fundamental": {
            "name": "åƒ¹å€¼æŠ•è³‡å¤§å¸«", 
            "style": "ç©©é‡ä¸”æ·±æ€ç†Ÿæ…®",
            "focus": "åŸºæœ¬é¢åˆ†æã€è²¡å ±è§£è®€",
            "language": "é‚è¼¯æ¸…æ™°ï¼Œé‡è¦–æ•¸æ“š"
        },
        "news_driven": {
            "name": "æ–°èçµäºº",
            "style": "æ•éŠ³ä¸”å³æ™‚", 
            "focus": "æ–°èå½±éŸ¿ã€æ”¿ç­–è®ŠåŒ–",
            "language": "ç”Ÿå‹•æ´»æ½‘ï¼Œæ™‚äº‹å°å‘"
        }
    }
    
    persona = kol_personas.get(kol_persona, kol_personas["technical"])
    
    # ç”Ÿæˆæ¨™é¡Œ - ç´”æ–‡å­—æ ¼å¼
    title = f"{stock_name} {persona['name']}è§€é»"
    
    # ç”Ÿæˆå…§å®¹ - ç´”æ–‡å­—æ ¼å¼
    content_md = f"""{stock_name}({stock_id}) æŠ€è¡“é¢åˆ†æå ±å‘Š

æ ¸å¿ƒè§€é»
{stock_name} ç›®å‰è™•æ–¼å¼·å‹¢çªç ´ç‹€æ…‹ï¼ŒæŠ€è¡“æŒ‡æ¨™é¡¯ç¤ºå¤šé ­è¨Šè™Ÿç¢ºèªã€‚

é—œéµæŠ€è¡“æŒ‡æ¨™
- MA5/MA20: é»ƒé‡‘äº¤å‰ç¢ºèªå¤šé ­è¶¨å‹¢
- RSI14: ä¸­æ€§åå¤šï¼Œä»æœ‰ä¸Šæ¼²ç©ºé–“
- MACDæŸ±ç‹€é«”: å¤šé ­è¨Šè™ŸæŒçºŒ

æŠ€è¡“è¨Šè™Ÿåˆ†æ
- åƒ¹æ¼²é‡å¢ï¼šè²·ç›¤åŠ›é“å¼·å‹ï¼Œå¾Œå¸‚çœ‹å¥½
- çªç ´å£“åŠ›ï¼šæˆåŠŸçªç ´é—œéµé˜»åŠ›ä½
- è¶¨å‹¢ç¢ºèªï¼šå¤šé ­æ’åˆ—å®Œæ•´

æŠ•è³‡å»ºè­°
åŸºæ–¼æŠ€è¡“åˆ†æï¼Œå»ºè­°é€¢ä½å¸ƒå±€ï¼Œç›®æ¨™åƒ¹ä½å¯æœŸå¾…10-15%æ¼²å¹…ã€‚

é¢¨éšªæé†’
- æ³¨æ„å¤§ç›¤ç’°å¢ƒè®ŠåŒ–
- è¨­å¥½åœæé»ä½
- åˆ†æ‰¹é€²å ´é™ä½é¢¨éšª

æ“ä½œç­–ç•¥
1. é€²å ´æ™‚æ©Ÿ: å›æ¸¬æ”¯æ’æ™‚åˆ†æ‰¹è²·é€²
2. åœæè¨­å®š: è·Œç ´é—œéµæ”¯æ’ä½
3. ç›®æ¨™åƒ¹ä½: æŠ€è¡“ç›®æ¨™åƒ¹ä½
4. æŒè‚¡æ¯”ä¾‹: å»ºè­°æ§åˆ¶åœ¨ç¸½è³‡ç”¢10%ä»¥å…§

ä»¥ä¸Šåˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°

æ•¸æ“šä¾†æº
æœ¬åˆ†ææ•´åˆäº†: æŠ€è¡“æŒ‡æ¨™æ•¸æ“š, å¸‚å ´æ‘˜è¦åˆ†æ, ç†±é–€è©±é¡Œæ•¸æ“š
"""
    
    return {
        "kol_id": f"kol_{persona['name']}",
        "kol_name": persona['name'],
        "stock_id": stock_id,
        "content_type": content_style,
        "title": title,
        "content_md": content_md,
        "key_points": [
            "æŠ€è¡“é¢å¼·å‹¢çªç ´",
            "å¤šé ­è¨Šè™Ÿç¢ºèª", 
            "åƒ¹æ¼²é‡å¢æ ¼å±€",
            "é€¢ä½å¸ƒå±€ç­–ç•¥"
        ],
        "investment_advice": {
            "recommendation": "buy",
            "confidence": 0.8,
            "target_price": "æŠ€è¡“ç›®æ¨™åƒ¹",
            "stop_loss": "é—œéµæ”¯æ’ä½"
        },
        "engagement_prediction": 0.75,
        "created_at": datetime.now().isoformat()
    }

def enhance_content_with_news(kol_content: Dict, topic: Dict, news_items: List[Dict]) -> Dict:
    """æ•´åˆæ–°èç´ æåˆ°KOLå…§å®¹ä¸­"""
    
    enhanced_content = kol_content.copy()
    
    # ç¢ºä¿ content_md å­˜åœ¨
    if "content_md" not in enhanced_content:
        enhanced_content["content_md"] = ""
    
    # åœ¨å…§å®¹ä¸­åŠ å…¥æ–°èç´ æ
    if news_items:
        news_section = "\n\nç›¸é—œæ–°èç´ æ\n"
        news_sources = []
        for i, news in enumerate(news_items[:5], 1):  # å–å‰5å‰‡æ–°è
            news_section += f"{news['title']}: {news['summary'][:100]}...\n\n"
            news_sources.append(f"{i}. {news['title']}\n   [é–±è®€æ›´å¤š]({news['url']})")
        
        # åœ¨å…§å®¹æœ«å°¾åŠ å…¥æ–°èç´ æ
        enhanced_content["content_md"] += news_section
        
        # æ·»åŠ æ–°èä¾†æºåˆ°æœ€å¾Œ - é¿å…é‡è¤‡æ·»åŠ 
        if news_sources:
            # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰æ–°èä¾†æº
            if "æ–°èä¾†æº:" not in enhanced_content["content_md"]:
                sources_section = "\n\næ–°èä¾†æº:\n" + "\n".join(news_sources)
                enhanced_content["content_md"] += sources_section
            else:
                print("âš ï¸ å…§å®¹ä¸­å·²åŒ…å«æ–°èä¾†æºï¼Œè·³éé‡è¤‡æ·»åŠ ")
        
        # æ›´æ–°é—œéµé»
        if "key_points" in enhanced_content:
            enhanced_content["key_points"].append("æ•´åˆæœ€æ–°æ–°èç´ æ")
        else:
            enhanced_content["key_points"] = ["æ•´åˆæœ€æ–°æ–°èç´ æ"]
    
    # åŠ å…¥è©±é¡Œæ¨™ç±¤
    if topic.get("title"):
        enhanced_content["content_md"] += f"\n\n---\n*å›æ‡‰ç†±é–€è©±é¡Œï¼š{topic['title']}*"
    
    return enhanced_content

async def post_to_platform(content: Dict, topic: Dict):
    """ç™¼æ–‡åˆ°æŒ‡å®šå¹³å° (æ¨¡æ“¬)"""
    
    # é€™è£¡å¯ä»¥æ•´åˆå¯¦éš›çš„ç™¼æ–‡å¹³å°API
    # ä¾‹å¦‚ï¼šTwitter API, LinkedIn API, æˆ–è‡ªå»ºå¹³å°
    
    post_data = {
        "content": content["content_md"],
        "title": content["title"],
        "stock_id": content["stock_id"],
        "kol_id": content["kol_id"],
        "topic_id": topic.get("id", "unknown"),
        "timestamp": datetime.now().isoformat()
    }
    
    # æ¨¡æ“¬ç™¼æ–‡æˆåŠŸ
    print(f"ğŸ“ ç™¼æ–‡æˆåŠŸ: {content['title']}")
    print(f"ğŸ“Š è‚¡ç¥¨: {content['stock_id']}")
    print(f"ğŸ‘¤ KOL: {content['kol_name']}")
    print(f"ğŸ”— è©±é¡Œ: {topic.get('title', 'N/A')}")
    
    # å¯¦éš›æ•´åˆæ™‚ï¼Œé€™è£¡æœƒèª¿ç”¨ç™¼æ–‡å¹³å°API
    # response = requests.post("https://api.twitter.com/2/tweets", json=post_data)
    
    return {"success": True, "post_id": f"post_{datetime.now().strftime('%Y%m%d_%H%M%S')}"}

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now(),
        "services": {
            "trending_api": "connected",
            "summary_api": "connected",
            "ohlc_api": "connected"
        }
    }

@app.get("/trending/preview")
async def preview_trending_content():
    """é è¦½ç†±é–€è©±é¡Œå…§å®¹"""
    
    try:
        # ç²å–ç†±é–€è©±é¡Œ
        trending_response = requests.get(f"{TRENDING_API_URL}/trending", params={"limit": 3})
        trending_response.raise_for_status()
        trending_topics = trending_response.json()
        
        # ç²å–ç†±é–€è‚¡ç¥¨
        stocks_response = requests.get(f"{TRENDING_API_URL}/trending/stocks", params={"limit": 5})
        stocks_response.raise_for_status()
        trending_stocks = stocks_response.json()
        
        return {
            "topics": trending_topics.get("topics", []),
            "stocks": trending_stocks.get("stocks", []),
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        return {"error": str(e), "timestamp": datetime.now()}

# ==================== KOLæ†‘è­‰ç®¡ç† ====================

class KOLCredentialManager:
    """KOLæ†‘è­‰ç®¡ç†å™¨"""
    
    def __init__(self):
        # ä½¿ç”¨ KOL æœå‹™è¼‰å…¥æ†‘è­‰
        self.kol_credentials = {}
        self.kol_tokens = {}
        self._load_kol_credentials()
        
        print("ğŸ” KOLæ†‘è­‰ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_kol_credentials(self):
        """å¾ KOL æœå‹™è¼‰å…¥æ†‘è­‰"""
        try:
            from kol_service import kol_service
            
            # ç²å–æ‰€æœ‰ KOL æ†‘è­‰
            for serial in kol_service.get_all_kol_serials():
                creds = kol_service.get_kol_credentials(serial)
                if creds:
                    self.kol_credentials[str(serial)] = {
                        "email": creds["email"],
                        "password": creds["password"],
                        "member_id": creds["member_id"]
                    }
                    print(f"è¼‰å…¥KOLæ†‘è­‰: {serial} - {creds['email']}")
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.kol_credentials)} å€‹KOLæ†‘è­‰")
            
        except Exception as e:
            print(f"âŒ å¾KOLæœå‹™è¼‰å…¥æ†‘è­‰å¤±æ•—: {e}")
            # ä½¿ç”¨é è¨­æ†‘è­‰ä½œç‚ºå‚™ç”¨
            self.kol_credentials = {
                "200": {"email": "forum_200@cmoney.com.tw", "password": "N9t1kY3x", "member_id": "9505546"},
                "201": {"email": "forum_201@cmoney.com.tw", "password": "m7C1lR4t", "member_id": "9505547"},
                "202": {"email": "forum_202@cmoney.com.tw", "password": "x2U9nW5p", "member_id": "9505548"},
                "203": {"email": "forum_203@cmoney.com.tw", "password": "D8k9mN2p", "member_id": "9505549"},
                "204": {"email": "forum_204@cmoney.com.tw", "password": "D8k9mN2p", "member_id": "9505550"},
                "205": {"email": "forum_205@cmoney.com.tw", "password": "Z5u6dL9o", "member_id": "9505551"},
                "206": {"email": "forum_206@cmoney.com.tw", "password": "T1t7kS9j", "member_id": "9505552"},
                "207": {"email": "forum_207@cmoney.com.tw", "password": "w2B3cF6l", "member_id": "9505553"},
                "208": {"email": "forum_208@cmoney.com.tw", "password": "q4N8eC7h", "member_id": "9505554"}
            }
            print("ä½¿ç”¨é è¨­KOLæ†‘è­‰é…ç½®")
    
    def get_kol_credentials(self, kol_serial: str) -> Optional[Dict[str, str]]:
        """ç²å–KOLæ†‘è­‰"""
        return self.kol_credentials.get(str(kol_serial))
    
    async def login_kol(self, kol_serial: str) -> Optional[str]:
        """ç™»å…¥KOLä¸¦è¿”å›access token"""
        try:
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰æœ‰æ•ˆtoken
            if kol_serial in self.kol_tokens:
                token_data = self.kol_tokens[kol_serial]
                if token_data.get('expires_at') and datetime.now() < token_data['expires_at']:
                    print(f"âœ… ä½¿ç”¨å¿«å–çš„KOL {kol_serial} token")
                    return token_data['token']
            
            # ç²å–æ†‘è­‰
            creds = self.get_kol_credentials(kol_serial)
            if not creds:
                print(f"âŒ æ‰¾ä¸åˆ°KOL {kol_serial} çš„æ†‘è­‰")
                return None
            
            print(f"ğŸ” é–‹å§‹ç™»å…¥KOL {kol_serial}...")
            
            # ä½¿ç”¨CMoney Clientç™»å…¥
            from src.clients.cmoney.cmoney_client import CMoneyClient, LoginCredentials
            cmoney_client = CMoneyClient()
            credentials = LoginCredentials(
                email=creds['email'],
                password=creds['password']
            )
            
            access_token = await cmoney_client.login(credentials)
            
            if access_token and access_token.token:
                # å¿«å–token
                self.kol_tokens[kol_serial] = {
                    'token': access_token.token,
                    'expires_at': access_token.expires_at
                }
                print(f"âœ… KOL {kol_serial} ç™»å…¥æˆåŠŸ")
                return access_token.token
            else:
                print(f"âŒ KOL {kol_serial} ç™»å…¥å¤±æ•—")
                return None
                
        except Exception as e:
            print(f"âŒ KOL {kol_serial} ç™»å…¥ç•°å¸¸: {e}")
            return None

# å…¨åŸŸKOLæ†‘è­‰ç®¡ç†å™¨
kol_credential_manager = KOLCredentialManager()


@app.get("/posts")
async def get_all_posts(skip: int = 0, limit: int = 1000, status: Optional[str] = None):
    """ç²å–æ‰€æœ‰è²¼æ–‡"""
    try:
        posts = get_post_record_service().get_all_posts()
        
        # æ ¹æ“šç‹€æ…‹ç¯©é¸
        if status:
            posts = [post for post in posts if post.status == status]
        
        # åˆ†é 
        total = len(posts)
        posts = posts[skip:skip + limit]
        
        return {
            "posts": posts,
            "count": total,
            "skip": skip,
            "limit": limit
        }
    except Exception as e:
        print(f"ç²å–è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–è²¼æ–‡å¤±æ•—: {str(e)}")


@app.get("/posts/pending-review")
async def get_pending_review_posts():
    """ç²å–å¾…å¯©æ ¸çš„è²¼æ–‡åˆ—è¡¨"""
    try:
        posts = get_post_record_service().get_pending_review_posts()
        print(f"æ‰¾åˆ° {len(posts)} ç¯‡å¾…å¯©æ ¸è²¼æ–‡")
        for post in posts:
            print(f"  - {post.post_id}: {post.title} (ç‹€æ…‹: {post.status})")
        
        return {
            "success": True,
            "posts": posts,
            "count": len(posts),
            "timestamp": datetime.now()
        }
    except Exception as e:
        print(f"ç²å–å¾…å¯©æ ¸è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/posts/review-sidebar")
async def get_review_sidebar_data():
    """ç²å–ç™¼æ–‡å¯©æ ¸ sidebar é é¢æ‰€éœ€çš„æ•¸æ“š"""
    try:
        # ç²å–æ‰€æœ‰å¾…å¯©æ ¸è²¼æ–‡
        pending_posts = get_post_record_service().get_pending_review_posts()
        
        # æŒ‰ session åˆ†çµ„
        session_groups = {}
        for post in pending_posts:
            session_id = post.session_id
            if session_id not in session_groups:
                session_groups[session_id] = []
            session_groups[session_id].append(post)
        
        # çµ±è¨ˆæ•¸æ“š
        stats = {
            "total_pending": len(pending_posts),
            "sessions_count": len(session_groups),
            "latest_session": max(session_groups.keys()) if session_groups else None,
            "oldest_pending": min([post.created_at for post in pending_posts]) if pending_posts else None
        }
        
        # æº–å‚™ sidebar æ•¸æ“š
        sidebar_data = {
            "sessions": []
        }
        
        for session_id, posts in session_groups.items():
            session_info = {
                "session_id": session_id,
                "posts_count": len(posts),
                "latest_post": max([post.created_at for post in posts]),
                "kol_personas": list(set([post.kol_persona for post in posts])),
                "stock_codes": list(set([post.stock_code for post in posts if post.stock_code])),
                "posts": posts
            }
            sidebar_data["sessions"].append(session_info)
        
        # æŒ‰æœ€æ–°è²¼æ–‡æ™‚é–“æ’åº
        sidebar_data["sessions"].sort(key=lambda x: x["latest_post"], reverse=True)
        
        return {
            "success": True,
            "stats": stats,
            "sidebar_data": sidebar_data,
            "timestamp": datetime.now()
        }
        
    except Exception as e:
        print(f"ç²å–å¯©æ ¸ sidebar æ•¸æ“šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/serper/test")
async def test_serper_api():
    """æ¸¬è©¦Serper APIé€£æ¥"""
    try:
        print("ğŸ” æ¸¬è©¦Serper APIé€£æ¥...")
        
        # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
        serper_api_key = os.getenv('SERPER_API_KEY')
        print(f"ğŸ”‘ SERPER_API_KEY ç‹€æ…‹: {'å·²è¨­å®š' if serper_api_key else 'æœªè¨­å®š'}")
        
        if not serper_api_key:
            return {
                "success": False,
                "error": "SERPER_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š",
                "timestamp": datetime.now().isoformat()
            }
        
        # æ¸¬è©¦APIé€£æ¥
        from serper_integration import serper_service
        
        # æ¸¬è©¦æœå°‹åŠŸèƒ½
        test_result = serper_service.search_stock_news("2330", "å°ç©é›»", limit=2, time_range="d2")
        
        return {
            "success": True,
            "api_key_configured": True,
            "test_query": "å°ç©é›» 2330 æ–°è æœ€æ–°",
            "results_count": len(test_result),
            "sample_results": test_result[:2] if test_result else [],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ Serper APIæ¸¬è©¦å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
            "api_key_configured": bool(os.getenv('SERPER_API_KEY')),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/posts/debug")
async def debug_posts():
    """èª¿è©¦ç«¯é»ï¼šæª¢æŸ¥æ‰€æœ‰è²¼æ–‡"""
    try:
        # ç²å–æ‰€æœ‰è²¼æ–‡
        all_posts = get_post_record_service().get_all_posts()
        print(f"è³‡æ–™åº«ä¸­å…±æœ‰ {len(all_posts)} ç¯‡è²¼æ–‡")
        
        # æŒ‰ç‹€æ…‹åˆ†çµ„
        status_groups = {}
        for post in all_posts:
            status = str(post.status)  # ç›´æ¥è½‰æ›ç‚ºå­—ç¬¦ä¸²
            if status not in status_groups:
                status_groups[status] = []
            status_groups[status].append(post)
        
        print("æŒ‰ç‹€æ…‹åˆ†çµ„:")
        for status, posts in status_groups.items():
            print(f"  {status}: {len(posts)} ç¯‡")
            for post in posts[:3]:  # åªé¡¯ç¤ºå‰3ç¯‡
                print(f"    - {post.post_id}: {post.title}")
        
        return {
            "success": True,
            "total_posts": len(all_posts),
            "posts_by_status": {status: len(posts) for status, posts in status_groups.items()},
            "posts": all_posts,
            "timestamp": datetime.now()
        }
    except Exception as e:
        print(f"èª¿è©¦è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/debug/data-source-assignment")
async def debug_data_source_assignment():
    """èª¿è©¦æ•¸æ“šæºåˆ†é…åŠŸèƒ½"""
    try:
        from smart_data_source_assigner import smart_assigner, KOLProfile, StockProfile
        
        # æ¸¬è©¦KOLé…ç½®
        test_kol = KOLProfile(
            serial=150,
            nickname="æ¸¬è©¦KOL",
            persona="technical",
            expertise_areas=["æŠ€è¡“åˆ†æ"],
            content_style="chart_analysis",
            target_audience="active_traders"
        )
        
        # æ¸¬è©¦è‚¡ç¥¨é…ç½®
        test_stock = StockProfile(
            stock_code="2208",
            stock_name="å°èˆ¹",
            industry="èˆªé‹",
            market_cap="medium",
            volatility="high",
            news_frequency="high"
        )
        
        # åŸ·è¡Œæ•¸æ“šæºåˆ†é…
        assignment = smart_assigner.assign_data_sources(
            kol_profile=test_kol,
            stock_profile=test_stock,
            batch_context={'trigger_type': 'after_hours_limit_up'}
        )
        
        return {
            "success": True,
            "kol_profile": {
                "serial": test_kol.serial,
                "nickname": test_kol.nickname,
                "persona": test_kol.persona
            },
            "stock_profile": {
                "stock_code": test_stock.stock_code,
                "stock_name": test_stock.stock_name,
                "market_cap": test_stock.market_cap,
                "volatility": test_stock.volatility
            },
            "data_source_assignment": {
                "primary_sources": [source.value for source in assignment.primary_sources],
                "secondary_sources": [source.value for source in assignment.secondary_sources],
                "excluded_sources": [source.value for source in assignment.excluded_sources],
                "assignment_reason": assignment.assignment_reason,
                "confidence_score": assignment.confidence_score
            }
        }
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šæºåˆ†é…èª¿è©¦å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/debug/data-source-usage")
async def debug_data_source_usage():
    """èª¿è©¦æ•¸æ“šæºå¯¦éš›ä½¿ç”¨æƒ…æ³"""
    try:
        # ç²å–æœ€è¿‘çš„è²¼æ–‡
        all_posts = get_post_record_service().get_all_posts()
        recent_posts = sorted(all_posts, key=lambda x: x.created_at, reverse=True)[:5]
        
        usage_analysis = []
        
        for post in recent_posts:
            # è§£æç”Ÿæˆåƒæ•¸
            generation_params = post.generation_params or {}
            if hasattr(generation_params, '__dict__'):
                generation_params = generation_params.__dict__
            
            data_sources = generation_params.get('data_sources', {})
            smart_assigned = generation_params.get('smart_assigned', [])
            assignment_reason = generation_params.get('assignment_reason', '')
            
            usage_analysis.append({
                "post_id": post.post_id,
                "title": post.title,
                "stock_code": post.stock_code,
                "kol_serial": post.kol_serial,
                "generation_params": {
                    "data_sources": data_sources,
                    "smart_assigned": smart_assigned,
                    "assignment_reason": assignment_reason
                },
                "content_preview": post.content[:200] + "..." if len(post.content) > 200 else post.content
            })
        
        return {
            "success": True,
            "total_posts": len(all_posts),
            "recent_posts_analysis": usage_analysis,
            "data_source_summary": {
                "smart_assignment_used": sum(1 for post in recent_posts 
                                           if post.generation_params and 
                                           hasattr(post.generation_params, 'smart_assigned')),
                "batch_data_sources_used": sum(1 for post in recent_posts 
                                              if post.generation_params and 
                                              hasattr(post.generation_params, 'data_sources')),
                "assignment_reasons_count": len(set(getattr(post.generation_params, 'assignment_reason', '') 
                                                   for post in recent_posts 
                                                   if post.generation_params))
            }
        }
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šæºä½¿ç”¨æƒ…æ³èª¿è©¦å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/posts/session/{session_id}")
async def get_session_posts(session_id: int, status: Optional[str] = None):
    """ç²å–æœƒè©±çš„æ‰€æœ‰è²¼æ–‡"""
    try:
        print(f"ğŸ” ç²å–æœƒè©±è²¼æ–‡: session_id={session_id}, status={status}")
        posts = get_post_record_service().get_session_posts(session_id, status)
        print(f"âœ… æ‰¾åˆ° {len(posts)} ç¯‡è²¼æ–‡")
        
        # å°‡ PostRecord å°è±¡è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„å­—å…¸
        posts_data = []
        for post in posts:
            post_data = {
                "post_id": post.post_id,
                "session_id": post.session_id,
                "kol_serial": post.kol_serial,
                "kol_nickname": post.kol_nickname,
                "kol_persona": post.kol_persona,
                "stock_code": post.stock_code,
                "stock_name": post.stock_name,
                "title": post.title,
                "content": post.content,
                "content_md": post.content_md,
                "status": post.status,
                "quality_score": post.quality_score,
                "ai_detection_score": post.ai_detection_score,
                "risk_level": post.risk_level,
                "reviewer_notes": post.reviewer_notes,
                "approved_by": post.approved_by,
                "approved_at": post.approved_at.isoformat() if post.approved_at else None,
                "scheduled_at": post.scheduled_at.isoformat() if post.scheduled_at else None,
                "published_at": post.published_at.isoformat() if post.published_at else None,
                "cmoney_post_id": post.cmoney_post_id,
                "cmoney_post_url": post.cmoney_post_url,
                "publish_error": post.publish_error,
                "views": post.views,
                "likes": post.likes,
                "comments": post.comments,
                "shares": post.shares,
                "topic_id": post.topic_id,
                "topic_title": post.topic_title,
                "alternative_versions": post.alternative_versions,  # æ–°å¢ï¼šå…¶ä»–ç‰ˆæœ¬
                "generation_params": post.generation_params,  # ğŸ”¥ æ–°å¢ï¼šç”Ÿæˆåƒæ•¸
                "trigger_type": post.generation_params.get('trigger_type') if post.generation_params else None,  # ğŸ”¥ æ–°å¢ï¼šè§¸ç™¼å™¨é¡å‹
                "created_at": post.created_at.isoformat() if post.created_at else None,
                "updated_at": post.updated_at.isoformat() if post.updated_at else None
            }
            posts_data.append(post_data)
        
        return {
            "success": True,
            "posts": posts_data,
            "count": len(posts_data),
            "session_id": session_id,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        print(f"âŒ ç²å–æœƒè©±è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/post/batch-generate-stream")
async def batch_generate_posts_stream(request: BatchPostRequest):
    """
    æ‰¹é‡ç”Ÿæˆè²¼æ–‡ - ä½¿ç”¨Server-Sent Eventsä¸€å‰‡ä¸€å‰‡å›å‚³
    """
    print(f"ğŸš€ é–‹å§‹æ‰¹é‡ç™¼æ–‡ç”Ÿæˆ - æœƒè©±ID: {request.session_id}, è²¼æ–‡æ•¸é‡: {len(request.posts)}")
    
    # å°å…¥å¿…è¦çš„æ¨¡çµ„
    try:
        from smart_data_source_assigner import smart_assigner, KOLProfile, StockProfile
    except ImportError as e:
        print(f"âŒ å°å…¥æ¨¡çµ„å¤±æ•—: {e}")
        async def error_generator():
            yield f"data: {json.dumps({'type': 'error', 'error': f'å°å…¥æ¨¡çµ„å¤±æ•—: {e}'})}\n\n"
        return StreamingResponse(error_generator(), media_type="text/plain")
    
    async def generate_posts():
        total_posts = len(request.posts)
        successful_posts = 0
        failed_posts = 0
        
        print(f"ğŸ“Š æ‰¹é‡ç”Ÿæˆçµ±è¨ˆ: ç¸½æ•¸={total_posts}, æˆåŠŸ={successful_posts}, å¤±æ•—={failed_posts}")
        
        # ç”Ÿæˆ batch ç´šåˆ¥çš„å…±äº« commodity tags
        batch_commodity_tags = []
        
        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨ã€Œå…¨è²¼åŒç¾¤è‚¡æ¨™ã€
        should_use_shared_tags = False
        
        # å„ªå…ˆæª¢æŸ¥ tags_config ä¸­çš„ batch_shared_tags è¨­å®š
        if request.tags_config and request.tags_config.get('stock_tags', {}).get('batch_shared_tags', False):
            should_use_shared_tags = True
            print("ğŸ·ï¸ æ ¹æ“šå‰ç«¯æ¨™ç±¤é…ç½®å•Ÿç”¨å…¨è²¼åŒç¾¤è‚¡æ¨™")
        # å…¶æ¬¡æª¢æŸ¥ batch_config ä¸­çš„ shared_commodity_tags è¨­å®š
        elif request.batch_config.get('shared_commodity_tags', True):
            should_use_shared_tags = True
            print("ğŸ·ï¸ æ ¹æ“šæ‰¹é‡é…ç½®å•Ÿç”¨å…±äº«æ¨™ç±¤")
        
        if should_use_shared_tags:
            print("ğŸ·ï¸ ç”Ÿæˆ batch ç´šåˆ¥çš„å…±äº« commodity tags...")
            unique_stocks = set()
            for post_data in request.posts:
                stock_code = post_data.get('stock_code')
                if stock_code:
                    unique_stocks.add(stock_code)
            
            # ç‚ºæ‰€æœ‰è‚¡ç¥¨ç”Ÿæˆ commodity tags
            for stock_code in unique_stocks:
                batch_commodity_tags.append({
                    "type": "Stock",
                    "key": stock_code,
                    "bullOrBear": 0  # é è¨­ä¸­æ€§
                })
            
            print(f"âœ… ç”Ÿæˆ {len(batch_commodity_tags)} å€‹å…±äº« commodity tags: {[tag['key'] for tag in batch_commodity_tags]}")
        else:
            print("ğŸ·ï¸ æœªå•Ÿç”¨å…±äº«æ¨™ç±¤ï¼Œæ¯å€‹è²¼æ–‡å°‡ä½¿ç”¨ç¨ç«‹æ¨™ç±¤")
        
        # ç™¼é€é–‹å§‹äº‹ä»¶
        yield f"data: {json.dumps({'type': 'batch_start', 'total': total_posts, 'session_id': request.session_id, 'shared_tags_count': len(batch_commodity_tags)})}\n\n"
        
        for index, post_data in enumerate(request.posts):
            try:
                print(f"ğŸ“ é–‹å§‹ç”Ÿæˆç¬¬ {index + 1}/{total_posts} ç¯‡è²¼æ–‡...")
                
                # ç™¼é€é€²åº¦äº‹ä»¶
                progress = {
                    'type': 'progress',
                    'current': index + 1,
                    'total': total_posts,
                    'percentage': round((index + 1) / total_posts * 100, 1),
                    'successful': successful_posts,
                    'failed': failed_posts
                }
                yield f"data: {json.dumps(progress)}\n\n"
                
                # ç‚ºæ¯å€‹è²¼æ–‡æ™ºèƒ½åˆ†é…æ•¸æ“šæº
                print(f"ğŸ§  ç‚ºç¬¬ {index + 1} ç¯‡è²¼æ–‡æ™ºèƒ½åˆ†é…æ•¸æ“šæº...")
                
                # å‰µå»ºKOLå’Œè‚¡ç¥¨é…ç½®
                kol_profile = KOLProfile(
                    serial=int(post_data.get('kol_serial', 150)),
                    nickname=f"KOL-{post_data.get('kol_serial', 150)}",
                    persona=request.batch_config.get('kol_persona', 'technical'),
                    expertise_areas=[],
                    content_style=request.batch_config.get('content_style', 'chart_analysis'),
                    target_audience=request.batch_config.get('target_audience', 'active_traders')
                )
                
                stock_profile = StockProfile(
                    stock_code=post_data.get('stock_code'),
                    stock_name=post_data.get('stock_name'),
                    industry='unknown',
                    market_cap='medium',  # é è¨­ä¸­ç­‰å¸‚å€¼
                    volatility='medium',  # é è¨­ä¸­ç­‰æ³¢å‹•
                    news_frequency='medium'  # é è¨­ä¸­ç­‰æ–°èé »ç‡
                )
                
                # æ™ºèƒ½åˆ†é…æ•¸æ“šæº
                data_source_assignment = smart_assigner.assign_data_sources(
                    kol_profile=kol_profile,
                    stock_profile=stock_profile,
                    batch_context={'trigger_type': 'manual_batch'}
                )
                
                # åˆä½µæ™ºèƒ½åˆ†é…çš„æ•¸æ“šæºå’Œæ‰¹æ¬¡é…ç½®çš„æ•¸æ“šæº
                smart_sources = [source.value for source in data_source_assignment.primary_sources]
                batch_sources = request.data_sources or {}
                
                # å‰µå»ºæ··åˆæ•¸æ“šæºé…ç½® - å„ªå…ˆä½¿ç”¨æ™ºèƒ½åˆ†é…çš„æ•¸æ“šæº
                hybrid_data_sources = {
                    **batch_sources,  # æ‰¹æ¬¡é…ç½®çš„æ•¸æ“šæº
                    'smart_assigned': smart_sources,  # æ™ºèƒ½åˆ†é…çš„æ•¸æ“šæº
                    'assignment_reason': data_source_assignment.assignment_reason,
                    'confidence_score': data_source_assignment.confidence_score
                }
                
                # å¦‚æœæ™ºèƒ½åˆ†é…æœ‰æ•¸æ“šæºï¼Œå„ªå…ˆä½¿ç”¨æ™ºèƒ½åˆ†é…çš„
                if smart_sources:
                    # å°‡æ™ºèƒ½åˆ†é…çš„æ•¸æ“šæºè¨­ç‚ºä¸»è¦æ•¸æ“šæº
                    for source in smart_sources:
                        if source == 'ohlc_api':
                            hybrid_data_sources['stock_price_api'] = True
                        elif source == 'revenue_api':
                            hybrid_data_sources['monthly_revenue_api'] = True
                        elif source == 'fundamental_api':
                            hybrid_data_sources['fundamental_data'] = ['è²¡å ±']
                        elif source == 'serper_api':
                            hybrid_data_sources['news_sources'] = ['å·¥å•†æ™‚å ±', 'ç¶“æ¿Ÿæ—¥å ±', 'ä¸­å¤®ç¤¾']
                        elif source == 'summary_api':
                            hybrid_data_sources['technical_indicators'] = ['MACD', 'RSI', 'ç§»å‹•å¹³å‡ç·š']
                
                print(f"ğŸ“Š æ•¸æ“šæºåˆ†é…: æ™ºèƒ½={smart_sources}, æ‰¹æ¬¡={list(batch_sources.keys())}")
                
                # ç‚ºç†±é–€è©±é¡Œè§¸ç™¼å™¨å‹•æ…‹èª¿æ•´æœç´¢é—œéµå­—
                news_config = request.news_config.copy() if request.news_config else {}
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºç†±é–€è©±é¡Œè§¸ç™¼å™¨ä¸”æœ‰å…·é«”è©±é¡Œ
                topic_id = post_data.get('topic_id')
                topic_title = post_data.get('topic_title')
                
                if topic_id and topic_title:
                    print(f"ğŸ¯ ç‚ºè²¼æ–‡å‹•æ…‹èª¿æ•´æœç´¢é—œéµå­— - è©±é¡Œ: {topic_title}")
                    
                    # ç‚ºé€™å€‹ç‰¹å®šè©±é¡Œç”Ÿæˆæœç´¢é—œéµå­—
                    topic_keywords = [
                        {
                            "id": "1",
                            "keyword": "{stock_name}",
                            "type": "stock_name",
                            "description": "è‚¡ç¥¨åç¨±"
                        },
                        {
                            "id": f"topic_{topic_id}",
                            "keyword": topic_title,
                            "type": "trigger_keyword",
                            "description": f"ç†±é–€è©±é¡Œé—œéµå­—: {topic_title}"
                        }
                    ]
                    
                    news_config['search_keywords'] = topic_keywords
                    print(f"âœ… æ›´æ–°å¾Œçš„æœç´¢é—œéµå­—: {topic_keywords}")
                
                # ç”Ÿæˆå–®å€‹è²¼æ–‡
                post_request = PostingRequest(
                    stock_code=post_data.get('stock_code'),
                    stock_name=post_data.get('stock_name'),
                    kol_serial=post_data.get('kol_serial'),
                    kol_persona=request.batch_config.get('kol_persona', 'technical'),
                    content_style=request.batch_config.get('content_style', 'chart_analysis'),
                    target_audience=request.batch_config.get('target_audience', 'active_traders'),
                    batch_mode=True,
                    session_id=request.session_id,
                    data_sources=hybrid_data_sources,  # ä½¿ç”¨æ··åˆæ•¸æ“šæº
                    explainability_config=request.explainability_config,
                    news_config=news_config,  # ä½¿ç”¨å‹•æ…‹èª¿æ•´å¾Œçš„ news_config
                    tags_config=request.tags_config,  # å‚³éæ¨™ç±¤é…ç½®
                    shared_commodity_tags=batch_commodity_tags  # å‚³éå…±äº«çš„ commodity tags
                )
                
                print(f"âš™ï¸ èª¿ç”¨å–®å€‹è²¼æ–‡ç”ŸæˆAPI...")
                result = await manual_post_content(post_request)
                print(f"âœ… ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”Ÿæˆå®Œæˆ: {result.success}")
                
                # ç™¼é€è²¼æ–‡ç”Ÿæˆå®Œæˆäº‹ä»¶
                post_response = {
                    'type': 'post_generated',
                    'success': result.success,
                    'post_id': result.post_id,
                    'content': result.content,
                    'error': result.error,
                    'timestamp': result.timestamp.isoformat(),
                    'progress': {
                        'current': index + 1,
                        'total': total_posts,
                        'percentage': round((index + 1) / total_posts * 100, 1)
                    }
                }
                
                if result.success:
                    successful_posts += 1
                    print(f"âœ… ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”ŸæˆæˆåŠŸ: {result.post_id}")
                else:
                    failed_posts += 1
                    print(f"âŒ ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”Ÿæˆå¤±æ•—: {result.error}")
                
                yield f"data: {json.dumps(post_response)}\n\n"
                
                # æ·»åŠ å»¶é²ï¼Œé¿å…éæ–¼é »ç¹çš„è«‹æ±‚
                await asyncio.sleep(0.5)
                
            except Exception as e:
                failed_posts += 1
                print(f"âŒ ç¬¬ {index + 1} ç¯‡è²¼æ–‡ç”Ÿæˆç•°å¸¸: {e}")
                error_response = {
                    'type': 'post_error',
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat(),
                    'progress': {
                        'current': index + 1,
                        'total': total_posts,
                        'percentage': round((index + 1) / total_posts * 100, 1)
                    }
                }
                yield f"data: {json.dumps(error_response)}\n\n"
        
        # ç™¼é€å®Œæˆäº‹ä»¶
        print(f"ğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆ: ç¸½æ•¸={total_posts}, æˆåŠŸ={successful_posts}, å¤±æ•—={failed_posts}")
        final_result = {
            'type': 'batch_complete',
            'total': total_posts,
            'successful': successful_posts,
            'failed': failed_posts,
            'session_id': request.session_id,
            'timestamp': datetime.now().isoformat()
        }
        yield f"data: {json.dumps(final_result)}\n\n"
    
    return StreamingResponse(
        generate_posts(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

@app.post("/posts/{post_id}/approve")
async def approve_post(post_id: str, request: Request):
    """å¯©æ ¸é€šéè²¼æ–‡"""
    logger.info(f"ğŸ” é–‹å§‹è™•ç†è²¼æ–‡å¯©æ ¸è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        # è¨˜éŒ„è«‹æ±‚è©³æƒ…
        logger.info(f"ğŸ“ å¯©æ ¸è«‹æ±‚è©³æƒ… - Post ID: {post_id}")
        
        # æª¢æŸ¥è²¼æ–‡æ˜¯å¦å­˜åœ¨
        existing_post = get_post_record_service().get_post_record(post_id)
        if not existing_post:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            logger.info(f"ğŸ“Š ç›®å‰è³‡æ–™åº«ä¸­çš„è²¼æ–‡æ•¸é‡: {get_post_record_service().get_posts_count()}")
            logger.info(f"ğŸ“‹ è³‡æ–™åº«ä¸­çš„è²¼æ–‡ ID åˆ—è¡¨: ç„¡æ³•ç²å–ï¼ˆPostgreSQL æ¨¡å¼ï¼‰")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
        
        logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç•¶å‰ç‹€æ…‹: {existing_post.status}")
        
        # è§£æè«‹æ±‚å…§å®¹
        body = await request.json()
        reviewer_notes = body.get("reviewer_notes")
        approved_by = body.get("approved_by", "system")
        
        logger.info(f"ğŸ“ å¯©æ ¸åƒæ•¸ - å¯©æ ¸è€…: {approved_by}, å‚™è¨»: {reviewer_notes}")
        
        # å‰µå»ºæ›´æ–°è³‡æ–™
        update_data = {
            "status": "approved",
            "reviewer_notes": reviewer_notes,
            "approved_by": approved_by,
            "approved_at": datetime.now()
        }
        
        logger.info(f"ğŸ”„ é–‹å§‹æ›´æ–°è²¼æ–‡ç‹€æ…‹ - Post ID: {post_id}")
        
        # æ›´æ–°è²¼æ–‡è¨˜éŒ„
        post_record = get_post_record_service().update_post_record(post_id, update_data)
        
        if post_record:
            logger.info(f"âœ… è²¼æ–‡å¯©æ ¸æˆåŠŸ - Post ID: {post_id}, æ–°ç‹€æ…‹: {post_record.status}")
            logger.info(f"ğŸ“Š æ›´æ–°å¾Œè³‡æ–™åº«ç‹€æ…‹ - ç¸½è²¼æ–‡æ•¸: {get_post_record_service().get_posts_count()}")
            
            return {
                "success": True,
                "message": "è²¼æ–‡å¯©æ ¸é€šé",
                "post": {
                    "post_id": post_record.id,
                    "status": post_record.status,
                    "approved_by": post_record.approved_by,
                    "approved_at": post_record.approved_at.isoformat() if post_record.approved_at else None,
                    "reviewer_notes": post_record.reviewer_notes
                },
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ æ›´æ–°è²¼æ–‡å¤±æ•— - Post ID: {post_id}")
            raise HTTPException(status_code=500, detail="æ›´æ–°è²¼æ–‡å¤±æ•—")
            
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}, è©³æƒ…: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"âŒ å¯©æ ¸è²¼æ–‡æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        logger.error(f"ğŸ” éŒ¯èª¤é¡å‹: {type(e).__name__}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"å¯©æ ¸å¤±æ•—: {str(e)}")

@app.post("/posts/{post_id}/reject")
async def reject_post(post_id: str, request: Request):
    """æ‹’çµ•è²¼æ–‡"""
    logger.info(f"ğŸ” é–‹å§‹è™•ç†è²¼æ–‡æ‹’çµ•è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        # æª¢æŸ¥è²¼æ–‡æ˜¯å¦å­˜åœ¨
        existing_post = get_post_record_service().get_post_record(post_id)
        if not existing_post:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            logger.info(f"ğŸ“Š ç›®å‰è³‡æ–™åº«ä¸­çš„è²¼æ–‡æ•¸é‡: {get_post_record_service().get_posts_count()}")
            logger.info(f"ğŸ“‹ è³‡æ–™åº«ä¸­çš„è²¼æ–‡ ID åˆ—è¡¨: ç„¡æ³•ç²å–ï¼ˆPostgreSQL æ¨¡å¼ï¼‰")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
        
        logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç•¶å‰ç‹€æ…‹: {existing_post.status}")
        
        # è§£æè«‹æ±‚å…§å®¹
        body = await request.json()
        reviewer_notes = body.get("reviewer_notes", "æ‹’çµ•")
        
        logger.info(f"ğŸ“ æ‹’çµ•åƒæ•¸ - å‚™è¨»: {reviewer_notes}")
        
        # å‰µå»ºæ›´æ–°è³‡æ–™
        update_data = {
            "status": "rejected",
            "reviewer_notes": reviewer_notes,
            "approved_by": "system"
        }
        
        logger.info(f"ğŸ”„ é–‹å§‹æ›´æ–°è²¼æ–‡ç‹€æ…‹ç‚ºæ‹’çµ• - Post ID: {post_id}")
        
        # æ›´æ–°è²¼æ–‡è¨˜éŒ„
        post_record = get_post_record_service().update_post_record(post_id, update_data)
        
        if post_record:
            logger.info(f"âœ… è²¼æ–‡æ‹’çµ•æˆåŠŸ - Post ID: {post_id}, æ–°ç‹€æ…‹: {post_record.status}")
            return {
                "success": True,
                "message": "è²¼æ–‡å·²æ‹’çµ•",
                "post": {
                    "post_id": post_record.id,
                    "status": post_record.status,
                    "reviewer_notes": post_record.reviewer_notes
                },
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ æ›´æ–°è²¼æ–‡å¤±æ•— - Post ID: {post_id}")
            raise HTTPException(status_code=500, detail="æ›´æ–°è²¼æ–‡å¤±æ•—")
            
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}, è©³æƒ…: {e.detail}")
        raise e
    except Exception as e:
        logger.error(f"âŒ æ‹’çµ•è²¼æ–‡æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"æ‹’çµ•å¤±æ•—: {str(e)}")

@app.post("/posts/{post_id}/publish")
async def publish_post_to_cmoney(post_id: str, cmoney_config: Optional[Dict[str, Any]] = None):
    """ç™¼å¸ƒè²¼æ–‡åˆ°CMoney"""
    try:
        # ç²å–è²¼æ–‡è¨˜éŒ„
        post_record = get_post_record_service().get_post_record(post_id)
        if not post_record:
            raise HTTPException(status_code=404, detail="è²¼æ–‡ä¸å­˜åœ¨")
        
        if post_record.status not in ["approved", "draft"]:
            raise HTTPException(status_code=400, detail=f"è²¼æ–‡ç‹€æ…‹ç‚º {post_record.status}ï¼Œç„¡æ³•ç™¼æ–‡ã€‚åªæœ‰å·²å¯©æ ¸æˆ–è‰ç¨¿ç‹€æ…‹çš„è²¼æ–‡æ‰èƒ½ç™¼å¸ƒ")
        
        # ä½¿ç”¨ç™¼ä½ˆæœå‹™ç™¼ä½ˆè²¼æ–‡
        from publish_service import publish_service
        publish_result = await publish_service.publish_post(post_record)
        
        # æ›´æ–°è²¼æ–‡ç‹€æ…‹ç‚ºpublished
        update_data = {
            "status": "published",
            "published_at": datetime.now(),
            "cmoney_post_id": publish_result["post_id"],
            "cmoney_post_url": publish_result["post_url"]
        }
        
        updated_post = get_post_record_service().update_post_record(post_id, update_data)
        
        return publish_result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"ç™¼å¸ƒå¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
            "post_id": post_id,
            "timestamp": datetime.now().isoformat()
        }


@app.get("/posts/{post_id}")
async def get_post(post_id: str):
    """ç²å–å–®å€‹è²¼æ–‡è©³æƒ…"""
    logger.info(f"ğŸ” ç²å–è²¼æ–‡è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        post_record = get_post_record_service().get_post_record(post_id)
        if post_record:
            logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç‹€æ…‹: {post_record.status}")
            
            # å°‡è²¼æ–‡è¨˜éŒ„è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„å­—å…¸
            post_data = {
                "post_id": post_record.id,
                "session_id": post_record.session_id,
                "kol_serial": post_record.kol_serial,
                "kol_nickname": post_record.kol_nickname,
                "kol_persona": post_record.kol_persona,
                "stock_code": post_record.stock_code,
                "stock_name": post_record.stock_name,
                "title": post_record.title,
                "content": post_record.content,
                "content_md": post_record.content_md,
                "status": post_record.status,
                "quality_score": post_record.quality_score,
                "ai_detection_score": post_record.ai_detection_score,
                "risk_level": post_record.risk_level,
                "reviewer_notes": post_record.reviewer_notes,
                "approved_by": post_record.approved_by,
                "approved_at": post_record.approved_at.isoformat() if post_record.approved_at else None,
                "scheduled_at": post_record.scheduled_at.isoformat() if post_record.scheduled_at else None,
                "published_at": post_record.published_at.isoformat() if post_record.published_at else None,
                "cmoney_post_id": post_record.cmoney_post_id,
                "cmoney_post_url": post_record.cmoney_post_url,
                "publish_error": post_record.publish_error,
                "views": post_record.views,
                "likes": post_record.likes,
                "comments": post_record.comments,
                "shares": post_record.shares,
                "topic_id": post_record.topic_id,
                "topic_title": post_record.topic_title,
                "created_at": post_record.created_at.isoformat() if post_record.created_at else None,
                "updated_at": post_record.updated_at.isoformat() if post_record.updated_at else None
            }
            
            return {
                "success": True,
                "post": post_data,
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
            
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}")
        raise e
    except Exception as e:
        logger.error(f"âŒ ç²å–è²¼æ–‡æ™‚ç™¼ç”ŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"ç²å–è²¼æ–‡å¤±æ•—: {str(e)}")

@app.put("/posts/{post_id}/content")
async def update_post_content(post_id: str, content_data: dict):
    """æ›´æ–°è²¼æ–‡å…§å®¹ï¼ˆç”¨æ–¼ç‰ˆæœ¬é¸æ“‡ï¼‰"""
    logger.info(f"ğŸ”„ æ›´æ–°è²¼æ–‡å…§å®¹è«‹æ±‚ - Post ID: {post_id}")
    
    try:
        # æª¢æŸ¥è²¼æ–‡æ˜¯å¦å­˜åœ¨
        existing_post = get_post_record_service().get_post_record(post_id)
        if not existing_post:
            logger.error(f"âŒ è²¼æ–‡ä¸å­˜åœ¨ - Post ID: {post_id}")
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
        
        logger.info(f"âœ… æ‰¾åˆ°è²¼æ–‡ - Post ID: {post_id}, ç•¶å‰æ¨™é¡Œ: {existing_post.title}")
        
        # æº–å‚™æ›´æ–°æ•¸æ“š
        update_data = {
            'updated_at': datetime.now()
        }
        
        # æ›´æ–°æ¨™é¡Œ
        if 'title' in content_data:
            update_data['title'] = content_data['title']
            logger.info(f"ğŸ“ æ›´æ–°æ¨™é¡Œ: {content_data['title']}")
        
        # æ›´æ–°å…§å®¹
        if 'content' in content_data:
            update_data['content'] = content_data['content']
            logger.info(f"ğŸ“ æ›´æ–°å…§å®¹: {len(content_data['content'])} å­—ç¬¦")
        
        # æ›´æ–° Markdown å…§å®¹
        if 'content_md' in content_data:
            update_data['content_md'] = content_data['content_md']
        elif 'content' in content_data:
            # å¦‚æœæ²’æœ‰æä¾› content_mdï¼Œä½¿ç”¨ content ä½œç‚º content_md
            update_data['content_md'] = content_data['content']
        
        # æ›´æ–°è²¼æ–‡è¨˜éŒ„
        post_record = get_post_record_service().update_post_record(post_id, update_data)
        
        if post_record:
            logger.info(f"âœ… è²¼æ–‡å…§å®¹æ›´æ–°æˆåŠŸ - Post ID: {post_id}")
            return {
                "success": True,
                "message": "è²¼æ–‡å…§å®¹æ›´æ–°æˆåŠŸ",
                "post_id": post_id,
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ è²¼æ–‡å…§å®¹æ›´æ–°å¤±æ•— - Post ID: {post_id}")
            raise HTTPException(status_code=500, detail="æ›´æ–°å¤±æ•—")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°è²¼æ–‡å…§å®¹å¤±æ•— - Post ID: {post_id}, éŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±æ•—: {str(e)}")

@app.get("/posts/{post_id}/self-learning-data")
async def get_post_self_learning_data(post_id: str):
    """ç²å–è²¼æ–‡çš„è‡ªæˆ‘å­¸ç¿’æ•¸æ“š - ç”¨æ–¼é‡å»ºç›¸åŒå…§å®¹"""
    logger.info(f"ğŸ§  ç²å–è‡ªæˆ‘å­¸ç¿’æ•¸æ“š - Post ID: {post_id}")
    
    try:
        post_record = get_post_record_service().get_post_record(post_id)
        if not post_record:
            raise HTTPException(status_code=404, detail=f"è²¼æ–‡ä¸å­˜åœ¨: {post_id}")
        
        # æº–å‚™è‡ªæˆ‘å­¸ç¿’æ•¸æ“š
        self_learning_data = {
            "post_id": post_record.id,
            "session_id": post_record.session_id,
            "kol_serial": post_record.kol_serial,
            "kol_nickname": post_record.kol_nickname,
            "kol_persona": post_record.kol_persona,
            "stock_code": post_record.stock_code,
            "stock_name": post_record.stock_name,
            
            # ç”Ÿæˆåƒæ•¸ - ç”¨æ–¼é‡å»ºç›¸åŒå…§å®¹
            "generation_params": post_record.generation_params.model_dump() if post_record.generation_params else {},
            
            # æŠ€è¡“åˆ†ææ•¸æ“š
            "technical_analysis": post_record.technical_analysis,
            
            # Serper æ–°èæ•¸æ“š
            "serper_data": post_record.serper_data,
            
            # å•†å“æ¨™ç±¤
            "commodity_tags": [tag.model_dump() for tag in post_record.commodity_tags] if post_record.commodity_tags else [],
            
            # ç¤¾ç¾¤è©±é¡Œ
            "community_topic": post_record.community_topic.model_dump() if post_record.community_topic else None,
            
            # å“è³ªè©•ä¼°æ•¸æ“š
            "quality_score": post_record.quality_score,
            "ai_detection_score": post_record.ai_detection_score,
            "risk_level": post_record.risk_level,
            
            # æ™‚é–“æˆ³è¨˜
            "created_at": post_record.created_at.isoformat() if post_record.created_at else None,
            
            # é‡å»ºæ‰€éœ€çš„å…¶ä»–åƒæ•¸
            "content_length": post_record.generation_params.content_style if post_record.generation_params else "chart_analysis",
            "target_audience": post_record.generation_params.target_audience if post_record.generation_params else "active_traders",
            "data_sources": post_record.generation_params.data_sources if post_record.generation_params else [],
            "technical_indicators": post_record.generation_params.technical_indicators if post_record.generation_params else []
        }
        
        logger.info(f"âœ… è‡ªæˆ‘å­¸ç¿’æ•¸æ“šæº–å‚™å®Œæˆ - Post ID: {post_id}")
        logger.info(f"ğŸ“Š æ•¸æ“šåŒ…å«: generation_params={bool(self_learning_data['generation_params'])}, "
                   f"technical_analysis={bool(self_learning_data['technical_analysis'])}, "
                   f"serper_data={bool(self_learning_data['serper_data'])}")
        
        return {
            "success": True,
            "self_learning_data": self_learning_data,
            "reconstruction_ready": bool(
                self_learning_data['generation_params'] and 
                self_learning_data['stock_code'] and 
                self_learning_data['kol_persona']
            ),
            
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException as e:
        logger.error(f"âŒ HTTP ç•°å¸¸ - Post ID: {post_id}, ç‹€æ…‹ç¢¼: {e.status_code}")
        raise e
    except Exception as e:
        logger.error(f"âŒ ç²å–è‡ªæˆ‘å­¸ç¿’æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ - Post ID: {post_id}, éŒ¯èª¤: {str(e)}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"ç²å–è‡ªæˆ‘å­¸ç¿’æ•¸æ“šå¤±æ•—: {str(e)}")

@app.post("/test/kol-login/{kol_serial}")
async def test_kol_login(kol_serial: str):
    """æ¸¬è©¦ KOL ç™»å…¥åŠŸèƒ½"""
    logger.info(f"ğŸ” æ¸¬è©¦ KOL ç™»å…¥ - Serial: {kol_serial}")
    
    try:
        # ä½¿ç”¨ç™¼ä½ˆæœå‹™æ¸¬è©¦ç™»å…¥
        from publish_service import publish_service
        
        # æ¸¬è©¦ç™»å…¥
        access_token = await publish_service.login_kol(kol_serial)
        
        if access_token:
            logger.info(f"âœ… KOL {kol_serial} ç™»å…¥æ¸¬è©¦æˆåŠŸ")
            return {
                "success": True,
                "message": f"KOL {kol_serial} ç™»å…¥æˆåŠŸ",
                "has_token": bool(access_token),
                "token_preview": access_token[:20] + "..." if access_token else None,
                "timestamp": datetime.now().isoformat()
            }
        else:
            logger.error(f"âŒ KOL {kol_serial} ç™»å…¥æ¸¬è©¦å¤±æ•—")
            return {
                "success": False,
                "message": f"KOL {kol_serial} ç™»å…¥å¤±æ•—",
                "error": "ç„¡æ³•ç²å– access token",
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"âŒ KOL ç™»å…¥æ¸¬è©¦ç•°å¸¸: {e}")
        import traceback
        logger.error(f"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}")
        return {
            "success": False,
            "message": f"KOL {kol_serial} ç™»å…¥æ¸¬è©¦ç•°å¸¸",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# Delete API å·²ç§»è‡³ routes/cmoney_routes.py

# ==================== æ–°å¢çš„å…§å®¹ç”Ÿæˆå‡½æ•¸ ====================

def generate_kol_content_with_serper(stock_id: str, stock_name: str, kol_persona: str, 
                                    content_style: str, target_audience: str,
                                    serper_analysis: Dict[str, Any],
                                    data_sources: List[str]) -> Dict[str, Any]:
    """ä½¿ç”¨Serperæ•¸æ“šç”ŸæˆKOLå…§å®¹"""
    
    try:
        # æå–Serperæ•¸æ“š
        news_items = serper_analysis.get('news_items', [])
        limit_up_analysis = serper_analysis.get('limit_up_analysis', {})
        limit_up_reasons = limit_up_analysis.get('limit_up_reasons', [])
        key_events = limit_up_analysis.get('key_events', [])
        market_sentiment = limit_up_analysis.get('market_sentiment', 'neutral')
        
        # æ§‹å»ºå¢å¼·ç‰ˆPrompt
        prompt_parts = []
        
        # 1. åŸºæœ¬åˆ†ææ¡†æ¶ - ç´”æ–‡å­—æ ¼å¼
        prompt_parts.append(f"{stock_name}({stock_id}) æ·±åº¦åˆ†æå ±å‘Š")
        prompt_parts.append("")
        prompt_parts.append("æ ¸å¿ƒè§€é»")
        prompt_parts.append("")
        
        # 2. æ•´åˆæ¼²åœåŸå› åˆ†æ
        if limit_up_reasons:
            prompt_parts.append(f"åŸºæ–¼æœ€æ–°å¸‚å ´è³‡è¨Šï¼Œ{stock_name} ç›®å‰è™•æ–¼å¼·å‹¢ä¸Šæ¼²ç‹€æ…‹ï¼š")
            for reason in limit_up_reasons[:2]:  # å–å‰2å€‹åŸå› 
                prompt_parts.append(f"- {reason['title']}: {reason['snippet'][:150]}")
        else:
            prompt_parts.append(f"{stock_name} ç›®å‰è™•æ–¼æŠ€è¡“é¢å¼·å‹¢ç‹€æ…‹ï¼Œå¤šé …æŒ‡æ¨™é¡¯ç¤ºä¸Šæ¼²å‹•èƒ½ã€‚")
        
        prompt_parts.append("")
        
        # 3. æŠ€è¡“åˆ†æéƒ¨åˆ†
        if 'ohlc_api' in data_sources:
            prompt_parts.append("æŠ€è¡“é¢åˆ†æ")
            prompt_parts.append("- MA5/MA20: é»ƒé‡‘äº¤å‰ç¢ºèªå¤šé ­è¶¨å‹¢")
            prompt_parts.append("- RSI14: ä¸­æ€§åå¤šï¼Œä»æœ‰ä¸Šæ¼²ç©ºé–“")
            prompt_parts.append("- MACDæŸ±ç‹€é«”: å¤šé ­è¨Šè™ŸæŒçºŒ")
            prompt_parts.append("")
        
        # 4. åŸºæœ¬é¢åˆ†æéƒ¨åˆ†
        if 'fundamental_api' in data_sources:
            prompt_parts.append("åŸºæœ¬é¢åˆ†æ")
            if key_events:
                prompt_parts.append("é—œéµäº‹ä»¶åˆ†æ:")
                for event in key_events[:2]:
                    prompt_parts.append(f"- {event['event']}: {event['description'][:100]}")
            else:
                prompt_parts.append("- è²¡å‹™æŒ‡æ¨™ç©©å¥ï¼Œç‡Ÿæ”¶æˆé•·å‹•èƒ½å¼·å‹")
                prompt_parts.append("- ç”¢æ¥­å‰æ™¯çœ‹å¥½ï¼Œé•·æœŸæŠ•è³‡åƒ¹å€¼é¡¯ç¾")
            prompt_parts.append("")
        
        # 5. æ–°èæ•´åˆéƒ¨åˆ†
        if news_items and 'serper_api' in data_sources:
            prompt_parts.append("å¸‚å ´å‹•æ…‹")
            prompt_parts.append("æœ€æ–°å¸‚å ´è³‡è¨Š:")
            for news in news_items[:2]:  # å–å‰2å‰‡æ–°è
                prompt_parts.append(f"- {news['title']}: {news['snippet'][:150]}")
            prompt_parts.append("")
        
        # 6. æŠ•è³‡å»ºè­°
        prompt_parts.append("æŠ•è³‡å»ºè­°")
        if market_sentiment == 'positive':
            prompt_parts.append("åŸºæ–¼æŠ€è¡“é¢å’ŒåŸºæœ¬é¢åˆ†æï¼Œå»ºè­°ç©æ¥µå¸ƒå±€ï¼Œç›®æ¨™åƒ¹ä½å¯æœŸå¾…15-20%æ¼²å¹…ã€‚")
        elif market_sentiment == 'negative':
            prompt_parts.append("é›–ç„¶æŠ€è¡“é¢å¼·å‹¢ï¼Œä½†éœ€æ³¨æ„åŸºæœ¬é¢é¢¨éšªï¼Œå»ºè­°è¬¹æ…æ“ä½œï¼Œè¨­å¥½åœæé»ä½ã€‚")
        else:
            prompt_parts.append("åŸºæ–¼ç¶œåˆåˆ†æï¼Œå»ºè­°é€¢ä½å¸ƒå±€ï¼Œç›®æ¨™åƒ¹ä½å¯æœŸå¾…10-15%æ¼²å¹…ã€‚")
        prompt_parts.append("")
        
        # 7. é¢¨éšªæé†’
        prompt_parts.append("é¢¨éšªæé†’")
        prompt_parts.append("- æ³¨æ„å¤§ç›¤ç’°å¢ƒè®ŠåŒ–")
        prompt_parts.append("- è¨­å¥½åœæé»ä½")
        prompt_parts.append("- åˆ†æ‰¹é€²å ´é™ä½é¢¨éšª")
        prompt_parts.append("")
        
        # 8. æ“ä½œç­–ç•¥
        prompt_parts.append("æ“ä½œç­–ç•¥")
        prompt_parts.append("1. é€²å ´æ™‚æ©Ÿ: å›æ¸¬æ”¯æ’æ™‚åˆ†æ‰¹è²·é€²")
        prompt_parts.append("2. åœæè¨­å®š: è·Œç ´é—œéµæ”¯æ’ä½")
        prompt_parts.append("3. ç›®æ¨™åƒ¹ä½: æŠ€è¡“ç›®æ¨™åƒ¹ä½")
        prompt_parts.append("4. æŒè‚¡æ¯”ä¾‹: å»ºè­°æ§åˆ¶åœ¨ç¸½è³‡ç”¢10%ä»¥å…§")
        
        # 9. å…è²¬è²æ˜
        prompt_parts.append("")
        prompt_parts.append("ä»¥ä¸Šåˆ†æåƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°")
        prompt_parts.append("")
        
        # 10. æ•¸æ“šä¾†æºæ¨™è¨»
        prompt_parts.append("æ•¸æ“šä¾†æº")
        data_source_names = {
            'ohlc_api': 'æŠ€è¡“æŒ‡æ¨™æ•¸æ“š',
            'serper_api': 'æœ€æ–°æ–°èè³‡è¨Š',
            'fundamental_api': 'åŸºæœ¬é¢æ•¸æ“š',
            'summary_api': 'å¸‚å ´æ‘˜è¦åˆ†æ',
            'revenue_api': 'ç‡Ÿæ”¶æ•¸æ“š',
            'financial_api': 'è²¡å‹™æ•¸æ“š'
        }
        used_sources = [data_source_names.get(source, source) for source in data_sources]
        prompt_parts.append(f"æœ¬åˆ†ææ•´åˆäº†: {', '.join(used_sources)}")
        
        # çµ„åˆå®Œæ•´å…§å®¹
        content_md = "\n".join(prompt_parts)
        
        # ç”Ÿæˆæ¨™é¡Œ - ç´”æ–‡å­—æ ¼å¼
        title = f"{stock_name} æ·±åº¦åˆ†æ"
        
        return {
            "title": title,
            "content": content_md,
            "content_md": content_md,
            "stock_id": stock_id,
            "stock_name": stock_name,
            "kol_persona": kol_persona,
            "content_style": content_style,
            "target_audience": target_audience,
            "data_sources": data_sources,
            "serper_integration": True,
            "news_count": len(news_items),
            "market_sentiment": market_sentiment,
            "generation_timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"Serperå…§å®¹ç”Ÿæˆå¤±æ•—: {e}")
        # å›é€€åˆ°åŸºæœ¬å…§å®¹ç”Ÿæˆ
        return generate_kol_content_direct(stock_id, stock_name, kol_persona, content_style, target_audience)

def enhance_content_with_serper_data(kol_content: Dict[str, Any], 
                                   serper_analysis: Dict[str, Any],
                                   data_source_assignment) -> Dict[str, Any]:
    """ä½¿ç”¨Serperæ•¸æ“šå¢å¼·å…§å®¹"""
    
    try:
        enhanced_content = kol_content.copy()
        
        # ç²å–æ–°èæ•¸æ“š
        news_items = serper_analysis.get('news_items', [])
        limit_up_analysis = serper_analysis.get('limit_up_analysis', {})
        
        # å¦‚æœæœ‰æ–°èæ•¸æ“šï¼Œæ•´åˆåˆ°å…§å®¹ä¸­
        if news_items:
            # å¾ serper_analysis ç²å–æ–°èé€£çµé…ç½®ï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨é è¨­å€¼
            news_max_links = serper_analysis.get('news_max_links', 5)
            enable_news_links = serper_analysis.get('enable_news_links', True)
            
            if not enable_news_links:
                print("âš ï¸ æ–°èé€£çµå·²åœç”¨ï¼Œè·³éæ–°èä¾†æºæ•´åˆ")
                return enhanced_content
            
            print(f"ğŸ”— æ•´åˆ {len(news_items)} å‰‡æ–°èåˆ°å…§å®¹ä¸­ (æœ€å¤š {news_max_links} å‰‡)")
            
            # æå–æ–°èæ‘˜è¦å’Œé€£çµ
            news_summary = []
            news_sources = []
            print(f"ğŸ” è™•ç† {len(news_items)} å‰‡æ–°è...")
            for i, news in enumerate(news_items[:news_max_links]):  # æ ¹æ“šé…ç½®å–æ–°èæ•¸é‡
                title = news.get('title', '')
                snippet = news.get('snippet', '')
                link = news.get('link', '')
                print(f"  æ–°è {i+1}: title='{title[:30]}...', snippet='{snippet[:30]}...', link='{link[:30]}...'")
                if title and snippet:
                    # æ–°èæ‘˜è¦ï¼ˆç°¡åŒ–ç‰ˆï¼Œä¸åŒ…å«emojiå’Œmarkdownï¼‰
                    news_summary.append(f"{title}: {snippet[:100]}...")
                    # æ–°èä¾†æºï¼ˆç”¨æ–¼æœ€å¾Œçš„ä¾†æºåˆ—è¡¨ï¼‰
                    if link:
                        news_sources.append(f"{i+1}. {title}\n   é€£çµ: {link}")
                        print(f"    âœ… æ·»åŠ æ–°èä¾†æº {i+1} (æœ‰é€£çµ): {link}")
                    else:
                        news_sources.append(f"{i+1}. {title}")
                        print(f"    âœ… æ·»åŠ æ–°èä¾†æº {i+1} (ç„¡é€£çµ)")
                else:
                    print(f"    âŒ è·³éæ–°è {i+1} (æ¨™é¡Œæˆ–æ‘˜è¦ç‚ºç©º)")
            
            # æ•´åˆæ–°èåˆ°å…§å®¹ä¸­
            original_content = enhanced_content.get('content', '')
            original_content_md = enhanced_content.get('content_md', '')
            
            # ä¸æ·»åŠ æ–°èæ‘˜è¦åˆ°å…§å®¹é–‹é ­ï¼Œåªä¿ç•™åŸå§‹å…§å®¹
            enhanced_content['content'] = original_content
            enhanced_content['content_md'] = original_content_md
            
            # åœ¨å…§å®¹æœ€å¾Œæ·»åŠ æ–°èä¾†æº
            print(f"ğŸ” æ–°èä¾†æºåˆ—è¡¨: {len(news_sources)} å€‹")
            for i, source in enumerate(news_sources):
                print(f"   {i+1}. {source[:50]}...")
            
            if news_sources:
                # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰æ–°èä¾†æºï¼Œé¿å…é‡è¤‡æ·»åŠ 
                if "æ–°èä¾†æº:" not in enhanced_content['content']:
                    sources_section = "\n\næ–°èä¾†æº:\n" + "\n".join(news_sources)
                    enhanced_content['content'] += sources_section
                    enhanced_content['content_md'] += sources_section
                    print(f"âœ… æ–°èä¾†æºå·²æ·»åŠ : {len(sources_section)} å­—")
                else:
                    print("âš ï¸ å…§å®¹ä¸­å·²åŒ…å«æ–°èä¾†æºï¼Œè·³éé‡è¤‡æ·»åŠ ")
            else:
                print("âš ï¸ æ²’æœ‰æ–°èä¾†æºå¯æ·»åŠ ")
            
            print(f"âœ… æ–°èæ•´åˆå®Œæˆï¼Œå…§å®¹é•·åº¦: {len(enhanced_content['content'])} å­—")
        
        # æ·»åŠ Serperæ•¸æ“šåˆ°å…§å®¹ä¸­
        enhanced_content.update({
            "serper_data": serper_analysis,
            "data_source_assignment": {
                "primary_sources": [source.value for source in data_source_assignment.primary_sources],
                "secondary_sources": [source.value for source in data_source_assignment.secondary_sources],
                "assignment_reason": data_source_assignment.assignment_reason,
                "confidence_score": data_source_assignment.confidence_score
            },
            "news_integration": True,
            "limit_up_analysis": limit_up_analysis,
            "market_sentiment": limit_up_analysis.get('market_sentiment', 'neutral')
        })
        
        return enhanced_content
        
    except Exception as e:
        print(f"Serperæ•¸æ“šå¢å¼·å¤±æ•—: {e}")
        return kol_content

@app.post("/api/test-stock-filter")
async def test_stock_filter(trigger_type: str = "limit_up_after_hours", max_stocks: int = 5):
    """æ¸¬è©¦è‚¡ç¥¨ç¯©é¸æœå‹™"""
    try:
        from stock_filter_service import stock_filter_service
        
        stocks = await stock_filter_service.filter_stocks_by_trigger(
            trigger_type=trigger_type,
            max_stocks=max_stocks
        )
        
        return {
            "success": True,
            "trigger_type": trigger_type,
            "max_stocks": max_stocks,
            "stocks_count": len(stocks),
            "stocks": stocks
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

print("ğŸ‰ æ‰€æœ‰æ¨¡çµ„è¼‰å…¥å®Œæˆï¼")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)

