"""
æ’ç¨‹æœå‹™ - æ•´åˆè³‡æ–™åº«æŒä¹…åŒ–
"""

import asyncio
import uuid
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import logging
import pytz

from schedule_database import schedule_db_service
from timezone_utils import get_taiwan_utcnow

logger = logging.getLogger(__name__)

class ScheduleTask:
    """æ’ç¨‹ä»»å‹™"""
    def __init__(self, task_id: str, session_id: int, post_ids: List[str], 
                 schedule_type: str, interval_seconds: int = 30, 
                 batch_duration_hours: Optional[int] = None,
                 schedule_name: Optional[str] = None,
                 schedule_description: Optional[str] = None,
                 daily_execution_time: Optional[str] = None,
                 weekdays_only: bool = True,
                 max_posts_per_hour: int = 2,
                 timezone: str = 'Asia/Taipei',
                 generation_config: Optional[Dict[str, Any]] = None,
                 batch_info: Optional[Dict[str, Any]] = None):
        self.task_id = task_id
        self.session_id = session_id
        self.post_ids = post_ids
        self.schedule_type = schedule_type
        self.interval_seconds = interval_seconds
        self.batch_duration_hours = batch_duration_hours
        self.schedule_name = schedule_name
        self.schedule_description = schedule_description
        self.daily_execution_time = daily_execution_time
        self.weekdays_only = weekdays_only
        self.max_posts_per_hour = max_posts_per_hour
        self.timezone = timezone
        self.generation_config = generation_config or {}
        self.batch_info = batch_info or {}
        self.status = 'pending'
        self.created_at = get_taiwan_utcnow()
        self.started_at = None
        self.completed_at = None
        self.error_message = None
        self.last_run = None
        self.next_run = None
        self.run_count = 0
        self.success_count = 0
        self.failure_count = 0

class ScheduleService:
    """æ’ç¨‹æœå‹™ - æ•´åˆè³‡æ–™åº«æŒä¹…åŒ–"""
    
    def __init__(self):
        self.tasks: Dict[str, ScheduleTask] = {}
        self.running_tasks: Dict[str, asyncio.Task] = {}
        self.db_service = schedule_db_service
        self.background_scheduler_running = False
    
    async def create_schedule_task(self, session_id: int, post_ids: List[str],
                                 schedule_type: str, interval_seconds: int = 30,
                                 batch_duration_hours: Optional[int] = None,
                                 schedule_name: Optional[str] = None,
                                 schedule_description: Optional[str] = None,
                                 daily_execution_time: Optional[str] = None,
                                 weekdays_only: bool = True,
                                 max_posts_per_hour: int = 2,
                                 timezone: str = 'Asia/Taipei',
                                 generation_config: Optional[Dict[str, Any]] = None,
                                 batch_info: Optional[Dict[str, Any]] = None,
                                 # ğŸ”¥ FIX: Add trigger_config and schedule_config parameters
                                 trigger_config: Optional[Dict[str, Any]] = None,
                                 schedule_config: Optional[Dict[str, Any]] = None,
                                 auto_posting: bool = False,
                                 # ä¾†æºè¿½è¹¤åƒæ•¸
                                 source_type: Optional[str] = None,
                                 source_batch_id: Optional[str] = None,
                                 source_experiment_id: Optional[str] = None,
                                 source_feature_name: Optional[str] = None,
                                 created_by: str = 'system') -> str:
        """å‰µå»ºæ’ç¨‹ä»»å‹™ - æŒä¹…åŒ–åˆ°è³‡æ–™åº«"""
        
        # ğŸ”¥ æ·»åŠ è©³ç´°çš„å‰µå»ºæ—¥èªŒè¨˜éŒ„
        print(f"ğŸš€ğŸš€ğŸš€ é–‹å§‹å‰µå»ºæ’ç¨‹ä»»å‹™ ğŸš€ğŸš€ğŸš€")
        print(f"ğŸ“‹ å‰µå»ºåƒæ•¸:")
        print(f"   ğŸ“Š Session ID: {session_id}")
        print(f"   ğŸ“ æ’ç¨‹åç¨±: {schedule_name}")
        print(f"   ğŸ“ æ’ç¨‹æè¿°: {schedule_description}")
        print(f"   ğŸ• æ’ç¨‹é¡å‹: {schedule_type}")
        print(f"   â° åŸ·è¡Œæ™‚é–“: {daily_execution_time}")
        print(f"   ğŸ“… åƒ…å·¥ä½œæ—¥: {weekdays_only}")
        print(f"   ğŸ¤– è‡ªå‹•ç™¼æ–‡: {auto_posting}")
        print(f"   â±ï¸ é–“éš”ç§’æ•¸: {interval_seconds}")
        print(f"   ğŸ“ˆ æ¯å°æ™‚æœ€å¤§ç™¼æ–‡æ•¸: {max_posts_per_hour}")
        print(f"   ğŸŒ æ™‚å€: {timezone}")
        print(f"   ğŸ“¦ æ‰¹æ¬¡è³‡è¨Š: {batch_info}")
        print(f"   ğŸ¯ ç”Ÿæˆé…ç½®: {generation_config}")
        
        # ğŸ”¥ è©³ç´°åˆ†æç”Ÿæˆé…ç½®
        if generation_config:
            print(f"ğŸ” ç”Ÿæˆé…ç½®è©³æƒ…:")
            print(f"   ğŸ¯ è§¸ç™¼å™¨é¡å‹: {generation_config.get('trigger_type', 'N/A')}")
            print(f"   ğŸ“ ç™¼æ–‡é¡å‹: {generation_config.get('posting_type', 'N/A')}")
            print(f"   ğŸ“Š è‚¡ç¥¨æ’åº: {generation_config.get('stock_sorting', 'N/A')}")
            print(f"   ğŸ“ˆ æœ€å¤§è‚¡ç¥¨æ•¸: {generation_config.get('max_stocks', 'N/A')}")
            print(f"   ğŸ‘¥ KOLåˆ†é…: {generation_config.get('kol_assignment', 'N/A')}")
            print(f"   ğŸ¨ å…§å®¹é¢¨æ ¼: {generation_config.get('content_style', 'N/A')}")
            print(f"   ğŸ“ å…§å®¹é•·åº¦: {generation_config.get('content_length', 'N/A')}")
            print(f"   ğŸ“° æ–°èé€£çµ: {generation_config.get('enable_news_links', 'N/A')}")
            print(f"   ğŸ”§ ç”Ÿæˆæ¨¡å¼: {generation_config.get('generation_mode', 'N/A')}")
        else:
            print(f"âš ï¸ æ²’æœ‰æä¾›ç”Ÿæˆé…ç½®")
        # ç”Ÿæˆé è¨­æ’ç¨‹åç¨±
        if not schedule_name:
            # ä½¿ç”¨å°ç£æ™‚å€ç”Ÿæˆæ™‚é–“æˆ³
            tz = pytz.timezone('Asia/Taipei')
            taiwan_time = datetime.now(tz)
            timestamp = taiwan_time.strftime('%Y%m%d_%H%M%S')
            
            # æ ¹æ“šè§¸ç™¼å™¨é¡å‹å’Œè‚¡ç¥¨æ’åºç”Ÿæˆåç¨±
            if generation_config:
                trigger_type = generation_config.get('trigger_type', 'unknown')
                stock_sorting = generation_config.get('stock_sorting', 'unknown')
                
                # è§¸ç™¼å™¨é¡å‹æ˜ å°„
                trigger_map = {
                    'limit_up_after_hours': 'ç›¤å¾Œæ¼²',
                    'limit_down_after_hours': 'ç›¤å¾Œè·Œ',
                    'intraday_limit_up': 'ç›¤ä¸­æ¼²',
                    'intraday_limit_down': 'ç›¤ä¸­è·Œ',
                    'custom_stocks': 'è‡ªé¸è‚¡',
                    'news_hot': 'ç†±é–€æ–°è'
                }
                
                # è‚¡ç¥¨æ’åºæ˜ å°„
                sorting_map = {
                    'five_day_change_desc': 'äº”æ—¥æ¼²å¹…',
                    'change_percent_desc': 'æ¼²è·Œå¹…',
                    'volume_desc': 'æˆäº¤é‡',
                    'current_price_desc': 'è‚¡åƒ¹',
                    'market_cap_desc': 'å¸‚å€¼'
                }
                
                trigger_name = trigger_map.get(trigger_type, 'æœªçŸ¥è§¸ç™¼')
                sorting_name = sorting_map.get(stock_sorting, 'æœªçŸ¥æ’åº')
                
                schedule_name = f"{trigger_name}_{sorting_name}_{timestamp}"
            else:
                # æ ¹æ“šæ’ç¨‹é¡å‹ç”Ÿæˆæ›´å‹å¥½çš„åç¨±
                if schedule_type == 'weekday_daily':
                    schedule_name = f"å·¥ä½œæ—¥æ’ç¨‹_{timestamp}"
                elif schedule_type == '24hour_batch':
                    schedule_name = f"24å°æ™‚æ‰¹æ¬¡_{timestamp}"
                elif schedule_type == '5min_batch':
                    schedule_name = f"5åˆ†é˜æ‰¹æ¬¡_{timestamp}"
                elif schedule_type == 'immediate':
                    schedule_name = f"ç«‹å³åŸ·è¡Œ_{timestamp}"
                else:
                    schedule_name = f"æ’ç¨‹ä»»å‹™_{timestamp}"
        
        # å‰µå»ºè³‡æ–™åº«è¨˜éŒ„
        schedule_id = await self.db_service.create_schedule_task(
            schedule_name=schedule_name,
            schedule_description=schedule_description,
            session_id=session_id,
            schedule_type=schedule_type,
            interval_seconds=interval_seconds,
            batch_duration_hours=batch_duration_hours,
            daily_execution_time=daily_execution_time,
            weekdays_only=weekdays_only,
            max_posts_per_hour=max_posts_per_hour,
            timezone=timezone,
            generation_config=generation_config,
            batch_info=batch_info,
            # ğŸ”¥ FIX: Pass trigger_config and schedule_config to database
            trigger_config=trigger_config,
            schedule_config=schedule_config,
            auto_posting=auto_posting,
            # ä¾†æºè¿½è¹¤åƒæ•¸
            source_type=source_type,
            source_batch_id=source_batch_id,
            source_experiment_id=source_experiment_id,
            source_feature_name=source_feature_name,
            created_by=created_by
        )
        
        # å‰µå»ºè¨˜æ†¶é«”ä¸­çš„ä»»å‹™å°è±¡ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
        task = ScheduleTask(
            task_id=schedule_id,
            session_id=session_id,
            post_ids=post_ids,
            schedule_type=schedule_type,
            interval_seconds=interval_seconds,
            batch_duration_hours=batch_duration_hours,
            schedule_name=schedule_name,
            schedule_description=schedule_description,
            daily_execution_time=daily_execution_time,
            weekdays_only=weekdays_only,
            max_posts_per_hour=max_posts_per_hour,
            timezone=timezone,
            generation_config=generation_config,
            batch_info=batch_info
        )
        
        self.tasks[schedule_id] = task
        logger.info(f"âœ… æ’ç¨‹ä»»å‹™å‰µå»ºæˆåŠŸ - Schedule ID: {schedule_id}, Session ID: {session_id}")
        logger.info(f"ğŸ“‹ æ’ç¨‹é¡å‹: {schedule_type}, å·¥ä½œæ—¥åŸ·è¡Œ: {weekdays_only}")
        if daily_execution_time:
            logger.info(f"â° æ¯æ—¥åŸ·è¡Œæ™‚é–“: {daily_execution_time}")
        
        return schedule_id
    
    async def start_background_scheduler(self):
        """å•Ÿå‹•èƒŒæ™¯æ’ç¨‹å™¨ï¼Œè‡ªå‹•å•Ÿå‹•æ‰€æœ‰ active æ’ç¨‹"""
        logger.info("ğŸš€ğŸš€ğŸš€ é–‹å§‹å•Ÿå‹•èƒŒæ™¯æ’ç¨‹å™¨ ğŸš€ğŸš€ğŸš€")
        
        if self.background_scheduler_running:
            logger.warning("âš ï¸ èƒŒæ™¯æ’ç¨‹å™¨å·²åœ¨é‹è¡Œä¸­ï¼Œè·³éå•Ÿå‹•")
            return
        
        self.background_scheduler_running = True
        logger.info("ğŸ”„ å•Ÿå‹•èƒŒæ™¯æ’ç¨‹å™¨ç‹€æ…‹: STARTING")
        
        try:
            # ç²å–æ‰€æœ‰ active æ’ç¨‹ä»»å‹™
            logger.info("ğŸ“Š æ­£åœ¨ç²å–æ‰€æœ‰ active æ’ç¨‹ä»»å‹™...")
            active_tasks = await self.db_service.get_active_schedule_tasks()
            logger.info(f"ğŸ“‹ è³‡æ–™åº«ä¸­ç™¼ç¾ {len(active_tasks)} å€‹ active æ’ç¨‹ä»»å‹™")
            
            if len(active_tasks) == 0:
                logger.info("âœ… æ²’æœ‰ active æ’ç¨‹ä»»å‹™ï¼ŒèƒŒæ™¯æ’ç¨‹å™¨ç©ºè½‰ç­‰å¾…")
                # æŒçºŒç­‰å¾…ï¼Œæ¯å°æ™‚æª¢æŸ¥ä¸€æ¬¡
                while self.background_scheduler_running:
                    await asyncio.sleep(3600)  # ç­‰å¾… 1 å°æ™‚
                    active_tasks = await self.db_service.get_active_schedule_tasks()
                    if len(active_tasks) > 0:
                        logger.info(f"ğŸ“‹ ç™¼ç¾æ–°çš„ active æ’ç¨‹ä»»å‹™: {len(active_tasks)} å€‹")
                        break
                return
            
            # å•Ÿå‹•æ‰€æœ‰ active æ’ç¨‹
            success_count = 0
            failure_count = 0
            
            for idx, task in enumerate(active_tasks, 1):
                task_id = task['schedule_id']
                schedule_name = task.get('schedule_name', 'Unknown')
                schedule_type = task.get('schedule_type', 'Unknown')
                daily_execution_time = task.get('daily_execution_time', 'Not Set')
                
                logger.info(f"ğŸ” è™•ç†æ’ç¨‹ä»»å‹™ {idx}/{len(active_tasks)}:")
                logger.info(f"   ğŸ“‹ Task ID: {task_id}")
                logger.info(f"   ğŸ“ æ’ç¨‹åç¨±: {schedule_name}")
                logger.info(f"   ğŸ• æ’ç¨‹é¡å‹: {schedule_type}")
                logger.info(f"   â° åŸ·è¡Œæ™‚é–“: {daily_execution_time}")
                logger.info(f"   ğŸ”„ ç‹€æ…‹: {task.get('status', 'Unknown')}")
                logger.info(f"   ğŸ“Š Session ID: {task.get('session_id', 'N/A')}")
                logger.info(f"   ğŸŒ æ™‚å€: {task.get('timezone', 'N/A')}")
                logger.info(f"   ğŸ“… åƒ…å·¥ä½œæ—¥: {task.get('weekdays_only', 'N/A')}")
                logger.info(f"   ğŸ¤– è‡ªå‹•ç™¼æ–‡: {task.get('auto_posting', 'N/A')}")
                logger.info(f"   â±ï¸ é–“éš”ç§’æ•¸: {task.get('interval_seconds', 'N/A')}")
                logger.info(f"   ğŸ“ˆ æ¯å°æ™‚æœ€å¤§ç™¼æ–‡æ•¸: {task.get('max_posts_per_hour', 'N/A')}")
                logger.info(f"   ğŸƒ åŸ·è¡Œæ¬¡æ•¸: {task.get('run_count', 0)}")
                logger.info(f"   âœ… æˆåŠŸæ¬¡æ•¸: {task.get('success_count', 0)}")
                logger.info(f"   âŒ å¤±æ•—æ¬¡æ•¸: {task.get('failure_count', 0)}")
                logger.info(f"   ğŸ“ˆ æˆåŠŸç‡: {task.get('success_rate', 0)}%")
                logger.info(f"   ğŸ“ ä¸‹æ¬¡åŸ·è¡Œ: {task.get('next_run', 'Not Set')}")
                logger.info(f"   ğŸ“ æœ€å¾ŒåŸ·è¡Œ: {task.get('last_run', 'Never')}")
                
                # ğŸ”¥ è¨ˆç®—ä¸¦é¡¯ç¤ºé è¨ˆåŸ·è¡Œæ™‚é–“
                try:
                    next_run_time = await self._calculate_next_run_time(task)
                    if next_run_time:
                        tz_next_run = next_run_time.strftime('%Y-%m-%d %H:%M:%S %Z')
                        logger.info(f"   ğŸ¯ é è¨ˆä¸‹æ¬¡åŸ·è¡Œæ™‚é–“: {tz_next_run}")
                        
                        # è¨ˆç®—è·é›¢åŸ·è¡Œé‚„æœ‰å¤šä¹…
                        now = datetime.now(pytz.timezone(task.get('timezone', 'Asia/Taipei')))
                        time_diff = next_run_time - now
                        if time_diff.total_seconds() > 0:
                            hours = int(time_diff.total_seconds() // 3600)
                            minutes = int((time_diff.total_seconds() % 3600) // 60)
                            logger.info(f"   â³ è·é›¢åŸ·è¡Œé‚„æœ‰: {hours}å°æ™‚{minutes}åˆ†é˜")
                        else:
                            logger.info(f"   âš ï¸ åŸ·è¡Œæ™‚é–“å·²éï¼Œå°‡é‡æ–°è¨ˆç®—")
                    else:
                        logger.warning(f"   âš ï¸ ç„¡æ³•è¨ˆç®—é è¨ˆåŸ·è¡Œæ™‚é–“")
                except Exception as calc_error:
                    logger.error(f"   âŒ è¨ˆç®—é è¨ˆåŸ·è¡Œæ™‚é–“å¤±æ•—: {calc_error}")
                
                # ğŸ”¥ é¡¯ç¤ºè§¸ç™¼å™¨é…ç½®
                trigger_config = task.get('trigger_config', {})
                if trigger_config:
                    logger.info(f"   ğŸ¯ è§¸ç™¼å™¨é…ç½®:")
                    logger.info(f"      ğŸ¯ è§¸ç™¼å™¨é¡å‹: {trigger_config.get('trigger_type', 'N/A')}")
                    logger.info(f"      ğŸ“Š æœ€å¤§è‚¡ç¥¨æ•¸: {trigger_config.get('max_stocks', 'N/A')}")
                    logger.info(f"      ğŸ‘¥ KOLåˆ†é…: {trigger_config.get('kol_assignment', 'N/A')}")
                    logger.info(f"      ğŸ“ˆ è‚¡ç¥¨æ’åº: {trigger_config.get('stock_sorting', 'N/A')}")
                
                # ğŸ”¥ é¡¯ç¤ºç”Ÿæˆé…ç½®
                generation_config = task.get('generation_config', {})
                if generation_config:
                    logger.info(f"   ğŸ¨ ç”Ÿæˆé…ç½®:")
                    logger.info(f"      ğŸ“ ç™¼æ–‡é¡å‹: {generation_config.get('posting_type', 'N/A')}")
                    logger.info(f"      ğŸ“ å…§å®¹é•·åº¦: {generation_config.get('content_length', 'N/A')}")
                    logger.info(f"      ğŸ¨ å…§å®¹é¢¨æ ¼: {generation_config.get('content_style', 'N/A')}")
                    logger.info(f"      ğŸ“° æ–°èé€£çµ: {generation_config.get('enable_news_links', 'N/A')}")
                
                # ğŸ”¥ é¡¯ç¤ºæ‰¹æ¬¡è³‡è¨Š
                batch_info = task.get('batch_info', {})
                if batch_info:
                    logger.info(f"   ğŸ“¦ æ‰¹æ¬¡è³‡è¨Š:")
                    logger.info(f"      ğŸ“Š ç¸½ç™¼æ–‡æ•¸: {batch_info.get('total_posts', 'N/A')}")
                    logger.info(f"      âœ… å·²ç™¼å¸ƒæ•¸: {batch_info.get('published_posts', 'N/A')}")
                    logger.info(f"      ğŸ“ˆ æˆåŠŸç‡: {batch_info.get('success_rate', 'N/A')}%")
                    logger.info(f"      ğŸ¢ è‚¡ç¥¨ä»£ç¢¼: {batch_info.get('stock_codes', 'N/A')}")
                    logger.info(f"      ğŸ‘¥ KOLåç¨±: {batch_info.get('kol_names', 'N/A')}")
                
                # æª¢æŸ¥æ˜¯å¦æœ‰åŸ·è¡Œæ™‚é–“è¨­å®š
                if not daily_execution_time or daily_execution_time == 'Not Set':
                    logger.warning(f"âš ï¸ æ’ç¨‹æ²’æœ‰è¨­å®šåŸ·è¡Œæ™‚é–“ï¼Œè·³éåŸ·è¡Œ - Task ID: {task_id}")
                    failure_count += 1
                    continue
                status = task.get('status', 'unknown')
                
                logger.info(f"ğŸš€ [{idx}/{len(active_tasks)}] æ­£åœ¨æº–å‚™å•Ÿå‹•æ’ç¨‹ä»»å‹™:")
                logger.info(f"   ğŸ“‹ Task ID: {task_id}")
                logger.info(f"   ğŸ“ æ’ç¨‹åç¨±: {schedule_name}")
                logger.info(f"   ğŸ• æ’ç¨‹é¡å‹: {schedule_type}")
                logger.info(f"   â° åŸ·è¡Œæ™‚é–“: {daily_execution_time}")
                logger.info(f"   ğŸ”„ ç•¶å‰ç‹€æ…‹: {status}")
                
                try:
                    # æª¢æŸ¥æ˜¯å¦å·²æœ‰é‹è¡Œä¸­çš„ä»»å‹™
                    if task_id in self.running_tasks:
                        existing_task = self.running_tasks[task_id]
                        if not existing_task.done():
                            logger.warning(f"âš ï¸ æ’ç¨‹ä»»å‹™å·²åœ¨é‹è¡Œ - Task ID: {task_id}")
                            success_count += 1
                            continue
                        else:
                            logger.info(f"ğŸ”„ æ¸…ç†å·²å®Œæˆçš„ä»»å‹™: {task_id}")
                            del self.running_tasks[task_id]
                    
                    # å•Ÿå‹•æ–°çš„æ’ç¨‹ä»»å‹™
                    logger.info(f"ğŸ¯ å‰µå»ºæ’ç¨‹ä»»å‹™å”ç¨‹ - Task ID: {task_id}")
                    running_task = asyncio.create_task(self._execute_schedule_task(task_id))
                    self.running_tasks[task_id] = running_task
                    
                    # ç­‰å¾…ä¸€å°æ®µæ™‚é–“ç¢ºä¿ä»»å‹™å•Ÿå‹•æˆåŠŸ
                    await asyncio.sleep(0.1)
                    
                    if not running_task.done():
                        success_count += 1
                        logger.info(f"âœ… æ’ç¨‹ä»»å‹™å•Ÿå‹•æˆåŠŸ - Task ID: {task_id}")
                    else:
                        failure_count += 1
                        logger.error(f"âŒ æ’ç¨‹ä»»å‹™ç«‹å³å®Œæˆï¼ˆå¯èƒ½å¤±æ•—ï¼‰- Task ID: {task_id}")
                        
                except Exception as e:
                    failure_count += 1
                    logger.error(f"âŒ æ’ç¨‹ä»»å‹™å•Ÿå‹•å¤±æ•— - Task ID: {task_id}")
                    logger.error(f"ğŸ” éŒ¯èª¤é¡å‹: {type(e).__name__}")
                    logger.error(f"ğŸ” éŒ¯èª¤è©³æƒ…: {str(e)}")
                    import traceback
                    logger.error(f"ğŸ” éŒ¯èª¤å †ç–Š:\n{traceback.format_exc()}")
            
            # å•Ÿå‹•ç¸½çµ
            logger.info("ğŸ“Š èƒŒæ™¯æ’ç¨‹å™¨å•Ÿå‹•ç¸½çµ:")
            logger.info(f"   âœ… æˆåŠŸå•Ÿå‹•: {success_count} å€‹ä»»å‹™")
            logger.info(f"   âŒ å•Ÿå‹•å¤±æ•—: {failure_count} å€‹ä»»å‹™")
            logger.info(f"   ğŸ”„ ç¸½é‹è¡Œä¸­: {len(self.running_tasks)} å€‹ä»»å‹™")
            
            if success_count > 0:
                logger.info("âœ… èƒŒæ™¯æ’ç¨‹å™¨å•Ÿå‹•å®Œæˆ - é–‹å§‹ç›£æ§åŸ·è¡Œ")
                self.background_scheduler_running = True
                
                # æŒçºŒç›£æ§é‹è¡Œä¸­çš„ä»»å‹™
                while self.background_scheduler_running:
                    try:
                        # æª¢æŸ¥æ˜¯å¦æœ‰ä»»å‹™éœ€è¦é‡å•Ÿ
                        active_tasks = await self.db_service.get_active_schedule_tasks()
                        current_running_task_ids = set(self.running_tasks.keys())
                        active_task_ids = {task['schedule_id'] for task in active_tasks}
                        
                        # å•Ÿå‹•æ–°çš„ active ä»»å‹™
                        for task in active_tasks:
                            task_id = task['schedule_id']
                            if task_id not in current_running_task_ids:
                                logger.info(f"ğŸ”„ ç™¼ç¾æ–°çš„ active ä»»å‹™ï¼Œæ­£åœ¨å•Ÿå‹•: {task_id}")
                                try:
                                    task_obj = asyncio.create_task(self._execute_schedule_task(task_id))
                                    self.running_tasks[task_id] = task_obj
                                    logger.info(f"âœ… æ–°ä»»å‹™å•Ÿå‹•æˆåŠŸ: {task_id}")
                                except Exception as e:
                                    logger.error(f"âŒ æ–°ä»»å‹™å•Ÿå‹•å¤±æ•—: {task_id}, Error: {e}")
                        
                        # æ¸…ç†å·²åœæ­¢çš„ä»»å‹™
                        for task_id in list(current_running_task_ids):
                            if task_id not in active_task_ids:
                                logger.info(f"ğŸ›‘ ä»»å‹™å·²åœæ­¢ï¼Œæ¸…ç†: {task_id}")
                                if task_id in self.running_tasks:
                                    self.running_tasks[task_id].cancel()
                                    del self.running_tasks[task_id]
                        
                        # ç­‰å¾… 5 åˆ†é˜å¾Œå†æ¬¡æª¢æŸ¥
                        await asyncio.sleep(300)
                        
                    except Exception as e:
                        logger.error(f"âŒ èƒŒæ™¯æ’ç¨‹å™¨ç›£æ§éŒ¯èª¤: {e}")
                        await asyncio.sleep(60)  # éŒ¯èª¤æ™‚ç­‰å¾… 1 åˆ†é˜
            else:
                logger.warning("âš ï¸ æ²’æœ‰æˆåŠŸå•Ÿå‹•ä»»ä½•æ’ç¨‹ä»»å‹™")
                
        except Exception as e:
            logger.error(f"âŒ èƒŒæ™¯æ’ç¨‹å™¨å•Ÿå‹•å¤±æ•—: {e}")
            logger.error(f"ğŸ” éŒ¯èª¤é¡å‹: {type(e).__name__}")
            import traceback
            logger.error(f"ğŸ” éŒ¯èª¤å †ç–Š:\n{traceback.format_exc()}")
            self.background_scheduler_running = False
    
    async def start_schedule_task(self, task_id: str) -> bool:
        """å•Ÿå‹•æ’ç¨‹ä»»å‹™"""
        logger.info(f"ğŸ¯ æº–å‚™å•Ÿå‹•å–®ä¸€æ’ç¨‹ä»»å‹™ - Task ID: {task_id}")
        
        # å…ˆå¾è³‡æ–™åº«ç²å–ä»»å‹™è³‡è¨Š
        logger.info(f"ğŸ“Š æ­£åœ¨å¾è³‡æ–™åº«ç²å–ä»»å‹™è³‡è¨Š...")
        db_task = await self.db_service.get_schedule_task(task_id)
        
        if not db_task:
            logger.error(f"âŒ æ’ç¨‹ä»»å‹™ä¸å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­ - Task ID: {task_id}")
            return False
        
        schedule_name = db_task.get('schedule_name', 'Unknown')
        schedule_type = db_task.get('schedule_type', 'Unknown')
        current_status = db_task.get('status', 'unknown')
        daily_execution_time = db_task.get('daily_execution_time', 'Not Set')
        
        logger.info(f"ğŸ“‹ ä»»å‹™è³‡è¨Šç¢ºèª:")
        logger.info(f"   ğŸ“‹ Task ID: {task_id}")
        logger.info(f"   ğŸ“ æ’ç¨‹åç¨±: {schedule_name}")
        logger.info(f"   ğŸ• æ’ç¨‹é¡å‹: {schedule_type}")
        logger.info(f"   ğŸ”„ ç•¶å‰ç‹€æ…‹: {current_status}")
        logger.info(f"   â° åŸ·è¡Œæ™‚é–“: {daily_execution_time}")
        
        # è©³ç´°çš„æ’ç¨‹è¨­å®šè³‡è¨Š
        logger.info(f"ğŸ”§ è©³ç´°æ’ç¨‹è¨­å®š:")
        logger.info(f"   ğŸ“Š Session ID: {db_task.get('session_id', 'N/A')}")
        logger.info(f"   ğŸ“ æè¿°: {db_task.get('schedule_description', 'N/A')}")
        logger.info(f"   â±ï¸ é–“éš”ç§’æ•¸: {db_task.get('interval_seconds', 'N/A')}")
        logger.info(f"   ğŸŒ æ™‚å€: {db_task.get('timezone', 'N/A')}")
        logger.info(f"   ğŸ“… åƒ…å·¥ä½œæ—¥: {db_task.get('weekdays_only', 'N/A')}")
        logger.info(f"   ğŸ“ˆ æ¯å°æ™‚æœ€å¤§ç™¼æ–‡æ•¸: {db_task.get('max_posts_per_hour', 'N/A')}")
        logger.info(f"   ğŸ¤– è‡ªå‹•ç™¼æ–‡: {db_task.get('auto_posting', 'N/A')}")
        
        # è§¸ç™¼å™¨é…ç½®
        trigger_config = db_task.get('trigger_config', {})
        if trigger_config:
            logger.info(f"ğŸ¯ è§¸ç™¼å™¨é…ç½®:")
            logger.info(f"   ğŸ¯ è§¸ç™¼å™¨é¡å‹: {trigger_config.get('trigger_type', 'N/A')}")
            logger.info(f"   ğŸ“Š æœ€å¤§è‚¡ç¥¨æ•¸: {trigger_config.get('max_stocks', 'N/A')}")
            logger.info(f"   ğŸ‘¥ KOLåˆ†é…: {trigger_config.get('kol_assignment', 'N/A')}")
            logger.info(f"   ğŸ“ˆ è‚¡ç¥¨æ’åº: {trigger_config.get('stock_sorting', 'N/A')}")
        
        # ç”Ÿæˆé…ç½®
        generation_config = db_task.get('generation_config', {})
        if generation_config:
            logger.info(f"ğŸ¨ ç”Ÿæˆé…ç½®:")
            logger.info(f"   ğŸ“ ç™¼æ–‡é¡å‹: {generation_config.get('posting_type', 'N/A')}")
            logger.info(f"   ğŸ“ å…§å®¹é•·åº¦: {generation_config.get('content_length', 'N/A')}")
            logger.info(f"   ğŸ¨ å…§å®¹é¢¨æ ¼: {generation_config.get('content_style', 'N/A')}")
            logger.info(f"   ğŸ“° æ–°èé€£çµ: {generation_config.get('enable_news_links', 'N/A')}")
        
        # æ‰¹æ¬¡è³‡è¨Š
        batch_info = db_task.get('batch_info', {})
        if batch_info:
            logger.info(f"ğŸ“¦ æ‰¹æ¬¡è³‡è¨Š:")
            logger.info(f"   ğŸ“Š ç¸½ç™¼æ–‡æ•¸: {batch_info.get('total_posts', 'N/A')}")
            logger.info(f"   âœ… å·²ç™¼å¸ƒæ•¸: {batch_info.get('published_posts', 'N/A')}")
            logger.info(f"   ğŸ“ˆ æˆåŠŸç‡: {batch_info.get('success_rate', 'N/A')}%")
            logger.info(f"   ğŸ¢ è‚¡ç¥¨ä»£ç¢¼: {batch_info.get('stock_codes', 'N/A')}")
            logger.info(f"   ğŸ‘¥ KOLåç¨±: {batch_info.get('kol_names', 'N/A')}")
        
        if current_status not in ['pending', 'cancelled', 'active']:
            logger.error(f"âŒ æ’ç¨‹ä»»å‹™ç‹€æ…‹ä¸æ­£ç¢º - Task ID: {task_id}, æœŸæœ›: pending, cancelled æˆ– active, å¯¦éš›: {current_status}")
            return False
        
        if current_status == 'active':
            logger.info(f"â„¹ï¸ æ’ç¨‹ä»»å‹™å·²ç¶“æ˜¯ active ç‹€æ…‹ï¼Œç›´æ¥å•Ÿå‹•åŸ·è¡Œå¾ªç’° - Task ID: {task_id}")
            # ç›´æ¥å•Ÿå‹•åŸ·è¡Œå¾ªç’°ï¼Œä¸æ”¹è®Šç‹€æ…‹
        else:
            logger.info(f"âœ… ä»»å‹™ç‹€æ…‹æª¢æŸ¥é€šéï¼Œç‹€æ…‹æœ‰æ•ˆ")
        
        logger.info(f"âœ… ä»»å‹™ç‹€æ…‹æª¢æŸ¥é€šéï¼Œç‹€æ…‹æœ‰æ•ˆ")
        
        try:
            logger.info(f"â° æ­£åœ¨è¨ˆç®—åˆå§‹åŸ·è¡Œæ™‚é–“...")
            # è¨ˆç®—åˆå§‹çš„ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“
            next_run_time = await self._calculate_next_run_time(db_task)
            
            if next_run_time:
                tz_next_run = next_run_time.strftime('%Y-%m-%d %H:%M:%S %Z')
                logger.info(f"âœ… è¨ˆç®—æˆåŠŸ - ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“: {tz_next_run}")
            else:
                logger.warning(f"âš ï¸ ç„¡æ³•è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“ï¼Œå°‡ä½¿ç”¨å®‰å…¨é»˜èªå€¼")
            
            logger.info(f"ğŸ’¾ æ­£åœ¨æ›´æ–°è³‡æ–™åº«ç‹€æ…‹ç‚º active...")
            # æ›´æ–°è³‡æ–™åº«ç‹€æ…‹å’Œä¸‹æ¬¡åŸ·è¡Œæ™‚é–“
            await self.db_service.update_schedule_status(
                task_id, 'active', started_at=datetime.utcnow()
            )
            logger.info(f"âœ… è³‡æ–™åº«ç‹€æ…‹æ›´æ–°æˆåŠŸ")
            
            if next_run_time:
                logger.info(f"ğŸ’¾ æ­£åœ¨æ›´æ–°ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“...")
                await self.db_service.update_schedule_next_run(task_id, next_run_time)
                logger.info(f"âœ… ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“æ›´æ–°æˆåŠŸ")
            
            # æ›´æ–°è¨˜æ†¶é«”ä¸­çš„ä»»å‹™ç‹€æ…‹
            if task_id in self.tasks:
                logger.info(f"ğŸ”„ æ­£åœ¨æ›´æ–°è¨˜æ†¶é«”ä¸­çš„ä»»å‹™ç‹€æ…‹...")
                task = self.tasks[task_id]
                task.status = 'active'
                task.started_at = datetime.utcnow()
                logger.info(f"âœ… è¨˜æ†¶é«”ç‹€æ…‹æ›´æ–°æˆåŠŸ")
            
            logger.info(f"ğŸš€ æ­£åœ¨å‰µå»ºç•°æ­¥ä»»å‹™å”ç¨‹...")
            # å‰µå»ºç•°æ­¥ä»»å‹™
            running_task = asyncio.create_task(self._execute_schedule_task(task_id))
            self.running_tasks[task_id] = running_task
            
            # æª¢æŸ¥ä»»å‹™æ˜¯å¦æˆåŠŸå•Ÿå‹•
            await asyncio.sleep(0.05)  # çŸ­æš«ç­‰å¾…
            
            if not running_task.done():
                logger.info(f"âœ… ç•°æ­¥ä»»å‹™æˆåŠŸå•Ÿå‹•ä¸¦é‹è¡Œä¸­")
                logger.info(f"ğŸ‰ æ’ç¨‹ä»»å‹™å•Ÿå‹•å®Œå…¨æˆåŠŸ - Task ID: {task_id}")
                logger.info(f"ğŸ“Š ç•¶å‰é‹è¡Œä¸­ä»»å‹™ç¸½æ•¸: {len(self.running_tasks)}")
                return True
            else:
                logger.error(f"âŒ ç•°æ­¥ä»»å‹™ç«‹å³å®Œæˆï¼ˆå¯èƒ½å•Ÿå‹•å¤±æ•—ï¼‰")
                return False
            
        except Exception as e:
            logger.error(f"âŒ å•Ÿå‹•æ’ç¨‹ä»»å‹™å¤±æ•— - Task ID: {task_id}")
            logger.error(f"ğŸ” éŒ¯èª¤é¡å‹: {type(e).__name__}")
            logger.error(f"ğŸ” éŒ¯èª¤è©³æƒ…: {str(e)}")
            import traceback
            logger.error(f"ğŸ” éŒ¯èª¤å †ç–Š:\n{traceback.format_exc()}")
            
            # å˜—è©¦æ›´æ–°è³‡æ–™åº«ç‹€æ…‹ç‚º failed
            try:
                await self.db_service.update_schedule_status(
                    task_id, 'failed', error_message=str(e)
                )
                logger.info(f"ğŸ’¾ å·²å°‡ä»»å‹™ç‹€æ…‹æ›´æ–°ç‚º failed")
            except Exception as db_error:
                logger.error(f"âŒ æ›´æ–°è³‡æ–™åº«ç‹€æ…‹å¤±æ•—: {db_error}")
            
            return False
    
    async def execute_task_immediately(self, task_id: str) -> bool:
        """ç«‹å³åŸ·è¡Œæ’ç¨‹ä»»å‹™ï¼ˆæ¸¬è©¦ç”¨ï¼‰- ä¸å½±éŸ¿æ’ç¨‹ç‹€æ…‹"""
        logger.info(f"ğŸ””ğŸ””ğŸ”” æ’ç¨‹ç³»çµ±ç«‹å³åŸ·è¡Œæ¸¬è©¦é–‹å§‹ - Task ID: {task_id} ğŸ””ğŸ””ğŸ””")
        logger.info(f"ğŸ¯ é–‹å§‹ç«‹å³åŸ·è¡Œæ’ç¨‹ä»»å‹™æ¸¬è©¦ - Task ID: {task_id}")
        
        try:
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            logger.info(f"â° ç•¶å‰åŸ·è¡Œæ™‚é–“: {current_time}")
            
            # å¾è³‡æ–™åº«ç²å–ä»»å‹™è³‡è¨Š
            logger.info(f"ğŸ“Š æ­£åœ¨ç²å–ä»»å‹™è©³ç´°è³‡è¨Š...")
            db_task = await self.db_service.get_schedule_task(task_id)
            
            if not db_task:
                logger.error(f"âŒ æ’ç¨‹ä»»å‹™ä¸å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­ - Task ID: {task_id}")
                return False
            
            schedule_name = db_task.get('schedule_name', 'Unknown')
            schedule_type = db_task.get('schedule_type', 'weekday_daily')
            current_status = db_task.get('status', 'unknown')
            generation_config = db_task.get('generation_config', {})
            
            logger.info(f"ğŸ“‹ ç«‹å³åŸ·è¡Œä»»å‹™è³‡è¨Š:")
            logger.info(f"   ğŸ“‹ Task ID: {task_id}")
            logger.info(f"   ğŸ“ æ’ç¨‹åç¨±: {schedule_name}")
            logger.info(f"   ğŸ• æ’ç¨‹é¡å‹: {schedule_type}")
            logger.info(f"   ğŸ”„ ç•¶å‰ç‹€æ…‹: {current_status}")
            logger.info(f"   âš™ï¸ ç”Ÿæˆé…ç½®: {generation_config}")
            
            # æ ¹æ“šæ’ç¨‹é¡å‹åŸ·è¡Œå°æ‡‰çš„é‚è¼¯
            logger.info(f"ğŸš€ æº–å‚™åŸ·è¡Œæ’ç¨‹é‚è¼¯...")
            
            if schedule_type == 'weekday_daily' or not schedule_type:
                logger.info(f"âœ… æ’ç¨‹é¡å‹ç¢ºèª: weekday_dailyï¼Œé–‹å§‹åŸ·è¡Œ...")
                # åŸ·è¡Œå·¥ä½œæ—¥æ¯æ—¥æ’ç¨‹
                result = await self._execute_weekday_daily_schedule(task_id, db_task)
                
                if result:
                    logger.info(f"âœ… å·¥ä½œæ—¥æ¯æ—¥æ’ç¨‹åŸ·è¡Œå®Œæˆ - Task ID: {task_id}")
                else:
                    logger.error(f"âŒ å·¥ä½œæ—¥æ¯æ—¥æ’ç¨‹åŸ·è¡Œå¤±æ•— - Task ID: {task_id}")
                    return False
            else:
                logger.warning(f"âš ï¸ ä¸æ”¯æŒçš„æ’ç¨‹é¡å‹: {schedule_type}")
                logger.info(f"ğŸ’¡ ç•¶å‰æ”¯æŒçš„æ’ç¨‹é¡å‹: weekday_daily")
                return False
            
            # è¨˜éŒ„åŸ·è¡Œå®Œæˆæ™‚é–“
            completion_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            duration = (datetime.now() - datetime.strptime(current_time, '%Y-%m-%d %H:%M:%S')).total_seconds()
            
            logger.info(f"ğŸ‰ ç«‹å³åŸ·è¡Œæ¸¬è©¦å®Œå…¨æˆåŠŸ - Task ID: {task_id}")
            logger.info(f"â±ï¸ åŸ·è¡Œå®Œæˆæ™‚é–“: {completion_time}")
            logger.info(f"â±ï¸ åŸ·è¡Œè€—æ™‚: {duration:.2f} ç§’")
            logger.info(f"ğŸ””ğŸ””ğŸ”” æ’ç¨‹ç³»çµ±ç«‹å³åŸ·è¡Œæ¸¬è©¦çµæŸ - Task ID: {task_id} ğŸ””ğŸ””ğŸ””")
            
            return True
            
        except Exception as e:
            error_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            logger.error(f"âŒ ç«‹å³åŸ·è¡Œæ¸¬è©¦å¤±æ•— - Task ID: {task_id}")
            logger.error(f"â° å¤±æ•—æ™‚é–“: {error_time}")
            logger.error(f"ğŸ” éŒ¯èª¤é¡å‹: {type(e).__name__}")
            logger.error(f"ğŸ” éŒ¯èª¤è©³æƒ…: {str(e)}")
            import traceback
            logger.error(f"ğŸ” éŒ¯èª¤å †ç–Š:\n{traceback.format_exc()}")
            return False
    
    async def _execute_schedule_task(self, task_id: str):
        """åŸ·è¡Œæ’ç¨‹ä»»å‹™ - æŒçºŒé‹è¡Œæ¨¡å¼"""
        try:
            logger.info(f"ğŸš€ é–‹å§‹åŸ·è¡Œæ’ç¨‹ä»»å‹™ - Task ID: {task_id}")
            
            # å¾è³‡æ–™åº«ç²å–ä»»å‹™è³‡è¨Š
            db_task = await self.db_service.get_schedule_task(task_id)
            if not db_task:
                raise Exception(f"æ’ç¨‹ä»»å‹™ä¸å­˜åœ¨: {task_id}")
            
            # æŒçºŒé‹è¡Œå¾ªç’°
            while True:
                try:
                    # æª¢æŸ¥ä»»å‹™æ˜¯å¦ä»ç‚º active ç‹€æ…‹
                    current_task = await self.db_service.get_schedule_task(task_id)
                    if not current_task or current_task['status'] != 'active':
                        logger.info(f"ğŸ›‘ æ’ç¨‹ä»»å‹™å·²åœæ­¢ - Task ID: {task_id}")
                        break
                    
                    # æª¢æŸ¥æ˜¯å¦æ‡‰è©²åŸ·è¡Œ
                    should_execute = await self._should_execute_now(current_task)
                    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    
                    if not should_execute:
                        logger.debug(f"â° æ’ç¨‹æœªåˆ°åŸ·è¡Œæ™‚é–“ - Task ID: {task_id}, æ™‚é–“: {current_time}")
                        # ç­‰å¾… 1 åˆ†é˜å¾Œå†æª¢æŸ¥ï¼Œç¢ºä¿ä¸æœƒéŒ¯éåŸ·è¡Œæ™‚é–“
                        await asyncio.sleep(60)
                        continue
                    
                    # ğŸ”¥ é—œéµä¿®å¾©ï¼šæª¢æŸ¥ä»Šæ—¥æ˜¯å¦å·²åŸ·è¡Œéï¼Œé¿å…é‡è¤‡åŸ·è¡Œ
                    last_run = current_task.get('last_run')
                    if last_run:
                        tz = pytz.timezone('Asia/Taipei')
                        
                        # è™•ç† last_run å¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…æ³
                        if isinstance(last_run, str):
                            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè§£æç‚º datetime
                            try:
                                if 'T' in last_run:
                                    # ISO æ ¼å¼
                                    last_run_dt = datetime.fromisoformat(last_run.replace('Z', '+00:00'))
                                else:
                                    # å…¶ä»–æ ¼å¼
                                    last_run_dt = datetime.strptime(last_run, '%Y-%m-%d %H:%M:%S')
                            except ValueError:
                                logger.warning(f"âš ï¸ ç„¡æ³•è§£æ last_run æ™‚é–“æ ¼å¼: {last_run}")
                                continue
                        else:
                            # å·²ç¶“æ˜¯ datetime å°è±¡
                            last_run_dt = last_run
                        
                        # ç¢ºä¿æ™‚å€è™•ç†æ­£ç¢º
                        if last_run_dt.tzinfo is None:
                            # æ²’æœ‰æ™‚å€ä¿¡æ¯ï¼Œå‡è¨­ç‚º UTC ç„¶å¾Œè½‰æ›
                            last_run_tz = pytz.UTC.localize(last_run_dt).astimezone(tz)
                        else:
                            # æœ‰æ™‚å€ä¿¡æ¯ï¼Œç›´æ¥è½‰æ›
                            last_run_tz = last_run_dt.astimezone(tz)
                        
                        now_tz = datetime.now(tz)
                        
                        # å¦‚æœä»Šæ—¥å·²åŸ·è¡Œéï¼Œè·³éæœ¬æ¬¡åŸ·è¡Œ
                        if last_run_tz.date() == now_tz.date():
                            logger.info(f"â° ä»Šæ—¥å·²åŸ·è¡Œéï¼Œè·³éé‡è¤‡åŸ·è¡Œ - Task ID: {task_id}, ä¸Šæ¬¡åŸ·è¡Œ: {last_run_tz.strftime('%Y-%m-%d %H:%M:%S')}")
                            # ç­‰å¾…åˆ°æ˜å¤©å†åŸ·è¡Œ
                            tomorrow = now_tz.date() + timedelta(days=1)
                            tomorrow_execution_time = current_task.get('daily_execution_time', '16:30')
                            try:
                                exec_time = datetime.strptime(tomorrow_execution_time.split('T')[1].split('.')[0], '%H:%M:%S').time() if 'T' in tomorrow_execution_time else datetime.strptime(tomorrow_execution_time.strip(), '%H:%M').time()
                                next_execution = tz.localize(datetime.combine(tomorrow, exec_time))
                                sleep_seconds = (next_execution - now_tz).total_seconds()
                                await asyncio.sleep(max(sleep_seconds, 3600))  # è‡³å°‘ç­‰å¾… 1 å°æ™‚
                            except:
                                await asyncio.sleep(86400)  # ç­‰å¾… 24 å°æ™‚
                            continue
                    
                    logger.info(f"â° ğŸš€ è§¸ç™¼æ’ç¨‹åŸ·è¡Œ - Task ID: {task_id}, æ™‚é–“: {current_time}")
                    logger.info(f"ğŸ“‹ æ’ç¨‹åç¨±: {current_task.get('schedule_name', 'Unknown')}")
                    logger.info(f"ğŸ• æ’ç¨‹é¡å‹: {current_task.get('schedule_type', 'Unknown')}")
                    
                    # æ›´æ–°æœ€å¾ŒåŸ·è¡Œæ™‚é–“
                    await self.db_service.update_schedule_status(
                        task_id, 'active', last_run=datetime.utcnow()
                    )
                    
                    # åŸ·è¡Œæ’ç¨‹é‚è¼¯
                    if current_task['schedule_type'] == 'immediate':
                        # ç«‹å³åŸ·è¡Œæ‰€æœ‰è²¼æ–‡
                        if current_task.get('auto_posting'):
                            await self._publish_posts_immediately(task_id, current_task.get('post_ids', []))
                        else:
                            logger.info("ğŸ›‘ è‡ªå‹•ç™¼æ–‡é—œé–‰ï¼Œè·³éç«‹å³ç™¼å¸ƒ")
                    elif current_task['schedule_type'] == '24hour_batch':
                        # 24å°æ™‚å…§åˆ†æ‰¹ç™¼æ–‡
                        if current_task.get('auto_posting'):
                            await self._publish_posts_with_interval(task_id, current_task.get('post_ids', []), current_task['interval_seconds'])
                        else:
                            logger.info("ğŸ›‘ è‡ªå‹•ç™¼æ–‡é—œé–‰ï¼Œè·³éåˆ†æ‰¹ç™¼å¸ƒ")
                    elif current_task['schedule_type'] == '5min_batch':
                        # 5åˆ†é˜å…§åˆ†æ‰¹ç™¼æ–‡
                        if current_task.get('auto_posting'):
                            await self._publish_posts_with_interval(task_id, current_task.get('post_ids', []), current_task['interval_seconds'])
                        else:
                            logger.info("ğŸ›‘ è‡ªå‹•ç™¼æ–‡é—œé–‰ï¼Œè·³éåˆ†æ‰¹ç™¼å¸ƒ")
                    elif current_task['schedule_type'] == 'weekday_daily':
                        # å·¥ä½œæ—¥æ¯æ—¥åŸ·è¡Œæ‰¹æ¬¡è…³æœ¬
                        await self._execute_weekday_daily_schedule(task_id, current_task)
                    
                    # ğŸ”¥ æ³¨æ„ï¼šçµ±è¨ˆæ•¸æ“šå·²åœ¨å…·é«”åŸ·è¡Œæ–¹æ³•ä¸­æ›´æ–°ï¼Œé€™è£¡ä¸éœ€è¦é‡è¤‡æ›´æ–°
                    # await self.db_service.increment_schedule_stats(
                    #     task_id, run_count=1, success_count=1
                    # )
                    
                    # è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“
                    next_run_time = await self._calculate_next_run_time(current_task)
                    if next_run_time:
                        # æ›´æ–°è³‡æ–™åº«ä¸­çš„ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“
                        await self.db_service.update_schedule_next_run(task_id, next_run_time)
                        logger.info(f"â° ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“: {next_run_time}")

                        # ç­‰å¾…åˆ°ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“
                        tz = pytz.timezone('Asia/Taipei')
                        now = datetime.now(tz)
                        # ç¢ºä¿å…©å€‹æ™‚é–“éƒ½æ˜¯ aware çš„
                        if next_run_time.tzinfo is None:
                            next_run_time = tz.localize(next_run_time)
                        elif next_run_time.tzinfo != tz:
                            # å¦‚æœæ™‚å€ä¸åŒï¼Œè½‰æ›åˆ°å°åŒ—æ™‚å€
                            next_run_time = next_run_time.astimezone(tz)
                        if now.tzinfo is None:
                            now = tz.localize(now)
                        sleep_seconds = (next_run_time - now).total_seconds()
                        
                        if sleep_seconds and sleep_seconds > 0:
                            logger.info(f"ğŸ˜´ ç­‰å¾… {sleep_seconds/3600:.1f} å°æ™‚å¾ŒåŸ·è¡Œ")
                            await asyncio.sleep(sleep_seconds)
                        else:
                            logger.warning("âš ï¸ ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“å·²éï¼Œç«‹å³åŸ·è¡Œ")
                    else:
                        # å¦‚æœç„¡æ³•è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“ï¼Œè¨­å®šç‚ºæ˜å¤©çš„åŒä¸€å€‹æ™‚é–“ + 15åˆ†é˜
                        logger.warning("âš ï¸ ç„¡æ³•è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“ï¼Œè¨­å®šç‚ºæ˜å¤© 16:30 (å®‰å…¨é»˜èªå€¼)")
                        try:
                            # å®‰å…¨é»˜èªï¼šæ˜å¤© 16:30 åŸ·è¡Œ
                            tz = pytz.timezone('Asia/Taipei')
                            now = datetime.now(tz)
                            tomorrow = now.date() + timedelta(days=1)
                            fallback_time = tz.localize(datetime.combine(tomorrow, datetime.strptime('16:30', '%H:%M').time()))
                            await self.db_service.update_schedule_next_run(task_id, fallback_time)
                            logger.info(f"âœ… è¨­å®šå®‰å…¨é»˜èªåŸ·è¡Œæ™‚é–“: {fallback_time}")
                            
                            # è¨ˆç®—ç­‰å¾…æ™‚é–“
                            sleep_seconds = (fallback_time - now).total_seconds()
                            if sleep_seconds > 0:
                                logger.info(f"ğŸ˜´ ç­‰å¾… {sleep_seconds/3600:.1f} å°æ™‚å¾ŒåŸ·è¡Œ")
                                await asyncio.sleep(min(sleep_seconds, 86400))  # æœ€å¤šç­‰å¾… 24 å°æ™‚
                        except Exception as fallback_error:
                            logger.error(f"âŒ è¨­å®šé»˜èªåŸ·è¡Œæ™‚é–“å¤±æ•—: {fallback_error}")
                            # æœ€å¾Œçš„å®‰å…¨æªæ–½ï¼šç­‰å¾… 4 å°æ™‚
                            await asyncio.sleep(14400)
                    
                except Exception as e:
                    logger.error(f"âŒ æ’ç¨‹ä»»å‹™åŸ·è¡Œå¤±æ•— - Task ID: {task_id}, Error: {e}")
                    
                    # æ›´æ–°å¤±æ•—çµ±è¨ˆ
                    try:
                        await self.db_service.increment_schedule_stats(
                            task_id, run_count=1, failure_count=1
                        )
                    except Exception as db_error:
                        logger.error(f"âŒ æ›´æ–°å¤±æ•—çµ±è¨ˆå¤±æ•—: {db_error}")
                    
                    # è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“ï¼ˆå³ä½¿å¤±æ•—ä¹Ÿè¦ç­‰åˆ°æ˜å¤©ï¼‰
                    try:
                        current_task = await self.db_service.get_schedule_task(task_id)
                        if current_task:
                            next_run_time = await self._calculate_next_run_time(current_task)
                            if next_run_time:
                                await self.db_service.update_schedule_next_run(task_id, next_run_time)
                                tz = pytz.timezone('Asia/Taipei')
                                now = datetime.now(tz)
                                if next_run_time.tzinfo is None:
                                    next_run_time = tz.localize(next_run_time)
                                elif next_run_time.tzinfo != tz:
                                    # å¦‚æœæ™‚å€ä¸åŒï¼Œè½‰æ›åˆ°å°åŒ—æ™‚å€
                                    next_run_time = next_run_time.astimezone(tz)
                                if now.tzinfo is None:
                                    now = tz.localize(now)
                                sleep_seconds = (next_run_time - now).total_seconds()
                                if sleep_seconds and sleep_seconds > 0:
                                    logger.info(f"âš ï¸ åŸ·è¡Œå¤±æ•—ï¼Œç­‰å¾… {sleep_seconds/3600:.1f} å°æ™‚å¾Œé‡è©¦")
                                    await asyncio.sleep(sleep_seconds)
                                else:
                                    logger.warning("âš ï¸ åŸ·è¡Œå¤±æ•—ï¼Œç­‰å¾… 1 å°æ™‚å¾Œé‡è©¦")
                                    await asyncio.sleep(3600)
                            else:
                                logger.warning("âš ï¸ ç„¡æ³•è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“ï¼Œç­‰å¾… 1 å°æ™‚å¾Œé‡è©¦")
                                await asyncio.sleep(3600)
                        else:
                            logger.warning("âš ï¸ ç„¡æ³•ç²å–ä»»å‹™è³‡è¨Šï¼Œç­‰å¾… 1 å°æ™‚å¾Œé‡è©¦")
                            await asyncio.sleep(3600)
                    except Exception as calc_error:
                        logger.error(f"âŒ è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“å¤±æ•—: {calc_error}, ç­‰å¾… 1 å°æ™‚")
                        await asyncio.sleep(3600)
            
            logger.info(f"âœ… æ’ç¨‹ä»»å‹™çµæŸ - Task ID: {task_id}")
            
        except Exception as e:
            logger.error(f"âŒ æ’ç¨‹ä»»å‹™åŸ·è¡Œå¤±æ•— - Task ID: {task_id}, Error: {e}")
            
            # æ›´æ–°å¤±æ•—ç‹€æ…‹
            await self.db_service.update_schedule_status(
                task_id, 'failed', error_message=str(e)
            )
            
            # æ›´æ–°è¨˜æ†¶é«”ä¸­çš„ä»»å‹™ç‹€æ…‹
            if task_id in self.tasks:
                self.tasks[task_id].status = 'failed'
                self.tasks[task_id].error_message = str(e)
    
    async def _publish_posts_immediately(self, task_id: str, post_ids: List[str]):
        """ç«‹å³ç™¼å¸ƒæ‰€æœ‰è²¼æ–‡"""
        logger.info(f"ğŸ“ ç«‹å³ç™¼å¸ƒ {len(post_ids)} ç¯‡è²¼æ–‡")
        
        success_count = 0
        for post_id in post_ids:
            try:
                logger.info(f"ğŸ“ ç™¼å¸ƒè²¼æ–‡ - Post ID: {post_id}")
                
                # èª¿ç”¨å¯¦éš›çš„ç™¼å¸ƒæœå‹™
                from publish_service import publish_service
                from main import get_post_record_service
                
                # ç²å–è²¼æ–‡è¨˜éŒ„
                post_service = get_post_record_service()
                post_record = post_service.get_post_record(post_id)
                
                if not post_record:
                    logger.error(f"âŒ æ‰¾ä¸åˆ°è²¼æ–‡è¨˜éŒ„ - Post ID: {post_id}")
                    continue
                
                if post_record.status not in ["approved", "draft"]:
                    logger.error(f"âŒ è²¼æ–‡ç‹€æ…‹ä¸æ­£ç¢ºï¼Œç„¡æ³•ç™¼æ–‡ - Post ID: {post_id}, ç‹€æ…‹: {post_record.status}")
                    continue
                
                # å¯¦éš›ç™¼å¸ƒåˆ° CMoney
                publish_result = await publish_service.publish_post(post_record)
                
                if publish_result.get("success"):
                    logger.info(f"âœ… è²¼æ–‡ç™¼å¸ƒæˆåŠŸ - Post ID: {post_id}")
                    success_count += 1
                else:
                    logger.error(f"âŒ è²¼æ–‡ç™¼å¸ƒå¤±æ•— - Post ID: {post_id}, éŒ¯èª¤: {publish_result.get('error')}")
                
                # è¨˜éŒ„è²¼æ–‡èˆ‡æ’ç¨‹çš„é—œè¯
                await self.db_service.add_generated_post(task_id, post_id)
                
            except Exception as e:
                logger.error(f"âŒ ç™¼å¸ƒè²¼æ–‡ç•°å¸¸ - Post ID: {post_id}, éŒ¯èª¤: {e}")
        
        # æ›´æ–°çµ±è¨ˆæ•¸æ“š
        await self.db_service.increment_schedule_stats(
            task_id, posts_generated=len(post_ids), success_count=success_count
        )
        
        logger.info(f"ğŸ“Š ç™¼å¸ƒå®Œæˆ - æˆåŠŸ: {success_count}/{len(post_ids)}")
    
    async def _publish_posts_with_interval(self, task_id: str, post_ids: List[str], interval_seconds: int):
        """æŒ‰é–“éš”ç™¼å¸ƒè²¼æ–‡"""
        logger.info(f"ğŸ“ æŒ‰é–“éš” {interval_seconds} ç§’ç™¼å¸ƒ {len(post_ids)} ç¯‡è²¼æ–‡")
        
        success_count = 0
        for i, post_id in enumerate(post_ids):
            try:
                logger.info(f"ğŸ“ ç™¼å¸ƒè²¼æ–‡ {i+1}/{len(post_ids)} - Post ID: {post_id}")
                
                # èª¿ç”¨å¯¦éš›çš„ç™¼å¸ƒæœå‹™
                from publish_service import publish_service
                from main import get_post_record_service
                
                # ç²å–è²¼æ–‡è¨˜éŒ„
                post_service = get_post_record_service()
                post_record = post_service.get_post_record(post_id)
                
                if not post_record:
                    logger.error(f"âŒ æ‰¾ä¸åˆ°è²¼æ–‡è¨˜éŒ„ - Post ID: {post_id}")
                    continue
                
                if post_record.status not in ["approved", "draft"]:
                    logger.error(f"âŒ è²¼æ–‡ç‹€æ…‹ä¸æ­£ç¢ºï¼Œç„¡æ³•ç™¼æ–‡ - Post ID: {post_id}, ç‹€æ…‹: {post_record.status}")
                    continue
                
                # å¯¦éš›ç™¼å¸ƒåˆ° CMoney
                publish_result = await publish_service.publish_post(post_record)
                
                if publish_result.get("success"):
                    logger.info(f"âœ… è²¼æ–‡ç™¼å¸ƒæˆåŠŸ - Post ID: {post_id}")
                    success_count += 1
                else:
                    logger.error(f"âŒ è²¼æ–‡ç™¼å¸ƒå¤±æ•— - Post ID: {post_id}, éŒ¯èª¤: {publish_result.get('error')}")
                
                # è¨˜éŒ„è²¼æ–‡èˆ‡æ’ç¨‹çš„é—œè¯
                await self.db_service.add_generated_post(task_id, post_id)
                
                if i < len(post_ids) - 1:  # ä¸æ˜¯æœ€å¾Œä¸€ç¯‡
                    logger.info(f"â³ ç­‰å¾… {interval_seconds} ç§’å¾Œç™¼å¸ƒä¸‹ä¸€ç¯‡...")
                    await asyncio.sleep(interval_seconds)
                
            except Exception as e:
                logger.error(f"âŒ ç™¼å¸ƒè²¼æ–‡ç•°å¸¸ - Post ID: {post_id}, éŒ¯èª¤: {e}")
        
        # æ›´æ–°çµ±è¨ˆæ•¸æ“š
        await self.db_service.increment_schedule_stats(
            task_id, posts_generated=len(post_ids), success_count=success_count
        )
        
        logger.info(f"ğŸ“Š é–“éš”ç™¼å¸ƒå®Œæˆ - æˆåŠŸ: {success_count}/{len(post_ids)}")
    
    async def _execute_weekday_daily_schedule(self, task_id: str, db_task: Dict[str, Any]):
        """åŸ·è¡Œå·¥ä½œæ—¥æ¯æ—¥æ’ç¨‹"""
        try:
            logger.info(f"ğŸš€ é–‹å§‹åŸ·è¡Œå·¥ä½œæ—¥æ’ç¨‹ - Task ID: {task_id}")
            logger.info(f"ğŸ“‹ æ’ç¨‹è¨­å®š: {db_task['schedule_name']}")
            logger.info(f"âš™ï¸ ç”Ÿæˆé…ç½®: {db_task['generation_config']}")
            
            # è©³ç´°è¨˜éŒ„åŸ·è¡Œåƒæ•¸
            trigger_type = db_task['generation_config'].get('trigger_type', 'unknown')
            stock_sorting = db_task['generation_config'].get('stock_sorting', 'unknown')
            max_stocks = db_task['generation_config'].get('max_stocks', 10)
            kol_assignment = db_task['generation_config'].get('kol_assignment', 'unknown')
            
            logger.info(f"ğŸ” åŸ·è¡Œåƒæ•¸è©³æƒ…:")
            logger.info(f"   ğŸ“ˆ è§¸ç™¼å™¨é¡å‹: {trigger_type}")
            logger.info(f"   ğŸ“Š è‚¡ç¥¨æ’åº: {stock_sorting}")
            logger.info(f"   ğŸ¯ æœ€å¤§è‚¡ç¥¨æ•¸: {max_stocks}")
            logger.info(f"   ğŸ‘¥ KOLåˆ†é…æ–¹å¼: {kol_assignment}")
            
            # 1. æ ¹æ“šè§¸ç™¼å™¨é¡å‹ç¯©é¸è‚¡ç¥¨
            logger.info(f"ğŸ” é–‹å§‹ç¯©é¸è‚¡ç¥¨ï¼ˆè§¸ç™¼å™¨: {trigger_type}ï¼‰...")
            stocks = await self._filter_stocks_by_trigger(db_task['generation_config'])
            logger.info(f"ğŸ“Š ç¯©é¸çµæœ: å…± {len(stocks)} æª”è‚¡ç¥¨")
            
            # è©³ç´°è¨˜éŒ„ç¯©é¸åˆ°çš„è‚¡ç¥¨
            if stocks:
                logger.info(f"ğŸ“‹ ç¯©é¸åˆ°çš„è‚¡ç¥¨:")
                for i, stock in enumerate(stocks, 1):
                    stock_code = stock.get('stock_code', 'N/A')
                    stock_name = stock.get('stock_name', 'N/A')
                    change_percent = stock.get('change_percent', 0)
                    logger.info(f"   {i}. {stock_code} {stock_name} ({change_percent:.2f}%)")
            
            # æª¢æŸ¥æ˜¯å¦ç¯©é¸åˆ°è‚¡ç¥¨
            if not stocks or len(stocks) == 0:
                logger.warning(f"âš ï¸ æœªç¯©é¸åˆ°è‚¡ç¥¨ï¼Œæœ¬æ¬¡æ’ç¨‹è·³éåŸ·è¡Œ - Task ID: {task_id}")
                # æ›´æ–°çµ±è¨ˆï¼šç®—ä½œå¤±æ•—
                await self.db_service.increment_schedule_stats(
                    task_id, run_count=1, failure_count=1
                )
                return False  # ç›´æ¥è¿”å›å¤±æ•—ï¼Œä¸æ‹‹å‡ºç•°å¸¸
            
            # 2. æ ¹æ“šKOLåˆ†é…æ–¹å¼åˆ†é…KOL
            logger.info(f"ğŸ‘¥ é–‹å§‹KOLåˆ†é…ï¼ˆæ–¹å¼: {kol_assignment}ï¼‰...")
            kol_assignments = await self._assign_kols_to_stocks(stocks, db_task['generation_config'])
            logger.info(f"ğŸ‘¥ KOLåˆ†é…å®Œæˆ: {len(kol_assignments)} å€‹åˆ†é…")
            
            # è©³ç´°è¨˜éŒ„KOLåˆ†é…çµæœ
            if kol_assignments:
                logger.info(f"ğŸ‘¥ åˆ†é…è©³æƒ…:")
                for i, assignment in enumerate(kol_assignments, 1):
                    stock_code = assignment.get('stock_code', 'N/A')
                    stock_name = assignment.get('stock_name', 'N/A')
                    kol_serial = assignment.get('kol_serial', 'N/A')
                    kol_nickname = assignment.get('kol_nickname', 'N/A')
                    logger.info(f"   {i}. {stock_code} {stock_name} â†’ KOL-{kol_serial} ({kol_nickname})")
            
            if not kol_assignments or len(kol_assignments) == 0:
                logger.warning(f"âš ï¸ KOLåˆ†é…å¤±æ•—ï¼Œæœ¬æ¬¡æ’ç¨‹è·³éåŸ·è¡Œ - Task ID: {task_id}")
                await self.db_service.increment_schedule_stats(
                    task_id, run_count=1, failure_count=1
                )
                return False
            
            # 3. ç”Ÿæˆè²¼æ–‡å…§å®¹
            logger.info(f"ğŸ“ é–‹å§‹ç”Ÿæˆè²¼æ–‡å…§å®¹...")
            posts = await self._generate_posts_with_config(kol_assignments, db_task['generation_config'], task_id)
            logger.info(f"ğŸ“ è²¼æ–‡ç”Ÿæˆå®Œæˆ: å…± {len(posts)} ç¯‡è²¼æ–‡")
            
            if not posts or len(posts) == 0:
                logger.warning(f"âš ï¸ æœªç”Ÿæˆä»»ä½•è²¼æ–‡ï¼Œæœ¬æ¬¡æ’ç¨‹è·³éåŸ·è¡Œ - Task ID: {task_id}")
                await self.db_service.increment_schedule_stats(
                    task_id, run_count=1, failure_count=1
                )
                return False
            
            # è©³ç´°è¨˜éŒ„ç”Ÿæˆçš„è²¼æ–‡
            logger.info(f"ğŸ“‹ ç”Ÿæˆçš„è²¼æ–‡è©³æƒ…:")
            for i, post in enumerate(posts, 1):
                post_id = post.get('post_id', 'N/A')
                stock_code = post.get('stock_code', 'N/A')
                stock_name = post.get('stock_name', 'N/A')
                kol_serial = post.get('kol_serial', 'N/A')
                title = post.get('title', 'N/A')
                logger.info(f"   {i}. {post_id}: {stock_code} {stock_name} (KOL-{kol_serial})")
                logger.info(f"      ğŸ“ æ¨™é¡Œ: {title[:50]}..." if len(title) > 50 else f"      ğŸ“ æ¨™é¡Œ: {title}")
            
            # 4. æŒ‰é–“éš”ç™¼å¸ƒè²¼æ–‡ï¼ˆå— auto_posting æ§åˆ¶ï¼‰
            auto_posting_value = db_task.get('auto_posting')
            logger.info(f"ğŸ” èª¿è©¦ auto_posting å€¼: {auto_posting_value} (é¡å‹: {type(auto_posting_value)})")
            
            if auto_posting_value:
                logger.info(f"ğŸš€ é–‹å§‹æŒ‰é–“éš”ç™¼å¸ƒè²¼æ–‡ (é–“éš”: {db_task['interval_seconds']} ç§’)...")
                await self._publish_posts_with_interval(task_id, [post['post_id'] for post in posts], db_task['interval_seconds'])
                logger.info(f"ğŸš€ è²¼æ–‡ç™¼å¸ƒå®Œæˆ")
            else:
                logger.info("ğŸ›‘ è‡ªå‹•ç™¼æ–‡é—œé–‰ï¼Œåƒ…ç”Ÿæˆè²¼æ–‡ä¸ç™¼å¸ƒ")
            
            # ğŸ”¥ æ›´æ–°çµ±è¨ˆæ•¸æ“š - è¨˜éŒ„ç”Ÿæˆçš„è²¼æ–‡æ•¸é‡
            await self.db_service.increment_schedule_stats(
                task_id, run_count=1, success_count=1, posts_generated=len(posts)
            )
            logger.info(f"ğŸ“Š å·²æ›´æ–°æ’ç¨‹çµ±è¨ˆ: ç”Ÿæˆ {len(posts)} ç¯‡è²¼æ–‡")
            
            # è¨˜éŒ„åŸ·è¡ŒæˆåŠŸ
            logger.info(f"âœ… å·¥ä½œæ—¥æ’ç¨‹åŸ·è¡ŒæˆåŠŸå®Œæˆ - Task ID: {task_id}")
            logger.info(f"ğŸ“Š åŸ·è¡Œæ‘˜è¦:")
            logger.info(f"   ğŸ¯ è§¸ç™¼å™¨: {trigger_type}")
            logger.info(f"   ğŸ“ˆ ç¯©é¸è‚¡ç¥¨: {len(stocks)} æª”")
            logger.info(f"   ğŸ‘¥ KOLåˆ†é…: {len(kol_assignments)} å€‹")
            logger.info(f"   ğŸ“ ç”Ÿæˆè²¼æ–‡: {len(posts)} ç¯‡")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæ—¥æ’ç¨‹åŸ·è¡Œå¤±æ•— - Task ID: {task_id}, Error: {e}")
            logger.error(f"ğŸ” éŒ¯èª¤é¡å‹: {type(e).__name__}")
            logger.error(f"ğŸ” éŒ¯èª¤è©³æƒ…: {str(e)}")
            import traceback
            logger.error(f"ğŸ” éŒ¯èª¤å †ç–Š:\n{traceback.format_exc()}")
            
            # å˜—è©¦æ›´æ–°å¤±æ•—çµ±è¨ˆ
            try:
                await self.db_service.increment_schedule_stats(
                    task_id, run_count=1, failure_count=1
                )
                logger.info(f"ğŸ’¾ å·²æ›´æ–°å¤±æ•—çµ±è¨ˆ")
            except Exception as stats_error:
                logger.error(f"âŒ æ›´æ–°å¤±æ•—çµ±è¨ˆå¤±æ•—: {stats_error}")
            
            return False
    
    async def _filter_stocks_by_trigger(self, generation_config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ ¹æ“šè§¸ç™¼å™¨é¡å‹ç¯©é¸è‚¡ç¥¨"""
        trigger_type = generation_config.get('trigger_type', 'limit_up_after_hours')
        stock_sorting = generation_config.get('stock_sorting', 'five_day_change_desc')
        max_stocks = generation_config.get('max_stocks', 10)
        
        logger.info(f"ğŸ” ç¯©é¸è‚¡ç¥¨ - è§¸ç™¼å™¨: {trigger_type}, æ’åº: {stock_sorting}, æœ€å¤§æª”æ•¸: {max_stocks}")
        
        try:
            # å°å…¥è‚¡ç¥¨ç¯©é¸æœå‹™
            from stock_filter_service import stock_filter_service
            
            # èª¿ç”¨å¯¦éš›çš„è‚¡ç¥¨ç¯©é¸æœå‹™
            stocks = await stock_filter_service.filter_stocks_by_trigger(
                trigger_type=trigger_type,
                stock_sorting=stock_sorting,
                max_stocks=max_stocks,
                additional_filters=generation_config.get('additional_filters')
            )
            
            logger.info(f"âœ… è‚¡ç¥¨ç¯©é¸å®Œæˆï¼Œå…± {len(stocks)} æª”è‚¡ç¥¨")
            return stocks
            
        except Exception as e:
            logger.error(f"âŒ è‚¡ç¥¨ç¯©é¸æœå‹™èª¿ç”¨å¤±æ•—: {e}")
            # è¿”å›æ¨¡æ“¬æ•¸æ“šä½œç‚ºå‚™ç”¨
            mock_stocks = [
                {"stock_code": "841", "stock_name": "å¤§æ±Ÿ", "change_percent": 9.8},
                {"stock_code": "2330", "stock_name": "å°ç©é›»", "change_percent": 5.2},
                {"stock_code": "2317", "stock_name": "é´»æµ·", "change_percent": 3.8},
                {"stock_code": "2454", "stock_name": "è¯ç™¼ç§‘", "change_percent": 4.1},
            ]
            return mock_stocks[:max_stocks]
    
    async def _assign_kols_to_stocks(self, stocks: List[Dict[str, Any]], generation_config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ ¹æ“šKOLåˆ†é…æ–¹å¼åˆ†é…KOL"""
        import random
        
        kol_assignment = generation_config.get('kol_assignment', 'random')
        
        logger.info(f"ğŸ‘¥ KOLåˆ†é… - æ–¹å¼: {kol_assignment}")
        
        # æ¨¡æ“¬KOLåˆ—è¡¨ - ä½¿ç”¨å¯¦éš›çš„KOLåç¨±å’Œåºè™Ÿ
        available_kols = [
            {"name": "å·å·å“¥", "serial": "200", "persona": "æŠ€è¡“æ´¾"},
            {"name": "å°é“çˆ†æ–™ç‹", "serial": "201", "persona": "æ¶ˆæ¯æ´¾"},
            {"name": "é•·ç·šéŸ­éŸ­", "serial": "202", "persona": "ç¸½ç¶“+åƒ¹å€¼æ´¾"},
            {"name": "ä¿¡è™Ÿå®…ç¥", "serial": "203", "persona": "é‡åŒ–æ´¾"},
            {"name": "æ¢…å·è¤²å­", "serial": "204", "persona": "æ–°èæ´¾"},
            {"name": "éŸ­å‰²å“¥", "serial": "205", "persona": "ç¸½ç¶“æ´¾"},
            {"name": "é¾œç‹—ä¸€æ—¥æ•£æˆ¶", "serial": "206", "persona": "ç±Œç¢¼æ´¾"},
            {"name": "æŠ€è¡“åˆ†æå¸«", "serial": "207", "persona": "æŠ€è¡“æ´¾"},
            {"name": "åŸºæœ¬é¢é”äºº", "serial": "208", "persona": "åƒ¹å€¼æ´¾"}
        ]
        
        assignments = []
        for i, stock in enumerate(stocks):
            if kol_assignment == 'random':
                # ğŸ”¥ çœŸæ­£çš„éš¨æ©Ÿåˆ†é…
                selected_kol = random.choice(available_kols)
                kol_name = selected_kol["name"]
                kol_serial = selected_kol["serial"]
            else:
                # å›ºå®šæŒ‡æ´¾ç¬¬ä¸€å€‹KOL
                selected_kol = available_kols[0]
                kol_name = selected_kol["name"]
                kol_serial = selected_kol["serial"]
            
            assignments.append({
                "stock_code": stock["stock_code"],
                "stock_name": stock["stock_name"],
                "kol_nickname": kol_name,
                "kol_serial": kol_serial
            })
            
            logger.info(f"ğŸ“Š è‚¡ç¥¨ {stock['stock_code']} åˆ†é…çµ¦ KOL: {kol_name} (åºè™Ÿ: {kol_serial})")
        
        return assignments
    
    async def _generate_posts_with_config(self, kol_assignments: List[Dict[str, Any]], generation_config: Dict[str, Any], task_id: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ç”Ÿæˆé…ç½®ç”Ÿæˆè²¼æ–‡"""
        content_style = generation_config.get('content_style', 'technical')
        content_length = generation_config.get('content_length', 'medium')
        max_words = generation_config.get('max_words', 1000)
        enable_news_links = generation_config.get('enable_news_links', True)  # æ–°å¢ï¼šæ–°èé€£çµé–‹é—œ
        news_max_links = generation_config.get('news_max_links', 5) if enable_news_links else 0  # åªæœ‰å•Ÿç”¨æ™‚æ‰è¨­å®šæ•¸é‡
        
        logger.info(f"ğŸ“ ç”Ÿæˆè²¼æ–‡ - é¢¨æ ¼: {content_style}, é•·åº¦: {content_length}, å­—æ•¸: {max_words}, æ–°èé€£çµ: {'å•Ÿç”¨' if enable_news_links else 'åœç”¨'}({news_max_links}å‰‡)")
        
        posts = []
        for assignment in kol_assignments:
            try:
                # èª¿ç”¨å¯¦éš›çš„å…§å®¹ç”Ÿæˆæœå‹™
                post = await self._generate_single_post(assignment, generation_config, task_id)
                posts.append(post)
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆè²¼æ–‡å¤±æ•— - è‚¡ç¥¨: {assignment['stock_code']}, éŒ¯èª¤: {e}")
                # ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šä½œç‚ºå‚™ç”¨
                post = {
                    "post_id": f"schedule_{assignment['stock_code']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "stock_code": assignment["stock_code"],
                    "stock_name": assignment["stock_name"],
                    "kol_nickname": assignment["kol_nickname"],
                    "kol_serial": assignment["kol_serial"],
                    "title": f"{assignment['stock_name']} æŠ€è¡“åˆ†æ",
                    "content": f"é€™æ˜¯ {assignment['stock_name']} çš„æŠ€è¡“åˆ†æå…§å®¹...",
                    "generation_config": generation_config
                }
                posts.append(post)
        
        return posts
    
    async def _generate_single_post(self, assignment: Dict[str, Any], generation_config: Dict[str, Any], task_id: str) -> Dict[str, Any]:
        """ç”Ÿæˆå–®å€‹è²¼æ–‡ - èª¿ç”¨å¯¦éš›çš„å…§å®¹ç”Ÿæˆæœå‹™"""
        try:
            # å°å…¥å¿…è¦çš„æœå‹™
            from main import manual_post_content
            from main import PostingRequest
            
            # ç²å–æ’ç¨‹ä»»å‹™çš„ auto_posting è¨­å®š
            db_task = await self.db_service.get_schedule_task(task_id)
            auto_posting = db_task.get('auto_posting', False) if db_task else False
            
            # æ§‹å»º PostingRequest
            posting_request = PostingRequest(
                stock_code=assignment["stock_code"],
                stock_name=assignment["stock_name"],
                kol_serial=assignment["kol_serial"],
                kol_persona=generation_config.get('kol_persona', 'technical'),
                content_style=generation_config.get('content_style', 'chart_analysis'),
                target_audience=generation_config.get('target_audience', 'active_traders'),
                content_length=generation_config.get('content_length', 'medium'),
                max_words=generation_config.get('max_words', 1000),
                auto_post=auto_posting,  # æ ¹æ“šæ’ç¨‹ä»»å‹™çš„ auto_posting è¨­å®šæ±ºå®šæ˜¯å¦è‡ªå‹•ç™¼æ–‡
                batch_mode=True,
                session_id=0,  # æ’ç¨‹ç³»çµ±ä½¿ç”¨ 0 ä½œç‚º session_id
                trigger_type=generation_config.get('trigger_type', 'limit_up_after_hours'),
                # æ–°å¢ï¼šæ–°èé€£çµé…ç½®
                enable_news_links=generation_config.get('enable_news_links', True),
                news_max_links=generation_config.get('news_max_links', 5) if generation_config.get('enable_news_links', True) else 0
            )
            
            logger.info(f"ğŸ¯ èª¿ç”¨å…§å®¹ç”Ÿæˆæœå‹™ - Task ID: {task_id}, è‚¡ç¥¨: {assignment['stock_code']}, KOL: {assignment['kol_serial']}")
            
            # è¨­ç½®ç•¶å‰task_idï¼Œä¾›manual_post_contentä½¿ç”¨
            import os
            os.environ['CURRENT_SCHEDULE_TASK_ID'] = task_id
            
            # èª¿ç”¨å…§å®¹ç”Ÿæˆæœå‹™
            result = await manual_post_content(posting_request)
            
            # ğŸ”¥ ä¿®å¾©ï¼šæ’ç¨‹å®Œæˆå¾Œæ¸…é™¤ç’°å¢ƒè®Šæ•¸ï¼Œé¿å…å½±éŸ¿å¾ŒçºŒæ‰‹å‹•æ“ä½œ
            if 'CURRENT_SCHEDULE_TASK_ID' in os.environ:
                del os.environ['CURRENT_SCHEDULE_TASK_ID']
            
            if result.success:
                logger.info(f"âœ… å…§å®¹ç”ŸæˆæˆåŠŸ - Post ID: {result.post_id}")
                return {
                    "post_id": result.post_id,
                    "stock_code": assignment["stock_code"],
                    "stock_name": assignment["stock_name"],
                    "kol_nickname": assignment["kol_nickname"],
                    "kol_serial": assignment["kol_serial"],
                    "title": result.content.get('title', f"{assignment['stock_name']} åˆ†æ"),
                    "content": result.content.get('content', ''),
                    "generation_config": generation_config
                }
            else:
                raise Exception(f"å…§å®¹ç”Ÿæˆå¤±æ•—: {result.error}")
                
        except Exception as e:
            logger.error(f"âŒ å–®å€‹è²¼æ–‡ç”Ÿæˆå¤±æ•—: {e}")
            raise e
    
    async def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """ç²å–ä»»å‹™ç‹€æ…‹ - å¾è³‡æ–™åº«ç²å–"""
        db_task = await self.db_service.get_schedule_task(task_id)
        if not db_task:
            return None
        
        # ç²å–ç”Ÿæˆçš„è²¼æ–‡åˆ—è¡¨
        generated_posts = await self.db_service.get_schedule_posts(task_id)
        
        # ç¢ºä¿æ‰€æœ‰æ™‚é–“æ¬„ä½éƒ½æ­£ç¢ºåºåˆ—åŒ–
        created_at_str = db_task['created_at'].isoformat() if db_task.get('created_at') else None
        last_run_str = db_task['last_run'].isoformat() if db_task.get('last_run') else None
        next_run_str = db_task['next_run'].isoformat() if db_task.get('next_run') else None
        started_at_str = db_task['started_at'].isoformat() if db_task.get('started_at') else None
        completed_at_str = db_task['completed_at'].isoformat() if db_task.get('completed_at') else None

        # ç¢ºä¿æ‰€æœ‰æ•¸å€¼æ¬„ä½éƒ½æ˜¯æ•¸å­—ï¼Œä¸æ˜¯ None
        run_count = db_task.get('run_count') or 0
        success_count = db_task.get('success_count') or 0
        failure_count = db_task.get('failure_count') or 0
        total_posts_generated = db_task.get('total_posts_generated') or 0
        interval_seconds = db_task.get('interval_seconds') or 30

        # è¨ˆç®—æˆåŠŸç‡ï¼Œç¢ºä¿ä¸æœƒé™¤ä»¥é›¶
        success_rate = (success_count / max(run_count, 1)) * 100 if run_count > 0 else 0.0

        return {
            'task_id': db_task['schedule_id'],
            'name': db_task.get('schedule_name') or 'Unnamed Schedule',
            'description': db_task.get('schedule_description') or f"åŸºæ–¼æ‰¹æ¬¡ {db_task.get('session_id', 'N/A')} çš„æ’ç¨‹",
            'session_id': db_task.get('session_id') or 0,
            'post_ids': generated_posts,  # å¾é—œè¯è¡¨ç²å–
            'schedule_type': db_task.get('schedule_type') or 'weekday_daily',
            'status': db_task.get('status') or 'pending',
            'auto_posting': bool(db_task.get('auto_posting', False)),  # ç¢ºä¿æ˜¯å¸ƒæ—å€¼
            'created_at': created_at_str,
            'last_run': last_run_str,
            'next_run': next_run_str,
            'run_count': run_count,
            'success_count': success_count,
            'failure_count': failure_count,
            'success_rate': round(success_rate, 2),
            'started_at': started_at_str,
            'completed_at': completed_at_str,
            'error_message': db_task.get('error_message'),
            'total_posts_generated': total_posts_generated,
            'interval_seconds': interval_seconds,
            'schedule_config': {
                'enabled': db_task.get('status') == 'active',
                'posting_time_slots': [db_task['daily_execution_time']] if db_task.get('daily_execution_time') else [],
                'timezone': db_task.get('timezone') or 'Asia/Taipei',
                'auto_posting': bool(db_task.get('auto_posting', False))
            },
            'trigger_config': {
                'trigger_type': (db_task.get('generation_config') or {}).get('trigger_type', 'limit_up_after_hours'),
                'stock_codes': [],  # ä¸é¡¯ç¤ºå…·é«”è‚¡ç¥¨ä»£ç¢¼
                'kol_assignment': (db_task.get('generation_config') or {}).get('kol_assignment', 'random'),
                'max_stocks': (db_task.get('generation_config') or {}).get('max_stocks', 10) or 10,
                'stock_sorting': {
                    'primary_sort': (db_task.get('generation_config') or {}).get('stock_sorting', 'five_day_change_desc')
                }
            },
            'batch_info': db_task.get('batch_info') or {},
            'generation_config': db_task.get('generation_config') or {}
        }
    
    async def get_all_tasks(self) -> List[Dict[str, Any]]:
        """ç²å–æ‰€æœ‰ä»»å‹™ - å¾è³‡æ–™åº«ç²å–"""
        db_tasks = await self.db_service.get_all_schedule_tasks()
        result = []
        for task in db_tasks:
            task_status = await self.get_task_status(task['schedule_id'])
            if task_status:
                result.append(task_status)
        return result
    
    async def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»å‹™"""
        # å–æ¶ˆæ­£åœ¨é‹è¡Œçš„ä»»å‹™
        if task_id in self.running_tasks:
            self.running_tasks[task_id].cancel()
            del self.running_tasks[task_id]
        
        # æ›´æ–°è³‡æ–™åº«ç‹€æ…‹
        success = await self.db_service.cancel_schedule_task(task_id)
        if success:
            # æ›´æ–°è¨˜æ†¶é«”ä¸­çš„ä»»å‹™ç‹€æ…‹
            if task_id in self.tasks:
                self.tasks[task_id].status = 'cancelled'
            logger.info(f"âœ… æ’ç¨‹ä»»å‹™å·²å–æ¶ˆ - Task ID: {task_id}")
        
        return success
    
    async def _should_execute_now(self, task: Dict[str, Any]) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²ç¾åœ¨åŸ·è¡Œæ’ç¨‹"""
        try:
            schedule_type = task['schedule_type']
            daily_execution_time = task.get('daily_execution_time')
            weekdays_only = task.get('weekdays_only', True)
            timezone = task.get('timezone', 'Asia/Taipei')
            
            logger.info(f"ğŸ” æª¢æŸ¥åŸ·è¡Œæ™‚é–“ - Task ID: {task.get('schedule_id')}")
            logger.info(f"   ğŸ“… daily_execution_time: {repr(daily_execution_time)}")
            logger.info(f"   ğŸŒ timezone: {timezone}")
            
            # ç²å–ç•¶å‰æ™‚é–“
            tz = pytz.timezone(timezone)
            now = datetime.now(tz)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºå·¥ä½œæ—¥
            if weekdays_only and now.weekday() >= 5:  # 0-4 æ˜¯é€±ä¸€åˆ°é€±äº”ï¼Œ5-6 æ˜¯é€±æœ«
                logger.info(f"ğŸ“… ä»Šå¤©æ˜¯é€±æœ«ï¼Œè·³éåŸ·è¡Œ - Task ID: {task['schedule_id']}")
                return False
            
            # æª¢æŸ¥åŸ·è¡Œæ™‚é–“
            if daily_execution_time:
                try:
                    # è§£æåŸ·è¡Œæ™‚é–“ (æ ¼å¼: "09:00" æˆ– "09:00-18:00" æˆ– ISO æ ¼å¼)
                    # å…ˆè™•ç† ISO æ ¼å¼æ™‚é–“ (2025-09-30T20:04:00.000Z)
                    if 'T' in daily_execution_time:
                        time_part = daily_execution_time.split('T')[1].split('.')[0]
                        execution_time = datetime.strptime(time_part, '%H:%M:%S').time()
                        current_time = now.time()
                        
                        # åš´æ ¼æŒ‰ç…§è¨­å®šæ™‚é–“åŸ·è¡Œï¼Œä¸å…è¨±æå‰åŸ·è¡Œ
                        current_seconds = current_time.hour * 3600 + current_time.minute * 60 + current_time.second
                        execution_seconds = execution_time.hour * 3600 + execution_time.minute * 60 + execution_time.second
                        
                        # åªå…è¨±åœ¨è¨­å®šæ™‚é–“ä¹‹å¾Œçš„ 2 åˆ†é˜å…§åŸ·è¡Œï¼ˆä¸å…è¨±æå‰ï¼‰
                        if current_seconds >= execution_seconds and current_seconds <= execution_seconds + 120:
                            return True
                    elif '-' in daily_execution_time and ':' in daily_execution_time:
                        # æ™‚é–“ç¯„åœæ ¼å¼ (09:00-18:00)
                        parts = daily_execution_time.split('-')
                        if len(parts) == 2:
                            start_time_str = parts[0].strip()
                            end_time_str = parts[1].strip()
                            start_time = datetime.strptime(start_time_str, '%H:%M').time()
                            end_time = datetime.strptime(end_time_str, '%H:%M').time()
                            
                            # æª¢æŸ¥æ˜¯å¦åœ¨åŸ·è¡Œæ™‚é–“ç¯„åœå…§
                            current_time = now.time()
                            if start_time <= current_time <= end_time:
                                return True
                    else:
                        # å–®ä¸€æ™‚é–“é»
                        logger.info(f"   ğŸ• è§£æå–®ä¸€æ™‚é–“é»: {daily_execution_time}")
                        execution_time = datetime.strptime(daily_execution_time.strip(), '%H:%M').time()
                        current_time = now.time()
                        
                        logger.info(f"   ğŸ• åŸ·è¡Œæ™‚é–“: {execution_time}")
                        logger.info(f"   ğŸ• ç•¶å‰æ™‚é–“: {current_time}")
                        
                        # åš´æ ¼æŒ‰ç…§è¨­å®šæ™‚é–“åŸ·è¡Œï¼Œä¸å…è¨±æå‰åŸ·è¡Œ
                        current_seconds = current_time.hour * 3600 + current_time.minute * 60 + current_time.second
                        execution_seconds = execution_time.hour * 3600 + execution_time.minute * 60
                        
                        logger.info(f"   ğŸ• ç•¶å‰ç§’æ•¸: {current_seconds}")
                        logger.info(f"   ğŸ• åŸ·è¡Œç§’æ•¸: {execution_seconds}")
                        
                        # åªå…è¨±åœ¨è¨­å®šæ™‚é–“ä¹‹å¾Œçš„ 1 åˆ†é˜å…§åŸ·è¡Œï¼ˆä¸å…è¨±æå‰ï¼‰
                        if current_seconds >= execution_seconds and current_seconds <= execution_seconds + 60:
                            logger.info(f"   âœ… æ™‚é–“æª¢æŸ¥é€šéï¼Œæ‡‰è©²åŸ·è¡Œ")
                            return True
                        else:
                            logger.info(f"   âŒ æ™‚é–“æª¢æŸ¥å¤±æ•—ï¼Œä¸åŸ·è¡Œ")
                            return False
                except ValueError as e:
                    logger.error(f"âŒ è§£æåŸ·è¡Œæ™‚é–“å¤±æ•—: {daily_execution_time}, Error: {e}")
                    logger.error(f"âŒ ç•¶å‰æ™‚é–“: {now}, æ™‚å€: {timezone}")
                    return False
            
            # å¦‚æœæ²’æœ‰è¨­å®šåŸ·è¡Œæ™‚é–“ï¼Œå‰‡ä¸åŸ·è¡Œï¼ˆç­‰å¾…è¨­å®šï¼‰
            logger.warning(f"âš ï¸ æ’ç¨‹æ²’æœ‰è¨­å®šåŸ·è¡Œæ™‚é–“ï¼Œè·³éåŸ·è¡Œ - Task ID: {task['schedule_id']}")
            return False
            
        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥åŸ·è¡Œæ™‚é–“å¤±æ•—: {e}")
            return False
    
    async def _calculate_next_run_time(self, task: Dict[str, Any]) -> Optional[datetime]:
        """è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“ - æ™‚å€å›ºå®šå°åŒ—æ™‚é–“ï¼Œæ˜å¤©åŒä¸€æ™‚é–“åŸ·è¡Œ"""
        try:
            daily_execution_time = task.get('daily_execution_time')
            task_id = task.get('schedule_id', 'Unknown')
            
            logger.info(f"â° é–‹å§‹è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“ - Task ID: {task_id}")
            logger.info(f"   ğŸ“ åŸ·è¡Œæ™‚é–“è¨­å®š: {daily_execution_time}")
            
            if not daily_execution_time:
                logger.error(f"âŒ æ²’æœ‰è¨­å®šåŸ·è¡Œæ™‚é–“ - Task ID: {task_id}")
                return None
            
            if not daily_execution_time:
                # å¦‚æœæ²’æœ‰è¨­å®šåŸ·è¡Œæ™‚é–“ï¼Œè¿”å› Noneï¼ˆæœƒç­‰å¾… 1 å°æ™‚ï¼‰
                return None
            
            # å›ºå®šä½¿ç”¨å°åŒ—æ™‚å€
            tz = pytz.timezone('Asia/Taipei')
            now = datetime.now(tz)
            
            try:
                # è™•ç† ISO æ ¼å¼æ™‚é–“ (2025-09-30T20:04:00.000Z)
                if 'T' in daily_execution_time:
                    # ISO æ ¼å¼ï¼Œæå–æ™‚é–“éƒ¨åˆ†
                    time_part_with_tz = daily_execution_time.split('T')[1]  # 20:04:00.000Z
                    time_part_only = time_part_with_tz.split('.')[0]  # 20:04:00
                    execution_time = datetime.strptime(time_part_only, '%H:%M:%S').time()
                elif ',' in daily_execution_time:
                    # å¤šå€‹æ™‚é–“ç¯„åœ (ä¾‹å¦‚: 09:00-12:00,14:00-18:00)
                    first_range = daily_execution_time.split(',')[0]
                    if '-' in first_range:
                        parts = first_range.split('-')
                        start_time_str = parts[0].strip()
                        execution_time = datetime.strptime(start_time_str, '%H:%M').time()
                    else:
                        execution_time = datetime.strptime(first_range.strip(), '%H:%M').time()
                elif '-' in daily_execution_time and ':' in daily_execution_time:
                    # æ™‚é–“ç¯„åœï¼Œè¨ˆç®—æ˜å¤©çš„é–‹å§‹æ™‚é–“ (ä¾‹å¦‚: 09:00-12:00)
                    parts = daily_execution_time.split('-')
                    start_time_str = parts[0].strip()
                    execution_time = datetime.strptime(start_time_str, '%H:%M').time()
                else:
                    # å–®ä¸€æ™‚é–“é»
                    execution_time = datetime.strptime(daily_execution_time.strip(), '%H:%M').time()
                
                # è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“ï¼šå…ˆæª¢æŸ¥ä»Šå¤©æ˜¯å¦å·²éåŸ·è¡Œæ™‚é–“
                today_execution = tz.localize(datetime.combine(now.date(), execution_time))
                
                if now < today_execution:
                    # ä»Šå¤©çš„åŸ·è¡Œæ™‚é–“é‚„æ²’åˆ°ï¼Œä½¿ç”¨ä»Šå¤©
                    next_run = today_execution
                    logger.info(f"â° è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“: {next_run} (ä»Šå¤©ï¼Œå°åŒ—æ™‚é–“)")
                else:
                    # ä»Šå¤©çš„åŸ·è¡Œæ™‚é–“å·²éï¼Œä½¿ç”¨æ˜å¤©
                    tomorrow = now.date() + timedelta(days=1)
                    next_run = tz.localize(datetime.combine(tomorrow, execution_time))
                    logger.info(f"â° è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“: {next_run} (æ˜å¤©ï¼Œå°åŒ—æ™‚é–“)")
                
                return next_run
                
            except ValueError as e:
                logger.error(f"âŒ è§£æåŸ·è¡Œæ™‚é–“å¤±æ•—: {daily_execution_time}, Error: {e}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“å¤±æ•—: {e}")
            return None

# å…¨å±€æ’ç¨‹æœå‹™å¯¦ä¾‹
schedule_service = ScheduleService()