"""
äº’å‹•æ•¸æ“šå»é‡å’Œæ‰¹é‡æŠ“å– API
"""

import json
import os
import asyncio
import sys
from datetime import datetime
from typing import List, Dict, Any, Optional
from fastapi import APIRouter, HTTPException, BackgroundTasks
import logging

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

logger = logging.getLogger(__name__)

# å‰µå»ºè·¯ç”±å™¨
router = APIRouter(prefix="/interactions", tags=["interactions"])

# å°å…¥å…¨å±€æœå‹™å¯¦ä¾‹
post_record_service = None

def get_post_record_service():
    global post_record_service
    if post_record_service is None:
        try:
            from postgresql_service import PostgreSQLPostRecordService
            post_record_service = PostgreSQLPostRecordService()
        except Exception as e:
            logger.error(f"âŒ PostgreSQL æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
            return None
    return post_record_service

def load_external_posts_data() -> Dict[str, Any]:
    """è¼‰å…¥å¤–éƒ¨è²¼æ–‡æ•¸æ“š"""
    try:
        external_data_file = "processed_external_posts.json"
        if os.path.exists(external_data_file):
            with open(external_data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # è™•ç†ä¸åŒçš„æ•¸æ“šæ ¼å¼
                if isinstance(data, list):
                    # å¦‚æœæ˜¯æ•¸çµ„æ ¼å¼
                    return {"posts": data, "kol_stats": {}, "total_posts": len(data)}
                elif isinstance(data, dict):
                    # å¦‚æœæ˜¯å°è±¡æ ¼å¼
                    return data
                else:
                    logger.warning("âš ï¸ å¤–éƒ¨è²¼æ–‡æ•¸æ“šæ ¼å¼ä¸æ­£ç¢º")
                    return {"posts": [], "kol_stats": {}, "total_posts": 0}
        else:
            logger.warning("âš ï¸ å¤–éƒ¨è²¼æ–‡æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨")
            return {"posts": [], "kol_stats": {}, "total_posts": 0}
    except Exception as e:
        logger.error(f"âŒ è¼‰å…¥å¤–éƒ¨è²¼æ–‡æ•¸æ“šå¤±æ•—: {e}")
        return {"posts": [], "kol_stats": {}, "total_posts": 0}

async def get_kol_credentials_from_db(kol_serial: int):
    """å¾ KOL SQL æ•¸æ“šåº«ç²å–æ†‘è­‰"""
    try:
        from kol_database_service import kol_db_service
        
        kol_data = kol_db_service.get_kol_by_serial(str(kol_serial))
        
        if not kol_data:
            logger.warning(f"âš ï¸ æ‰¾ä¸åˆ° KOL-{kol_serial} çš„æ•¸æ“š")
            return None
            
        # å°å…¥ LoginCredentials
        try:
            from src.clients.cmoney.cmoney_client import LoginCredentials
        except ImportError:
            logger.error("âŒ ç„¡æ³•å°å…¥ LoginCredentials")
            return None
        
        credentials = LoginCredentials(
            email=kol_data.email,
            password=kol_data.password
        )
        
        logger.info(f"âœ… å¾æ•¸æ“šåº«ç²å– KOL-{kol_serial} æ†‘è­‰æˆåŠŸ")
        return credentials
        
    except Exception as e:
        logger.error(f"âŒ å¾æ•¸æ“šåº«ç²å– KOL-{kol_serial} æ†‘è­‰å¤±æ•—: {e}")
        return None

async def get_kol_credentials_fallback(kol_serial: int):
    """ç¡¬ç·¨ç¢¼ KOL æ†‘è­‰å›é€€å‡½æ•¸"""
    try:
        try:
            from src.clients.cmoney.cmoney_client import LoginCredentials
        except ImportError:
            logger.error("âŒ ç„¡æ³•å°å…¥ LoginCredentials")
            return None
        
        # å¾ç’°å¢ƒè®Šæ•¸ç²å– KOL æ†‘è­‰
        import os
        kol_email = os.getenv(f'KOL_{kol_serial}_EMAIL')
        kol_password = os.getenv(f'KOL_{kol_serial}_PASSWORD')
        
        if kol_email and kol_password:
            credentials = LoginCredentials(email=kol_email, password=kol_password)
            logger.info(f"âœ… å¾ç’°å¢ƒè®Šæ•¸ç²å– KOL-{kol_serial} æ†‘è­‰")
            return credentials
        else:
            logger.warning(f"âš ï¸ ç’°å¢ƒè®Šæ•¸ä¸­æ‰¾ä¸åˆ° KOL-{kol_serial} çš„æ†‘è­‰")
            # å˜—è©¦ä½¿ç”¨é è¨­ KOL æ†‘è­‰
            default_email = os.getenv('DEFAULT_KOL_EMAIL')
            default_password = os.getenv('DEFAULT_KOL_PASSWORD')
            
            if default_email and default_password:
                return LoginCredentials(email=default_email, password=default_password)
            else:
                logger.error(f"âŒ ç’°å¢ƒè®Šæ•¸ä¸­æ‰¾ä¸åˆ°é è¨­ KOL æ†‘è­‰")
                return None
                
    except Exception as e:
        logger.error(f"âŒ å¾ç’°å¢ƒè®Šæ•¸ç²å– KOL æ†‘è­‰å¤±æ•—: {e}")
        return None

@router.post("/deduplicate")
async def deduplicate_posts():
    """å»é‡åŠŸèƒ½ï¼šåˆªé™¤é‡è¤‡çš„ article_id"""
    
    try:
        logger.info("ğŸ”„ é–‹å§‹åŸ·è¡Œå»é‡æ“ä½œ...")
        
        # ç²å–æ‰€æœ‰è²¼æ–‡ï¼ˆç³»çµ± + å¤–éƒ¨ï¼‰
        system_posts = []
        if get_post_record_service():
            published_posts = get_post_record_service().get_all_posts(status='published')
            system_posts = [
                {
                    "post_id": post.post_id,
                    "article_id": post.cmoney_post_id,
                    "kol_serial": post.kol_serial,
                    "source": "system"
                }
                for post in published_posts if post.cmoney_post_id
            ]
        
        external_data = load_external_posts_data()
        external_posts = [
            {
                "post_id": post["post_id"],
                "article_id": post["article_id"],
                "kol_serial": post["kol_serial"],
                "source": "external"
            }
            for post in external_data.get("posts", [])
        ]
        
        all_posts = system_posts + external_posts
        
        # çµ±è¨ˆ article_id å‡ºç¾æ¬¡æ•¸
        article_id_count = {}
        for post in all_posts:
            article_id = post["article_id"]
            if article_id not in article_id_count:
                article_id_count[article_id] = []
            article_id_count[article_id].append(post)
        
        # æ‰¾å‡ºé‡è¤‡çš„ article_id
        duplicates = {aid: posts for aid, posts in article_id_count.items() if len(posts) > 1}
        
        # å»é‡ç­–ç•¥ï¼šä¿ç•™ç³»çµ±ç™¼æ–‡ï¼Œåˆªé™¤å¤–éƒ¨é‡è¤‡
        removed_count = 0
        duplicate_details = []
        
        for article_id, posts in duplicates.items():
            system_posts_for_article = [p for p in posts if p["source"] == "system"]
            external_posts_for_article = [p for p in posts if p["source"] == "external"]
            
            if system_posts_for_article and external_posts_for_article:
                # å¦‚æœæœ‰ç³»çµ±ç™¼æ–‡ï¼Œä¿ç•™ç³»çµ±ç™¼æ–‡ï¼Œåˆªé™¤å¤–éƒ¨é‡è¤‡
                for external_post in external_posts_for_article:
                    duplicate_details.append({
                        "article_id": article_id,
                        "removed_post_id": external_post["post_id"],
                        "removed_source": "external",
                        "kept_post_id": system_posts_for_article[0]["post_id"],
                        "kept_source": "system"
                    })
                    removed_count += 1
            elif len(external_posts_for_article) > 1:
                # å¦‚æœåªæœ‰å¤–éƒ¨ç™¼æ–‡ï¼Œä¿ç•™ç¬¬ä¸€å€‹ï¼Œåˆªé™¤å…¶ä»–
                kept_post = external_posts_for_article[0]
                for external_post in external_posts_for_article[1:]:
                    duplicate_details.append({
                        "article_id": article_id,
                        "removed_post_id": external_post["post_id"],
                        "removed_source": "external",
                        "kept_post_id": kept_post["post_id"],
                        "kept_source": "external"
                    })
                    removed_count += 1
        
        logger.info(f"âœ… å»é‡å®Œæˆ - ç™¼ç¾ {len(duplicates)} å€‹é‡è¤‡ article_idï¼Œç§»é™¤ {removed_count} å€‹é‡è¤‡è¨˜éŒ„")
        
        return {
            "success": True,
            "message": f"å»é‡å®Œæˆ - ç™¼ç¾ {len(duplicates)} å€‹é‡è¤‡ article_idï¼Œç§»é™¤ {removed_count} å€‹é‡è¤‡è¨˜éŒ„",
            "duplicate_count": len(duplicates),
            "removed_count": removed_count,
            "duplicate_details": duplicate_details,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ å»é‡æ“ä½œå¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å»é‡æ“ä½œå¤±æ•—: {str(e)}")

@router.post("/fetch-all-interactions")
async def fetch_all_interactions(background_tasks: BackgroundTasks):
    """ä¸€éµæŠ“å–æ‰€æœ‰éå¾€äº’å‹•æ•¸æ“š"""
    
    try:
        logger.info("ğŸ”„ é–‹å§‹ä¸€éµæŠ“å–æ‰€æœ‰éå¾€äº’å‹•æ•¸æ“š...")
        
        # ç²å–æ‰€æœ‰è²¼æ–‡ï¼ˆç³»çµ± + å¤–éƒ¨ï¼‰
        system_posts = []
        if get_post_record_service():
            published_posts = get_post_record_service().get_all_posts(status='published')
            system_posts = [
                {
                    "post_id": post.post_id,
                    "article_id": post.cmoney_post_id,
                    "kol_serial": post.kol_serial,
                    "source": "system"
                }
                for post in published_posts if post.cmoney_post_id
            ]
        
        external_data = load_external_posts_data()
        external_posts = [
            {
                "post_id": post["post_id"],
                "article_id": post["article_id"],
                "kol_serial": post["kol_serial"],
                "source": "external"
            }
            for post in external_data.get("posts", [])
        ]
        
        all_posts = system_posts + external_posts
        total_posts = len(all_posts)
        
        logger.info(f"ğŸ“Š æ‰¾åˆ° {total_posts} ç¯‡è²¼æ–‡éœ€è¦æŠ“å–äº’å‹•æ•¸æ“š")
        
        # åœ¨èƒŒæ™¯ä»»å‹™ä¸­åŸ·è¡ŒæŠ“å–
        background_tasks.add_task(fetch_interactions_background, all_posts)
        
        return {
            "success": True,
            "message": f"å·²é–‹å§‹æŠ“å– {total_posts} ç¯‡è²¼æ–‡çš„äº’å‹•æ•¸æ“šï¼Œè«‹ç¨å¾ŒæŸ¥çœ‹çµæœ",
            "total_posts": total_posts,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ ä¸€éµæŠ“å–å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä¸€éµæŠ“å–å¤±æ•—: {str(e)}")

async def fetch_interactions_background(all_posts: List[Dict[str, Any]]):
    """èƒŒæ™¯ä»»å‹™ï¼šæŠ“å–æ‰€æœ‰è²¼æ–‡çš„äº’å‹•æ•¸æ“š"""
    
    logger.info(f"ğŸ”„ èƒŒæ™¯ä»»å‹™é–‹å§‹æŠ“å– {len(all_posts)} ç¯‡è²¼æ–‡çš„äº’å‹•æ•¸æ“š")
    
    success_count = 0
    failed_count = 0
    results = []
    
    for i, post in enumerate(all_posts, 1):
        try:
            logger.info(f"ğŸ“Š è™•ç†ç¬¬ {i}/{len(all_posts)} ç¯‡è²¼æ–‡: {post['article_id']}")
            
            # èª¿ç”¨äº’å‹•æ•¸æ“šç²å–å‡½æ•¸
            from routes.interaction_routes import get_cmoney_interaction_data
            
            interaction_data = await get_cmoney_interaction_data(
                post["article_id"], 
                post["kol_serial"]
            )
            
            if interaction_data:
                result = {
                    "post_id": post["post_id"],
                    "article_id": post["article_id"],
                    "kol_serial": post["kol_serial"],
                    "source": post["source"],
                    "interaction_data": interaction_data,
                    "status": "success"
                }
                
                # æ›´æ–°æ•¸æ“š
                if post["source"] == "system" and get_post_record_service():
                    # ç³»çµ±è²¼æ–‡ï¼šæ›´æ–°æ•¸æ“šåº«
                    update_data = {
                        'views': interaction_data.get('views', 0),
                        'likes': interaction_data.get('likes', 0),
                        'comments': interaction_data.get('comments', 0),
                        'shares': interaction_data.get('shares', 0),
                        'updated_at': datetime.now()
                    }
                    
                    get_post_record_service().update_post_record(post["post_id"], update_data)
                    logger.info(f"âœ… ç³»çµ±è²¼æ–‡æ•¸æ“šå·²æ›´æ–°åˆ°æ•¸æ“šåº« - {post['article_id']}")
                    
                elif post["source"] == "external":
                    # å¤–éƒ¨è²¼æ–‡ï¼šæ›´æ–° JSON æ–‡ä»¶
                    try:
                        external_data = load_external_posts_data()
                        posts = external_data.get("posts", [])
                        
                        # æ‰¾åˆ°å°æ‡‰çš„å¤–éƒ¨è²¼æ–‡ä¸¦æ›´æ–°
                        for j, ext_post in enumerate(posts):
                            if ext_post.get("post_id") == post["post_id"]:
                                posts[j].update({
                                    'views': interaction_data.get('views', 0),
                                    'likes': interaction_data.get('likes', 0),
                                    'comments': interaction_data.get('comments', 0),
                                    'shares': interaction_data.get('shares', 0),
                                    'bookmarks': interaction_data.get('bookmarks', 0),
                                    'donations': interaction_data.get('donations', 0),
                                    'updated_at': datetime.now().isoformat()
                                })
                                break
                        
                        # ä¿å­˜æ›´æ–°å¾Œçš„æ•¸æ“š
                        external_data["posts"] = posts
                        with open("processed_external_posts.json", 'w', encoding='utf-8') as f:
                            json.dump(external_data, f, ensure_ascii=False, indent=2)
                        
                        logger.info(f"âœ… å¤–éƒ¨è²¼æ–‡æ•¸æ“šå·²æ›´æ–°åˆ°æ–‡ä»¶ - {post['article_id']}")
                        
                    except Exception as e:
                        logger.error(f"âŒ æ›´æ–°å¤–éƒ¨è²¼æ–‡æ•¸æ“šå¤±æ•— - {post['article_id']}: {e}")
                
                success_count += 1
                logger.info(f"âœ… æˆåŠŸæŠ“å– - {post['article_id']}: {interaction_data}")
            else:
                result = {
                    "post_id": post["post_id"],
                    "article_id": post["article_id"],
                    "kol_serial": post["kol_serial"],
                    "source": post["source"],
                    "status": "failed",
                    "error": "ç„¡æ³•ç²å–äº’å‹•æ•¸æ“š"
                }
                failed_count += 1
                logger.warning(f"âš ï¸ æŠ“å–å¤±æ•— - {post['article_id']}")
            
            results.append(result)
            
            # é¿å…è«‹æ±‚éæ–¼é »ç¹
            await asyncio.sleep(0.5)
            
        except Exception as e:
            logger.error(f"âŒ æŠ“å–è²¼æ–‡ {post['article_id']} å¤±æ•—: {str(e)}")
            failed_count += 1
            results.append({
                "post_id": post["post_id"],
                "article_id": post["article_id"],
                "kol_serial": post["kol_serial"],
                "source": post["source"],
                "status": "error",
                "error": str(e)
            })
    
    logger.info(f"âœ… èƒŒæ™¯ä»»å‹™å®Œæˆ - æˆåŠŸ: {success_count}, å¤±æ•—: {failed_count}")
    
    # ä¿å­˜çµæœåˆ°æ–‡ä»¶
    result_file = f"interaction_fetch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            "summary": {
                "total_posts": len(all_posts),
                "success_count": success_count,
                "failed_count": failed_count,
                "timestamp": datetime.now().isoformat()
            },
            "results": results
        }, f, ensure_ascii=False, indent=2)
    
    logger.info(f"ğŸ’¾ æŠ“å–çµæœå·²ä¿å­˜åˆ°: {result_file}")

@router.post("/refresh-all")
async def refresh_all_interactions():
    """æ‰¹é‡åˆ·æ–°æ‰€æœ‰è²¼æ–‡çš„äº’å‹•æ•¸æ“šï¼ˆæ”¹é€²ç‰ˆï¼‰"""
    
    try:
        logger.info("ğŸ”„ é–‹å§‹æ‰¹é‡åˆ·æ–°æ‰€æœ‰è²¼æ–‡çš„äº’å‹•æ•¸æ“š...")
        
        # å…ˆåŸ·è¡Œå»é‡
        deduplicate_result = await deduplicate_posts()
        
        # å†åŸ·è¡Œä¸€éµæŠ“å–
        fetch_result = await fetch_all_interactions(BackgroundTasks())
        
        return {
            "success": True,
            "message": "æ‰¹é‡åˆ·æ–°å®Œæˆ - å·²å»é‡ä¸¦æŠ“å–æœ€æ–°äº’å‹•æ•¸æ“š",
            "deduplicate": deduplicate_result,
            "fetch": fetch_result,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡åˆ·æ–°å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡åˆ·æ–°å¤±æ•—: {str(e)}")

@router.get("/stats")
async def get_interaction_stats():
    """ç²å–äº’å‹•æ•¸æ“šçµ±è¨ˆ"""
    try:
        post_service = get_post_record_service()
        if not post_service:
            raise HTTPException(status_code=500, detail="æ•¸æ“šåº«æœå‹™ä¸å¯ç”¨")
        
        all_posts = post_service.get_all_posts(limit=10000)
        
        total_posts = len(all_posts)
        posts_with_interactions = sum(1 for post in all_posts if post.get('likes', 0) > 0 or post.get('views', 0) > 0)
        
        total_views = sum(post.get('views', 0) for post in all_posts)
        total_likes = sum(post.get('likes', 0) for post in all_posts)
        total_comments = sum(post.get('comments', 0) for post in all_posts)
        total_shares = sum(post.get('shares', 0) for post in all_posts)
        
        return {
            "total_posts": total_posts,
            "posts_with_interactions": posts_with_interactions,
            "interaction_coverage": round(posts_with_interactions / total_posts * 100, 2) if total_posts > 0 else 0,
            "total_views": total_views,
            "total_likes": total_likes,
            "total_comments": total_comments,
            "total_shares": total_shares,
            "total_engagement": total_likes + total_comments + total_shares
        }
        
    except Exception as e:
        logger.error(f"âŒ ç²å–äº’å‹•æ•¸æ“šçµ±è¨ˆå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"çµ±è¨ˆå¤±æ•—: {str(e)}")