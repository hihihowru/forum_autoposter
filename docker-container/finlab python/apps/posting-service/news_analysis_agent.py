"""
æ–°èåˆ†æAgent
é¡ä¼¼ChatGPTçš„å¤šç¶­åº¦æ–°èåˆ†æå’Œç¸½çµç³»çµ±
"""

import os
import openai
import requests
import json
from typing import Dict, List, Any, Optional
import logging
from datetime import datetime
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv('../../../../.env')

logger = logging.getLogger(__name__)

class NewsAnalysisAgent:
    """æ–°èåˆ†æAgent - å¤šç¶­åº¦åˆ†ææ–°èä¸¦æä¾›å»ºè¨­æ€§è¦‹è§£"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = None):
        # é‡æ–°è¼‰å…¥ç’°å¢ƒè®Šæ•¸ä»¥ç¢ºä¿API Keyæ­£ç¢ºè¼‰å…¥
        load_dotenv('../../../../.env')
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.model = model or os.getenv('OPENAI_MODEL', 'gpt-4o-mini')
        
        print(f"ğŸ”‘ æ–°èåˆ†æAgentåˆå§‹åŒ–: API Key={'æœ‰' if self.api_key else 'ç„¡'}, æ¨¡å‹={self.model}")
        
        if self.api_key:
            # æ¸…é™¤å¯èƒ½çš„ä»£ç†è¨­ç½®
            for key in list(os.environ.keys()):
                if 'proxy' in key.lower():
                    del os.environ[key]
            
            openai.api_key = self.api_key
            logger.info(f"æ–°èåˆ†æAgentåˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.model}")
        else:
            logger.warning("OPENAI_API_KEY æœªè¨­å®šï¼Œå°‡ä½¿ç”¨åŸºæœ¬åˆ†æ")
    
    def analyze_stock_news(self, 
                          stock_code: str, 
                          stock_name: str, 
                          news_items: List[Dict[str, Any]],
                          kol_persona: str = "mixed",
                          content_length: str = "medium",
                          max_words: int = 200) -> Dict[str, Any]:
        """å¤šç¶­åº¦åˆ†æè‚¡ç¥¨æ–°è"""
        
        try:
            if not self.api_key or not news_items:
                print(f"âš ï¸ æ–°èåˆ†æAgentå›é€€åˆ°åŸºæœ¬åˆ†æ: api_key={'æœ‰' if self.api_key else 'ç„¡'}, news_items={len(news_items) if news_items else 0}")
                return self._basic_news_analysis(stock_code, stock_name, news_items)
            
            print(f"ğŸ¤– æ–°èåˆ†æAgenté–‹å§‹GPTåˆ†æ: {stock_name}({stock_code}), å­—æ•¸è¦æ±‚: {max_words}å­—")
            
            # æ§‹å»ºæ–°èåˆ†æprompt
            prompt = self._build_news_analysis_prompt(
                stock_code, stock_name, news_items, kol_persona, content_length, max_words
            )
            
            # æ¸…é™¤å¯èƒ½çš„ä»£ç†è¨­ç½®
            import os
            for key in list(os.environ.keys()):
                if 'proxy' in key.lower():
                    del os.environ[key]
            
            print(f"ğŸ” æº–å‚™èª¿ç”¨GPT APIï¼ŒAPI Key: {'æœ‰' if self.api_key else 'ç„¡'}")
            print(f"ğŸ” ç’°å¢ƒè®Šé‡æª¢æŸ¥: {[k for k in os.environ.keys() if 'proxy' in k.lower()]}")
            
            # èª¿ç”¨GPT APIé€²è¡Œæ·±åº¦åˆ†æ
            try:
                # ä½¿ç”¨ requests ç›´æ¥èª¿ç”¨ OpenAI API
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è‚¡ç¥¨åˆ†æå¸«ï¼Œæ“…é•·å¾å¤šå€‹è§’åº¦åˆ†ææ–°èäº‹ä»¶å°è‚¡ç¥¨çš„å½±éŸ¿ã€‚
                            
ä½ çš„åˆ†æç‰¹é»ï¼š
1. å¤šç¶­åº¦åˆ†æï¼šå¾é¡Œæé¢ã€åŸºæœ¬é¢ã€æŠ€è¡“é¢ã€ç±Œç¢¼é¢ç­‰è§’åº¦åˆ†æ
2. æ–°èæ•´åˆï¼šå°‡å¤šå€‹æ–°èä¾†æºçš„è³‡è¨Šæ•´åˆæˆæœ‰æ¢ç†çš„è¦‹è§£
3. å»ºè¨­æ€§è§€é»ï¼šæä¾›å…·é«”çš„æŠ•è³‡å»ºè­°å’Œé¢¨éšªæé†’
4. å¹³è¡¡è§€é»ï¼šæ—¢åˆ†æåˆ©å¤šä¹ŸæŒ‡å‡ºé¢¨éšª
5. æ•¸æ“šæ”¯æ’ï¼šåŸºæ–¼å…·é«”çš„æ–°èå…§å®¹çµ¦å‡ºåˆ†æ"""
                        },
                        {
                            "role": "user", 
                            "content": prompt
                        }
                    ],
                    "max_completion_tokens": 2000,
                    "temperature": 1.0
                }
                
                response = requests.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=30
                )
                
                if response.status_code != 200:
                    raise Exception(f"OpenAI API éŒ¯èª¤: {response.status_code} - {response.text}")
                
                response_data = response.json()
                analysis_content = response_data["choices"][0]["message"]["content"]
                
            except Exception as e:
                print(f"ğŸ” GPT API èª¿ç”¨è©³ç´°éŒ¯èª¤: {type(e).__name__}: {str(e)}")
                raise e
            
            print(f"âœ… GPTåˆ†æå®Œæˆï¼Œå…§å®¹é•·åº¦: {len(analysis_content)} å­—")
            
            # è§£æåˆ†æçµæœ
            return self._parse_news_analysis(analysis_content, stock_code, stock_name, news_items)
            
        except Exception as e:
            print(f"âŒ æ–°èåˆ†æAgent GPTèª¿ç”¨å¤±æ•—: {e}")
            logger.error(f"æ–°èåˆ†æå¤±æ•—: {e}")
            return self._basic_news_analysis(stock_code, stock_name, news_items)
    
    def _build_news_analysis_prompt(self, 
                                   stock_code: str, 
                                   stock_name: str, 
                                   news_items: List[Dict[str, Any]],
                                   kol_persona: str,
                                   content_length: str = "medium",
                                   max_words: int = 200) -> str:
        """æ§‹å»ºæ–°èåˆ†æprompt"""
        
        # æ•´ç†æ–°èè³‡è¨Š
        news_summary = f"é—œæ–¼ {stock_name}({stock_code}) çš„æœ€æ–°æ–°èï¼š\n\n"
        
        for i, news in enumerate(news_items[:8], 1):  # æœ€å¤šåˆ†æ8å‰‡æ–°è
            news_summary += f"{i}. {news.get('source', 'æœªçŸ¥ä¾†æº')}\n"
            news_summary += f"   æ¨™é¡Œï¼š{news.get('title', '')}\n"
            news_summary += f"   å…§å®¹ï¼š{news.get('snippet', '')}\n"
            if news.get('link'):
                news_summary += f"   é€£çµï¼š{news.get('link', '')}\n"
            if news.get('date'):
                news_summary += f"   æ™‚é–“ï¼š{news.get('date', '')}\n"
            news_summary += "\n"
        
        # æ ¹æ“šKOLäººè¨­èª¿æ•´åˆ†æé‡é»
        analysis_focus = self._get_analysis_focus(kol_persona)
        
        prompt = f"""
è«‹åŸºæ–¼ä»¥ä¸‹æ–°èè³‡è¨Šï¼Œå° {stock_name}({stock_code}) é€²è¡Œæ·±åº¦åˆ†æï¼š

{news_summary}

{analysis_focus}

è«‹æŒ‰ç…§ä»¥ä¸‹çµæ§‹æä¾›ç²¾è¯åˆ†æï¼ˆä¸è¦åŒ…å«æ¨™é¡Œï¼Œç›´æ¥é–‹å§‹åˆ†æå…§å®¹ï¼‰ï¼š

é¡Œæé¢
- ç°¡è¦åˆ†æä¸»è¦é¡Œæå’Œå½±éŸ¿

åŸºæœ¬é¢  
- é—œéµè²¡å‹™æ•¸æ“šå’Œç‡Ÿé‹ç‹€æ³

æŠ€è¡“é¢
- é‡è¦æŠ€è¡“æŒ‡æ¨™å’Œåƒ¹ä½

ç±Œç¢¼é¢
- æ³•äººå‹•å‘å’Œè³‡é‡‘æµå‘

æ“ä½œå»ºè­°
- é€²å ´é»ä½å’Œåœæåœåˆ©
- é¢¨éšªæé†’

è¦æ±‚ï¼š
1. åŸºæ–¼å¯¦éš›æ–°èå…§å®¹ï¼Œç°¡æ½”æœ‰åŠ›
2. æä¾›å…·é«”æ•¸æ“šæ”¯æ’
3. èªè¨€å°ˆæ¥­æ˜“æ‡‚ï¼Œç´”æ–‡å­—æ ¼å¼
4. é•·åº¦æ§åˆ¶åœ¨{max_words}å­—ï¼Œç¢ºä¿å…§å®¹å……å¯¦å®Œæ•´
5. é‡é»çªå‡ºï¼Œé¿å…å†—é•·
6. ä¸è¦ä½¿ç”¨Markdownæ ¼å¼ï¼ˆ##ã€**ç­‰ï¼‰
7. ä¸è¦ä½¿ç”¨emojiè¡¨æƒ…ç¬¦è™Ÿ
8. å¿…é ˆé”åˆ°æœ€ä½{max_words}å­—è¦æ±‚ï¼Œå…§å®¹è¦è©³ç´°å®Œæ•´
9. ä¸è¦ç”Ÿæˆä»»ä½•æ¨™é¡Œï¼Œç›´æ¥é–‹å§‹åˆ†æå…§å®¹

è«‹ç›´æ¥è¼¸å‡ºåˆ†æå…§å®¹ï¼Œä¸è¦åŒ…å«é¡å¤–çš„èªªæ˜æ–‡å­—ã€‚
"""
        
        return prompt
    
    def _get_analysis_focus(self, kol_persona: str) -> str:
        """æ ¹æ“šKOLäººè¨­ç²å–åˆ†æé‡é»"""
        
        focus_map = {
            'technical': """
åˆ†æé‡é»ï¼šæŠ€è¡“åˆ†æç‚ºä¸»
- é‡é»åˆ†ææŠ€è¡“æŒ‡æ¨™å’Œåœ–è¡¨å½¢æ…‹
- é—œæ³¨æˆäº¤é‡è®ŠåŒ–å’Œçªç ´é»
- æä¾›å…·é«”çš„æŠ€è¡“æ“ä½œå»ºè­°
- åˆ†ææ”¯æ’é˜»åŠ›ä½å’Œè¶¨å‹¢ç·š
""",
            'fundamental': """
åˆ†æé‡é»ï¼šåŸºæœ¬é¢åˆ†æç‚ºä¸»
- é‡é»åˆ†æè²¡å‹™æ•¸æ“šå’Œç‡Ÿé‹ç‹€æ³
- é—œæ³¨ç”¢æ¥­è¶¨å‹¢å’Œç«¶çˆ­åœ°ä½
- æä¾›é•·ç·šæŠ•è³‡å»ºè­°
- åˆ†æä¼°å€¼åˆç†æ€§å’Œæˆé•·æ€§
""",
            'news_driven': """
åˆ†æé‡é»ï¼šæ¶ˆæ¯é¢åˆ†æç‚ºä¸»
- é‡é»åˆ†ææ–°èäº‹ä»¶å½±éŸ¿
- é—œæ³¨æ”¿ç­–è®ŠåŒ–å’Œå¸‚å ´æƒ…ç·’
- æä¾›çŸ­ç·šæ“ä½œå»ºè­°
- åˆ†ææŠ•è³‡äººå¿ƒç†å’Œè³‡é‡‘æµå‘
""",
            'mixed': """
åˆ†æé‡é»ï¼šç¶œåˆåˆ†æ
- æŠ€è¡“é¢ã€åŸºæœ¬é¢ã€æ¶ˆæ¯é¢ç¶œåˆåˆ†æ
- å¤šç¶­åº¦é¢¨éšªè©•ä¼°
- æä¾›å¹³è¡¡çš„æŠ•è³‡è§€é»
- é•·çŸ­æœŸæŠ•è³‡ç­–ç•¥ä¸¦é‡
"""
        }
        
        return focus_map.get(kol_persona, focus_map['mixed'])
    
    def _parse_news_analysis(self, 
                            analysis_content: str, 
                            stock_code: str, 
                            stock_name: str,
                            news_items: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è§£ææ–°èåˆ†æçµæœ"""
        
        # ç”Ÿæˆç²¾ç°¡æ¨™é¡Œ
        title = f"{stock_name} åˆ†æ"
        
        return {
            "title": title,
            "content": analysis_content,
            "content_md": analysis_content,
            "commodity_tags": [{"type": "Stock", "key": stock_code, "bullOrBear": 0}],
            "community_topic": None,
            "generation_method": "news_analysis_agent",
            "model_used": self.model,
            "news_sources_count": len(news_items),
            "analysis_timestamp": datetime.now().isoformat(),
            "news_items": news_items
        }
    
    def _basic_news_analysis(self, 
                            stock_code: str, 
                            stock_name: str, 
                            news_items: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åŸºæœ¬æ–°èåˆ†æï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        
        # ç°¡å–®çš„æ–°èæ‘˜è¦
        news_summary = f"ã€æ–°èæ‘˜è¦ã€‘{stock_name}({stock_code})\n\n"
        
        if news_items:
            news_summary += "ç›¸é—œæ–°èï¼š\n"
            for i, news in enumerate(news_items[:3], 1):
                news_summary += f"{i}. {news.get('title', '')}\n"
                news_summary += f"   {news.get('snippet', '')[:100]}...\n\n"
        else:
            news_summary += "æš«ç„¡ç›¸é—œæ–°èè³‡è¨Š\n\n"
        
        news_summary += "âš ï¸ æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°"
        
        return {
            "title": f"{stock_name}({stock_code}) æ–°èåˆ†æ",
            "content": news_summary,
            "content_md": news_summary,
            "commodity_tags": [{"type": "Stock", "key": stock_code, "bullOrBear": 0}],
            "community_topic": None,
            "generation_method": "basic_analysis",
            "model_used": "template",
            "news_sources_count": len(news_items),
            "analysis_timestamp": datetime.now().isoformat(),
            "news_items": news_items
        }

# å…¨åŸŸå¯¦ä¾‹
news_analysis_agent = NewsAnalysisAgent()
