"""
Serper API æ•´åˆæœå‹™
è² è²¬æœå°‹è‚¡ç¥¨ç›¸é—œæ–°èå’Œæ¼²åœåŸå› åˆ†æ
"""

import os
import requests
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import json

logger = logging.getLogger(__name__)

class SerperNewsService:
    """Serper API æ–°èæœå°‹æœå‹™"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv('SERPER_API_KEY')
        self.base_url = "https://google.serper.dev/search"
        
        if not self.api_key:
            logger.warning("SERPER_API_KEY æœªè¨­å®šï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")
    
    def search_stock_news(self, stock_code: str, stock_name: str, limit: int = 5, 
                          search_keywords: Optional[List[Dict[str, Any]]] = None,
                          time_range: str = "d1") -> List[Dict[str, Any]]:
        """æœå°‹è‚¡ç¥¨ç›¸é—œæ–°è"""
        try:
            if not self.api_key:
                return self._get_mock_news(stock_code, stock_name)
            
            headers = {
                "X-API-KEY": self.api_key,
                "Content-Type": "application/json"
            }
            
            # æ§‹å»ºæœå°‹æŸ¥è©¢ - ä½¿ç”¨å‰ç«¯é…ç½®çš„é—œéµå­—
            if search_keywords:
                query_parts = []
                for keyword_config in search_keywords:
                    keyword = keyword_config.get('keyword', '')
                    keyword_type = keyword_config.get('type', 'custom')
                    
                    # æ ¹æ“šé—œéµå­—é¡å‹æ›¿æ›è®Šæ•¸
                    if keyword_type == 'stock_name':
                        query_parts.append(stock_name)
                    elif keyword_type == 'trigger_keyword':
                        # é€™è£¡å¯ä»¥æ ¹æ“šè§¸ç™¼å™¨é¡å‹å‹•æ…‹é¸æ“‡é—œéµå­—
                        query_parts.append(keyword)
                    else:  # custom
                        query_parts.append(keyword)
                
                query = ' '.join(query_parts)
                print(f"ğŸ” ä½¿ç”¨å‰ç«¯é…ç½®æœå°‹é—œéµå­—: {query}")
            else:
                # é è¨­æœå°‹æŸ¥è©¢
                query = f"{stock_name} {stock_code} æ–°è æœ€æ–°"
                print(f"ğŸ” ä½¿ç”¨é è¨­æœå°‹é—œéµå­—: {query}")
            
            payload = {
                "q": query,
                "num": limit,
                "type": "search",
                "gl": "tw",  # å°ç£åœ°å€
                "hl": "zh-tw",  # ç¹é«”ä¸­æ–‡
                "tbs": self._get_time_range_filter(time_range)  # æ™‚é–“ç¯„åœéæ¿¾å™¨
            }
            
            response = requests.post(self.base_url, headers=headers, json=payload, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            organic_results = data.get('organic', [])
            
            # è™•ç†æœå°‹çµæœ
            news_items = []
            for result in organic_results:
                news_items.append({
                    'title': result.get('title', ''),
                    'snippet': result.get('snippet', ''),
                    'link': result.get('link', ''),
                    'date': result.get('date', ''),
                    'source': self._extract_source(result.get('link', ''))
                })
            
            logger.info(f"ç‚º {stock_name}({stock_code}) æ‰¾åˆ° {len(news_items)} å‰‡æ–°è")
            return news_items
            
        except Exception as e:
            logger.error(f"æœå°‹ {stock_name}({stock_code}) æ–°èå¤±æ•—: {e}")
            return self._get_mock_news(stock_code, stock_name)
    
    def analyze_limit_up_reason(self, stock_code: str, stock_name: str, 
                               search_keywords: Optional[List[Dict[str, Any]]] = None,
                               time_range: str = "d1", trigger_type: str = None) -> Dict[str, Any]:
        """åˆ†ææ¼²åœåŸå› """
        try:
            if not self.api_key:
                return self._get_mock_limit_up_analysis(stock_code, stock_name)
            
            headers = {
                "X-API-KEY": self.api_key,
                "Content-Type": "application/json"
            }
            
            # æœå°‹æ¼²åœç›¸é—œè³‡è¨Š - ä½¿ç”¨å‰ç«¯é…ç½®çš„é—œéµå­—
            if search_keywords:
                query_parts = []
                for keyword_config in search_keywords:
                    keyword = keyword_config.get('keyword', '')
                    keyword_type = keyword_config.get('type', 'custom')
                    
                    if keyword_type == 'stock_name':
                        query_parts.append(stock_name)
                    elif keyword_type == 'trigger_keyword':
                        query_parts.append(keyword)
                    else:  # custom
                        query_parts.append(keyword)
                
                # æ ¹æ“šè§¸ç™¼å™¨é¡å‹æ·»åŠ ç›¸é—œé—œéµå­—
                if trigger_type == 'intraday_limit_down' or trigger_type == 'limit_down_after_hours':
                    # è·Œåœè§¸ç™¼å™¨
                    query_parts.extend(['è·Œåœ', 'åŸå› ', 'åˆ©ç©º', 'æ¶ˆæ¯'])
                    print(f"ğŸ” ä½¿ç”¨å‰ç«¯é…ç½®åˆ†æè·ŒåœåŸå› : {' '.join(query_parts)}")
                elif trigger_type == 'intraday_limit_up' or trigger_type == 'limit_up_after_hours':
                    # æ¼²åœè§¸ç™¼å™¨
                    query_parts.extend(['æ¼²åœ', 'åŸå› ', 'åˆ©å¤š', 'æ¶ˆæ¯'])
                    print(f"ğŸ” ä½¿ç”¨å‰ç«¯é…ç½®åˆ†ææ¼²åœåŸå› : {' '.join(query_parts)}")
                else:
                    # å…¶ä»–è§¸ç™¼å™¨ï¼Œä½¿ç”¨ä¸­æ€§é—œéµå­—
                    query_parts.extend(['è¡¨ç¾', 'åŸå› ', 'åˆ†æ', 'æ¶ˆæ¯'])
                    print(f"ğŸ” ä½¿ç”¨å‰ç«¯é…ç½®åˆ†æè¡¨ç¾åŸå› : {' '.join(query_parts)}")
                
                query = ' '.join(query_parts)
            else:
                # é è¨­æœå°‹æŸ¥è©¢
                query = f"{stock_name} {stock_code} æ¼²åœ åŸå›  åˆ©å¤š æ¶ˆæ¯"
                print(f"ğŸ” ä½¿ç”¨é è¨­åˆ†æé—œéµå­—: {query}")
            
            payload = {
                "q": query,
                "num": 3,
                "type": "search",
                "gl": "tw",
                "hl": "zh-tw",
                "tbs": self._get_time_range_filter(time_range)  # æ™‚é–“ç¯„åœéæ¿¾å™¨
            }
            
            response = requests.post(self.base_url, headers=headers, json=payload, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            organic_results = data.get('organic', [])
            
            # åˆ†ææ¼²åœåŸå› 
            reasons = []
            key_events = []
            market_sentiment = "neutral"
            
            for result in organic_results:
                title = result.get('title', '')
                snippet = result.get('snippet', '')
                
                # æå–é—œéµè³‡è¨Š
                if any(keyword in title.lower() or keyword in snippet.lower() 
                      for keyword in ['æ¼²åœ', 'å¤§æ¼²', 'é£†æ¼²', 'åˆ©å¤š', 'å¥½æ¶ˆæ¯', 'è²¡å ±', 'ç‡Ÿæ”¶']):
                    reasons.append({
                        'title': title,
                        'snippet': snippet,
                        'link': result.get('link', ''),
                        'relevance_score': self._calculate_relevance_score(title, snippet)
                    })
                
                # æå–é—œéµäº‹ä»¶
                if any(keyword in title.lower() or keyword in snippet.lower()
                      for keyword in ['è²¡å ±', 'ç‡Ÿæ”¶', 'åˆä½œ', 'è¨‚å–®', 'ç²åˆ©', 'æˆé•·']):
                    key_events.append({
                        'event': title,
                        'description': snippet,
                        'link': result.get('link', '')
                    })
            
            # åˆ¤æ–·å¸‚å ´æƒ…ç·’
            positive_keywords = ['åˆ©å¤š', 'å¥½æ¶ˆæ¯', 'æˆé•·', 'ç²åˆ©', 'åˆä½œ', 'è¨‚å–®']
            negative_keywords = ['åˆ©ç©º', 'å£æ¶ˆæ¯', 'è™§æ', 'ä¸‹è·Œ', 'é¢¨éšª']
            
            all_text = ' '.join([r['title'] + ' ' + r['snippet'] for r in reasons])
            positive_count = sum(1 for keyword in positive_keywords if keyword in all_text.lower())
            negative_count = sum(1 for keyword in negative_keywords if keyword in all_text.lower())
            
            if positive_count > negative_count:
                market_sentiment = "positive"
            elif negative_count > positive_count:
                market_sentiment = "negative"
            
            return {
                'stock_code': stock_code,
                'stock_name': stock_name,
                'limit_up_reasons': reasons,
                'key_events': key_events,
                'market_sentiment': market_sentiment,
                'analysis_timestamp': datetime.now().isoformat(),
                'data_source': 'serper_api'
            }
            
        except Exception as e:
            logger.error(f"åˆ†æ {stock_name}({stock_code}) æ¼²åœåŸå› å¤±æ•—: {e}")
            return self._get_mock_limit_up_analysis(stock_code, stock_name)
    
    def get_comprehensive_stock_analysis(self, stock_code: str, stock_name: str, 
                                        search_keywords: Optional[List[Dict[str, Any]]] = None,
                                        time_range: str = "d1", trigger_type: str = None) -> Dict[str, Any]:
        """ç²å–è‚¡ç¥¨ç¶œåˆåˆ†æè³‡æ–™"""
        try:
            # æ ¹æ“šè§¸ç™¼å™¨é¡å‹èª¿æ•´æœå°‹é—œéµå­—
            adjusted_keywords = self._adjust_keywords_for_trigger(search_keywords, trigger_type)
            
            # ä¸¦è¡Œç²å–æ–°èå’Œæ¼²åœåˆ†æ
            news_items = self.search_stock_news(stock_code, stock_name, limit=5, search_keywords=adjusted_keywords, time_range=time_range)
            limit_up_analysis = self.analyze_limit_up_reason(stock_code, stock_name, search_keywords=adjusted_keywords, time_range=time_range, trigger_type=trigger_type)
            
            return {
                'stock_code': stock_code,
                'stock_name': stock_name,
                'news_items': news_items,
                'limit_up_analysis': limit_up_analysis,
                'analysis_timestamp': datetime.now().isoformat(),
                'data_quality': 'high' if self.api_key else 'mock',
                'enable_news_links': True,  # æ·»åŠ æ–°èé€£çµé…ç½®
                'news_max_links': 5
            }
            
        except Exception as e:
            logger.error(f"ç²å– {stock_name}({stock_code}) ç¶œåˆåˆ†æå¤±æ•—: {e}")
            return self._get_mock_comprehensive_analysis(stock_code, stock_name)
    
    def _adjust_keywords_for_trigger(self, search_keywords: Optional[List[Dict[str, Any]]], trigger_type: str) -> Optional[List[Dict[str, Any]]]:
        """æ ¹æ“šè§¸ç™¼å™¨é¡å‹èª¿æ•´æœå°‹é—œéµå­—"""
        if not search_keywords:
            return search_keywords
        
        # è¤‡è£½é—œéµå­—åˆ—è¡¨
        adjusted_keywords = search_keywords.copy()
        
        # æ ¹æ“šè§¸ç™¼å™¨é¡å‹èª¿æ•´é—œéµå­—
        if trigger_type == 'intraday_limit_down' or trigger_type == 'limit_down_after_hours':
            # è·Œåœè§¸ç™¼å™¨ï¼šç§»é™¤æ¼²åœç›¸é—œé—œéµå­—ï¼Œç¢ºä¿æœå°‹è·Œåœç›¸é—œå…§å®¹
            for keyword_config in adjusted_keywords:
                if keyword_config.get('type') == 'trigger_keyword':
                    keyword = keyword_config.get('keyword', '')
                    if 'æ¼²åœ' in keyword:
                        keyword_config['keyword'] = keyword.replace('æ¼²åœ', 'è·Œåœ')
                    elif keyword == 'è·Œåœ':
                        # ä¿æŒè·Œåœé—œéµå­—
                        pass
                    else:
                        # å…¶ä»–é—œéµå­—ä¿æŒä¸è®Š
                        pass
        elif trigger_type == 'intraday_limit_up' or trigger_type == 'limit_up_after_hours':
            # æ¼²åœè§¸ç™¼å™¨ï¼šç¢ºä¿æœå°‹æ¼²åœç›¸é—œå…§å®¹
            for keyword_config in adjusted_keywords:
                if keyword_config.get('type') == 'trigger_keyword':
                    keyword = keyword_config.get('keyword', '')
                    if 'è·Œåœ' in keyword:
                        keyword_config['keyword'] = keyword.replace('è·Œåœ', 'æ¼²åœ')
                    elif keyword == 'æ¼²åœ':
                        # ä¿æŒæ¼²åœé—œéµå­—
                        pass
        
        logger.info(f"ğŸ”§ æ ¹æ“šè§¸ç™¼å™¨é¡å‹ {trigger_type} èª¿æ•´é—œéµå­—: {[kw.get('keyword') for kw in adjusted_keywords]}")
        return adjusted_keywords
    
    def _get_time_range_filter(self, time_range: str) -> str:
        """ç²å–æ™‚é–“ç¯„åœéæ¿¾å™¨
        
        Args:
            time_range: æ™‚é–“ç¯„åœé¸é …
                - "h1": éå»1å°æ™‚
                - "d1": éå»1å¤© (é è¨­)
                - "d2": éå»2å¤©
                - "w1": éå»1é€±
                - "m1": éå»1å€‹æœˆ
                - "y1": éå»1å¹´
        
        Returns:
            Google æœå°‹æ™‚é–“éæ¿¾å™¨å­—ä¸²
        """
        time_filters = {
            "h1": "qdr:h",      # éå»1å°æ™‚
            "d1": "qdr:d",      # éå»1å¤©
            "d2": "qdr:d2",     # éå»2å¤©
            "w1": "qdr:w",      # éå»1é€±
            "m1": "qdr:m",      # éå»1å€‹æœˆ
            "y1": "qdr:y"       # éå»1å¹´
        }
        
        return time_filters.get(time_range, "qdr:d")  # é è¨­ç‚ºéå»1å¤©
    
    def _extract_source(self, url: str) -> str:
        """å¾URLæå–æ–°èä¾†æº"""
        try:
            if 'money.udn.com' in url:
                return 'è¯åˆæ–°èç¶²'
            elif 'chinatimes.com' in url:
                return 'ä¸­æ™‚æ–°èç¶²'
            elif 'ltn.com.tw' in url:
                return 'è‡ªç”±æ™‚å ±'
            elif 'cnyes.com' in url:
                return 'é‰…äº¨ç¶²'
            elif 'moneydj.com' in url:
                return 'MoneyDJ'
            elif 'cmoney.tw' in url:
                return 'CMoney'
            else:
                return 'å…¶ä»–'
        except:
            return 'æœªçŸ¥'
    
    def _calculate_relevance_score(self, title: str, snippet: str) -> float:
        """è¨ˆç®—ç›¸é—œæ€§åˆ†æ•¸"""
        score = 0.0
        text = (title + ' ' + snippet).lower()
        
        # é—œéµå­—æ¬Šé‡
        keywords = {
            'æ¼²åœ': 2.0,
            'å¤§æ¼²': 1.8,
            'é£†æ¼²': 1.8,
            'åˆ©å¤š': 1.5,
            'å¥½æ¶ˆæ¯': 1.5,
            'è²¡å ±': 1.2,
            'ç‡Ÿæ”¶': 1.2,
            'æˆé•·': 1.0,
            'ç²åˆ©': 1.0
        }
        
        for keyword, weight in keywords.items():
            if keyword in text:
                score += weight
        
        return min(score, 10.0)  # æœ€é«˜10åˆ†
    
    def _get_mock_news(self, stock_code: str, stock_name: str) -> List[Dict[str, Any]]:
        """æ¨¡æ“¬æ–°èæ•¸æ“š"""
        return [
            {
                'title': f'{stock_name}({stock_code}) æœ€æ–°è²¡å ±è¡¨ç¾äº®çœ¼',
                'snippet': f'{stock_name} ç™¼å¸ƒæœ€æ–°è²¡å ±ï¼Œç‡Ÿæ”¶æˆé•·è¶…é æœŸï¼Œç²åˆ©èƒ½åŠ›æŒçºŒæå‡ï¼Œå¸‚å ´çœ‹å¥½å¾Œå¸‚è¡¨ç¾ã€‚',
                'link': f'https://example.com/news/{stock_code}',
                'date': datetime.now().strftime('%Y-%m-%d'),
                'source': 'æ¨¡æ“¬æ–°è'
            },
            {
                'title': f'{stock_name} æŠ€è¡“é¢çªç ´é—œéµé˜»åŠ›ä½',
                'snippet': f'{stock_name} æŠ€è¡“æŒ‡æ¨™é¡¯ç¤ºå¼·å‹¢çªç ´ï¼Œæˆäº¤é‡æ”¾å¤§ï¼Œå¾Œå¸‚å¯æœŸã€‚',
                'link': f'https://example.com/analysis/{stock_code}',
                'date': datetime.now().strftime('%Y-%m-%d'),
                'source': 'æ¨¡æ“¬åˆ†æ'
            }
        ]
    
    def _get_mock_limit_up_analysis(self, stock_code: str, stock_name: str) -> Dict[str, Any]:
        """æ¨¡æ“¬æ¼²åœåˆ†ææ•¸æ“š"""
        return {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'limit_up_reasons': [
                {
                    'title': f'{stock_name} è²¡å ±äº®çœ¼å¸¶å‹•è‚¡åƒ¹ä¸Šæ¼²',
                    'snippet': f'{stock_name} æœ€æ–°è²¡å ±è¡¨ç¾å„ªç•°ï¼Œç‡Ÿæ”¶æˆé•·è¶…é æœŸï¼Œç²åˆ©èƒ½åŠ›æŒçºŒæå‡ã€‚',
                    'link': f'https://example.com/news/{stock_code}',
                    'relevance_score': 8.5
                }
            ],
            'key_events': [
                {
                    'event': f'{stock_name} ç‡Ÿæ”¶æˆé•·è¶…é æœŸ',
                    'description': f'{stock_name} æœ€æ–°ç‡Ÿæ”¶æ•¸æ“šé¡¯ç¤ºå¼·å‹æˆé•·å‹•èƒ½ã€‚',
                    'link': f'https://example.com/earnings/{stock_code}'
                }
            ],
            'market_sentiment': 'positive',
            'analysis_timestamp': datetime.now().isoformat(),
            'data_source': 'mock_data'
        }
    
    def _get_mock_comprehensive_analysis(self, stock_code: str, stock_name: str) -> Dict[str, Any]:
        """æ¨¡æ“¬ç¶œåˆåˆ†ææ•¸æ“š"""
        return {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'news_items': self._get_mock_news(stock_code, stock_name),
            'limit_up_analysis': self._get_mock_limit_up_analysis(stock_code, stock_name),
            'analysis_timestamp': datetime.now().isoformat(),
            'data_quality': 'mock'
        }

# å…¨åŸŸå¯¦ä¾‹
serper_service = SerperNewsService()
