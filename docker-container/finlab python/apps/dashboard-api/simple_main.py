"""
ç°¡åŒ–ç‰ˆ Dashboard API æœå‹™
åªåŒ…å«è‡ªæˆ‘å­¸ç¿’ç›¸é—œçš„ API ç«¯é»
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime
import logging
import httpx

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ğŸ”¥ çœŸæ­£çš„è‡ªæˆ‘å­¸ç¿’åˆ†æï¼šå¾è²¼æ–‡æ•¸æ“šåº«ç²å–äº’å‹•æ•¸æ“š
async def fetch_all_posts_with_interactions(
    kol_serial: Optional[int] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    include_external: bool = True
) -> List[Dict]:
    """å¾è²¼æ–‡æ•¸æ“šåº«ç²å–æ‰€æœ‰è²¼æ–‡çš„äº’å‹•æ•¸æ“š"""
    try:
        print(f"ğŸ” é–‹å§‹å¾è²¼æ–‡æ•¸æ“šåº«ç²å–äº’å‹•æ•¸æ“š...")
        
        # èª¿ç”¨ posting-service çš„ API ç²å–æ‰€æœ‰è²¼æ–‡
        async with httpx.AsyncClient(timeout=30.0) as client:
            # æ§‹å»ºè«‹æ±‚åƒæ•¸
            params = {
                "limit": 5000,  # ç²å–å¤§é‡è²¼æ–‡
                "include_interactions": True
            }
            
            if kol_serial:
                params["kol_serial"] = kol_serial
            if start_date:
                params["start_date"] = start_date
            if end_date:
                params["end_date"] = end_date
            if include_external is not None:
                params["include_external"] = include_external
            
            response = await client.get("http://localhost:8001/posts", params=params)
            
            if response.status_code == 200:
                data = response.json()
                posts = data.get('posts', [])
                print(f"âœ… å¾è²¼æ–‡æ•¸æ“šåº«ç²å–åˆ° {len(posts)} ç¯‡è²¼æ–‡")
                
                # éæ¿¾æœ‰äº’å‹•æ•¸æ“šçš„è²¼æ–‡
                posts_with_interactions = []
                for post in posts:
                    # æª¢æŸ¥æ˜¯å¦æœ‰äº’å‹•æ•¸æ“šï¼ˆåŸºæ–¼ post_records è¡¨çš„å¯¦éš›æ¬„ä½ï¼‰
                    if (post.get('likes', 0) > 0 or 
                        post.get('comments', 0) > 0 or 
                        post.get('shares', 0) > 0 or 
                        post.get('views', 0) > 0 or
                        post.get('donations', 0) > 0):
                        posts_with_interactions.append(post)
                
                print(f"ğŸ“Š å…¶ä¸­ {len(posts_with_interactions)} ç¯‡æœ‰äº’å‹•æ•¸æ“š")
                return posts_with_interactions
            else:
                print(f"âš ï¸ è²¼æ–‡æ•¸æ“šåº« API è«‹æ±‚å¤±æ•—: HTTP {response.status_code}")
                return []
                
    except Exception as e:
        print(f"âŒ ç²å–è²¼æ–‡äº’å‹•æ•¸æ“šå¤±æ•—: {e}")
        return []

def generate_posting_settings_from_features(features: List) -> List:
    """åŸºæ–¼é«˜æˆæ•ˆç‰¹å¾µç”Ÿæˆç™¼æ–‡è¨­å®š"""
    settings = []
    
    # åŸºæ–¼å‰3å€‹æœ€é«˜æˆæ•ˆç‰¹å¾µç”Ÿæˆè¨­å®š
    top_features = features[:3] if len(features) >= 3 else features
    
    for i, feature in enumerate(top_features):
        setting = PostingSetting(
            setting_id=f"feature_based_{i+1}",
            setting_name=f"åŸºæ–¼{feature.feature_name}çš„è¨­å®š",
            description=f"åŸºæ–¼ã€Œ{feature.feature_name}ã€ç‰¹å¾µçš„ç™¼æ–‡è¨­å®šï¼Œæ”¹å–„æ½›åŠ›ï¼š{(feature.improvement_potential * 100):.1f}%",
            trigger_type="limit_up_after_hours",
            content_length="medium",
            has_news_link=True,
            has_question_interaction=feature.feature_id == 'has_question',
            has_emoji=feature.feature_id == 'has_emoji',
            has_hashtag=True,
            humor_level="light",
            kol_style="casual",
            posting_time_preference=["14:00-16:00", "19:00-21:00"],
            stock_tags_count=3,
            content_structure="mixed",
            interaction_elements=["question", "emoji"] if feature.feature_id == 'has_question' else ["emoji"] if feature.feature_id == 'has_emoji' else [],
            expected_performance=60 + (feature.improvement_potential * 40),
            confidence_level=0.8,
            based_on_features=[feature.feature_name]
        )
        settings.append(setting)
    
    return settings

# å‰µå»º FastAPI æ‡‰ç”¨
app = FastAPI(
    title="Dashboard API",
    description="è™›æ“¬ KOL ç³»çµ±å„€è¡¨æ¿ API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# æ·»åŠ  CORS ä¸­é–“ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== æ•¸æ“šæ¨¡å‹ ====================

class HighPerformanceFeature(BaseModel):
    feature_id: str
    feature_name: str
    feature_type: str
    description: str
    frequency_in_top_posts: float
    frequency_in_all_posts: float
    improvement_potential: float
    setting_key: str
    is_modifiable: bool
    modification_method: str
    examples: List[str]

class ContentCategory(BaseModel):
    category_id: str
    category_name: str
    description: str
    top_posts: List[Dict[str, Any]]
    avg_performance_score: float
    key_characteristics: List[str]
    success_rate: float

class PostingSetting(BaseModel):
    setting_id: str
    setting_name: str
    description: str
    trigger_type: str
    content_length: str
    has_news_link: bool
    has_question_interaction: bool
    has_emoji: bool
    has_hashtag: bool
    humor_level: str
    kol_style: str
    posting_time_preference: List[str]
    stock_tags_count: int
    content_structure: str
    interaction_elements: List[str]
    expected_performance: float
    confidence_level: float
    based_on_features: List[str]

class EnhancedAnalysisReport(BaseModel):
    analysis_timestamp: str
    total_posts_analyzed: int
    top_performance_features: List[HighPerformanceFeature]
    content_categories: List[ContentCategory]
    generated_settings: List[PostingSetting]
    modification_capabilities: Dict[str, Any]
    recommendations: List[str]

# ==================== API ç«¯é» ====================

@app.get("/")
async def root():
    """æ ¹è·¯å¾‘"""
    return {
        "message": "Dashboard API æœå‹™é‹è¡Œä¸­",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat(),
        "endpoints": {
            "enhanced_self_learning": "/enhanced-self-learning/enhanced-analysis",
            "fetch_performance_data": "/enhanced-self-learning/fetch-performance-data",
            "interactions": {
                "analysis": "/interactions/analysis",
                "refresh_all": "/interactions/refresh-all",
                "fetch_all": "/interactions/fetch-all-interactions",
                "deduplicate": "/interactions/deduplicate"
            }
        }
    }

@app.get("/enhanced-self-learning/enhanced-analysis")
async def get_enhanced_analysis(
    kol_serial: Optional[int] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    include_external: bool = True
):
    """ç²å–å¢å¼·ç‰ˆè‡ªæˆ‘å­¸ç¿’åˆ†æ"""
    try:
        # ğŸ”¥ çœŸæ­£çš„è‡ªæˆ‘å­¸ç¿’åˆ†æï¼šå¾è²¼æ–‡æ•¸æ“šåº«çˆ¬å–äº’å‹•æ•¸æ“š
        print(f"ğŸ” é–‹å§‹çœŸæ­£çš„è‡ªæˆ‘å­¸ç¿’åˆ†æ...")
        
        # 1. å¾è²¼æ–‡æ•¸æ“šåº«ç²å–æ‰€æœ‰è²¼æ–‡çš„äº’å‹•æ•¸æ“š
        posts_data = await fetch_all_posts_with_interactions(kol_serial, start_date, end_date, include_external)
        print(f"ğŸ“Š ç²å–åˆ° {len(posts_data)} ç¯‡è²¼æ–‡çš„äº’å‹•æ•¸æ“š")
        
        if not posts_data:
            print("âš ï¸ æ²’æœ‰è²¼æ–‡æ•¸æ“šï¼Œä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")
            # å›é€€åˆ°æ¨¡æ“¬æ•¸æ“š
            return await get_mock_enhanced_analysis()
        
        # 2. ä½¿ç”¨çœŸæ­£çš„è‡ªæˆ‘å­¸ç¿’åˆ†æé‚è¼¯
        print(f"ğŸ§  é–‹å§‹åˆ†æ {len(posts_data)} ç¯‡è²¼æ–‡çš„é«˜æˆæ•ˆç‰¹å¾µ...")
        
        # å°å…¥çœŸæ­£çš„åˆ†ææœå‹™
        from enhanced_self_learning_api import HighPerformanceFeatureAnalyzer, LLMContentClassifier
        
        # 3. åˆ†æé«˜æˆæ•ˆç‰¹å¾µ
        feature_analyzer = HighPerformanceFeatureAnalyzer()
        high_performance_features = await feature_analyzer.analyze_features(posts_data)
        print(f"âœ… åˆ†æå‡º {len(high_performance_features)} å€‹é«˜æˆæ•ˆç‰¹å¾µ")
        
        # 4. LLM å…§å®¹åˆ†é¡
        content_classifier = LLMContentClassifier()
        content_categories = await content_classifier.classify_posts(posts_data)
        print(f"âœ… å®Œæˆ {len(content_categories)} å€‹å…§å®¹åˆ†é¡")
        
        # 5. ç”Ÿæˆç™¼æ–‡è¨­å®š
        generated_settings = generate_posting_settings_from_features(high_performance_features)
        print(f"âœ… ç”Ÿæˆ {len(generated_settings)} å€‹ç™¼æ–‡è¨­å®š")
        
        return {
            "success": True,
            "data": {
                "top_performance_features": [feature.dict() for feature in high_performance_features],
                "content_categories": [category.dict() for category in content_categories],
                "generated_settings": [setting.dict() for setting in generated_settings]
            },
            "analysis_summary": {
                "total_posts_analyzed": len(posts_data),
                "high_performance_features_count": len(high_performance_features),
                "content_categories_count": len(content_categories),
                "generated_settings_count": len(generated_settings),
                "analysis_timestamp": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        print(f"âŒ çœŸæ­£çš„è‡ªæˆ‘å­¸ç¿’åˆ†æå¤±æ•—: {e}")
        # å›é€€åˆ°æ¨¡æ“¬æ•¸æ“š
        return await get_mock_enhanced_analysis()

async def get_mock_enhanced_analysis():
    """ç²å–æ¨¡æ“¬çš„å¢å¼·ç‰ˆè‡ªæˆ‘å­¸ç¿’åˆ†æ"""
    mock_features = [
            HighPerformanceFeature(
                feature_id="has_question",
                feature_name="å•å¥äº’å‹•",
                feature_type="interaction",
                description="åŒ…å«å•å¥çš„è²¼æ–‡äº’å‹•ç‡è¼ƒé«˜",
                frequency_in_top_posts=0.85,
                frequency_in_all_posts=0.45,
                improvement_potential=0.40,
                setting_key="include_questions",
                is_modifiable=True,
                modification_method="åœ¨å…§å®¹ç”Ÿæˆä¸­åŠ å…¥å•å¥",
                examples=["å¤§å®¶è¦ºå¾—æœƒå›èª¿å—ï¼Ÿ", "ä½ å€‘æœ‰è²·å—ï¼Ÿ", "æ€éº¼çœ‹é€™å€‹è¶¨å‹¢ï¼Ÿ"]
            ),
            HighPerformanceFeature(
                feature_id="has_emoji",
                feature_name="è¡¨æƒ…ç¬¦è™Ÿ",
                feature_type="interaction",
                description="ä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿçš„è²¼æ–‡æ›´å—æ­¡è¿",
                frequency_in_top_posts=0.75,
                frequency_in_all_posts=0.35,
                improvement_potential=0.40,
                setting_key="include_emoji",
                is_modifiable=True,
                modification_method="åœ¨å…§å®¹ç”Ÿæˆä¸­åŠ å…¥è¡¨æƒ…ç¬¦è™Ÿ",
                examples=["ğŸ˜‚", "ğŸ˜„", "ğŸ‘", "ğŸ‘"]
            ),
            HighPerformanceFeature(
                feature_id="content_length_medium",
                feature_name="ä¸­ç­‰é•·åº¦å…§å®¹",
                feature_type="content",
                description="200-500å­—çš„å…§å®¹æ•ˆæœæœ€ä½³",
                frequency_in_top_posts=0.70,
                frequency_in_all_posts=0.30,
                improvement_potential=0.40,
                setting_key="content_length",
                is_modifiable=True,
                modification_method="èª¿æ•´å…§å®¹ç”Ÿæˆé•·åº¦è¨­å®š",
                examples=["é©ä¸­çš„åˆ†æå…§å®¹", "ç°¡æ½”æ˜ç­çš„è§€é»"]
            )
        ]

        mock_categories = [
            ContentCategory(
                category_id="analysis_type",
                category_name="åˆ†æå‹å…§å®¹",
                description="æŠ€è¡“åˆ†æå’Œå¸‚å ´è§£è®€é¡å…§å®¹",
                top_posts=[
                    {"title": "2330å°ç©é›»æŠ€è¡“åˆ†æ", "performance_score": 85},
                    {"title": "2317é´»æµ·æ¼²åœåˆ†æ", "performance_score": 82}
                ],
                avg_performance_score=83.5,
                key_characteristics=["å°ˆæ¥­", "æ•¸æ“šé©…å‹•", "æŠ€è¡“æŒ‡æ¨™"],
                success_rate=0.75
            ),
            ContentCategory(
                category_id="interactive_type",
                category_name="äº’å‹•å‹å…§å®¹",
                description="åŒ…å«å•å¥å’Œäº’å‹•å…ƒç´ çš„å…§å®¹",
                top_posts=[
                    {"title": "å¤§å®¶è¦ºå¾—æœƒå›èª¿å—ï¼Ÿ", "performance_score": 90},
                    {"title": "ä½ å€‘æœ‰è²·é€™æ”¯å—ï¼Ÿ", "performance_score": 88}
                ],
                avg_performance_score=89.0,
                key_characteristics=["å•å¥", "äº’å‹•", "è¦ªåˆ‡"],
                success_rate=0.85
            )
        ]

        mock_settings = [
            PostingSetting(
                setting_id="high_interaction_1",
                setting_name="é«˜äº’å‹•è¨­å®š",
                description="åŸºæ–¼å•å¥äº’å‹•ç‰¹å¾µçš„ç™¼æ–‡è¨­å®š",
                trigger_type="limit_up",
                content_length="medium",
                has_news_link=True,
                has_question_interaction=True,
                has_emoji=True,
                has_hashtag=True,
                humor_level="light",
                kol_style="casual",
                posting_time_preference=["14:00-16:00", "19:00-21:00"],
                stock_tags_count=2,
                content_structure="mixed",
                interaction_elements=["question", "emoji"],
                expected_performance=85.0,
                confidence_level=0.8,
                based_on_features=["å•å¥äº’å‹•", "è¡¨æƒ…ç¬¦è™Ÿ"]
            ),
            PostingSetting(
                setting_id="professional_1",
                setting_name="å°ˆæ¥­åˆ†æè¨­å®š",
                description="åŸºæ–¼åˆ†æå‹å…§å®¹çš„ç™¼æ–‡è¨­å®š",
                trigger_type="volume_surge",
                content_length="long",
                has_news_link=True,
                has_question_interaction=False,
                has_emoji=False,
                has_hashtag=True,
                humor_level="none",
                kol_style="professional",
                posting_time_preference=["09:00-11:00", "15:00-17:00"],
                stock_tags_count=3,
                content_structure="narrative",
                interaction_elements=["hashtag"],
                expected_performance=80.0,
                confidence_level=0.75,
                based_on_features=["ä¸­ç­‰é•·åº¦å…§å®¹", "å°ˆæ¥­åˆ†æ"]
            )
        ]

        modification_capabilities = {
            'modifiable_features': 3,
            'total_features': 3,
            'modification_methods': [
                'åœ¨å…§å®¹ç”Ÿæˆä¸­åŠ å…¥å•å¥',
                'åœ¨å…§å®¹ç”Ÿæˆä¸­åŠ å…¥è¡¨æƒ…ç¬¦è™Ÿ',
                'èª¿æ•´å…§å®¹ç”Ÿæˆé•·åº¦è¨­å®š'
            ],
            'unmodifiable_features': []
        }

        recommendations = [
            'å»ºè­°å„ªå…ˆèª¿æ•´å¯ä¿®æ”¹çš„é«˜æˆæ•ˆç‰¹å¾µ',
            'çµåˆå¤šå€‹ç‰¹å¾µç”Ÿæˆç¶œåˆç™¼æ–‡è¨­å®š',
            'å®šæœŸæ›´æ–°ç‰¹å¾µåˆ†æä»¥ä¿æŒæ•ˆæœ',
            'æ¸¬è©¦ä¸åŒè¨­å®šçµ„åˆçš„å¯¦éš›æ•ˆæœ'
        ]

        report = EnhancedAnalysisReport(
            analysis_timestamp=datetime.now().isoformat(),
            total_posts_analyzed=150,
            top_performance_features=mock_features,
            content_categories=mock_categories,
            generated_settings=mock_settings,
            modification_capabilities=modification_capabilities,
            recommendations=recommendations
        )

        return {
            "success": True,
            "data": report.dict()
        }
        
    except Exception as e:
        logger.error(f"ç²å–å¢å¼·ç‰ˆåˆ†æå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–å¢å¼·ç‰ˆåˆ†æå¤±æ•—: {str(e)}")

# ==================== æ’ç¨‹ç®¡ç† API ====================

class ScheduleRequest(BaseModel):
    schedule_name: str
    schedule_description: str
    schedule_type: str
    daily_execution_time: str
    enabled: bool
    max_posts_per_hour: int
    timezone: str
    generation_config: Dict[str, Any]

@app.post("/schedule/create")
async def create_schedule(schedule_data: ScheduleRequest):
    """å‰µå»ºæ’ç¨‹ä»»å‹™"""
    try:
        # æ¨¡æ“¬å‰µå»ºæ’ç¨‹ä»»å‹™
        schedule_id = f"schedule_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # é€™è£¡æ‡‰è©²å¯¦éš›ä¿å­˜åˆ°æ•¸æ“šåº«
        # æš«æ™‚è¿”å›æˆåŠŸéŸ¿æ‡‰
        
        logger.info(f"å‰µå»ºæ’ç¨‹ä»»å‹™: {schedule_id}")
        logger.info(f"æ’ç¨‹è¨­å®š: {schedule_data.dict()}")
        
        return {
            "success": True,
            "message": "æ’ç¨‹ä»»å‹™å‰µå»ºæˆåŠŸ",
            "schedule_id": schedule_id,
            "data": schedule_data.dict()
        }
        
    except Exception as e:
        logger.error(f"å‰µå»ºæ’ç¨‹ä»»å‹™å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"å‰µå»ºæ’ç¨‹ä»»å‹™å¤±æ•—: {str(e)}")

@app.get("/schedule/list")
async def get_schedules():
    """ç²å–æ’ç¨‹ä»»å‹™åˆ—è¡¨"""
    try:
        # æ¨¡æ“¬æ’ç¨‹ä»»å‹™åˆ—è¡¨
        schedules = [
            {
                "schedule_id": "schedule_001",
                "schedule_name": "åŸºæ–¼å•å¥äº’å‹•çš„æ’ç¨‹",
                "schedule_type": "weekday_daily",
                "posting_type": "interaction",
                "status": "active",
                "created_at": datetime.now().isoformat()
            },
            {
                "schedule_id": "schedule_002", 
                "schedule_name": "åŸºæ–¼è¡¨æƒ…ç¬¦è™Ÿçš„æ’ç¨‹",
                "schedule_type": "weekday_daily",
                "posting_type": "analysis",
                "status": "active",
                "created_at": datetime.now().isoformat()
            }
        ]
        
        return {
            "success": True,
            "data": schedules
        }
        
    except Exception as e:
        logger.error(f"ç²å–æ’ç¨‹ä»»å‹™åˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æ’ç¨‹ä»»å‹™åˆ—è¡¨å¤±æ•—: {str(e)}")

@app.post("/enhanced-self-learning/fetch-performance-data")
async def fetch_performance_data(request: dict):
    """æŠ“å–è²¼æ–‡æˆæ•ˆæ•¸æ“š"""
    try:
        logger.info("é–‹å§‹æŠ“å–è²¼æ–‡æˆæ•ˆæ•¸æ“š")
        
        # æ¨¡æ“¬æ•¸æ“šæŠ“å–éç¨‹
        import time
        time.sleep(2)  # æ¨¡æ“¬æŠ“å–æ™‚é–“
        
        # æ¨¡æ“¬æŠ“å–çµæœ
        fetched_count = 150
        updated_count = 45
        
        logger.info(f"è²¼æ–‡æˆæ•ˆæ•¸æ“šæŠ“å–å®Œæˆ: æŠ“å– {fetched_count} ç¯‡ï¼Œæ›´æ–° {updated_count} ç¯‡")
        
        return {
            "success": True,
            "message": f"æˆåŠŸæŠ“å– {fetched_count} ç¯‡è²¼æ–‡æˆæ•ˆæ•¸æ“šï¼Œæ›´æ–° {updated_count} ç¯‡",
            "data": {
                "fetched_count": fetched_count,
                "updated_count": updated_count,
                "timestamp": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"æŠ“å–è²¼æ–‡æˆæ•ˆæ•¸æ“šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"æŠ“å–è²¼æ–‡æˆæ•ˆæ•¸æ“šå¤±æ•—: {str(e)}")

# ==================== Interactions API ç«¯é» ====================

@app.get("/interactions/analysis")
async def get_interactions_analysis(
    kol_serial: Optional[int] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    include_external: bool = True
):
    """ç²å–äº’å‹•åˆ†ææ•¸æ“š"""
    try:
        logger.info(f"ç²å–äº’å‹•åˆ†ææ•¸æ“š: kol_serial={kol_serial}, include_external={include_external}")
        
        # æ¨¡æ“¬äº’å‹•åˆ†ææ•¸æ“š
        mock_posts = [
            {
                "post_id": f"post_{i}",
                "title": f"è‚¡ç¥¨åˆ†æè²¼æ–‡ {i}",
                "content": f"é€™æ˜¯ç¬¬ {i} ç¯‡è²¼æ–‡çš„å…§å®¹...",
                "kol_serial": (i % 3) + 1,
                "kol_name": f"KOL_{i % 3 + 1}",
                "likes": 10 + (i * 5),
                "comments": 2 + (i * 2),
                "shares": 1 + i,
                "bookmarks": 3 + (i * 3),
                "engagement_rate": 0.1 + (i * 0.05),
                "created_at": "2025-01-08T10:00:00Z"
            }
            for i in range(1, 21)
        ]
        
        return {
            "success": True,
            "data": {
                "posts": mock_posts,
                "kol_stats": {
                    "1": {"total_posts": 7, "avg_engagement": 0.15},
                    "2": {"total_posts": 7, "avg_engagement": 0.12},
                    "3": {"total_posts": 6, "avg_engagement": 0.18}
                },
                "overall_stats": {
                    "total_posts": 20,
                    "total_interactions": 500,
                    "avg_engagement_rate": 0.15
                }
            }
        }
        
    except Exception as e:
        logger.error(f"ç²å–äº’å‹•åˆ†ææ•¸æ“šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–äº’å‹•åˆ†ææ•¸æ“šå¤±æ•—: {str(e)}")

@app.post("/interactions/refresh-all")
async def refresh_all_interactions():
    """æ‰¹é‡åˆ·æ–°äº’å‹•æ•¸æ“š"""
    try:
        logger.info("é–‹å§‹æ‰¹é‡åˆ·æ–°äº’å‹•æ•¸æ“š")
        
        # æ¨¡æ“¬åˆ·æ–°éç¨‹
        import time
        time.sleep(2)
        
        return {
            "success": True,
            "message": "æ‰¹é‡åˆ·æ–°å®Œæˆï¼Œæ›´æ–°äº† 45 ç¯‡è²¼æ–‡çš„äº’å‹•æ•¸æ“š"
        }
        
    except Exception as e:
        logger.error(f"æ‰¹é‡åˆ·æ–°å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡åˆ·æ–°å¤±æ•—: {str(e)}")

@app.post("/interactions/fetch-all-interactions")
async def fetch_all_interactions():
    """ä¸€éµæŠ“å–æ‰€æœ‰äº’å‹•æ•¸æ“š"""
    try:
        logger.info("é–‹å§‹ä¸€éµæŠ“å–æ‰€æœ‰äº’å‹•æ•¸æ“š")
        
        # æ¨¡æ“¬æŠ“å–éç¨‹
        import time
        time.sleep(3)
        
        return {
            "success": True,
            "message": "ä¸€éµæŠ“å–å®Œæˆï¼Œæ–°å¢ 150 ç¯‡è²¼æ–‡ï¼Œæ›´æ–° 45 ç¯‡äº’å‹•æ•¸æ“š"
        }
        
    except Exception as e:
        logger.error(f"ä¸€éµæŠ“å–å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ä¸€éµæŠ“å–å¤±æ•—: {str(e)}")

@app.post("/interactions/deduplicate")
async def deduplicate_interactions():
    """å»é‡åŠŸèƒ½"""
    try:
        logger.info("é–‹å§‹å»é‡è™•ç†")
        
        # æ¨¡æ“¬å»é‡éç¨‹
        import time
        time.sleep(1)
        
        return {
            "success": True,
            "message": "å»é‡å®Œæˆï¼Œç§»é™¤äº† 12 ç¯‡é‡è¤‡è²¼æ–‡"
        }
        
    except Exception as e:
        logger.error(f"å»é‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"å»é‡å¤±æ•—: {str(e)}")

# ==================== ç™¼æ–‡å¯©æ ¸ API ç«¯é» ====================

@app.get("/posts")
async def get_posts(
    skip: int = 0,
    limit: int = 5000,
    status: Optional[str] = None
):
    """ç²å–æ‰€æœ‰è²¼æ–‡"""
    try:
        logger.info(f"ç²å–è²¼æ–‡åˆ—è¡¨: skip={skip}, limit={limit}, status={status}")
        
        # æ¨¡æ“¬è²¼æ–‡æ•¸æ“š
        mock_posts = [
            {
                "id": f"post_{i}",
                "session_id": f"session_{i % 3 + 1}",
                "kol_nickname": f"KOL_{i % 3 + 1}",
                "title": f"è‚¡ç¥¨åˆ†æè²¼æ–‡ {i}",
                "content": f"é€™æ˜¯ç¬¬ {i} ç¯‡è²¼æ–‡çš„å…§å®¹...",
                "status": ["pending_review", "approved", "published", "draft"][i % 4],
                "stock_codes": ["2330", "2317", "2454"][:i % 3 + 1],
                "stock_names": ["å°ç©é›»", "é´»æµ·", "è¯ç™¼ç§‘"][:i % 3 + 1],
                "created_at": "2025-01-08T10:00:00Z",
                "quality_score": 0.8 + (i * 0.05),
                "ai_detection": "passed"
            }
            for i in range(1, 21)
        ]
        
        # æ ¹æ“šç‹€æ…‹ç¯©é¸
        if status:
            mock_posts = [post for post in mock_posts if post["status"] == status]
        
        return {
            "posts": mock_posts[skip:skip + limit],
            "total": len(mock_posts),
            "skip": skip,
            "limit": limit
        }
        
    except Exception as e:
        logger.error(f"ç²å–è²¼æ–‡åˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–è²¼æ–‡åˆ—è¡¨å¤±æ•—: {str(e)}")

@app.get("/posts/session/{session_id}")
async def get_session_posts(
    session_id: int,
    status: Optional[str] = None
):
    """ç²å–ç‰¹å®š session çš„è²¼æ–‡"""
    try:
        logger.info(f"ç²å– session {session_id} çš„è²¼æ–‡: status={status}")
        
        # æ¨¡æ“¬è©² session çš„è²¼æ–‡æ•¸æ“š
        mock_posts = [
            {
                "id": f"post_{session_id}_{i}",
                "session_id": str(session_id),
                "kol_nickname": f"KOL_{i % 2 + 1}",
                "title": f"Session {session_id} è²¼æ–‡ {i}",
                "content": f"é€™æ˜¯ session {session_id} çš„ç¬¬ {i} ç¯‡è²¼æ–‡...",
                "status": ["pending_review", "approved", "published"][i % 3],
                "stock_codes": ["2330", "2317"][:i % 2 + 1],
                "stock_names": ["å°ç©é›»", "é´»æµ·"][:i % 2 + 1],
                "created_at": "2025-01-08T10:00:00Z",
                "quality_score": 0.8 + (i * 0.05),
                "ai_detection": "passed"
            }
            for i in range(1, 6)
        ]
        
        # æ ¹æ“šç‹€æ…‹ç¯©é¸
        if status:
            mock_posts = [post for post in mock_posts if post["status"] == status]
        
        return {
            "success": True,
            "posts": mock_posts,
            "count": len(mock_posts),
            "session_id": session_id,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ç²å– session è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å– session è²¼æ–‡å¤±æ•—: {str(e)}")

@app.get("/posts/review-sidebar")
async def get_review_sidebar_data():
    """ç²å–ç™¼æ–‡å¯©æ ¸ sidebar æ•¸æ“š"""
    try:
        logger.info("ç²å–ç™¼æ–‡å¯©æ ¸ sidebar æ•¸æ“š")
        
        # æ¨¡æ“¬ sidebar æ•¸æ“š
        return {
            "success": True,
            "data": {
                "sessions": [
                    {
                        "session_id": "1",
                        "total_posts": 5,
                        "pending_posts": 2,
                        "approved_posts": 2,
                        "published_posts": 1,
                        "success_rate": 80
                    },
                    {
                        "session_id": "2", 
                        "total_posts": 3,
                        "pending_posts": 1,
                        "approved_posts": 1,
                        "published_posts": 1,
                        "success_rate": 100
                    }
                ],
                "overall_stats": {
                    "total_sessions": 2,
                    "total_posts": 8,
                    "pending_posts": 3,
                    "approved_posts": 3,
                    "published_posts": 2
                }
            }
        }
        
    except Exception as e:
        logger.error(f"ç²å– sidebar æ•¸æ“šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å– sidebar æ•¸æ“šå¤±æ•—: {str(e)}")

@app.post("/posts/{post_id}/approve")
async def approve_post(post_id: str, request: dict):
    """å¯©æ ¸é€šéè²¼æ–‡"""
    try:
        logger.info(f"å¯©æ ¸é€šéè²¼æ–‡: {post_id}")
        
        # æ¨¡æ“¬å¯©æ ¸é€šé
        return {
            "success": True,
            "message": f"è²¼æ–‡ {post_id} å¯©æ ¸é€šé"
        }
        
    except Exception as e:
        logger.error(f"å¯©æ ¸é€šéå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"å¯©æ ¸é€šéå¤±æ•—: {str(e)}")

@app.post("/posts/{post_id}/reject")
async def reject_post(post_id: str, request: dict):
    """æ‹’çµ•è²¼æ–‡"""
    try:
        logger.info(f"æ‹’çµ•è²¼æ–‡: {post_id}")
        
        # æ¨¡æ“¬æ‹’çµ•
        return {
            "success": True,
            "message": f"è²¼æ–‡ {post_id} å·²æ‹’çµ•"
        }
        
    except Exception as e:
        logger.error(f"æ‹’çµ•è²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"æ‹’çµ•è²¼æ–‡å¤±æ•—: {str(e)}")

@app.post("/posts/{post_id}/publish")
async def publish_post(post_id: str):
    """ç™¼å¸ƒè²¼æ–‡åˆ° CMoney"""
    try:
        logger.info(f"ç™¼å¸ƒè²¼æ–‡: {post_id}")
        
        # æ¨¡æ“¬ç™¼å¸ƒ
        return {
            "success": True,
            "article_id": f"cmoney_{post_id}",
            "url": f"https://cmoney.tw/article/{post_id}",
            "message": f"è²¼æ–‡ {post_id} ç™¼å¸ƒæˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"ç™¼å¸ƒè²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç™¼å¸ƒè²¼æ–‡å¤±æ•—: {str(e)}")

# ==================== æ’ç¨‹ç®¡ç† API ç«¯é» ====================

@app.get("/api/schedule/tasks")
async def get_schedule_tasks():
    """ç²å–æ’ç¨‹ä»»å‹™åˆ—è¡¨ - æ’ç¨‹ç®¡ç†é é¢ä½¿ç”¨"""
    try:
        logger.info("ç²å–æ’ç¨‹ä»»å‹™åˆ—è¡¨")
        
        # æ¨¡æ“¬æ’ç¨‹ä»»å‹™æ•¸æ“š
        mock_tasks = [
            {
                "task_id": "schedule_001",
                "schedule_name": "åŸºæ–¼å•å¥äº’å‹•çš„æ’ç¨‹",
                "schedule_type": "weekday_daily",
                "posting_type": "interaction",
                "status": "active",
                "enabled": True,
                "created_at": "2025-10-08T10:14:29.587648",
                "next_run": "2025-10-09T14:00:00Z",
                "last_run": None,
                "generation_config": {
                    "trigger_type": "limit_up_after_hours",
                    "posting_type": "interaction",
                    "max_stocks": 3
                }
            },
            {
                "task_id": "schedule_002", 
                "schedule_name": "åŸºæ–¼è¡¨æƒ…ç¬¦è™Ÿçš„æ’ç¨‹",
                "schedule_type": "weekday_daily",
                "posting_type": "analysis",
                "status": "active",
                "enabled": True,
                "created_at": "2025-10-08T10:14:29.587652",
                "next_run": "2025-10-09T15:00:00Z",
                "last_run": None,
                "generation_config": {
                    "trigger_type": "volume_surge",
                    "posting_type": "analysis",
                    "max_stocks": 5
                }
            }
        ]
        
        return {
            "tasks": mock_tasks
        }
        
    except Exception as e:
        logger.error(f"ç²å–æ’ç¨‹ä»»å‹™åˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æ’ç¨‹ä»»å‹™åˆ—è¡¨å¤±æ•—: {str(e)}")

@app.get("/api/schedule/daily-stats")
async def get_daily_stats():
    """ç²å–æ¯æ—¥çµ±è¨ˆæ•¸æ“š"""
    try:
        logger.info("ç²å–æ¯æ—¥çµ±è¨ˆæ•¸æ“š")
        
        # æ¨¡æ“¬æ¯æ—¥çµ±è¨ˆæ•¸æ“š
        return {
            "date": "2025-10-08",
            "totals": {
                "generated": 15,
                "published": 12,
                "successful": 10,
                "draft": 2,
                "pending_review": 3
            },
            "success_rate": 83.3
        }
        
    except Exception as e:
        logger.error(f"ç²å–æ¯æ—¥çµ±è¨ˆæ•¸æ“šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æ¯æ—¥çµ±è¨ˆæ•¸æ“šå¤±æ•—: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8011)
