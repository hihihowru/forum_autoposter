"""
æˆæ•ˆåˆ†æç³»çµ± API
å–å‰10%æˆæ•ˆå¥½çš„è²¼æ–‡é€²è¡Œæ·±åº¦åˆ†æ
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import logging
import json
import asyncio
from dataclasses import dataclass, asdict
import statistics

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/performance-analysis", tags=["performance-analysis"])

# ==================== æ•¸æ“šæ¨¡å‹ ====================

class PerformanceMetric(BaseModel):
    metric_name: str
    value: float
    unit: str
    trend: str  # 'up', 'down', 'stable'
    change_percentage: float
    significance: str  # 'high', 'medium', 'low'

class TopPostAnalysis(BaseModel):
    post_id: str
    article_id: str
    kol_nickname: str
    title: str
    content: str
    create_time: str
    total_interactions: int
    engagement_rate: float
    performance_score: float
    ranking: int
    key_features: List[str]
    success_factors: List[str]

class FeatureCorrelation(BaseModel):
    feature_pair: str
    correlation_score: float
    significance: str
    description: str
    recommendation: str

class PerformanceInsight(BaseModel):
    insight_id: str
    insight_type: str  # 'pattern', 'anomaly', 'opportunity', 'risk'
    title: str
    description: str
    confidence: float
    impact_score: float
    evidence: List[str]
    actionable_recommendations: List[str]
    affected_kols: List[str]

class PerformanceReport(BaseModel):
    analysis_period: str
    total_posts_analyzed: int
    top10_percent_count: int
    overall_performance_score: float
    performance_metrics: List[PerformanceMetric]
    top_posts_analysis: List[TopPostAnalysis]
    feature_correlations: List[FeatureCorrelation]
    insights: List[PerformanceInsight]
    summary: str
    timestamp: str

# ==================== æˆæ•ˆåˆ†ææœå‹™ ====================

class PerformanceAnalysisService:
    def __init__(self):
        self.analysis_cache = {}
        self.performance_thresholds = {
            'high_performance': 80,
            'medium_performance': 60,
            'low_performance': 40
        }
    
    async def analyze_top_performers(self, posts: List[Dict]) -> List[TopPostAnalysis]:
        """åˆ†æå‰10%é«˜æˆæ•ˆè²¼æ–‡"""
        if not posts:
            return []
        
        # è¨ˆç®—æ¯ç¯‡è²¼æ–‡çš„æˆæ•ˆåˆ†æ•¸
        scored_posts = []
        for post in posts:
            score = self._calculate_performance_score(post)
            scored_posts.append((post, score))
        
        # æŒ‰åˆ†æ•¸æ’åº
        scored_posts.sort(key=lambda x: x[1], reverse=True)
        
        # å–å‰10%
        total_posts = len(scored_posts)
        top10_count = max(1, int(total_posts * 0.1))
        top_posts = scored_posts[:top10_count]
        
        # åˆ†ææ¯ç¯‡é«˜æˆæ•ˆè²¼æ–‡
        top_post_analyses = []
        for i, (post, score) in enumerate(top_posts):
            analysis = TopPostAnalysis(
                post_id=post.get('post_id', ''),
                article_id=post.get('article_id', ''),
                kol_nickname=post.get('kol_nickname', ''),
                title=post.get('title', ''),
                content=post.get('content', ''),
                create_time=post.get('create_time', ''),
                total_interactions=self._calculate_total_interactions(post),
                engagement_rate=post.get('engagement_rate', 0),
                performance_score=score,
                ranking=i + 1,
                key_features=self._extract_key_features(post),
                success_factors=self._identify_success_factors(post)
            )
            top_post_analyses.append(analysis)
        
        return top_post_analyses
    
    def _calculate_performance_score(self, post: Dict) -> float:
        """è¨ˆç®—è²¼æ–‡æˆæ•ˆåˆ†æ•¸"""
        # åŸºç¤äº’å‹•åˆ†æ•¸ (40%)
        total_interactions = self._calculate_total_interactions(post)
        interaction_score = min(total_interactions / 100, 1.0) * 40
        
        # äº’å‹•ç‡åˆ†æ•¸ (30%)
        engagement_rate = post.get('engagement_rate', 0)
        engagement_score = min(engagement_rate / 10, 1.0) * 30
        
        # å…§å®¹å“è³ªåˆ†æ•¸ (20%)
        content_quality = self._assess_content_quality(post)
        quality_score = content_quality * 20
        
        # æ™‚æ©Ÿåˆ†æ•¸ (10%)
        timing_score = self._assess_timing_score(post) * 10
        
        return interaction_score + engagement_score + quality_score + timing_score
    
    def _calculate_total_interactions(self, post: Dict) -> int:
        """è¨ˆç®—ç¸½äº’å‹•æ•¸"""
        return (post.get('likes', 0) or 0) + (post.get('comments', 0) or 0) + (post.get('shares', 0) or 0) + (post.get('bookmarks', 0) or 0)
    
    def _assess_content_quality(self, post: Dict) -> float:
        """è©•ä¼°å…§å®¹å“è³ª"""
        title = post.get('title', '')
        content = post.get('content', '')
        full_text = f"{title} {content}"
        
        quality_score = 0.5  # åŸºç¤åˆ†æ•¸
        
        # å…§å®¹é•·åº¦é©ä¸­
        if 100 <= len(content) <= 800:
            quality_score += 0.1
        
        # åŒ…å«è‚¡ç¥¨æ¨™è¨˜
        if post.get('commodity_tags'):
            quality_score += 0.1
        
        # åŒ…å«äº’å‹•å…ƒç´ 
        if any(keyword in full_text for keyword in ['ï¼Ÿ', '?', 'ï¼', '!']):
            quality_score += 0.1
        
        # åŒ…å«Emoji
        if any(emoji in full_text for emoji in ['ğŸ˜‚', 'ğŸ˜„', 'ğŸ˜†', 'ğŸ‘', 'ğŸ‘']):
            quality_score += 0.1
        
        # åŒ…å«æ•¸å­—
        if any(char.isdigit() for char in full_text):
            quality_score += 0.1
        
        return min(quality_score, 1.0)
    
    def _assess_timing_score(self, post: Dict) -> float:
        """è©•ä¼°ç™¼æ–‡æ™‚æ©Ÿåˆ†æ•¸"""
        create_time = post.get('create_time', '')
        if not create_time:
            return 0.5
        
        try:
            post_time = datetime.fromisoformat(create_time.replace('Z', '+00:00'))
            hour = post_time.hour
            
            # æœ€ä½³ç™¼æ–‡æ™‚æ®µ
            if 9 <= hour <= 11 or 19 <= hour <= 21:
                return 1.0
            elif 14 <= hour <= 16:
                return 0.8
            elif 12 <= hour <= 13 or 22 <= hour <= 23:
                return 0.6
            else:
                return 0.4
        except:
            return 0.5
    
    def _extract_key_features(self, post: Dict) -> List[str]:
        """æå–é—œéµç‰¹å¾µ"""
        features = []
        title = post.get('title', '')
        content = post.get('content', '')
        full_text = f"{title} {content}"
        
        # ç™¼æ–‡æ™‚é–“ç‰¹å¾µ
        create_time = post.get('create_time', '')
        if create_time:
            try:
                post_time = datetime.fromisoformat(create_time.replace('Z', '+00:00'))
                hour = post_time.hour
                if 9 <= hour <= 11:
                    features.append('ä¸Šåˆç™¼æ–‡')
                elif 14 <= hour <= 16:
                    features.append('ä¸‹åˆç™¼æ–‡')
                elif 19 <= hour <= 21:
                    features.append('æ™šä¸Šç™¼æ–‡')
            except:
                pass
        
        # å…§å®¹ç‰¹å¾µ
        if post.get('commodity_tags'):
            features.append('åŒ…å«è‚¡ç¥¨æ¨™è¨˜')
        
        if any(keyword in full_text for keyword in ['å“ˆå“ˆ', 'ç¬‘æ­»', 'æç¬‘', 'å¹½é»˜']):
            features.append('å¹½é»˜å…§å®¹')
        
        if any(emoji in full_text for emoji in ['ğŸ˜‚', 'ğŸ˜„', 'ğŸ˜†']):
            features.append('ä½¿ç”¨Emoji')
        
        if any(keyword in full_text for keyword in ['ï¼Ÿ', '?']):
            features.append('äº’å‹•å¼•å°')
        
        if len(content) >= 200:
            features.append('è©³ç´°å…§å®¹')
        
        return features
    
    def _identify_success_factors(self, post: Dict) -> List[str]:
        """è­˜åˆ¥æˆåŠŸå› ç´ """
        factors = []
        title = post.get('title', '')
        content = post.get('content', '')
        full_text = f"{title} {content}"
        
        # é«˜äº’å‹•ç‡
        engagement_rate = post.get('engagement_rate', 0)
        if engagement_rate > 5:
            factors.append('é«˜äº’å‹•ç‡')
        
        # å…§å®¹é•·åº¦é©ä¸­
        if 200 <= len(content) <= 500:
            factors.append('å…§å®¹é•·åº¦é©ä¸­')
        
        # åŒ…å«ç†±é–€è©±é¡Œ
        if post.get('community_topic'):
            factors.append('ç†±é–€è©±é¡Œ')
        
        # ç³»çµ±ç™¼æ–‡
        if post.get('source') == 'system':
            factors.append('ç³»çµ±ç™¼æ–‡')
        
        # åŒ…å«æ•¸å­—
        if any(char.isdigit() for char in full_text):
            factors.append('æ•¸æ“šæ”¯æ’')
        
        return factors
    
    async def analyze_feature_correlations(self, top_posts: List[TopPostAnalysis]) -> List[FeatureCorrelation]:
        """åˆ†æç‰¹å¾µç›¸é—œæ€§"""
        correlations = []
        
        if len(top_posts) < 3:
            return correlations
        
        # åˆ†æç™¼æ–‡æ™‚é–“èˆ‡æˆæ•ˆçš„ç›¸é—œæ€§
        time_correlations = self._analyze_time_correlation(top_posts)
        correlations.extend(time_correlations)
        
        # åˆ†æå…§å®¹ç‰¹å¾µèˆ‡æˆæ•ˆçš„ç›¸é—œæ€§
        content_correlations = self._analyze_content_correlation(top_posts)
        correlations.extend(content_correlations)
        
        # åˆ†æKOLèˆ‡æˆæ•ˆçš„ç›¸é—œæ€§
        kol_correlations = self._analyze_kol_correlation(top_posts)
        correlations.extend(kol_correlations)
        
        return correlations
    
    def _analyze_time_correlation(self, top_posts: List[TopPostAnalysis]) -> List[FeatureCorrelation]:
        """åˆ†ææ™‚é–“ç›¸é—œæ€§"""
        correlations = []
        
        # çµ±è¨ˆä¸åŒæ™‚æ®µçš„æˆæ•ˆ
        time_performance = {'morning': [], 'afternoon': [], 'evening': [], 'night': []}
        
        for post in top_posts:
            try:
                post_time = datetime.fromisoformat(post.create_time.replace('Z', '+00:00'))
                hour = post_time.hour
                
                if 6 <= hour < 12:
                    time_performance['morning'].append(post.performance_score)
                elif 12 <= hour < 18:
                    time_performance['afternoon'].append(post.performance_score)
                elif 18 <= hour < 24:
                    time_performance['evening'].append(post.performance_score)
                else:
                    time_performance['night'].append(post.performance_score)
            except:
                continue
        
        # è¨ˆç®—å„æ™‚æ®µçš„å¹³å‡æˆæ•ˆ
        for time_slot, scores in time_performance.items():
            if scores:
                avg_score = statistics.mean(scores)
                if avg_score > 70:
                    correlations.append(FeatureCorrelation(
                        feature_pair=f'ç™¼æ–‡æ™‚æ®µ-{time_slot}',
                        correlation_score=avg_score,
                        significance='high' if avg_score > 80 else 'medium',
                        description=f'{time_slot}æ™‚æ®µç™¼æ–‡æˆæ•ˆè¼ƒä½³',
                        recommendation=f'å»ºè­°åœ¨{time_slot}æ™‚æ®µå¢åŠ ç™¼æ–‡é »ç‡'
                    ))
        
        return correlations
    
    def _analyze_content_correlation(self, top_posts: List[TopPostAnalysis]) -> List[FeatureCorrelation]:
        """åˆ†æå…§å®¹ç›¸é—œæ€§"""
        correlations = []
        
        # çµ±è¨ˆä¸åŒå…§å®¹ç‰¹å¾µçš„æˆæ•ˆ
        feature_performance = {
            'has_stock_tags': [],
            'has_humor': [],
            'has_emoji': [],
            'has_interaction': [],
            'detailed_content': []
        }
        
        for post in top_posts:
            if 'åŒ…å«è‚¡ç¥¨æ¨™è¨˜' in post.key_features:
                feature_performance['has_stock_tags'].append(post.performance_score)
            
            if 'å¹½é»˜å…§å®¹' in post.key_features:
                feature_performance['has_humor'].append(post.performance_score)
            
            if 'ä½¿ç”¨Emoji' in post.key_features:
                feature_performance['has_emoji'].append(post.performance_score)
            
            if 'äº’å‹•å¼•å°' in post.key_features:
                feature_performance['has_interaction'].append(post.performance_score)
            
            if 'è©³ç´°å…§å®¹' in post.key_features:
                feature_performance['detailed_content'].append(post.performance_score)
        
        # è¨ˆç®—å„ç‰¹å¾µçš„å¹³å‡æˆæ•ˆ
        feature_names = {
            'has_stock_tags': 'è‚¡ç¥¨æ¨™è¨˜',
            'has_humor': 'å¹½é»˜å…§å®¹',
            'has_emoji': 'Emojiä½¿ç”¨',
            'has_interaction': 'äº’å‹•å¼•å°',
            'detailed_content': 'è©³ç´°å…§å®¹'
        }
        
        for feature, scores in feature_performance.items():
            if scores:
                avg_score = statistics.mean(scores)
                if avg_score > 70:
                    correlations.append(FeatureCorrelation(
                        feature_pair=feature_names[feature],
                        correlation_score=avg_score,
                        significance='high' if avg_score > 80 else 'medium',
                        description=f'{feature_names[feature]}èˆ‡é«˜æˆæ•ˆç›¸é—œ',
                        recommendation=f'å»ºè­°å¢åŠ {feature_names[feature]}çš„ä½¿ç”¨'
                    ))
        
        return correlations
    
    def _analyze_kol_correlation(self, top_posts: List[TopPostAnalysis]) -> List[FeatureCorrelation]:
        """åˆ†æKOLç›¸é—œæ€§"""
        correlations = []
        
        # çµ±è¨ˆä¸åŒKOLçš„æˆæ•ˆ
        kol_performance = {}
        
        for post in top_posts:
            kol_name = post.kol_nickname
            if kol_name not in kol_performance:
                kol_performance[kol_name] = []
            kol_performance[kol_name].append(post.performance_score)
        
        # è¨ˆç®—å„KOLçš„å¹³å‡æˆæ•ˆ
        for kol_name, scores in kol_performance.items():
            if len(scores) >= 2:  # è‡³å°‘2ç¯‡è²¼æ–‡
                avg_score = statistics.mean(scores)
                if avg_score > 70:
                    correlations.append(FeatureCorrelation(
                        feature_pair=f'KOL-{kol_name}',
                        correlation_score=avg_score,
                        significance='high' if avg_score > 80 else 'medium',
                        description=f'{kol_name}çš„è²¼æ–‡æˆæ•ˆè¼ƒä½³',
                        recommendation=f'å»ºè­°å¢åŠ {kol_name}çš„ç™¼æ–‡é »ç‡'
                    ))
        
        return correlations
    
    async def generate_performance_insights(self, top_posts: List[TopPostAnalysis], correlations: List[FeatureCorrelation]) -> List[PerformanceInsight]:
        """ç”Ÿæˆæˆæ•ˆæ´å¯Ÿ"""
        insights = []
        
        if not top_posts:
            return insights
        
        # åˆ†ææˆæ•ˆæ¨¡å¼
        pattern_insights = self._analyze_performance_patterns(top_posts)
        insights.extend(pattern_insights)
        
        # åˆ†æç•°å¸¸æƒ…æ³
        anomaly_insights = self._analyze_performance_anomalies(top_posts)
        insights.extend(anomaly_insights)
        
        # åˆ†ææ©Ÿæœƒ
        opportunity_insights = self._analyze_opportunities(top_posts, correlations)
        insights.extend(opportunity_insights)
        
        # åˆ†æé¢¨éšª
        risk_insights = self._analyze_risks(top_posts)
        insights.extend(risk_insights)
        
        return insights
    
    def _analyze_performance_patterns(self, top_posts: List[TopPostAnalysis]) -> List[PerformanceInsight]:
        """åˆ†ææˆæ•ˆæ¨¡å¼"""
        insights = []
        
        # åˆ†æç™¼æ–‡æ™‚é–“æ¨¡å¼
        time_patterns = {}
        for post in top_posts:
            try:
                post_time = datetime.fromisoformat(post.create_time.replace('Z', '+00:00'))
                hour = post_time.hour
                time_slot = 'morning' if 6 <= hour < 12 else 'afternoon' if 12 <= hour < 18 else 'evening' if 18 <= hour < 24 else 'night'
                
                if time_slot not in time_patterns:
                    time_patterns[time_slot] = []
                time_patterns[time_slot].append(post.performance_score)
            except:
                continue
        
        # æ‰¾å‡ºæœ€ä½³æ™‚æ®µ
        best_time_slot = max(time_patterns.keys(), key=lambda k: statistics.mean(time_patterns[k])) if time_patterns else None
        if best_time_slot:
            insights.append(PerformanceInsight(
                insight_id='pattern_1',
                insight_type='pattern',
                title='ç™¼æ–‡æ™‚é–“æ¨¡å¼åˆ†æ',
                description=f'{best_time_slot}æ™‚æ®µç™¼æ–‡æˆæ•ˆæœ€ä½³ï¼Œå¹³å‡åˆ†æ•¸{statistics.mean(time_patterns[best_time_slot]):.1f}',
                confidence=0.85,
                impact_score=0.8,
                evidence=[f'{best_time_slot}æ™‚æ®µæœ‰{len(time_patterns[best_time_slot])}ç¯‡é«˜æˆæ•ˆè²¼æ–‡'],
                actionable_recommendations=[f'å»ºè­°åœ¨{best_time_slot}æ™‚æ®µå¢åŠ ç™¼æ–‡é »ç‡'],
                affected_kols=list(set(post.kol_nickname for post in top_posts))
            ))
        
        return insights
    
    def _analyze_performance_anomalies(self, top_posts: List[TopPostAnalysis]) -> List[PerformanceInsight]:
        """åˆ†æç•°å¸¸æƒ…æ³"""
        insights = []
        
        # åˆ†æè¶…é«˜æˆæ•ˆè²¼æ–‡
        high_performers = [post for post in top_posts if post.performance_score > 90]
        if high_performers:
            insights.append(PerformanceInsight(
                insight_id='anomaly_1',
                insight_type='anomaly',
                title='è¶…é«˜æˆæ•ˆè²¼æ–‡åˆ†æ',
                description=f'ç™¼ç¾{len(high_performers)}ç¯‡è¶…é«˜æˆæ•ˆè²¼æ–‡ï¼Œå¹³å‡åˆ†æ•¸{statistics.mean([p.performance_score for p in high_performers]):.1f}',
                confidence=0.9,
                impact_score=0.9,
                evidence=[f'è¶…é«˜æˆæ•ˆè²¼æ–‡ä½”æ¯”{len(high_performers)/len(top_posts)*100:.1f}%'],
                actionable_recommendations=['åˆ†æè¶…é«˜æˆæ•ˆè²¼æ–‡çš„å…±åŒç‰¹å¾µ', 'è¤‡è£½æˆåŠŸæ¨¡å¼åˆ°å…¶ä»–è²¼æ–‡'],
                affected_kols=list(set(post.kol_nickname for post in high_performers))
            ))
        
        return insights
    
    def _analyze_opportunities(self, top_posts: List[TopPostAnalysis], correlations: List[FeatureCorrelation]) -> List[PerformanceInsight]:
        """åˆ†ææ©Ÿæœƒ"""
        insights = []
        
        # åˆ†ææœªå……åˆ†åˆ©ç”¨çš„ç‰¹å¾µ
        all_features = set()
        for post in top_posts:
            all_features.update(post.key_features)
        
        # æ‰¾å‡ºé«˜ç›¸é—œæ€§ä½†ä½¿ç”¨ç‡ä½çš„ç‰¹å¾µ
        for correlation in correlations:
            if correlation.significance == 'high':
                insights.append(PerformanceInsight(
                    insight_id='opportunity_1',
                    insight_type='opportunity',
                    title='é«˜æˆæ•ˆç‰¹å¾µæ©Ÿæœƒ',
                    description=f'{correlation.feature_pair}èˆ‡é«˜æˆæ•ˆç›¸é—œï¼Œå»ºè­°å¢åŠ ä½¿ç”¨',
                    confidence=correlation.correlation_score / 100,
                    impact_score=0.7,
                    evidence=[f'{correlation.feature_pair}ç›¸é—œæ€§åˆ†æ•¸{correlation.correlation_score:.1f}'],
                    actionable_recommendations=[correlation.recommendation],
                    affected_kols=list(set(post.kol_nickname for post in top_posts))
                ))
        
        return insights
    
    def _analyze_risks(self, top_posts: List[TopPostAnalysis]) -> List[PerformanceInsight]:
        """åˆ†æé¢¨éšª"""
        insights = []
        
        # åˆ†æKOLä¾è³´é¢¨éšª
        kol_counts = {}
        for post in top_posts:
            kol_name = post.kol_nickname
            kol_counts[kol_name] = kol_counts.get(kol_name, 0) + 1
        
        # æ‰¾å‡ºéåº¦ä¾è³´çš„KOL
        total_posts = len(top_posts)
        for kol_name, count in kol_counts.items():
            if count / total_posts > 0.5:  # è¶…é50%
                insights.append(PerformanceInsight(
                    insight_id='risk_1',
                    insight_type='risk',
                    title='KOLä¾è³´é¢¨éšª',
                    description=f'{kol_name}ä½”é«˜æˆæ•ˆè²¼æ–‡{count/total_posts*100:.1f}%ï¼Œå­˜åœ¨éåº¦ä¾è³´é¢¨éšª',
                    confidence=0.8,
                    impact_score=0.6,
                    evidence=[f'{kol_name}è²¢ç»äº†{count}ç¯‡é«˜æˆæ•ˆè²¼æ–‡'],
                    actionable_recommendations=['åˆ†æ•£ç™¼æ–‡é¢¨éšª', 'åŸ¹é¤Šå…¶ä»–KOL'],
                    affected_kols=[kol_name]
                ))
        
        return insights
    
    async def generate_performance_report(self, posts: List[Dict]) -> PerformanceReport:
        """ç”Ÿæˆæˆæ•ˆåˆ†æå ±å‘Š"""
        # åˆ†æå‰10%é«˜æˆæ•ˆè²¼æ–‡
        top_posts = await self.analyze_top_performers(posts)
        
        # åˆ†æç‰¹å¾µç›¸é—œæ€§
        correlations = await self.analyze_feature_correlations(top_posts)
        
        # ç”Ÿæˆæ´å¯Ÿ
        insights = await self.generate_performance_insights(top_posts, correlations)
        
        # è¨ˆç®—æ•´é«”æˆæ•ˆæŒ‡æ¨™
        performance_metrics = self._calculate_performance_metrics(posts, top_posts)
        
        # ç”Ÿæˆç¸½çµ
        summary = self._generate_summary(top_posts, correlations, insights)
        
        return PerformanceReport(
            analysis_period=f"æœ€è¿‘{len(posts)}ç¯‡è²¼æ–‡",
            total_posts_analyzed=len(posts),
            top10_percent_count=len(top_posts),
            overall_performance_score=statistics.mean([post.performance_score for post in top_posts]) if top_posts else 0,
            performance_metrics=performance_metrics,
            top_posts_analysis=top_posts,
            feature_correlations=correlations,
            insights=insights,
            summary=summary,
            timestamp=datetime.now().isoformat()
        )
    
    def _calculate_performance_metrics(self, all_posts: List[Dict], top_posts: List[TopPostAnalysis]) -> List[PerformanceMetric]:
        """è¨ˆç®—æˆæ•ˆæŒ‡æ¨™"""
        metrics = []
        
        if not all_posts:
            return metrics
        
        # å¹³å‡äº’å‹•æ•¸
        avg_interactions = statistics.mean([self._calculate_total_interactions(post) for post in all_posts])
        metrics.append(PerformanceMetric(
            metric_name='å¹³å‡äº’å‹•æ•¸',
            value=avg_interactions,
            unit='æ¬¡',
            trend='stable',
            change_percentage=0,
            significance='medium'
        ))
        
        # å¹³å‡äº’å‹•ç‡
        avg_engagement_rate = statistics.mean([post.get('engagement_rate', 0) for post in all_posts])
        metrics.append(PerformanceMetric(
            metric_name='å¹³å‡äº’å‹•ç‡',
            value=avg_engagement_rate,
            unit='%',
            trend='stable',
            change_percentage=0,
            significance='high'
        ))
        
        # é«˜æˆæ•ˆè²¼æ–‡æ¯”ä¾‹
        high_performance_ratio = len(top_posts) / len(all_posts) * 100
        metrics.append(PerformanceMetric(
            metric_name='é«˜æˆæ•ˆè²¼æ–‡æ¯”ä¾‹',
            value=high_performance_ratio,
            unit='%',
            trend='stable',
            change_percentage=0,
            significance='high'
        ))
        
        return metrics
    
    def _generate_summary(self, top_posts: List[TopPostAnalysis], correlations: List[FeatureCorrelation], insights: List[PerformanceInsight]) -> str:
        """ç”Ÿæˆç¸½çµ"""
        if not top_posts:
            return "æš«ç„¡é«˜æˆæ•ˆè²¼æ–‡æ•¸æ“š"
        
        summary_parts = []
        
        # åŸºæœ¬çµ±è¨ˆ
        summary_parts.append(f"åˆ†æäº†{len(top_posts)}ç¯‡é«˜æˆæ•ˆè²¼æ–‡")
        
        # æœ€ä½³KOL
        kol_counts = {}
        for post in top_posts:
            kol_counts[post.kol_nickname] = kol_counts.get(post.kol_nickname, 0) + 1
        
        best_kol = max(kol_counts.keys(), key=lambda k: kol_counts[k]) if kol_counts else None
        if best_kol:
            summary_parts.append(f"æœ€ä½³KOL: {best_kol}")
        
        # é—œéµç‰¹å¾µ
        if correlations:
            top_correlation = max(correlations, key=lambda c: c.correlation_score)
            summary_parts.append(f"é—œéµç‰¹å¾µ: {top_correlation.feature_pair}")
        
        # ä¸»è¦æ´å¯Ÿ
        if insights:
            high_impact_insights = [i for i in insights if i.impact_score > 0.7]
            if high_impact_insights:
                summary_parts.append(f"ä¸»è¦æ´å¯Ÿ: {high_impact_insights[0].title}")
        
        return "ï¼›".join(summary_parts)

# å…¨å±€æœå‹™å¯¦ä¾‹
performance_service = PerformanceAnalysisService()

# ==================== API ç«¯é» ====================

@router.get("/report")
async def get_performance_report(
    kol_serial: Optional[int] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    include_external: bool = True
):
    """ç²å–æˆæ•ˆåˆ†æå ±å‘Š"""
    try:
        # é€™è£¡æ‡‰è©²å¾å¯¦éš›æ•¸æ“šæºç²å–è²¼æ–‡æ•¸æ“š
        # æš«æ™‚ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
        mock_posts = [
            {
                'post_id': '1',
                'article_id': 'A001',
                'kol_nickname': 'é¾œç‹—ä¸€æ—¥æ•£æˆ¶',
                'title': 'æ¸¬è©¦æ¨™é¡Œ1',
                'content': 'æ¸¬è©¦å…§å®¹1',
                'create_time': '2024-12-19T10:00:00Z',
                'likes': 50,
                'comments': 20,
                'shares': 10,
                'bookmarks': 5,
                'engagement_rate': 8.5,
                'source': 'system',
                'commodity_tags': [{'key': '2330', 'type': 'stock', 'bullOrBear': '0'}]
            },
            {
                'post_id': '2',
                'article_id': 'A002',
                'kol_nickname': 'æ¿æ©‹å¤§who',
                'title': 'æ¸¬è©¦æ¨™é¡Œ2',
                'content': 'æ¸¬è©¦å…§å®¹2',
                'create_time': '2024-12-19T14:00:00Z',
                'likes': 80,
                'comments': 30,
                'shares': 15,
                'bookmarks': 8,
                'engagement_rate': 12.3,
                'source': 'system',
                'commodity_tags': [{'key': '2317', 'type': 'stock', 'bullOrBear': '1'}]
            }
        ]
        
        report = await performance_service.generate_performance_report(mock_posts)
        
        return {
            "success": True,
            "data": report.dict()
        }
        
    except Exception as e:
        logger.error(f"ç²å–æˆæ•ˆåˆ†æå ±å‘Šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æˆæ•ˆåˆ†æå ±å‘Šå¤±æ•—: {str(e)}")

@router.get("/top-posts")
async def get_top_performers(
    limit: int = 10,
    kol_serial: Optional[int] = None
):
    """ç²å–é«˜æˆæ•ˆè²¼æ–‡åˆ—è¡¨"""
    try:
        # é€™è£¡æ‡‰è©²å¾å¯¦éš›æ•¸æ“šæºç²å–æ•¸æ“š
        mock_posts = [
            {
                'post_id': '1',
                'article_id': 'A001',
                'kol_nickname': 'é¾œç‹—ä¸€æ—¥æ•£æˆ¶',
                'title': 'æ¸¬è©¦æ¨™é¡Œ1',
                'content': 'æ¸¬è©¦å…§å®¹1',
                'create_time': '2024-12-19T10:00:00Z',
                'likes': 50,
                'comments': 20,
                'shares': 10,
                'bookmarks': 5,
                'engagement_rate': 8.5,
                'source': 'system',
                'commodity_tags': [{'key': '2330', 'type': 'stock', 'bullOrBear': '0'}]
            }
        ]
        
        top_posts = await performance_service.analyze_top_performers(mock_posts)
        
        return {
            "success": True,
            "data": [post.dict() for post in top_posts[:limit]]
        }
        
    except Exception as e:
        logger.error(f"ç²å–é«˜æˆæ•ˆè²¼æ–‡å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–é«˜æˆæ•ˆè²¼æ–‡å¤±æ•—: {str(e)}")

@router.get("/correlations")
async def get_feature_correlations():
    """ç²å–ç‰¹å¾µç›¸é—œæ€§åˆ†æ"""
    try:
        # é€™è£¡æ‡‰è©²å¾å¯¦éš›æ•¸æ“šæºç²å–æ•¸æ“š
        mock_posts = [
            {
                'post_id': '1',
                'article_id': 'A001',
                'kol_nickname': 'é¾œç‹—ä¸€æ—¥æ•£æˆ¶',
                'title': 'æ¸¬è©¦æ¨™é¡Œ1',
                'content': 'æ¸¬è©¦å…§å®¹1',
                'create_time': '2024-12-19T10:00:00Z',
                'likes': 50,
                'comments': 20,
                'shares': 10,
                'bookmarks': 5,
                'engagement_rate': 8.5,
                'source': 'system',
                'commodity_tags': [{'key': '2330', 'type': 'stock', 'bullOrBear': '0'}]
            }
        ]
        
        top_posts = await performance_service.analyze_top_performers(mock_posts)
        correlations = await performance_service.analyze_feature_correlations(top_posts)
        
        return {
            "success": True,
            "data": [correlation.dict() for correlation in correlations]
        }
        
    except Exception as e:
        logger.error(f"ç²å–ç‰¹å¾µç›¸é—œæ€§å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–ç‰¹å¾µç›¸é—œæ€§å¤±æ•—: {str(e)}")

@router.get("/insights")
async def get_performance_insights():
    """ç²å–æˆæ•ˆæ´å¯Ÿ"""
    try:
        # é€™è£¡æ‡‰è©²å¾å¯¦éš›æ•¸æ“šæºç²å–æ•¸æ“š
        mock_posts = [
            {
                'post_id': '1',
                'article_id': 'A001',
                'kol_nickname': 'é¾œç‹—ä¸€æ—¥æ•£æˆ¶',
                'title': 'æ¸¬è©¦æ¨™é¡Œ1',
                'content': 'æ¸¬è©¦å…§å®¹1',
                'create_time': '2024-12-19T10:00:00Z',
                'likes': 50,
                'comments': 20,
                'shares': 10,
                'bookmarks': 5,
                'engagement_rate': 8.5,
                'source': 'system',
                'commodity_tags': [{'key': '2330', 'type': 'stock', 'bullOrBear': '0'}]
            }
        ]
        
        top_posts = await performance_service.analyze_top_performers(mock_posts)
        correlations = await performance_service.analyze_feature_correlations(top_posts)
        insights = await performance_service.generate_performance_insights(top_posts, correlations)
        
        return {
            "success": True,
            "data": [insight.dict() for insight in insights]
        }
        
    except Exception as e:
        logger.error(f"ç²å–æˆæ•ˆæ´å¯Ÿå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æˆæ•ˆæ´å¯Ÿå¤±æ•—: {str(e)}")

@router.get("/metrics")
async def get_performance_metrics():
    """ç²å–æˆæ•ˆæŒ‡æ¨™"""
    try:
        # é€™è£¡æ‡‰è©²å¾å¯¦éš›æ•¸æ“šæºç²å–æ•¸æ“š
        mock_posts = [
            {
                'post_id': '1',
                'article_id': 'A001',
                'kol_nickname': 'é¾œç‹—ä¸€æ—¥æ•£æˆ¶',
                'title': 'æ¸¬è©¦æ¨™é¡Œ1',
                'content': 'æ¸¬è©¦å…§å®¹1',
                'create_time': '2024-12-19T10:00:00Z',
                'likes': 50,
                'comments': 20,
                'shares': 10,
                'bookmarks': 5,
                'engagement_rate': 8.5,
                'source': 'system',
                'commodity_tags': [{'key': '2330', 'type': 'stock', 'bullOrBear': '0'}]
            }
        ]
        
        top_posts = await performance_service.analyze_top_performers(mock_posts)
        metrics = performance_service._calculate_performance_metrics(mock_posts, top_posts)
        
        return {
            "success": True,
            "data": [metric.dict() for metric in metrics]
        }
        
    except Exception as e:
        logger.error(f"ç²å–æˆæ•ˆæŒ‡æ¨™å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æˆæ•ˆæŒ‡æ¨™å¤±æ•—: {str(e)}")





