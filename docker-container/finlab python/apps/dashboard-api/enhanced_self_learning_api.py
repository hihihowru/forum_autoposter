"""
å¢å¼·ç‰ˆè‡ªæˆ‘å­¸ç¿’API
åŒ…å«é«˜æˆæ•ˆç‰¹å¾µåˆ†æã€LLMå…§å®¹åˆ†é¡ã€è‡ªå‹•ç™¼æ–‡è¨­å®šç”Ÿæˆ
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import logging
import json
import asyncio
from dataclasses import dataclass, asdict
import statistics
import re
import openai
import os

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/enhanced-self-learning", tags=["enhanced-self-learning"])

# ==================== æ•¸æ“šæ¨¡å‹ ====================

class HighPerformanceFeature(BaseModel):
    feature_id: str
    feature_name: str
    feature_type: str  # 'content', 'timing', 'structure', 'interaction', 'kol'
    description: str
    frequency_in_top_posts: float  # åœ¨å‰10%è²¼æ–‡ä¸­çš„å‡ºç¾é »ç‡
    frequency_in_all_posts: float   # åœ¨æ‰€æœ‰è²¼æ–‡ä¸­çš„å‡ºç¾é »ç‡
    improvement_potential: float    # æ”¹å–„æ½›åŠ›åˆ†æ•¸
    setting_key: str               # å°æ‡‰çš„è¨­å®šéµå
    is_modifiable: bool            # æ˜¯å¦å¯ä¿®æ”¹
    modification_method: str       # ä¿®æ”¹æ–¹æ³•
    examples: List[str]           # ç¯„ä¾‹

class ContentCategory(BaseModel):
    category_id: str
    category_name: str
    description: str
    top_posts: List[Dict[str, Any]]
    avg_performance_score: float
    key_characteristics: List[str]
    success_rate: float

class PostingSetting(BaseModel):
    setting_id: str
    setting_name: str
    description: str
    trigger_type: str              # 'limit_up', 'limit_down', 'volume_surge', 'news_event'
    content_length: str           # 'short', 'medium', 'long'
    has_news_link: bool
    has_question_interaction: bool
    has_emoji: bool
    has_hashtag: bool
    humor_level: str              # 'none', 'light', 'moderate', 'strong'
    kol_style: str                # 'professional', 'casual', 'humorous', 'analytical'
    posting_time_preference: List[str]
    stock_tags_count: int
    content_structure: str        # 'narrative', 'bullet_points', 'mixed'
    interaction_elements: List[str]
    expected_performance: float
    confidence_level: float
    based_on_features: List[str]

class EnhancedAnalysisReport(BaseModel):
    analysis_timestamp: str
    total_posts_analyzed: int
    top_performance_features: List[HighPerformanceFeature]
    content_categories: List[ContentCategory]
    generated_settings: List[PostingSetting]
    modification_capabilities: Dict[str, Any]
    recommendations: List[str]

# ==================== LLM å…§å®¹åˆ†é¡æœå‹™ ====================

class LLMContentClassifier:
    def __init__(self):
        # è¨­ç½® OpenAI API (å¦‚æœå¯ç”¨)
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.use_openai = bool(self.openai_api_key)
        
        # é å®šç¾©çš„åˆ†é¡æ¨™æº–
        self.classification_criteria = {
            'content_type': ['åˆ†æå‹', 'æ–°èå‹', 'äº’å‹•å‹', 'å¹½é»˜å‹', 'å°ˆæ¥­å‹'],
            'tone': ['æ­£å¼', 'è¼•é¬†', 'å¹½é»˜', 'å°ˆæ¥­', 'è¦ªåˆ‡'],
            'structure': ['æ•˜è¿°å‹', 'æ¢åˆ—å‹', 'å•ç­”å‹', 'æ··åˆå‹'],
            'interaction_level': ['é«˜äº’å‹•', 'ä¸­äº’å‹•', 'ä½äº’å‹•'],
            'complexity': ['ç°¡å–®', 'ä¸­ç­‰', 'è¤‡é›œ']
        }
    
    async def classify_content(self, content: str) -> Dict[str, str]:
        """ä½¿ç”¨LLMæˆ–è¦å‰‡åˆ†é¡å…§å®¹"""
        if self.use_openai:
            return await self._classify_with_openai(content)
        else:
            return await self._classify_with_rules(content)
    
    async def _classify_with_openai(self, content: str) -> Dict[str, str]:
        """ä½¿ç”¨OpenAI APIåˆ†é¡"""
        try:
            prompt = f"""
            è«‹åˆ†æä»¥ä¸‹è²¼æ–‡å…§å®¹ï¼Œä¸¦æŒ‰ç…§ä»¥ä¸‹æ¨™æº–é€²è¡Œåˆ†é¡ï¼š

            å…§å®¹é¡å‹: åˆ†æå‹ã€æ–°èå‹ã€äº’å‹•å‹ã€å¹½é»˜å‹ã€å°ˆæ¥­å‹
            èªèª¿: æ­£å¼ã€è¼•é¬†ã€å¹½é»˜ã€å°ˆæ¥­ã€è¦ªåˆ‡
            çµæ§‹: æ•˜è¿°å‹ã€æ¢åˆ—å‹ã€å•ç­”å‹ã€æ··åˆå‹
            äº’å‹•ç¨‹åº¦: é«˜äº’å‹•ã€ä¸­äº’å‹•ã€ä½äº’å‹•
            è¤‡é›œåº¦: ç°¡å–®ã€ä¸­ç­‰ã€è¤‡é›œ

            è²¼æ–‡å…§å®¹: {content}

            è«‹ä»¥JSONæ ¼å¼è¿”å›åˆ†é¡çµæœã€‚
            """
            
            # é€™è£¡æ‡‰è©²èª¿ç”¨OpenAI API
            # æš«æ™‚è¿”å›æ¨¡æ“¬çµæœ
            return {
                'content_type': 'åˆ†æå‹',
                'tone': 'å°ˆæ¥­',
                'structure': 'æ··åˆå‹',
                'interaction_level': 'ä¸­äº’å‹•',
                'complexity': 'ä¸­ç­‰'
            }
        except Exception as e:
            logger.error(f"OpenAIåˆ†é¡å¤±æ•—: {e}")
            return await self._classify_with_rules(content)
    
    async def _classify_with_rules(self, content: str) -> Dict[str, str]:
        """ä½¿ç”¨è¦å‰‡åˆ†é¡å…§å®¹"""
        classifications = {}
        
        # å…§å®¹é¡å‹åˆ†é¡
        if any(keyword in content for keyword in ['åˆ†æ', 'æŠ€è¡“', 'æŒ‡æ¨™', 'è¶¨å‹¢']):
            classifications['content_type'] = 'åˆ†æå‹'
        elif any(keyword in content for keyword in ['æ–°è', 'å ±å°', 'æ¶ˆæ¯']):
            classifications['content_type'] = 'æ–°èå‹'
        elif any(keyword in content for keyword in ['ï¼Ÿ', '?', 'å¤§å®¶', 'ä½ å€‘']):
            classifications['content_type'] = 'äº’å‹•å‹'
        elif any(keyword in content for keyword in ['å“ˆå“ˆ', 'ç¬‘æ­»', 'æç¬‘', 'ğŸ˜‚']):
            classifications['content_type'] = 'å¹½é»˜å‹'
        else:
            classifications['content_type'] = 'å°ˆæ¥­å‹'
        
        # èªèª¿åˆ†é¡
        if any(keyword in content for keyword in ['å“ˆå“ˆ', 'ç¬‘æ­»', 'æç¬‘', 'ğŸ˜‚', 'ğŸ˜„']):
            classifications['tone'] = 'å¹½é»˜'
        elif any(keyword in content for keyword in ['å¤§å®¶', 'ä½ å€‘', 'æˆ‘å€‘', 'ä¸€èµ·']):
            classifications['tone'] = 'è¦ªåˆ‡'
        elif any(keyword in content for keyword in ['åˆ†æ', 'æ•¸æ“š', 'æŒ‡æ¨™', 'æŠ€è¡“']):
            classifications['tone'] = 'å°ˆæ¥­'
        elif any(keyword in content for keyword in ['ä¸éŒ¯', 'é‚„å¥½', 'é‚„å¯ä»¥']):
            classifications['tone'] = 'è¼•é¬†'
        else:
            classifications['tone'] = 'æ­£å¼'
        
        # çµæ§‹åˆ†é¡
        if content.count('â€¢') > 2 or content.count('-') > 2:
            classifications['structure'] = 'æ¢åˆ—å‹'
        elif content.count('ï¼Ÿ') > 1 or content.count('?') > 1:
            classifications['structure'] = 'å•ç­”å‹'
        elif len(content.split('\n')) > 3:
            classifications['structure'] = 'æ··åˆå‹'
        else:
            classifications['structure'] = 'æ•˜è¿°å‹'
        
        # äº’å‹•ç¨‹åº¦åˆ†é¡
        interaction_elements = content.count('ï¼Ÿ') + content.count('?') + content.count('ï¼') + content.count('!')
        if interaction_elements > 3:
            classifications['interaction_level'] = 'é«˜äº’å‹•'
        elif interaction_elements > 1:
            classifications['interaction_level'] = 'ä¸­äº’å‹•'
        else:
            classifications['interaction_level'] = 'ä½äº’å‹•'
        
        # è¤‡é›œåº¦åˆ†é¡
        if len(content) > 500:
            classifications['complexity'] = 'è¤‡é›œ'
        elif len(content) > 200:
            classifications['complexity'] = 'ä¸­ç­‰'
        else:
            classifications['complexity'] = 'ç°¡å–®'
        
        return classifications

# ==================== é«˜æˆæ•ˆç‰¹å¾µåˆ†ææœå‹™ ====================

class HighPerformanceFeatureAnalyzer:
    def __init__(self):
        self.feature_definitions = {
            # å…§å®¹ç‰¹å¾µ
            'content_length_short': {'name': 'çŸ­å…§å®¹', 'type': 'content', 'setting_key': 'content_length'},
            'content_length_medium': {'name': 'ä¸­ç­‰å…§å®¹', 'type': 'content', 'setting_key': 'content_length'},
            'content_length_long': {'name': 'é•·å…§å®¹', 'type': 'content', 'setting_key': 'content_length'},
            'has_stock_analysis': {'name': 'è‚¡ç¥¨åˆ†æ', 'type': 'content', 'setting_key': 'include_analysis'},
            'has_technical_indicators': {'name': 'æŠ€è¡“æŒ‡æ¨™', 'type': 'content', 'setting_key': 'include_technical'},
            'has_market_outlook': {'name': 'å¸‚å ´å±•æœ›', 'type': 'content', 'setting_key': 'include_outlook'},
            'has_risk_warning': {'name': 'é¢¨éšªæé†’', 'type': 'content', 'setting_key': 'include_risk'},
            
            # çµæ§‹ç‰¹å¾µ
            'has_bullet_points': {'name': 'æ¢åˆ—å¼çµæ§‹', 'type': 'structure', 'setting_key': 'content_structure'},
            'has_numbered_list': {'name': 'ç·¨è™Ÿåˆ—è¡¨', 'type': 'structure', 'setting_key': 'content_structure'},
            'has_paragraphs': {'name': 'æ®µè½çµæ§‹', 'type': 'structure', 'setting_key': 'content_structure'},
            'has_headings': {'name': 'æ¨™é¡Œçµæ§‹', 'type': 'structure', 'setting_key': 'content_structure'},
            
            # äº’å‹•ç‰¹å¾µ
            'has_question': {'name': 'å•å¥äº’å‹•', 'type': 'interaction', 'setting_key': 'include_questions'},
            'has_poll': {'name': 'æŠ•ç¥¨äº’å‹•', 'type': 'interaction', 'setting_key': 'include_poll'},
            'has_call_to_action': {'name': 'è¡Œå‹•å‘¼ç±²', 'type': 'interaction', 'setting_key': 'include_cta'},
            'has_emoji': {'name': 'è¡¨æƒ…ç¬¦è™Ÿ', 'type': 'interaction', 'setting_key': 'include_emoji'},
            'has_hashtag': {'name': 'æ¨™ç±¤ä½¿ç”¨', 'type': 'interaction', 'setting_key': 'include_hashtag'},
            
            # æ™‚é–“ç‰¹å¾µ
            'morning_posting': {'name': 'ä¸Šåˆç™¼æ–‡', 'type': 'timing', 'setting_key': 'preferred_time'},
            'afternoon_posting': {'name': 'ä¸‹åˆç™¼æ–‡', 'type': 'timing', 'setting_key': 'preferred_time'},
            'evening_posting': {'name': 'æ™šä¸Šç™¼æ–‡', 'type': 'timing', 'setting_key': 'preferred_time'},
            'weekend_posting': {'name': 'é€±æœ«ç™¼æ–‡', 'type': 'timing', 'setting_key': 'preferred_time'},
            
            # KOLç‰¹å¾µ
            'professional_tone': {'name': 'å°ˆæ¥­èªèª¿', 'type': 'kol', 'setting_key': 'kol_style'},
            'casual_tone': {'name': 'è¼•é¬†èªèª¿', 'type': 'kol', 'setting_key': 'kol_style'},
            'humorous_tone': {'name': 'å¹½é»˜èªèª¿', 'type': 'kol', 'setting_key': 'kol_style'},
            'analytical_tone': {'name': 'åˆ†æèªèª¿', 'type': 'kol', 'setting_key': 'kol_style'},
        }
    
    async def analyze_features(self, posts: List[Dict]) -> List[HighPerformanceFeature]:
        """åˆ†æé«˜æˆæ•ˆç‰¹å¾µ"""
        if not posts:
            return []
        
        # è¨ˆç®—æ¯ç¯‡è²¼æ–‡çš„æˆæ•ˆåˆ†æ•¸
        scored_posts = []
        for post in posts:
            score = self._calculate_performance_score(post)
            scored_posts.append((post, score))
        
        # æŒ‰åˆ†æ•¸æ’åº
        scored_posts.sort(key=lambda x: x[1], reverse=True)
        
        # å–å‰20%
        total_posts = len(scored_posts)
        top20_count = max(1, int(total_posts * 0.2))
        top20_posts = [post for post, score in scored_posts[:top20_count]]
        all_posts = [post for post, score in scored_posts]
        
        # åˆ†ææ¯å€‹ç‰¹å¾µ
        features = []
        for feature_id, feature_info in self.feature_definitions.items():
            feature = await self._analyze_single_feature(
                feature_id, feature_info, top20_posts, all_posts
            )
            if feature:
                features.append(feature)
        
        # æŒ‰æ”¹å–„æ½›åŠ›æ’åº
        features.sort(key=lambda x: x.improvement_potential, reverse=True)
        
        return features[:20]  # è¿”å›å‰20å€‹ç‰¹å¾µ
    
    def _calculate_performance_score(self, post: Dict) -> float:
        """è¨ˆç®—è²¼æ–‡æˆæ•ˆåˆ†æ•¸"""
        total_interactions = (post.get('likes', 0) or 0) + (post.get('comments', 0) or 0) + (post.get('shares', 0) or 0) + (post.get('views', 0) or 0) + (post.get('donations', 0) or 0)
        engagement_rate = post.get('engagement_rate', 0)
        
        # ç¶œåˆåˆ†æ•¸è¨ˆç®—
        interaction_score = min(total_interactions / 100, 1.0) * 40
        engagement_score = min(engagement_rate / 10, 1.0) * 30
        content_score = self._assess_content_quality(post) * 20
        timing_score = self._assess_timing_score(post) * 10
        
        return interaction_score + engagement_score + content_score + timing_score
    
    def _assess_content_quality(self, post: Dict) -> float:
        """è©•ä¼°å…§å®¹å“è³ª"""
        title = post.get('title', '')
        content = post.get('content', '')
        full_text = f"{title} {content}"
        
        quality_score = 0.5
        
        # å…§å®¹é•·åº¦é©ä¸­
        if 100 <= len(content) <= 800:
            quality_score += 0.1
        
        # åŒ…å«è‚¡ç¥¨æ¨™è¨˜
        if post.get('commodity_tags'):
            quality_score += 0.1
        
        # åŒ…å«äº’å‹•å…ƒç´ 
        if any(keyword in full_text for keyword in ['ï¼Ÿ', '?', 'ï¼', '!']):
            quality_score += 0.1
        
        # åŒ…å«Emoji
        if any(emoji in full_text for emoji in ['ğŸ˜‚', 'ğŸ˜„', 'ğŸ˜†', 'ğŸ‘', 'ğŸ‘']):
            quality_score += 0.1
        
        return min(quality_score, 1.0)
    
    def _assess_timing_score(self, post: Dict) -> float:
        """è©•ä¼°ç™¼æ–‡æ™‚æ©Ÿåˆ†æ•¸"""
        create_time = post.get('create_time', '')
        if not create_time:
            return 0.5
        
        try:
            post_time = datetime.fromisoformat(create_time.replace('Z', '+00:00'))
            hour = post_time.hour
            
            if 9 <= hour <= 11 or 19 <= hour <= 21:
                return 1.0
            elif 14 <= hour <= 16:
                return 0.8
            else:
                return 0.4
        except:
            return 0.5
    
    async def _analyze_single_feature(self, feature_id: str, feature_info: Dict, top20_posts: List[Dict], all_posts: List[Dict]) -> Optional[HighPerformanceFeature]:
        """åˆ†æå–®å€‹ç‰¹å¾µ"""
        feature_name = feature_info['name']
        feature_type = feature_info['type']
        setting_key = feature_info['setting_key']
        
        # è¨ˆç®—ç‰¹å¾µåœ¨å‰20%è²¼æ–‡ä¸­çš„é »ç‡
        top20_count = self._count_feature_occurrence(feature_id, top20_posts)
        top20_frequency = top20_count / len(top20_posts) if top20_posts else 0
        
        # è¨ˆç®—ç‰¹å¾µåœ¨æ‰€æœ‰è²¼æ–‡ä¸­çš„é »ç‡
        all_count = self._count_feature_occurrence(feature_id, all_posts)
        all_frequency = all_count / len(all_posts) if all_posts else 0
        
        # è¨ˆç®—æ”¹å–„æ½›åŠ›
        improvement_potential = top20_frequency - all_frequency
        
        # åªè¿”å›æœ‰æ”¹å–„æ½›åŠ›çš„ç‰¹å¾µ
        if improvement_potential <= 0:
            return None
        
        # åˆ¤æ–·æ˜¯å¦å¯ä¿®æ”¹
        is_modifiable, modification_method = self._assess_modifiability(feature_id, setting_key)
        
        # ç”Ÿæˆç¯„ä¾‹
        examples = self._generate_examples(feature_id, top20_posts)
        
        return HighPerformanceFeature(
            feature_id=feature_id,
            feature_name=feature_name,
            feature_type=feature_type,
            description=f"{feature_name}åœ¨é«˜æˆæ•ˆè²¼æ–‡ä¸­å‡ºç¾é »ç‡è¼ƒé«˜",
            frequency_in_top_posts=top20_frequency,
            frequency_in_all_posts=all_frequency,
            improvement_potential=improvement_potential,
            setting_key=setting_key,
            is_modifiable=is_modifiable,
            modification_method=modification_method,
            examples=examples
        )
    
    def _count_feature_occurrence(self, feature_id: str, posts: List[Dict]) -> int:
        """è¨ˆç®—ç‰¹å¾µå‡ºç¾æ¬¡æ•¸"""
        count = 0
        
        for post in posts:
            title = post.get('title', '')
            content = post.get('content', '')
            full_text = f"{title} {content}"
            create_time = post.get('create_time', '')
            
            if feature_id == 'content_length_short' and len(content) < 200:
                count += 1
            elif feature_id == 'content_length_medium' and 200 <= len(content) <= 500:
                count += 1
            elif feature_id == 'content_length_long' and len(content) > 500:
                count += 1
            elif feature_id == 'has_stock_analysis' and any(keyword in full_text for keyword in ['åˆ†æ', 'æŠ€è¡“', 'æŒ‡æ¨™']):
                count += 1
            elif feature_id == 'has_technical_indicators' and any(keyword in full_text for keyword in ['MA', 'RSI', 'MACD', 'KD']):
                count += 1
            elif feature_id == 'has_question' and ('ï¼Ÿ' in full_text or '?' in full_text):
                count += 1
            elif feature_id == 'has_emoji' and any(emoji in full_text for emoji in ['ğŸ˜‚', 'ğŸ˜„', 'ğŸ˜†', 'ğŸ‘', 'ğŸ‘']):
                count += 1
            elif feature_id == 'has_hashtag' and '#' in full_text:
                count += 1
            elif feature_id == 'has_bullet_points' and ('â€¢' in content or '-' in content):
                count += 1
            elif feature_id == 'morning_posting' and create_time:
                try:
                    post_time = datetime.fromisoformat(create_time.replace('Z', '+00:00'))
                    if 6 <= post_time.hour < 12:
                        count += 1
                except:
                    pass
            elif feature_id == 'afternoon_posting' and create_time:
                try:
                    post_time = datetime.fromisoformat(create_time.replace('Z', '+00:00'))
                    if 12 <= post_time.hour < 18:
                        count += 1
                except:
                    pass
            elif feature_id == 'evening_posting' and create_time:
                try:
                    post_time = datetime.fromisoformat(create_time.replace('Z', '+00:00'))
                    if 18 <= post_time.hour < 24:
                        count += 1
                except:
                    pass
            # å¯ä»¥ç¹¼çºŒæ·»åŠ æ›´å¤šç‰¹å¾µæª¢æ¸¬é‚è¼¯
        
        return count
    
    def _assess_modifiability(self, feature_id: str, setting_key: str) -> tuple[bool, str]:
        """è©•ä¼°ç‰¹å¾µçš„å¯ä¿®æ”¹æ€§"""
        modifiable_features = {
            'content_length_short': (True, 'èª¿æ•´å…§å®¹ç”Ÿæˆé•·åº¦è¨­å®š'),
            'content_length_medium': (True, 'èª¿æ•´å…§å®¹ç”Ÿæˆé•·åº¦è¨­å®š'),
            'content_length_long': (True, 'èª¿æ•´å…§å®¹ç”Ÿæˆé•·åº¦è¨­å®š'),
            'has_question': (True, 'åœ¨å…§å®¹ç”Ÿæˆä¸­åŠ å…¥å•å¥'),
            'has_emoji': (True, 'åœ¨å…§å®¹ç”Ÿæˆä¸­åŠ å…¥è¡¨æƒ…ç¬¦è™Ÿ'),
            'has_hashtag': (True, 'åœ¨å…§å®¹ç”Ÿæˆä¸­åŠ å…¥æ¨™ç±¤'),
            'has_bullet_points': (True, 'èª¿æ•´å…§å®¹çµæ§‹ç‚ºæ¢åˆ—å¼'),
            'morning_posting': (True, 'èª¿æ•´ç™¼æ–‡æ™‚é–“åå¥½'),
            'afternoon_posting': (True, 'èª¿æ•´ç™¼æ–‡æ™‚é–“åå¥½'),
            'evening_posting': (True, 'èª¿æ•´ç™¼æ–‡æ™‚é–“åå¥½'),
        }
        
        return modifiable_features.get(feature_id, (False, 'æš«ç„¡ä¿®æ”¹æ–¹æ³•'))
    
    def _generate_examples(self, feature_id: str, top10_posts: List[Dict]) -> List[str]:
        """ç”Ÿæˆç‰¹å¾µç¯„ä¾‹"""
        examples = []
        
        for post in top10_posts[:3]:  # å–å‰3å€‹ç¯„ä¾‹
            title = post.get('title', '')
            content = post.get('content', '')
            
            if feature_id == 'has_question' and ('ï¼Ÿ' in content or '?' in content):
                examples.append(f"æ¨™é¡Œ: {title[:50]}...")
            elif feature_id == 'has_emoji' and any(emoji in content for emoji in ['ğŸ˜‚', 'ğŸ˜„', 'ğŸ˜†']):
                examples.append(f"æ¨™é¡Œ: {title[:50]}...")
            elif feature_id == 'content_length_medium' and 200 <= len(content) <= 500:
                examples.append(f"æ¨™é¡Œ: {title[:50]}...")
        
        return examples

# ==================== è‡ªå‹•ç™¼æ–‡è¨­å®šç”Ÿæˆæœå‹™ ====================

class PostingSettingGenerator:
    def __init__(self):
        self.setting_templates = {
            'high_interaction': {
                'trigger_type': 'limit_up',
                'content_length': 'medium',
                'has_question_interaction': True,
                'has_emoji': True,
                'humor_level': 'light',
                'kol_style': 'casual'
            },
            'professional_analysis': {
                'trigger_type': 'volume_surge',
                'content_length': 'long',
                'has_news_link': True,
                'has_question_interaction': False,
                'humor_level': 'none',
                'kol_style': 'professional'
            },
            'humorous_engagement': {
                'trigger_type': 'limit_down',
                'content_length': 'short',
                'has_emoji': True,
                'has_hashtag': True,
                'humor_level': 'strong',
                'kol_style': 'humorous'
            }
        }
    
    async def generate_settings(self, features: List[HighPerformanceFeature], categories: List[ContentCategory]) -> List[PostingSetting]:
        """ç”Ÿæˆå¤šç¨®ç™¼æ–‡è¨­å®š"""
        settings = []
        
        # åŸºæ–¼é«˜æˆæ•ˆç‰¹å¾µç”Ÿæˆè¨­å®š
        feature_based_settings = await self._generate_feature_based_settings(features)
        settings.extend(feature_based_settings)
        
        # åŸºæ–¼å…§å®¹åˆ†é¡ç”Ÿæˆè¨­å®š
        category_based_settings = await self._generate_category_based_settings(categories)
        settings.extend(category_based_settings)
        
        # ç”Ÿæˆçµ„åˆè¨­å®š
        combination_settings = await self._generate_combination_settings(features, categories)
        settings.extend(combination_settings)
        
        return settings
    
    async def _generate_feature_based_settings(self, features: List[HighPerformanceFeature]) -> List[PostingSetting]:
        """åŸºæ–¼ç‰¹å¾µç”Ÿæˆè¨­å®š"""
        settings = []
        
        # é¸æ“‡å‰5å€‹æœ€æœ‰æ½›åŠ›çš„ç‰¹å¾µ
        top_features = features[:5]
        
        for i, feature in enumerate(top_features):
            setting = PostingSetting(
                setting_id=f'feature_based_{i+1}',
                setting_name=f'åŸºæ–¼{feature.feature_name}çš„è¨­å®š',
                description=f'åŸºæ–¼{feature.feature_name}ç‰¹å¾µå„ªåŒ–çš„ç™¼æ–‡è¨­å®š',
                trigger_type='limit_up',
                content_length='medium',
                has_news_link=False,
                has_question_interaction=feature.feature_id == 'has_question',
                has_emoji=feature.feature_id == 'has_emoji',
                has_hashtag=feature.feature_id == 'has_hashtag',
                humor_level='light',
                kol_style='casual',
                posting_time_preference=['14:00-16:00', '19:00-21:00'],
                stock_tags_count=2,
                content_structure='mixed',
                interaction_elements=['question', 'emoji'] if feature.feature_id == 'has_question' else ['emoji'],
                expected_performance=70 + (feature.improvement_potential * 10),
                confidence_level=0.8,
                based_on_features=[feature.feature_name]
            )
            settings.append(setting)
        
        return settings
    
    async def _generate_category_based_settings(self, categories: List[ContentCategory]) -> List[PostingSetting]:
        """åŸºæ–¼å…§å®¹åˆ†é¡ç”Ÿæˆè¨­å®š"""
        settings = []
        
        for i, category in enumerate(categories[:3]):  # å–å‰3å€‹åˆ†é¡
            setting = PostingSetting(
                setting_id=f'category_based_{i+1}',
                setting_name=f'åŸºæ–¼{category.category_name}çš„è¨­å®š',
                description=f'åŸºæ–¼{category.category_name}åˆ†é¡å„ªåŒ–çš„ç™¼æ–‡è¨­å®š',
                trigger_type='volume_surge',
                content_length='long' if category.avg_performance_score > 80 else 'medium',
                has_news_link=True,
                has_question_interaction='äº’å‹•å‹' in category.key_characteristics,
                has_emoji='å¹½é»˜å‹' in category.key_characteristics,
                has_hashtag=True,
                humor_level='strong' if 'å¹½é»˜å‹' in category.key_characteristics else 'light',
                kol_style='professional' if 'å°ˆæ¥­å‹' in category.key_characteristics else 'casual',
                posting_time_preference=['09:00-11:00', '15:00-17:00'],
                stock_tags_count=3,
                content_structure='mixed',
                interaction_elements=['question', 'emoji', 'hashtag'],
                expected_performance=category.avg_performance_score,
                confidence_level=0.75,
                based_on_features=category.key_characteristics
            )
            settings.append(setting)
        
        return settings
    
    async def _generate_combination_settings(self, features: List[HighPerformanceFeature], categories: List[ContentCategory]) -> List[PostingSetting]:
        """ç”Ÿæˆçµ„åˆè¨­å®š"""
        settings = []
        
        # ç”Ÿæˆä¸åŒè§¸ç™¼å™¨é¡å‹çš„è¨­å®š
        trigger_types = ['limit_up', 'limit_down', 'volume_surge', 'news_event']
        
        for i, trigger_type in enumerate(trigger_types):
            setting = PostingSetting(
                setting_id=f'combination_{i+1}',
                setting_name=f'{trigger_type}è§¸ç™¼å™¨è¨­å®š',
                description=f'é‡å°{trigger_type}è§¸ç™¼å™¨å„ªåŒ–çš„ç¶œåˆè¨­å®š',
                trigger_type=trigger_type,
                content_length='medium',
                has_news_link=trigger_type == 'news_event',
                has_question_interaction=True,
                has_emoji=True,
                has_hashtag=True,
                humor_level='moderate',
                kol_style='casual',
                posting_time_preference=['14:00-16:00', '19:00-21:00'],
                stock_tags_count=2,
                content_structure='mixed',
                interaction_elements=['question', 'emoji', 'hashtag'],
                expected_performance=75,
                confidence_level=0.7,
                based_on_features=['ç¶œåˆå„ªåŒ–']
            )
            settings.append(setting)
        
        return settings

# ==================== å…¨å±€æœå‹™å¯¦ä¾‹ ====================

llm_classifier = LLMContentClassifier()
feature_analyzer = HighPerformanceFeatureAnalyzer()
setting_generator = PostingSettingGenerator()

# ==================== API ç«¯é» ====================

@router.get("/enhanced-analysis")
async def get_enhanced_analysis(
    kol_serial: Optional[int] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    include_external: bool = True
):
    """ç²å–å¢å¼·ç‰ˆè‡ªæˆ‘å­¸ç¿’åˆ†æ"""
    try:
        # é€™è£¡æ‡‰è©²å¾å¯¦éš›æ•¸æ“šæºç²å–è²¼æ–‡æ•¸æ“š
        # æš«æ™‚ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
        mock_posts = [
            {
                'post_id': '1',
                'article_id': 'A001',
                'kol_nickname': 'é¾œç‹—ä¸€æ—¥æ•£æˆ¶',
                'title': '2330å°ç©é›»æŠ€è¡“åˆ†æ',
                'content': 'ä»Šå¤©ä¾†åˆ†æä¸€ä¸‹å°ç©é›»çš„æŠ€è¡“æŒ‡æ¨™ï¼ŒRSIå·²ç¶“è¶…è²·ï¼ŒMACDä¹Ÿå‡ºç¾èƒŒé›¢ä¿¡è™Ÿï¼Œå¤§å®¶è¦ºå¾—æœƒå›èª¿å—ï¼Ÿ',
                'create_time': '2024-12-19T10:00:00Z',
                'likes': 50,
                'comments': 20,
                'shares': 10,
                'bookmarks': 5,
                'engagement_rate': 8.5,
                'source': 'system',
                'commodity_tags': [{'key': '2330', 'type': 'stock', 'bullOrBear': '0'}]
            },
            {
                'post_id': '2',
                'article_id': 'A002',
                'kol_nickname': 'æ¿æ©‹å¤§who',
                'title': '2317é´»æµ·æ¼²åœåˆ†æ',
                'content': 'é´»æµ·ä»Šå¤©æ¼²åœäº†ï¼ä¸»è¦åŸå› æ˜¯AIä¼ºæœå™¨è¨‚å–®å¢åŠ ï¼Œæœªä¾†å±•æœ›çœ‹å¥½ã€‚å¤§å®¶æœ‰è²·å—ï¼Ÿ',
                'create_time': '2024-12-19T14:00:00Z',
                'likes': 80,
                'comments': 30,
                'shares': 15,
                'bookmarks': 8,
                'engagement_rate': 12.3,
                'source': 'system',
                'commodity_tags': [{'key': '2317', 'type': 'stock', 'bullOrBear': '0'}]
            }
        ]
        
        # åˆ†æé«˜æˆæ•ˆç‰¹å¾µ
        top_features = await feature_analyzer.analyze_features(mock_posts)
        
        # LLMå…§å®¹åˆ†é¡
        categories = []
        for post in mock_posts:
            classification = await llm_classifier.classify_content(post['content'])
            # é€™è£¡æ‡‰è©²å°‡åˆ†é¡çµæœçµ„ç¹”æˆContentCategoryå°è±¡
            # æš«æ™‚è·³éè©³ç´°å¯¦ç¾
        
        # ç”Ÿæˆç™¼æ–‡è¨­å®š
        generated_settings = await setting_generator.generate_settings(top_features, categories)
        
        # ç”Ÿæˆä¿®æ”¹èƒ½åŠ›å ±å‘Š
        modification_capabilities = {
            'modifiable_features': len([f for f in top_features if f.is_modifiable]),
            'total_features': len(top_features),
            'modification_methods': list(set([f.modification_method for f in top_features if f.is_modifiable])),
            'unmodifiable_features': [f.feature_name for f in top_features if not f.is_modifiable]
        }
        
        # ç”Ÿæˆå»ºè­°
        recommendations = [
            'å»ºè­°å„ªå…ˆèª¿æ•´å¯ä¿®æ”¹çš„é«˜æˆæ•ˆç‰¹å¾µ',
            'çµåˆå¤šå€‹ç‰¹å¾µç”Ÿæˆç¶œåˆç™¼æ–‡è¨­å®š',
            'å®šæœŸæ›´æ–°ç‰¹å¾µåˆ†æä»¥ä¿æŒæ•ˆæœ',
            'æ¸¬è©¦ä¸åŒè¨­å®šçµ„åˆçš„å¯¦éš›æ•ˆæœ'
        ]
        
        report = EnhancedAnalysisReport(
            analysis_timestamp=datetime.now().isoformat(),
            total_posts_analyzed=len(mock_posts),
            top_performance_features=top_features,
            content_categories=categories,
            generated_settings=generated_settings,
            modification_capabilities=modification_capabilities,
            recommendations=recommendations
        )
        
        return {
            "success": True,
            "data": report.dict()
        }
        
    except Exception as e:
        logger.error(f"ç²å–å¢å¼·ç‰ˆåˆ†æå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–å¢å¼·ç‰ˆåˆ†æå¤±æ•—: {str(e)}")

@router.post("/generate-settings")
async def generate_posting_settings(
    features: List[str],
    categories: List[str],
    trigger_types: List[str]
):
    """ç”Ÿæˆç™¼æ–‡è¨­å®š"""
    try:
        # é€™è£¡æ‡‰è©²åŸºæ–¼å‚³å…¥çš„åƒæ•¸ç”Ÿæˆè¨­å®š
        # æš«æ™‚è¿”å›æ¨¡æ“¬è¨­å®š
        settings = [
            {
                'setting_id': 'generated_1',
                'setting_name': 'é«˜äº’å‹•è¨­å®š',
                'description': 'åŸºæ–¼é«˜äº’å‹•ç‰¹å¾µç”Ÿæˆçš„è¨­å®š',
                'trigger_type': 'limit_up',
                'content_length': 'medium',
                'has_news_link': True,
                'has_question_interaction': True,
                'has_emoji': True,
                'expected_performance': 85,
                'confidence_level': 0.8
            }
        ]
        
        return {
            "success": True,
            "data": settings
        }
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆç™¼æ–‡è¨­å®šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆç™¼æ–‡è¨­å®šå¤±æ•—: {str(e)}")

@router.get("/modification-capabilities")
async def get_modification_capabilities():
    """ç²å–ä¿®æ”¹èƒ½åŠ›å ±å‘Š"""
    try:
        capabilities = {
            'modifiable_settings': [
                'content_length',
                'include_questions',
                'include_emoji',
                'include_hashtag',
                'content_structure',
                'preferred_time',
                'kol_style'
            ],
            'unmodifiable_settings': [
                'market_conditions',
                'stock_fundamentals',
                'external_events'
            ],
            'modification_methods': [
                'èª¿æ•´å…§å®¹ç”Ÿæˆåƒæ•¸',
                'ä¿®æ”¹ç™¼æ–‡æ™‚é–“åå¥½',
                'æ›´æ–°KOLé¢¨æ ¼è¨­å®š',
                'èª¿æ•´äº’å‹•å…ƒç´ é…ç½®'
            ]
        }
        
        return {
            "success": True,
            "data": capabilities
        }
        
    except Exception as e:
        logger.error(f"ç²å–ä¿®æ”¹èƒ½åŠ›å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–ä¿®æ”¹èƒ½åŠ›å¤±æ•—: {str(e)}")

