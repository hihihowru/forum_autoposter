# -*- coding: utf-8 -*-
"""
CMoney Article Fetcher
å¾ž CMoney è³‡æ–™åº«æŠ“å–æ–‡ç« è³‡æ–™
"""

import pandas as pd
import random
import requests
import json
from datetime import datetime, timedelta
from typing import List, Tuple
import logging

logger = logging.getLogger(__name__)

# CMoney API Cookie (from your provided code)
CMONEY_COOKIE = 'PLAY_SESSION=eyJhbGciOiJIUzI1NiJ9.eyJkYXRhIjp7InVzZXJuYW1lIjoiZm9ydW10ZWFtIn0sIm5iZiI6MTc2MjgzOTI1OCwiaWF0IjoxNzYyODM5MjU4fQ.2KV6UwSaNLjvdYjLCppy1BJ84hgpMKb1qhLJ_2tpmKg'


def query_cmoney_db(sql_query: str) -> Tuple[int, pd.DataFrame]:
    """
    æŸ¥è©¢ CMoney è³‡æ–™åº«

    Args:
        sql_query: SQL æŸ¥è©¢èªžå¥

    Returns:
        (status_code, dataframe)
    """
    job_id = random.randrange(10000000, 99999999, 1)
    logger.info(f"ðŸ” [CMoney Query] jobid: {job_id}")

    url = 'https://anya.cmoney.tw/api/queryResult'

    headers = {
        'Cookie': CMONEY_COOKIE,
        'Content-Type': 'application/json; charset=UTF-8',
        'Accept': '*/*',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
        'Connection': 'keep-alive'
    }

    body = {
        'jobId': job_id,
        'limit': 99999999,
        'sql': sql_query,
        'txDate': '2023-03-28 00:00:00'
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(body), timeout=30)
        status_code = response.status_code

        logger.info(f"âœ… [CMoney Query] status_code: {status_code}")

        if status_code == 200:
            json_data = response.content.decode('utf-8')
            df_dict = json.loads(json_data)
            df = pd.DataFrame(df_dict['data'], columns=df_dict['columns'])
            logger.info(f"âœ… [CMoney Query] Retrieved {len(df)} rows")
            return status_code, df
        else:
            logger.error(f"âŒ [CMoney Query] Failed with status {status_code}")
            return status_code, pd.DataFrame()

    except Exception as e:
        logger.error(f"âŒ [CMoney Query] Error: {e}")
        return 500, pd.DataFrame()


def fetch_past_hour_articles(hours: int = 1, article_type: str = 'normal') -> List[int]:
    """
    å¾ž Kafka äº‹ä»¶æµæŠ“å–éŽåŽ» N å°æ™‚çš„æ–°æ–‡ç«  IDï¼ˆå³æ™‚è³‡æ–™ï¼‰

    Args:
        hours: å›žæŽ¨å°æ™‚æ•¸ï¼ˆé è¨­ 1ï¼‰
        article_type: æ–‡ç« é¡žåž‹ï¼ˆé è¨­ 'normal'ï¼‰

    Returns:
        List of article IDs (int)
    """
    # è¨ˆç®—æ™‚é–“ç¯„åœ
    now = datetime.now()
    start_time = now - timedelta(hours=hours)

    # æ ¼å¼åŒ–æ™‚é–“ï¼ˆç²¾ç¢ºåˆ°å°æ™‚ï¼‰
    start_datetime = start_time.strftime('%Y-%m-%d %H:00')
    end_datetime = now.strftime('%Y-%m-%d %H:00')

    # æ§‹å»º SQL æŸ¥è©¢ï¼ˆåŸºæ–¼ Kafka äº‹ä»¶æµï¼‰
    query = f"""
    with create_post as (
        select
            date_format(timestamp_millis(CAST(CreateTime AS BIGINT)),'yyyy-MM-dd') as ddate,
            date_format(timestamp_millis(CAST(CreateTime AS BIGINT)),'yyyy-MM-dd HH:mm:ss.SSS') as create_time,
            ArticleId as articleid,
            case
                when Content.askPoint > 0 then 'question'
                when Content.groupId > 0 then 'group'
                when Content.newsId > 0 then 'news'
                when Content.botId > 0 then 'bot'
                when Content.creatorId = 4426063 then 'report'
                else Content.articleType
            end as articletype,
            coalesce(Content.creatorId, User.Subject.memberId) as memberid,
            coalesce(Content.appId, User.Subject.appId, get_json_object(User.Application, '$.appId')) as appid
        from ext_create_article_message
        where Content.articleType = '{article_type}'
            and kafka_event_date between to_date('{start_datetime}') and to_date('{end_datetime}')
            and (date_format(timestamp_millis(CAST(CreateTime AS BIGINT)),'yyyy-MM-dd HH:00') >= '{start_datetime}'
                 and date_format(timestamp_millis(CAST(CreateTime AS BIGINT)),'yyyy-MM-dd HH:00') < '{end_datetime}')
    )

    select DISTINCT create_action.articleid, create_action.create_time
    from create_post as create_action
    left join (
        select
            ArticleId as articleid,
            OriginalValue.content.creatorId as memberid,
            to_date(kafka_event_date) as delete_date
        from ext_delete_article_message_struct
        where kafka_event_date between to_date('{start_datetime}') and to_date('{end_datetime}')
    ) as delete_action
        on create_action.articleid = delete_action.articleid
        and create_action.memberid = delete_action.memberid
    where delete_action.delete_date is null
    order by create_action.create_time DESC
    """

    logger.info(f"ðŸ” [Fetch Articles] Querying Kafka events from {start_datetime} to {end_datetime} (past {hours} hours)")

    status_code, df = query_cmoney_db(query)

    if status_code == 200 and not df.empty:
        # è½‰æ›ç‚ºæ•´æ•¸åˆ—è¡¨
        article_ids = df['articleid'].astype(int).tolist()
        logger.info(f"âœ… [Fetch Articles] Found {len(article_ids)} new articles from Kafka stream")
        return article_ids
    else:
        logger.warning(f"âš ï¸  [Fetch Articles] No articles found or query failed")
        return []


def test_query():
    """æ¸¬è©¦æŸ¥è©¢åŠŸèƒ½"""
    try:
        # å…ˆæª¢æŸ¥è³‡æ–™è¡¨çµæ§‹ï¼ˆå‰ 5 ç­†çš„æ‰€æœ‰æ¬„ä½ï¼‰
        query_structure = """
        SELECT *
        FROM trans_post_latest_all
        LIMIT 5
        """
        status_code, structure_data = query_cmoney_db(query_structure)
        print(f"=== Table Structure (first 5 rows, all columns) ===")
        print(f"Columns: {structure_data.columns.tolist()}")
        print(structure_data.head())

        # æ¸¬è©¦æŸ¥è©¢ï¼ˆlimit 10 ç­†ï¼‰
        query = """
        SELECT articleid, createtime, title
        FROM trans_post_latest_all
        LIMIT 10
        """
        status_code, data = query_cmoney_db(query)
        print(f"\nStatus Code: {status_code}")
        print(f"Data:\n{data}")

        # æŸ¥è©¢æœ€æ–°çš„æ–‡ç« æ™‚é–“
        query_latest = """
        SELECT articleid, createtime, title
        FROM trans_post_latest_all
        WHERE createtime IS NOT NULL
        ORDER BY createtime DESC
        LIMIT 20
        """
        status_code, latest_data = query_cmoney_db(query_latest)
        print(f"\n=== Latest 20 Articles (by createtime) ===")
        print(latest_data)

        # æª¢æŸ¥æœ€æ–°æ–‡ç« çš„æ™‚é–“æ˜¯å¦æ˜¯ä»Šå¤©
        if not latest_data.empty:
            latest_time = pd.to_datetime(latest_data.iloc[0]['createtime'])
            print(f"\næœ€æ–°æ–‡ç« æ™‚é–“ (createtime): {latest_time}")
            print(f"ç¾åœ¨æ™‚é–“: {datetime.now()}")
            time_diff = datetime.now() - latest_time
            print(f"æ™‚é–“å·®: {time_diff}")

        # æŸ¥è©¢æŒ‰ ddate æŽ’åºçš„æœ€æ–°æ–‡ç« 
        query_ddate = """
        SELECT articleid, createtime, ddate, title
        FROM trans_post_latest_all
        WHERE ddate IS NOT NULL
        ORDER BY ddate DESC
        LIMIT 10
        """
        status_code, ddate_data = query_cmoney_db(query_ddate)
        print(f"\n=== Latest 10 Articles (by ddate) ===")
        print(ddate_data)

        # æ¸¬è©¦éŽåŽ»ä¸€å°æ™‚æ–‡ç« ï¼ˆä½¿ç”¨æ–°çš„ Kafka è³‡æ–™æµï¼‰
        print(f"\n{'='*60}")
        print(f"Testing Kafka Stream (Real-time Data)")
        print(f"{'='*60}")

        article_ids = fetch_past_hour_articles(hours=1)
        print(f"\nâœ… Past 1 hour articles (Kafka): {article_ids[:10] if len(article_ids) > 10 else article_ids}")
        print(f"Total count: {len(article_ids)}")

        # æ¸¬è©¦éŽåŽ» 3 å°æ™‚æ–‡ç« 
        article_ids_3h = fetch_past_hour_articles(hours=3)
        print(f"\nâœ… Past 3 hours articles (Kafka): {article_ids_3h[:10] if len(article_ids_3h) > 10 else article_ids_3h}")
        print(f"Total count: {len(article_ids_3h)}")

        # æ¸¬è©¦éŽåŽ» 24 å°æ™‚
        now = datetime.now()
        one_day_ago = now - timedelta(hours=24)
        time_filter = one_day_ago.strftime('%Y-%m-%d %H:%M:%S')

        query_24h = f"""
        SELECT COUNT(DISTINCT articleid) as count
        FROM trans_post_latest_all
        WHERE createtime >= '{time_filter}'
        AND articleid IS NOT NULL
        """
        status_code, count_data = query_cmoney_db(query_24h)
        print(f"\nPast 24 hours article count: {count_data}")

    except Exception as err_msg:
        print(f"Error: {str(err_msg)}")


if __name__ == "__main__":
    # è¨­å®š logging
    logging.basicConfig(level=logging.INFO)
    test_query()
