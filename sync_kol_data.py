"""
KOLæ•¸æ“šåŒæ­¥æœå‹™
å¾Google SheetsåŒæ­¥KOLæ•¸æ“šåˆ°PostgreSQLæ•¸æ“šåº«
"""

import os
import sys
import asyncio
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from src.clients.google.sheets_client import GoogleSheetsClient

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ•¸æ“šåº«é…ç½®
DATABASE_URL = os.getenv(
    "DATABASE_URL", 
    "postgresql://postgres:password@localhost:5432/posting_management"
)

class KOLDataSyncService:
    """KOLæ•¸æ“šåŒæ­¥æœå‹™"""
    
    def __init__(self):
        # åˆå§‹åŒ–Google Sheetså®¢æˆ¶ç«¯
        credentials_file = os.getenv('GOOGLE_CREDENTIALS_FILE', './credentials/google-service-account.json')
        spreadsheet_id = os.getenv('GOOGLE_SHEETS_ID', '148CUhBxqE-BZDPTKaAmOJG6m52CxB4KrxD9p5LikN2s')
        self.sheets_client = GoogleSheetsClient(credentials_file, spreadsheet_id)
        
        # åˆå§‹åŒ–æ•¸æ“šåº«é€£æ¥
        self.engine = create_engine(DATABASE_URL)
        self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
        
    def read_kol_data_from_sheets(self) -> List[Dict[str, Any]]:
        """å¾Google Sheetsè®€å–KOLæ•¸æ“š"""
        try:
            logger.info("å¾Google Sheetsè®€å–KOLæ•¸æ“š...")
            
            # è®€å–åŒå­¸æœƒå¸³è™Ÿç®¡ç†è¡¨
            data = self.sheets_client.read_sheet('åŒå­¸æœƒå¸³è™Ÿç®¡ç†')
            
            if not data or len(data) < 2:
                logger.warning("æ²’æœ‰æ‰¾åˆ°KOLé…ç½®æ•¸æ“š")
                return []
            
            headers = data[0]
            rows = data[1:]
            
            logger.info(f"æ‰¾åˆ° {len(rows)} å€‹KOLè¨˜éŒ„")
            logger.info(f"æ¬„ä½: {headers}")
            
            # å»ºç«‹æ¬„ä½ç´¢å¼•æ˜ å°„
            field_map = {}
            for i, header in enumerate(headers):
                if 'åºè™Ÿ' in header:
                    field_map['serial'] = i
                elif 'æš±ç¨±' in header:
                    field_map['nickname'] = i
                elif 'Email' in header or 'å¸³è™Ÿ' in header:
                    field_map['email'] = i
                elif 'å¯†ç¢¼' in header:
                    field_map['password'] = i
                elif 'MemberId' in header:
                    field_map['member_id'] = i
                elif 'äººè¨­' in header:
                    field_map['persona'] = i
                elif 'ç‹€æ…‹' in header and i < 20:
                    field_map['status'] = i
                elif 'Topicåå¥½é¡åˆ¥' in header:
                    field_map['topic_preferences'] = i
                elif 'ç¦è¬›é¡åˆ¥' in header:
                    field_map['forbidden_categories'] = i
                elif 'è³‡æ–™åå¥½' in header:
                    field_map['data_preferences'] = i
                elif 'å…§å®¹é¡å‹' in header:
                    field_map['content_types'] = i
                elif 'ç›®æ¨™å—çœ¾' in header:
                    field_map['target_audience'] = i
                elif 'èªæ°£é¢¨æ ¼' in header:
                    field_map['tone_style'] = i
                elif 'å¸¸ç”¨è©å½™' in header:
                    field_map['common_words'] = i
                elif 'å£èªåŒ–ç”¨è©' in header:
                    field_map['colloquial_words'] = i
                elif 'å¸¸ç”¨æ‰“å­—ç¿’æ…£' in header:
                    field_map['typing_habit'] = i
                elif 'å‰å°æ•…äº‹' in header:
                    field_map['background_story'] = i
                elif 'å°ˆé•·é ˜åŸŸ' in header:
                    field_map['expertise_areas'] = i
                elif 'PromptCTA' in header:
                    field_map['signature'] = i
                elif 'QuestionRatio' in header:
                    field_map['question_ratio'] = i
                elif 'ContentLength' in header:
                    field_map['content_length'] = i
                elif 'InteractionStarters' in header:
                    field_map['interaction_starters'] = i
                elif 'RequireFinlabAPI' in header:
                    field_map['require_finlab_api'] = i
                elif 'AllowHashtags' in header:
                    field_map['allow_hashtags'] = i
            
            logger.info(f"æ¬„ä½æ˜ å°„: {field_map}")
            
            # è§£æKOLè³‡æ–™
            kol_profiles = []
            for row_idx, row in enumerate(rows):
                if len(row) < 5:  # è·³éç©ºè¡Œ
                    continue
                    
                try:
                    # ç¢ºä¿è¡Œé•·åº¦èˆ‡æ¨™é¡Œä¸€è‡´
                    padded_row = row + [''] * (len(headers) - len(row))
                    
                    kol_data = {
                        'serial': int(padded_row[field_map.get('serial', 0)]) if field_map.get('serial') and padded_row[field_map['serial']] else None,
                        'nickname': padded_row[field_map.get('nickname', 1)] if field_map.get('nickname') else '',
                        'email': padded_row[field_map.get('email', 2)] if field_map.get('email') else '',
                        'password': padded_row[field_map.get('password', 3)] if field_map.get('password') else '',
                        'member_id': padded_row[field_map.get('member_id', 4)] if field_map.get('member_id') else '',
                        'persona': padded_row[field_map.get('persona', 5)] if field_map.get('persona') else '',
                        'status': padded_row[field_map.get('status', 6)] if field_map.get('status') else 'active',
                        'topic_preferences': self._parse_csv(padded_row[field_map.get('topic_preferences', 7)]) if field_map.get('topic_preferences') else [],
                        'forbidden_categories': self._parse_csv(padded_row[field_map.get('forbidden_categories', 8)]) if field_map.get('forbidden_categories') else [],
                        'data_preferences': self._parse_csv(padded_row[field_map.get('data_preferences', 9)]) if field_map.get('data_preferences') else [],
                        'content_types': self._parse_csv(padded_row[field_map.get('content_types', 10)]) if field_map.get('content_types') else [],
                        'target_audience': padded_row[field_map.get('target_audience', 11)] if field_map.get('target_audience') else '',
                        'tone_style': padded_row[field_map.get('tone_style', 12)] if field_map.get('tone_style') else '',
                        'common_words': self._parse_csv(padded_row[field_map.get('common_words', 13)]) if field_map.get('common_words') else [],
                        'colloquial_words': self._parse_csv(padded_row[field_map.get('colloquial_words', 14)]) if field_map.get('colloquial_words') else [],
                        'typing_habit': padded_row[field_map.get('typing_habit', 15)] if field_map.get('typing_habit') else '',
                        'background_story': padded_row[field_map.get('background_story', 16)] if field_map.get('background_story') else '',
                        'expertise_areas': self._parse_csv(padded_row[field_map.get('expertise_areas', 17)]) if field_map.get('expertise_areas') else [],
                        'signature': padded_row[field_map.get('signature', 18)] if field_map.get('signature') else '',
                        'question_ratio': float(padded_row[field_map.get('question_ratio', 19)]) if field_map.get('question_ratio') and padded_row[field_map['question_ratio']] else 0.5,
                        'content_length': padded_row[field_map.get('content_length', 20)] if field_map.get('content_length') else 'medium',
                        'interaction_starters': self._parse_csv(padded_row[field_map.get('interaction_starters', 21)]) if field_map.get('interaction_starters') else [],
                        'require_finlab_api': padded_row[field_map.get('require_finlab_api', 22)].strip().upper() == 'TRUE' if field_map.get('require_finlab_api') else False,
                        'allow_hashtags': padded_row[field_map.get('allow_hashtags', 23)].strip().upper() == 'TRUE' if field_map.get('allow_hashtags') else True,
                        'created_at': datetime.utcnow(),
                        'updated_at': datetime.utcnow()
                    }
                    
                    # åªè™•ç†æœ‰æ•ˆçš„KOLï¼ˆæœ‰åºè™Ÿå’Œæš±ç¨±ï¼‰
                    if kol_data['serial'] and kol_data['nickname']:
                        kol_profiles.append(kol_data)
                        logger.info(f"è§£æKOL: {kol_data['serial']} - {kol_data['nickname']}")
                    
                except Exception as e:
                    logger.error(f"è§£æç¬¬ {row_idx + 2} è¡ŒKOLæ•¸æ“šå¤±æ•—: {e}")
                    continue
            
            logger.info(f"æˆåŠŸè§£æ {len(kol_profiles)} å€‹KOLè³‡æ–™")
            return kol_profiles
            
        except Exception as e:
            logger.error(f"å¾Google Sheetsè®€å–KOLæ•¸æ“šå¤±æ•—: {e}")
            return []
    
    def _parse_csv(self, value: str) -> List[str]:
        """è§£æCSVæ ¼å¼çš„å­—ç¬¦ä¸²"""
        if not value:
            return []
        return [item.strip() for item in value.split(',') if item.strip()]
    
    def sync_kols_to_database(self, kol_profiles: List[Dict[str, Any]]) -> bool:
        """å°‡KOLæ•¸æ“šåŒæ­¥åˆ°æ•¸æ“šåº«"""
        try:
            logger.info("é–‹å§‹åŒæ­¥KOLæ•¸æ“šåˆ°æ•¸æ“šåº«...")
            
            with self.SessionLocal() as db:
                # æ¸…ç©ºç¾æœ‰KOLæ•¸æ“š
                db.execute(text("DELETE FROM kol_profiles"))
                logger.info("æ¸…ç©ºç¾æœ‰KOLæ•¸æ“š")
                
                # æ’å…¥æ–°çš„KOLæ•¸æ“š
                for kol_data in kol_profiles:
                    try:
                        # æ§‹å»ºæ’å…¥SQL
                        insert_sql = text("""
                            INSERT INTO kol_profiles (
                                serial, nickname, name, persona, style_preference,
                                expertise_areas, activity_level, question_ratio,
                                content_length, interaction_starters, is_active,
                                created_at, updated_at
                            ) VALUES (
                                :serial, :nickname, :name, :persona, :style_preference,
                                :expertise_areas, :activity_level, :question_ratio,
                                :content_length, :interaction_starters, :is_active,
                                :created_at, :updated_at
                            )
                        """)
                        
                        # æº–å‚™æ•¸æ“š
                        db_data = {
                            'serial': kol_data['serial'],
                            'nickname': kol_data['nickname'],
                            'name': kol_data.get('name', ''),
                            'persona': kol_data['persona'],
                            'style_preference': kol_data.get('tone_style', ''),
                            'expertise_areas': kol_data['expertise_areas'],
                            'activity_level': 'high' if kol_data['status'] == 'active' else 'low',
                            'question_ratio': kol_data['question_ratio'],
                            'content_length': kol_data['content_length'],
                            'interaction_starters': kol_data['interaction_starters'],
                            'is_active': kol_data['status'] == 'active',
                            'created_at': kol_data['created_at'],
                            'updated_at': kol_data['updated_at']
                        }
                        
                        db.execute(insert_sql, db_data)
                        logger.info(f"æ’å…¥KOL: {kol_data['serial']} - {kol_data['nickname']}")
                        
                    except Exception as e:
                        logger.error(f"æ’å…¥KOL {kol_data['serial']} å¤±æ•—: {e}")
                        continue
                
                db.commit()
                logger.info(f"æˆåŠŸåŒæ­¥ {len(kol_profiles)} å€‹KOLåˆ°æ•¸æ“šåº«")
                return True
                
        except Exception as e:
            logger.error(f"åŒæ­¥KOLæ•¸æ“šåˆ°æ•¸æ“šåº«å¤±æ•—: {e}")
            return False
    
    def run_sync(self) -> bool:
        """åŸ·è¡Œå®Œæ•´çš„åŒæ­¥æµç¨‹"""
        try:
            logger.info("ğŸš€ é–‹å§‹KOLæ•¸æ“šåŒæ­¥æµç¨‹...")
            
            # 1. å¾Google Sheetsè®€å–æ•¸æ“š
            kol_profiles = self.read_kol_data_from_sheets()
            if not kol_profiles:
                logger.error("æ²’æœ‰è®€å–åˆ°KOLæ•¸æ“š")
                return False
            
            # 2. åŒæ­¥åˆ°æ•¸æ“šåº«
            success = self.sync_kols_to_database(kol_profiles)
            if success:
                logger.info("âœ… KOLæ•¸æ“šåŒæ­¥å®Œæˆï¼")
                return True
            else:
                logger.error("âŒ KOLæ•¸æ“šåŒæ­¥å¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"KOLæ•¸æ“šåŒæ­¥æµç¨‹å¤±æ•—: {e}")
            return False

def main():
    """ä¸»å‡½æ•¸"""
    try:
        sync_service = KOLDataSyncService()
        success = sync_service.run_sync()
        
        if success:
            print("ğŸ‰ KOLæ•¸æ“šåŒæ­¥æˆåŠŸï¼")
            print("ğŸ“Š ç¾åœ¨å¯ä»¥å¾æ•¸æ“šåº«è®€å–KOLæ•¸æ“šäº†")
        else:
            print("âŒ KOLæ•¸æ“šåŒæ­¥å¤±æ•—")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ åŒæ­¥æœå‹™å•Ÿå‹•å¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
