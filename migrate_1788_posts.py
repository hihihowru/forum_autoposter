#!/usr/bin/env python3
"""
é·ç§» 1788 ç­† post_records å¾æœ¬åœ°åˆ° Railway
ç¢ºä¿æ‰€æœ‰æ¬„ä½å’Œæ•¸æ“šå®Œå…¨ä¸€è‡´
"""

import os
import sys
import logging
import psycopg2
from psycopg2.extras import RealDictCursor
import json
from datetime import datetime

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_local_db_connection():
    """ç²å–æœ¬åœ°æ•¸æ“šåº«é€£æ¥ (n8n-migration-project)"""
    try:
        # æœ¬åœ°æ•¸æ“šåº«é€£æ¥
        local_db_url = "postgresql://postgres:password@localhost:5432/posting_management"
        return psycopg2.connect(local_db_url)
    except Exception as e:
        logger.error(f"âŒ é€£æ¥æœ¬åœ°æ•¸æ“šåº«å¤±æ•—: {e}")
        raise

def get_railway_db_connection():
    """ç²å– Railway æ•¸æ“šåº«é€£æ¥"""
    try:
        # Railway æ•¸æ“šåº«é€£æ¥ - ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ–ç›´æ¥æŒ‡å®š
        railway_db_url = os.getenv("RAILWAY_DATABASE_URL", "postgresql://postgres:IIhZsyFLGLWQRcDrXGWsEQqPGPijfqJo@postgres.railway.internal:5432/railway")
        
        # å¦‚æœä½¿ç”¨å¤–éƒ¨é€£æ¥ï¼Œéœ€è¦æ›¿æ› internal ç‚º public
        if "railway.internal" in railway_db_url:
            # å˜—è©¦ä½¿ç”¨ Railway çš„å¤–éƒ¨é€£æ¥
            railway_db_url = railway_db_url.replace("postgres.railway.internal", "containers-us-west-1.railway.app")
            railway_db_url = railway_db_url.replace(":5432", ":5432")
        
        return psycopg2.connect(railway_db_url)
    except Exception as e:
        logger.error(f"âŒ é€£æ¥ Railway æ•¸æ“šåº«å¤±æ•—: {e}")
        logger.error("è«‹ç¢ºä¿ Railway æ•¸æ“šåº«å¯ä»¥å¾å¤–éƒ¨è¨ªå•")
        raise

def export_local_data(local_conn):
    """å¾æœ¬åœ°æ•¸æ“šåº«å°å‡ºæ‰€æœ‰ post_records"""
    try:
        with local_conn.cursor(cursor_factory=RealDictCursor) as cursor:
            # ç²å–æ‰€æœ‰ post_records
            cursor.execute("SELECT * FROM post_records ORDER BY created_at")
            records = cursor.fetchall()
            
            logger.info(f"ğŸ“Š å¾æœ¬åœ°æ•¸æ“šåº«å°å‡º {len(records)} ç­†è¨˜éŒ„")
            
            # è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            records_list = []
            for record in records:
                record_dict = dict(record)
                # è™•ç† datetime å°è±¡
                for key, value in record_dict.items():
                    if isinstance(value, datetime):
                        record_dict[key] = value.isoformat()
                    elif value is None:
                        record_dict[key] = None
                
                records_list.append(record_dict)
            
            return records_list
            
    except Exception as e:
        logger.error(f"âŒ å°å‡ºæœ¬åœ°æ•¸æ“šå¤±æ•—: {e}")
        raise

def import_to_railway(railway_conn, records):
    """å°å…¥æ•¸æ“šåˆ° Railway æ•¸æ“šåº«"""
    try:
        with railway_conn.cursor() as cursor:
            # æ¸…ç©ºç¾æœ‰æ•¸æ“šï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            cursor.execute("DELETE FROM post_records")
            logger.info("ğŸ—‘ï¸ æ¸…ç©º Railway æ•¸æ“šåº«ä¸­çš„ç¾æœ‰æ•¸æ“š")
            
            # æ‰¹é‡æ’å…¥æ•¸æ“š
            insert_sql = """
                INSERT INTO post_records (
                    post_id, created_at, updated_at, session_id, kol_serial, kol_nickname, 
                    kol_persona, stock_code, stock_name, title, content, content_md, 
                    status, reviewer_notes, approved_by, approved_at, scheduled_at, 
                    published_at, cmoney_post_id, cmoney_post_url, publish_error, 
                    views, likes, comments, shares, topic_id, topic_title, 
                    technical_analysis, serper_data, quality_score, ai_detection_score, 
                    risk_level, generation_params, commodity_tags, alternative_versions
                ) VALUES (
                    %(post_id)s, %(created_at)s, %(updated_at)s, %(session_id)s, 
                    %(kol_serial)s, %(kol_nickname)s, %(kol_persona)s, %(stock_code)s, 
                    %(stock_name)s, %(title)s, %(content)s, %(content_md)s, %(status)s, 
                    %(reviewer_notes)s, %(approved_by)s, %(approved_at)s, %(scheduled_at)s, 
                    %(published_at)s, %(cmoney_post_id)s, %(cmoney_post_url)s, 
                    %(publish_error)s, %(views)s, %(likes)s, %(comments)s, %(shares)s, 
                    %(topic_id)s, %(topic_title)s, %(technical_analysis)s, %(serper_data)s, 
                    %(quality_score)s, %(ai_detection_score)s, %(risk_level)s, 
                    %(generation_params)s, %(commodity_tags)s, %(alternative_versions)s
                )
            """
            
            # è½‰æ›è¨˜éŒ„æ ¼å¼
            records_dict = []
            for record in records:
                record_dict = dict(record)
                
                # è™•ç† datetime å­—ç¬¦ä¸²
                for datetime_field in ['created_at', 'updated_at', 'approved_at', 'scheduled_at', 'published_at']:
                    if record_dict.get(datetime_field):
                        if isinstance(record_dict[datetime_field], str):
                            try:
                                record_dict[datetime_field] = datetime.fromisoformat(record_dict[datetime_field].replace('Z', '+00:00'))
                            except:
                                record_dict[datetime_field] = None
                        elif not isinstance(record_dict[datetime_field], datetime):
                            record_dict[datetime_field] = None
                    else:
                        record_dict[datetime_field] = None
                
                # è™•ç† JSON å­—æ®µ - ç¢ºä¿æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                for json_field in ['technical_analysis', 'serper_data', 'generation_params', 'commodity_tags', 'alternative_versions']:
                    if record_dict.get(json_field):
                        if isinstance(record_dict[json_field], (dict, list)):
                            # å¦‚æœæ˜¯å­—å…¸æˆ–åˆ—è¡¨ï¼Œè½‰æ›ç‚º JSON å­—ç¬¦ä¸²
                            try:
                                record_dict[json_field] = json.dumps(record_dict[json_field], ensure_ascii=False)
                            except:
                                record_dict[json_field] = None
                        elif isinstance(record_dict[json_field], str):
                            # å¦‚æœå·²ç¶“æ˜¯å­—ç¬¦ä¸²ï¼Œä¿æŒä¸è®Š
                            pass
                        else:
                            record_dict[json_field] = None
                    else:
                        record_dict[json_field] = None
                
                records_dict.append(record_dict)
            
            # æ‰¹é‡æ’å…¥
            logger.info(f"ğŸ“¥ é–‹å§‹æ’å…¥ {len(records_dict)} ç­†è¨˜éŒ„åˆ° Railway...")
            cursor.executemany(insert_sql, records_dict)
            railway_conn.commit()
            
            logger.info(f"âœ… æˆåŠŸå°å…¥ {len(records_dict)} ç­†è¨˜éŒ„åˆ° Railway æ•¸æ“šåº«")
            
            # é©—è­‰å°å…¥çµæœ
            cursor.execute("SELECT COUNT(*) FROM post_records")
            count = cursor.fetchone()[0]
            logger.info(f"ğŸ“Š Railway æ•¸æ“šåº«ä¸­ç¾æœ‰ {count} ç­†è¨˜éŒ„")
            
            # é¡¯ç¤ºç‹€æ…‹çµ±è¨ˆ
            cursor.execute("SELECT status, COUNT(*) FROM post_records GROUP BY status")
            status_stats = cursor.fetchall()
            logger.info("ğŸ“Š ç‹€æ…‹çµ±è¨ˆ:")
            for status, count in status_stats:
                logger.info(f"  {status}: {count} ç­†")
            
            # é¡¯ç¤ºå‰å¹¾ç­†è¨˜éŒ„çš„æ‘˜è¦
            cursor.execute("SELECT post_id, title, status, created_at FROM post_records ORDER BY created_at DESC LIMIT 5")
            sample_records = cursor.fetchall()
            logger.info("ğŸ“‹ å‰ 5 ç­†è¨˜éŒ„æ‘˜è¦:")
            for record in sample_records:
                logger.info(f"  {record[0]}: {record[1][:50]}... ({record[2]}) - {record[3]}")
            
    except Exception as e:
        logger.error(f"âŒ å°å…¥æ•¸æ“šåˆ° Railway å¤±æ•—: {e}")
        railway_conn.rollback()
        raise

def main():
    """ä¸»å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹é·ç§» 1788 ç­† post_records æ•¸æ“š...")
    
    local_conn = None
    railway_conn = None
    
    try:
        # é€£æ¥æœ¬åœ°æ•¸æ“šåº«
        logger.info("ğŸ”— é€£æ¥æœ¬åœ°æ•¸æ“šåº« (n8n-migration-project)...")
        local_conn = get_local_db_connection()
        
        # é€£æ¥ Railway æ•¸æ“šåº«
        logger.info("ğŸ”— é€£æ¥ Railway æ•¸æ“šåº«...")
        railway_conn = get_railway_db_connection()
        
        # å°å‡ºæœ¬åœ°æ•¸æ“š
        logger.info("ğŸ“¤ å°å‡ºæœ¬åœ°æ•¸æ“š...")
        records = export_local_data(local_conn)
        
        if len(records) != 1788:
            logger.warning(f"âš ï¸ é æœŸ 1788 ç­†è¨˜éŒ„ï¼Œå¯¦éš›å°å‡º {len(records)} ç­†")
        
        # å°å…¥åˆ° Railway
        logger.info("ğŸ“¥ å°å…¥æ•¸æ“šåˆ° Railway...")
        import_to_railway(railway_conn, records)
        
        logger.info("ğŸ‰ æ•¸æ“šé·ç§»å®Œæˆï¼")
        logger.info("ğŸ” è«‹æ¸¬è©¦ Railway çš„ /posts ç«¯é»ç¢ºèªæ•¸æ“šå·²æ­£ç¢ºé·ç§»")
        
    except Exception as e:
        logger.error(f"âŒ æ•¸æ“šé·ç§»å¤±æ•—: {e}")
        sys.exit(1)
    finally:
        if local_conn:
            local_conn.close()
        if railway_conn:
            railway_conn.close()

if __name__ == "__main__":
    main()
