# éƒ¨ç½²ç›£æ§ç³»çµ±æŠ€è¡“æ–‡ä»¶

## ğŸ“‹ ç³»çµ±æ¦‚è¿°

éƒ¨ç½²ç›£æ§ç³»çµ±æ˜¯ n8n-migration-project çš„é‹ç¶­æ ¸å¿ƒï¼Œè² è²¬ç›£æ§æ•´å€‹ç³»çµ±çš„é‹è¡Œç‹€æ…‹ã€æœå‹™å¥åº·åº¦ã€è³‡æºä½¿ç”¨æƒ…æ³ï¼Œä»¥åŠä»»å‹™åŸ·è¡Œç‹€æ…‹ã€‚ç³»çµ±æä¾›å¯¦æ™‚ç›£æ§ã€å‘Šè­¦æ©Ÿåˆ¶ã€æ€§èƒ½åˆ†æå’Œæ•…éšœè¨ºæ–·åŠŸèƒ½ï¼Œç¢ºä¿ç³»çµ±ç©©å®šé‹è¡Œã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. **ç³»çµ±ç‹€æ…‹ç›£æ§**
- æ•´é«”ç³»çµ±å¥åº·åº¦ç›£æ§
- KOL å’Œè²¼æ–‡çµ±è¨ˆæ•¸æ“š
- ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
- æ•¸æ“šåº«é€£æ¥ç‹€æ…‹

### 2. **å¾®æœå‹™ç›£æ§**
- å„å¾®æœå‹™å¥åº·ç‹€æ…‹æª¢æŸ¥
- æœå‹™éŸ¿æ‡‰æ™‚é–“ç›£æ§
- æœå‹™å¯ç”¨æ€§çµ±è¨ˆ
- æœå‹™é–“ä¾è³´é—œä¿‚ç›£æ§

### 3. **ä»»å‹™åŸ·è¡Œç›£æ§**
- å®šæ™‚ä»»å‹™åŸ·è¡Œç‹€æ…‹
- ä»»å‹™æˆåŠŸç‡çµ±è¨ˆ
- ä»»å‹™åŸ·è¡Œæ™‚é–“åˆ†æ
- å¤±æ•—ä»»å‹™é‡è©¦æ©Ÿåˆ¶

### 4. **æ•¸æ“šæºç›£æ§**
- å¤–éƒ¨ API é€£æ¥ç‹€æ…‹
- æ•¸æ“šåŒæ­¥ç‹€æ…‹
- æ•¸æ“šå“è³ªç›£æ§
- æ•¸æ“šæºå¯ç”¨æ€§æª¢æŸ¥

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

### å‰ç«¯ç›£æ§çµ„ä»¶

```typescript
// SystemMonitoring.tsx - ç³»çµ±ç›£æ§çµ„ä»¶
interface SystemMonitoringProps {
  data: SystemMonitoringData | null;
  loading: boolean;
  error: string | null;
}

interface SystemMonitoringData {
  timestamp: string;
  system_overview: {
    total_kols: number;
    active_kols: number;
    total_posts: number;
    published_posts: number;
    success_rate: number;
  };
  microservices: {
    [key: string]: {
      status: string;
      uptime: string;
      response_time: string;
    };
  };
  task_execution: {
    hourly_tasks: { success: number; failed: number; total: number };
    daily_tasks: { success: number; failed: number; total: number };
    weekly_tasks: { success: number; failed: number; total: number };
  };
  data_sources: {
    google_sheets: string;
    cmoney_api: string;
    finlab_api: string;
  };
}
```

### å¾Œç«¯ç›£æ§ API

```python
# ç³»çµ±ç›£æ§ API
@app.get("/api/dashboard/system-monitoring")
async def get_system_monitoring_data():
    """ç²å–ç³»çµ±ç›£æ§å„€è¡¨æ¿æ•¸æ“š"""
    
# å¥åº·æª¢æŸ¥ API
@app.get("/health")
async def health_check():
    """æœå‹™å¥åº·æª¢æŸ¥"""
    
# å¾®æœå‹™ç‹€æ…‹ API
@app.get("/api/microservices/status")
async def get_microservices_status():
    """ç²å–å¾®æœå‹™ç‹€æ…‹"""
    
# ä»»å‹™åŸ·è¡Œçµ±è¨ˆ API
@app.get("/api/tasks/execution-stats")
async def get_task_execution_stats():
    """ç²å–ä»»å‹™åŸ·è¡Œçµ±è¨ˆ"""
```

## ğŸ“Š ç›£æ§æ•¸æ“šæ¨¡å‹

### ç³»çµ±æ¦‚è¦½æ•¸æ“š

```python
@dataclass
class SystemOverview:
    """ç³»çµ±æ¦‚è¦½æ•¸æ“š"""
    total_kols: int
    active_kols: int
    total_posts: int
    published_posts: int
    success_rate: float
    system_uptime: float
    memory_usage: float
    cpu_usage: float
    disk_usage: float
    network_io: Dict[str, float]
    timestamp: datetime
```

### å¾®æœå‹™ç‹€æ…‹æ•¸æ“š

```python
@dataclass
class MicroserviceStatus:
    """å¾®æœå‹™ç‹€æ…‹æ•¸æ“š"""
    service_name: str
    status: str  # healthy, warning, error, unknown
    uptime: float
    response_time: float
    memory_usage: float
    cpu_usage: float
    request_count: int
    error_count: int
    last_check: datetime
    dependencies: List[str]
    health_endpoint: str
```

### ä»»å‹™åŸ·è¡Œæ•¸æ“š

```python
@dataclass
class TaskExecutionStats:
    """ä»»å‹™åŸ·è¡Œçµ±è¨ˆæ•¸æ“š"""
    task_type: str  # hourly, daily, weekly
    total_tasks: int
    successful_tasks: int
    failed_tasks: int
    success_rate: float
    avg_execution_time: float
    last_execution: datetime
    next_execution: datetime
    error_details: List[str]
```

### æ•¸æ“šæºç‹€æ…‹æ•¸æ“š

```python
@dataclass
class DataSourceStatus:
    """æ•¸æ“šæºç‹€æ…‹æ•¸æ“š"""
    source_name: str
    status: str  # connected, disconnected, error
    last_sync: datetime
    sync_frequency: str
    data_quality: float
    error_count: int
    response_time: float
    api_quota_used: float
    api_quota_limit: float
```

## ğŸ”„ ç›£æ§æµç¨‹

### 1. **ç³»çµ±ç‹€æ…‹æ”¶é›†**

```python
async def collect_system_status() -> SystemOverview:
    """æ”¶é›†ç³»çµ±ç‹€æ…‹"""
    
    # ç²å– KOL æ•¸æ“š
    kol_service = get_kol_service()
    total_kols = kol_service.get_total_count()
    active_kols = kol_service.get_active_count()
    
    # ç²å–è²¼æ–‡æ•¸æ“š
    post_service = get_post_record_service()
    total_posts = post_service.get_total_count()
    published_posts = post_service.get_published_count()
    
    # è¨ˆç®—æˆåŠŸç‡
    success_rate = (published_posts / total_posts * 100) if total_posts > 0 else 0
    
    # ç²å–ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
    system_metrics = get_system_metrics()
    
    return SystemOverview(
        total_kols=total_kols,
        active_kols=active_kols,
        total_posts=total_posts,
        published_posts=published_posts,
        success_rate=success_rate,
        system_uptime=system_metrics['uptime'],
        memory_usage=system_metrics['memory_usage'],
        cpu_usage=system_metrics['cpu_usage'],
        disk_usage=system_metrics['disk_usage'],
        network_io=system_metrics['network_io'],
        timestamp=datetime.now()
    )
```

### 2. **å¾®æœå‹™å¥åº·æª¢æŸ¥**

```python
async def check_microservices_health() -> Dict[str, MicroserviceStatus]:
    """æª¢æŸ¥å¾®æœå‹™å¥åº·ç‹€æ…‹"""
    
    microservices = {
        'ohlc_api': 'http://ohlc-api:8002/health',
        'analyze_api': 'http://analyze-api:8003/health',
        'summary_api': 'http://summary-api:8004/health',
        'trending_api': 'http://trending-api:8005/health',
        'posting_service': 'http://posting-service:8001/health',
        'trainer': 'http://trainer:8006/health'
    }
    
    status_results = {}
    
    for service_name, health_url in microservices.items():
        try:
            # ç™¼é€å¥åº·æª¢æŸ¥è«‹æ±‚
            response = await http_client.get(health_url, timeout=5)
            
            if response.status_code == 200:
                health_data = response.json()
                status_results[service_name] = MicroserviceStatus(
                    service_name=service_name,
                    status='healthy',
                    uptime=health_data.get('uptime', 0),
                    response_time=health_data.get('response_time', 0),
                    memory_usage=health_data.get('memory_usage', 0),
                    cpu_usage=health_data.get('cpu_usage', 0),
                    request_count=health_data.get('request_count', 0),
                    error_count=health_data.get('error_count', 0),
                    last_check=datetime.now(),
                    dependencies=health_data.get('dependencies', []),
                    health_endpoint=health_url
                )
            else:
                status_results[service_name] = MicroserviceStatus(
                    service_name=service_name,
                    status='error',
                    uptime=0,
                    response_time=0,
                    memory_usage=0,
                    cpu_usage=0,
                    request_count=0,
                    error_count=1,
                    last_check=datetime.now(),
                    dependencies=[],
                    health_endpoint=health_url
                )
                
        except Exception as e:
            logger.error(f"å¾®æœå‹™ {service_name} å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
            status_results[service_name] = MicroserviceStatus(
                service_name=service_name,
                status='error',
                uptime=0,
                response_time=0,
                memory_usage=0,
                cpu_usage=0,
                request_count=0,
                error_count=1,
                last_check=datetime.now(),
                dependencies=[],
                health_endpoint=health_url
            )
    
    return status_results
```

### 3. **ä»»å‹™åŸ·è¡Œç›£æ§**

```python
async def monitor_task_execution() -> Dict[str, TaskExecutionStats]:
    """ç›£æ§ä»»å‹™åŸ·è¡Œç‹€æ…‹"""
    
    task_types = ['hourly', 'daily', 'weekly']
    execution_stats = {}
    
    for task_type in task_types:
        # ç²å–ä»»å‹™åŸ·è¡Œè¨˜éŒ„
        task_records = get_task_execution_records(task_type)
        
        total_tasks = len(task_records)
        successful_tasks = len([t for t in task_records if t.status == 'success'])
        failed_tasks = total_tasks - successful_tasks
        success_rate = (successful_tasks / total_tasks * 100) if total_tasks > 0 else 0
        
        # è¨ˆç®—å¹³å‡åŸ·è¡Œæ™‚é–“
        execution_times = [t.execution_time for t in task_records if t.execution_time]
        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0
        
        # ç²å–éŒ¯èª¤è©³æƒ…
        error_details = [t.error_message for t in task_records if t.status == 'failed']
        
        execution_stats[task_type] = TaskExecutionStats(
            task_type=task_type,
            total_tasks=total_tasks,
            successful_tasks=successful_tasks,
            failed_tasks=failed_tasks,
            success_rate=success_rate,
            avg_execution_time=avg_execution_time,
            last_execution=get_last_execution_time(task_type),
            next_execution=get_next_execution_time(task_type),
            error_details=error_details
        )
    
    return execution_stats
```

### 4. **æ•¸æ“šæºç›£æ§**

```python
async def monitor_data_sources() -> Dict[str, DataSourceStatus]:
    """ç›£æ§æ•¸æ“šæºç‹€æ…‹"""
    
    data_sources = {
        'google_sheets': GoogleSheetsClient(),
        'cmoney_api': CMoneyClient(),
        'finlab_api': FinLabClient()
    }
    
    source_status = {}
    
    for source_name, client in data_sources.items():
        try:
            # æ¸¬è©¦é€£æ¥
            start_time = time.time()
            test_result = await client.test_connection()
            response_time = (time.time() - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’
            
            if test_result['success']:
                source_status[source_name] = DataSourceStatus(
                    source_name=source_name,
                    status='connected',
                    last_sync=test_result.get('last_sync'),
                    sync_frequency=test_result.get('sync_frequency', 'unknown'),
                    data_quality=test_result.get('data_quality', 0),
                    error_count=0,
                    response_time=response_time,
                    api_quota_used=test_result.get('quota_used', 0),
                    api_quota_limit=test_result.get('quota_limit', 0)
                )
            else:
                source_status[source_name] = DataSourceStatus(
                    source_name=source_name,
                    status='error',
                    last_sync=None,
                    sync_frequency='unknown',
                    data_quality=0,
                    error_count=1,
                    response_time=response_time,
                    api_quota_used=0,
                    api_quota_limit=0
                )
                
        except Exception as e:
            logger.error(f"æ•¸æ“šæº {source_name} ç›£æ§å¤±æ•—: {e}")
            source_status[source_name] = DataSourceStatus(
                source_name=source_name,
                status='error',
                last_sync=None,
                sync_frequency='unknown',
                data_quality=0,
                error_count=1,
                response_time=0,
                api_quota_used=0,
                api_quota_limit=0
            )
    
    return source_status
```

## ğŸš¨ å‘Šè­¦æ©Ÿåˆ¶

### 1. **å‘Šè­¦è¦å‰‡å®šç¾©**

```python
class AlertRule:
    """å‘Šè­¦è¦å‰‡"""
    
    def __init__(self, name: str, condition: Callable, severity: str, message: str):
        self.name = name
        self.condition = condition
        self.severity = severity  # critical, warning, info
        self.message = message
        self.enabled = True
        self.last_triggered = None

# å®šç¾©å‘Šè­¦è¦å‰‡
ALERT_RULES = [
    AlertRule(
        name="å¾®æœå‹™é›¢ç·š",
        condition=lambda data: any(s.status == 'error' for s in data['microservices'].values()),
        severity="critical",
        message="æª¢æ¸¬åˆ°å¾®æœå‹™é›¢ç·š"
    ),
    AlertRule(
        name="ä»»å‹™åŸ·è¡Œå¤±æ•—ç‡éé«˜",
        condition=lambda data: any(s.success_rate < 90 for s in data['task_execution'].values()),
        severity="warning",
        message="ä»»å‹™åŸ·è¡Œå¤±æ•—ç‡è¶…é10%"
    ),
    AlertRule(
        name="æ•¸æ“šæºé€£æ¥å¤±æ•—",
        condition=lambda data: any(s.status == 'error' for s in data['data_sources'].values()),
        severity="warning",
        message="æ•¸æ“šæºé€£æ¥å¤±æ•—"
    ),
    AlertRule(
        name="ç³»çµ±è³‡æºä½¿ç”¨ç‡éé«˜",
        condition=lambda data: data['system_overview'].cpu_usage > 80 or data['system_overview'].memory_usage > 80,
        severity="warning",
        message="ç³»çµ±è³‡æºä½¿ç”¨ç‡è¶…é80%"
    )
]
```

### 2. **å‘Šè­¦è™•ç†**

```python
class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self):
        self.alert_history = []
        self.notification_channels = []
    
    async def check_alerts(self, monitoring_data: Dict[str, Any]):
        """æª¢æŸ¥å‘Šè­¦æ¢ä»¶"""
        
        triggered_alerts = []
        
        for rule in ALERT_RULES:
            if not rule.enabled:
                continue
                
            try:
                if rule.condition(monitoring_data):
                    alert = Alert(
                        rule_name=rule.name,
                        severity=rule.severity,
                        message=rule.message,
                        timestamp=datetime.now(),
                        data=monitoring_data
                    )
                    
                    triggered_alerts.append(alert)
                    rule.last_triggered = datetime.now()
                    
                    # ç™¼é€é€šçŸ¥
                    await self.send_notification(alert)
                    
            except Exception as e:
                logger.error(f"å‘Šè­¦è¦å‰‡ {rule.name} æª¢æŸ¥å¤±æ•—: {e}")
        
        return triggered_alerts
    
    async def send_notification(self, alert: Alert):
        """ç™¼é€å‘Šè­¦é€šçŸ¥"""
        
        for channel in self.notification_channels:
            try:
                await channel.send(alert)
            except Exception as e:
                logger.error(f"ç™¼é€å‘Šè­¦é€šçŸ¥å¤±æ•—: {e}")
```

## ğŸ“ˆ æ€§èƒ½ç›£æ§

### 1. **æ€§èƒ½æŒ‡æ¨™æ”¶é›†**

```python
class PerformanceMonitor:
    """æ€§èƒ½ç›£æ§å™¨"""
    
    def __init__(self):
        self.metrics_history = []
        self.performance_thresholds = {
            'response_time': 1000,  # 1ç§’
            'memory_usage': 80,     # 80%
            'cpu_usage': 80,        # 80%
            'error_rate': 5         # 5%
        }
    
    async def collect_performance_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†æ€§èƒ½æŒ‡æ¨™"""
        
        metrics = {
            'timestamp': datetime.now(),
            'system_metrics': self.get_system_metrics(),
            'application_metrics': self.get_application_metrics(),
            'database_metrics': self.get_database_metrics(),
            'network_metrics': self.get_network_metrics()
        }
        
        # æª¢æŸ¥æ€§èƒ½é–¾å€¼
        alerts = self.check_performance_thresholds(metrics)
        
        # è¨˜éŒ„æŒ‡æ¨™æ­·å²
        self.metrics_history.append(metrics)
        
        # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœå…§
        if len(self.metrics_history) > 1000:
            self.metrics_history = self.metrics_history[-500:]
        
        return metrics
    
    def get_system_metrics(self) -> Dict[str, float]:
        """ç²å–ç³»çµ±æŒ‡æ¨™"""
        import psutil
        
        return {
            'cpu_usage': psutil.cpu_percent(),
            'memory_usage': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent,
            'load_average': psutil.getloadavg()[0] if hasattr(psutil, 'getloadavg') else 0
        }
    
    def get_application_metrics(self) -> Dict[str, Any]:
        """ç²å–æ‡‰ç”¨ç¨‹åºæŒ‡æ¨™"""
        return {
            'active_connections': get_active_connections_count(),
            'request_count': get_request_count(),
            'error_count': get_error_count(),
            'response_time_avg': get_average_response_time()
        }
```

### 2. **æ€§èƒ½åˆ†æ**

```python
def analyze_performance_trends(metrics_history: List[Dict]) -> Dict[str, Any]:
    """åˆ†ææ€§èƒ½è¶¨å‹¢"""
    
    if len(metrics_history) < 2:
        return {'trend': 'insufficient_data'}
    
    # æå–é—œéµæŒ‡æ¨™
    cpu_usage = [m['system_metrics']['cpu_usage'] for m in metrics_history]
    memory_usage = [m['system_metrics']['memory_usage'] for m in metrics_history]
    response_time = [m['application_metrics']['response_time_avg'] for m in metrics_history]
    
    # è¨ˆç®—è¶¨å‹¢
    trends = {
        'cpu_trend': calculate_trend(cpu_usage),
        'memory_trend': calculate_trend(memory_usage),
        'response_time_trend': calculate_trend(response_time)
    }
    
    # è­˜åˆ¥ç•°å¸¸
    anomalies = detect_anomalies(metrics_history)
    
    # ç”Ÿæˆå»ºè­°
    recommendations = generate_performance_recommendations(trends, anomalies)
    
    return {
        'trends': trends,
        'anomalies': anomalies,
        'recommendations': recommendations,
        'summary': generate_performance_summary(trends)
    }
```

## ğŸ”§ æ•…éšœè¨ºæ–·

### 1. **è‡ªå‹•è¨ºæ–·**

```python
class FaultDiagnostic:
    """æ•…éšœè¨ºæ–·å™¨"""
    
    def __init__(self):
        self.diagnostic_rules = [
            self.diagnose_service_failure,
            self.diagnose_database_issues,
            self.diagnose_network_problems,
            self.diagnose_resource_exhaustion
        ]
    
    async def diagnose_issues(self, monitoring_data: Dict[str, Any]) -> List[DiagnosticResult]:
        """è¨ºæ–·å•é¡Œ"""
        
        diagnostic_results = []
        
        for rule in self.diagnostic_rules:
            try:
                result = await rule(monitoring_data)
                if result:
                    diagnostic_results.append(result)
            except Exception as e:
                logger.error(f"è¨ºæ–·è¦å‰‡ {rule.__name__} åŸ·è¡Œå¤±æ•—: {e}")
        
        return diagnostic_results
    
    async def diagnose_service_failure(self, data: Dict[str, Any]) -> Optional[DiagnosticResult]:
        """è¨ºæ–·æœå‹™æ•…éšœ"""
        
        failed_services = [
            name for name, status in data['microservices'].items() 
            if status.status == 'error'
        ]
        
        if failed_services:
            return DiagnosticResult(
                issue_type='service_failure',
                severity='critical',
                description=f"æœå‹™æ•…éšœ: {', '.join(failed_services)}",
                possible_causes=[
                    'æœå‹™é€²ç¨‹å´©æ½°',
                    'ç¶²çµ¡é€£æ¥å•é¡Œ',
                    'è³‡æºä¸è¶³',
                    'é…ç½®éŒ¯èª¤'
                ],
                suggested_actions=[
                    'æª¢æŸ¥æœå‹™æ—¥èªŒ',
                    'é‡å•Ÿæœå‹™',
                    'æª¢æŸ¥è³‡æºä½¿ç”¨æƒ…æ³',
                    'é©—è­‰é…ç½®'
                ]
            )
        
        return None
```

### 2. **æ•…éšœæ¢å¾©**

```python
class FaultRecovery:
    """æ•…éšœæ¢å¾©å™¨"""
    
    def __init__(self):
        self.recovery_strategies = {
            'service_failure': self.restart_service,
            'database_connection': self.reconnect_database,
            'memory_exhaustion': self.clear_memory_cache,
            'disk_full': self.cleanup_disk_space
        }
    
    async def attempt_recovery(self, diagnostic_result: DiagnosticResult) -> bool:
        """å˜—è©¦æ•…éšœæ¢å¾©"""
        
        strategy = self.recovery_strategies.get(diagnostic_result.issue_type)
        
        if not strategy:
            logger.warning(f"æ²’æœ‰æ‰¾åˆ° {diagnostic_result.issue_type} çš„æ¢å¾©ç­–ç•¥")
            return False
        
        try:
            success = await strategy(diagnostic_result)
            if success:
                logger.info(f"æˆåŠŸæ¢å¾© {diagnostic_result.issue_type} æ•…éšœ")
            else:
                logger.warning(f"æ¢å¾© {diagnostic_result.issue_type} æ•…éšœå¤±æ•—")
            
            return success
            
        except Exception as e:
            logger.error(f"æ¢å¾© {diagnostic_result.issue_type} æ•…éšœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    async def restart_service(self, diagnostic_result: DiagnosticResult) -> bool:
        """é‡å•Ÿæœå‹™"""
        # å¯¦ç¾æœå‹™é‡å•Ÿé‚è¼¯
        pass
    
    async def reconnect_database(self, diagnostic_result: DiagnosticResult) -> bool:
        """é‡æ–°é€£æ¥æ•¸æ“šåº«"""
        # å¯¦ç¾æ•¸æ“šåº«é‡é€£é‚è¼¯
        pass
```

## ğŸš€ éƒ¨ç½²é…ç½®

### 1. **Docker Compose é…ç½®**

```yaml
# docker-compose.yml
version: '3.8'

services:
  # ç›£æ§æœå‹™
  monitoring-service:
    build: ./monitoring-service
    ports:
      - "8007:8000"
    environment:
      - MONITORING_ENABLED=true
      - ALERT_ENABLED=true
      - PERFORMANCE_MONITORING=true
    volumes:
      - ./monitoring-data:/app/data
    depends_on:
      - postgres
      - posting-service
      - ohlc-api
      - analyze-api
      - summary-api
      - trending-api
      - trainer
  
  # ç³»çµ±ç›£æ§å„€è¡¨æ¿
  system-monitoring:
    build: ./system-monitoring
    ports:
      - "8008:8000"
    environment:
      - MONITORING_API_URL=http://monitoring-service:8000
    depends_on:
      - monitoring-service
  
  # æ—¥èªŒèšåˆæœå‹™
  log-aggregator:
    build: ./log-aggregator
    ports:
      - "8009:8000"
    volumes:
      - /var/log:/var/log:ro
    depends_on:
      - monitoring-service
```

### 2. **ç’°å¢ƒè®Šé‡é…ç½®**

```bash
# ç›£æ§ç³»çµ±é…ç½®
MONITORING_ENABLED=true
MONITORING_INTERVAL=30  # ç›£æ§é–“éš”ï¼ˆç§’ï¼‰
ALERT_ENABLED=true
ALERT_CHANNELS=email,slack,webhook

# æ€§èƒ½ç›£æ§é…ç½®
PERFORMANCE_MONITORING=true
PERFORMANCE_METRICS_RETENTION_DAYS=30
PERFORMANCE_THRESHOLDS_CPU=80
PERFORMANCE_THRESHOLDS_MEMORY=80
PERFORMANCE_THRESHOLDS_DISK=90

# å‘Šè­¦é…ç½®
ALERT_EMAIL_SMTP_HOST=smtp.gmail.com
ALERT_EMAIL_SMTP_PORT=587
ALERT_EMAIL_USERNAME=alerts@company.com
ALERT_EMAIL_PASSWORD=password
ALERT_SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxx
ALERT_WEBHOOK_URL=https://monitoring.company.com/webhook

# æ•¸æ“šåº«é…ç½®
MONITORING_DB_HOST=postgres
MONITORING_DB_PORT=5432
MONITORING_DB_NAME=monitoring
MONITORING_DB_USER=monitoring_user
MONITORING_DB_PASSWORD=monitoring_password
```

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### 1. **å•Ÿå‹•ç›£æ§ç³»çµ±**

```python
# å•Ÿå‹•ç›£æ§ç³»çµ±
async def start_monitoring_system():
    """å•Ÿå‹•ç›£æ§ç³»çµ±"""
    
    # å‰µå»ºç›£æ§çµ„ä»¶
    performance_monitor = PerformanceMonitor()
    alert_manager = AlertManager()
    fault_diagnostic = FaultDiagnostic()
    fault_recovery = FaultRecovery()
    
    # å•Ÿå‹•ç›£æ§å¾ªç’°
    while True:
        try:
            # æ”¶é›†ç›£æ§æ•¸æ“š
            monitoring_data = await collect_monitoring_data()
            
            # æª¢æŸ¥å‘Šè­¦
            alerts = await alert_manager.check_alerts(monitoring_data)
            
            # è¨ºæ–·å•é¡Œ
            diagnostic_results = await fault_diagnostic.diagnose_issues(monitoring_data)
            
            # å˜—è©¦æ¢å¾©
            for result in diagnostic_results:
                await fault_recovery.attempt_recovery(result)
            
            # è¨˜éŒ„ç›£æ§æ•¸æ“š
            await save_monitoring_data(monitoring_data)
            
            # ç­‰å¾…ä¸‹æ¬¡ç›£æ§
            await asyncio.sleep(MONITORING_INTERVAL)
            
        except Exception as e:
            logger.error(f"ç›£æ§ç³»çµ±é‹è¡ŒéŒ¯èª¤: {e}")
            await asyncio.sleep(60)  # éŒ¯èª¤æ™‚ç­‰å¾…1åˆ†é˜
```

### 2. **ç›£æ§å„€è¡¨æ¿**

```python
# ç›£æ§å„€è¡¨æ¿ API
@app.get("/api/monitoring/dashboard")
async def get_monitoring_dashboard():
    """ç²å–ç›£æ§å„€è¡¨æ¿æ•¸æ“š"""
    
    # ç²å–æœ€æ–°ç›£æ§æ•¸æ“š
    latest_data = await get_latest_monitoring_data()
    
    # ç²å–æ­·å²è¶¨å‹¢
    historical_trends = await get_historical_trends(days=7)
    
    # ç²å–å‘Šè­¦ç‹€æ…‹
    active_alerts = await get_active_alerts()
    
    # ç²å–æ€§èƒ½åˆ†æ
    performance_analysis = await analyze_performance_trends()
    
    return {
        'current_status': latest_data,
        'historical_trends': historical_trends,
        'active_alerts': active_alerts,
        'performance_analysis': performance_analysis,
        'timestamp': datetime.now().isoformat()
    }
```

## ğŸ”§ æ•…éšœæ’é™¤

### 1. **å¸¸è¦‹å•é¡Œ**

#### å•é¡Œï¼šç›£æ§æ•¸æ“šä¸æ›´æ–°
**ç—‡ç‹€**: å„€è¡¨æ¿é¡¯ç¤ºèˆŠæ•¸æ“š
**è§£æ±ºæ–¹æ¡ˆ**:
```python
# æª¢æŸ¥ç›£æ§æœå‹™ç‹€æ…‹
async def check_monitoring_service():
    """æª¢æŸ¥ç›£æ§æœå‹™ç‹€æ…‹"""
    try:
        response = await http_client.get('http://monitoring-service:8000/health')
        if response.status_code == 200:
            logger.info("âœ… ç›£æ§æœå‹™æ­£å¸¸")
        else:
            logger.error("âŒ ç›£æ§æœå‹™ç•°å¸¸")
    except Exception as e:
        logger.error(f"âŒ ç›£æ§æœå‹™é€£æ¥å¤±æ•—: {e}")
```

#### å•é¡Œï¼šå‘Šè­¦ä¸ç™¼é€
**ç—‡ç‹€**: ç³»çµ±ç•°å¸¸ä½†æ²’æœ‰æ”¶åˆ°å‘Šè­¦
**è§£æ±ºæ–¹æ¡ˆ**:
```python
# æ¸¬è©¦å‘Šè­¦é€šé“
async def test_alert_channels():
    """æ¸¬è©¦å‘Šè­¦é€šé“"""
    test_alert = Alert(
        rule_name="æ¸¬è©¦å‘Šè­¦",
        severity="info",
        message="é€™æ˜¯ä¸€å€‹æ¸¬è©¦å‘Šè­¦",
        timestamp=datetime.now(),
        data={}
    )
    
    for channel in alert_manager.notification_channels:
        try:
            await channel.send(test_alert)
            logger.info(f"âœ… {channel.name} å‘Šè­¦é€šé“æ­£å¸¸")
        except Exception as e:
            logger.error(f"âŒ {channel.name} å‘Šè­¦é€šé“å¤±æ•—: {e}")
```

### 2. **æ€§èƒ½å•é¡Œ**

#### å•é¡Œï¼šç›£æ§ç³»çµ±å½±éŸ¿ä¸»ç³»çµ±æ€§èƒ½
**è§£æ±ºæ–¹æ¡ˆ**:
- é™ä½ç›£æ§é »ç‡
- ä½¿ç”¨ç•°æ­¥ç›£æ§
- å„ªåŒ–æ•¸æ“šæ”¶é›†ç®—æ³•

#### å•é¡Œï¼šç›£æ§æ•¸æ“šå­˜å„²ç©ºé–“ä¸è¶³
**è§£æ±ºæ–¹æ¡ˆ**:
- å¯¦æ–½æ•¸æ“šå£“ç¸®
- è¨­ç½®æ•¸æ“šä¿ç•™ç­–ç•¥
- ä½¿ç”¨å¤–éƒ¨å­˜å„²

## ğŸ“ˆ æœªä¾†æ”¹é€²

### 1. **æ™ºèƒ½ç›£æ§**
- æ©Ÿå™¨å­¸ç¿’ç•°å¸¸æª¢æ¸¬
- é æ¸¬æ€§ç¶­è­·
- è‡ªå‹•åŒ–æ•…éšœæ¢å¾©

### 2. **å¯è¦–åŒ–å¢å¼·**
- å¯¦æ™‚å„€è¡¨æ¿
- äº’å‹•å¼åœ–è¡¨
- 3D ç³»çµ±æ‹“æ’²åœ–

### 3. **å¤šé›²ç›£æ§**
- è·¨é›²å¹³å°ç›£æ§
- æ··åˆé›²ç’°å¢ƒæ”¯æŒ
- é›²åŸç”Ÿç›£æ§

### 4. **å®‰å…¨ç›£æ§**
- å®‰å…¨äº‹ä»¶ç›£æ§
- å¨è„…æª¢æ¸¬
- åˆè¦æ€§æª¢æŸ¥

## ğŸ“š ç›¸é—œæ–‡æª”

- [ç³»çµ±æ¦‚è¿°](./01-system-overview.md)
- [å¾Œç«¯æ¶æ§‹](./03-backend-architecture.md)
- [Bug åˆ†æå’Œå•é¡Œæ¸…å–®](./07-bug-analysis-and-issues.md)
- [è‡ªæˆ‘å­¸ç¿’ç³»çµ±](./08-self-learning-system.md)
- [äº’å‹•åˆ†æç³»çµ±](./09-interaction-analysis-system.md)


