# å…§å®¹ç”Ÿæˆæµç¨‹

## ğŸ¯ å…§å®¹ç”Ÿæˆæµç¨‹æ¦‚è¦½

å…§å®¹ç”Ÿæˆæµç¨‹æ˜¯è™›æ“¬ KOL ç³»çµ±çš„æ ¸å¿ƒï¼ŒåŒ…å«å¾è§¸ç™¼å™¨æª¢æ¸¬åˆ°æœ€çµ‚å…§å®¹ç™¼å¸ƒçš„å®Œæ•´æµç¨‹ã€‚æµç¨‹åˆ†ç‚ºæ¨™æº–å…§å®¹ç”Ÿæˆå’Œå€‹äººåŒ–è™•ç†å…©å€‹éšæ®µã€‚

## ğŸ”„ å®Œæ•´å…§å®¹ç”Ÿæˆæµç¨‹

### 1. æ¨™æº–å…§å®¹ç”Ÿæˆéšæ®µ

```mermaid
graph TD
    A[è§¸ç™¼å™¨æª¢æ¸¬] --> B[æ•¸æ“šæ”¶é›†]
    B --> C[è‚¡ç¥¨æ•¸æ“š]
    B --> D[æ–°èæ•¸æ“š]
    B --> E[æŠ€è¡“æŒ‡æ¨™]
    
    C --> F[AI å…§å®¹ç”Ÿæˆ]
    D --> F
    E --> F
    
    F --> G[æ¨™æº–å…§å®¹]
    G --> H[å€‹äººåŒ–è™•ç†]
    H --> I[éš¨æ©Ÿæ€§ç”Ÿæˆå¤šå€‹ç‰ˆæœ¬]
    I --> J[é¸æ“‡æœ€ä½³ç‰ˆæœ¬]
    J --> K{æ˜¯å¦éœ€è¦å¯©æ ¸}
    K -->|æ˜¯| L[æ–‡ç« å¯©æ ¸]
    K -->|å¦| M[ç›´æ¥ç™¼å¸ƒ]
    L --> N{å¯©æ ¸çµæœ}
    N -->|é€šé| M[ç™¼å¸ƒè²¼æ–‡]
    N -->|æ‹’çµ•| O[å…§å®¹ä¿®æ”¹]
    O --> H
    M --> P[æ’ç¨‹ç™¼å¸ƒ]
```

### 2. AI å…§å®¹ç”Ÿæˆè©³ç´°æµç¨‹

#### OpenAI GPT å…§å®¹ç”Ÿæˆ
```python
class ContentGenerator:
    def __init__(self):
        self.openai_client = OpenAIClient(os.getenv("OPENAI_API_KEY"))
        self.serper_client = SerperClient(os.getenv("SERPER_API_KEY"))
        self.finlab_client = FinLabClient()
    
    async def generate_standard_content(self, request: PostingRequest) -> GeneratedContent:
        """ç”Ÿæˆæ¨™æº–å…§å®¹"""
        try:
            # 1. æ”¶é›†è‚¡ç¥¨æ•¸æ“š
            stock_data = await self._collect_stock_data(request)
            
            # 2. æœå°‹ç›¸é—œæ–°è
            news_data = await self._search_news(request)
            
            # 3. ç²å–æŠ€è¡“æŒ‡æ¨™
            technical_data = await self._get_technical_indicators(request)
            
            # 4. æ§‹å»º AI æç¤ºè©
            prompt = self._build_ai_prompt(stock_data, news_data, technical_data, request)
            
            # 5. èª¿ç”¨ OpenAI API
            ai_response = await self.openai_client.generate_content(prompt)
            
            # 6. è§£æ AI éŸ¿æ‡‰
            parsed_content = self._parse_ai_response(ai_response)
            
            # 7. å¾Œè™•ç†å’Œé©—è­‰
            final_content = self._post_process_content(parsed_content, request)
            
            return GeneratedContent(
                title=final_content['title'],
                content=final_content['content'],
                content_md=final_content['content_md'],
                technical_analysis=final_content['technical_analysis'],
                serper_data=news_data,
                quality_score=self._calculate_quality_score(final_content),
                generation_params=request.generation_params
            )
            
        except Exception as e:
            logger.error(f"âŒ æ¨™æº–å…§å®¹ç”Ÿæˆå¤±æ•—: {e}")
            raise
    
    def _build_ai_prompt(self, stock_data: Dict, news_data: Dict, technical_data: Dict, request: PostingRequest) -> str:
        """æ§‹å»º AI æç¤ºè©"""
        prompt_template = """
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è‚¡ç¥¨åˆ†æå¸«ï¼Œè«‹æ ¹æ“šä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€ç¯‡æŠ•è³‡åˆ†ææ–‡ç« ï¼š

## è‚¡ç¥¨ä¿¡æ¯
- è‚¡ç¥¨ä»£è™Ÿï¼š{stock_code}
- è‚¡ç¥¨åç¨±ï¼š{stock_name}
- ç•¶å‰åƒ¹æ ¼ï¼š{current_price}
- æ¼²è·Œå¹…ï¼š{change_percent}%

## æŠ€è¡“æŒ‡æ¨™
{technical_indicators}

## ç›¸é—œæ–°è
{news_summary}

## åˆ†æè¦æ±‚
- å…§å®¹é¢¨æ ¼ï¼š{content_style}
- ç›®æ¨™å—çœ¾ï¼š{target_audience}
- åˆ†ææ·±åº¦ï¼š{analysis_depth}
- æœ€å¤§å­—æ•¸ï¼š{max_words}

## å…§å®¹çµæ§‹
1. é¡Œæé¢åˆ†æ
2. åŸºæœ¬é¢åˆ†æ
3. æŠ€è¡“é¢åˆ†æ
4. ç±Œç¢¼é¢åˆ†æ
5. æ“ä½œå»ºè­°
6. é¢¨éšªæé†’

è«‹ç”Ÿæˆæ¨™é¡Œå’Œå…§å®¹ï¼Œç¢ºä¿å…§å®¹å°ˆæ¥­ã€å®¢è§€ã€æœ‰åƒè€ƒåƒ¹å€¼ã€‚
"""
        
        return prompt_template.format(
            stock_code=stock_data.get('stock_code', ''),
            stock_name=stock_data.get('stock_name', ''),
            current_price=stock_data.get('current_price', ''),
            change_percent=stock_data.get('change_percent', ''),
            technical_indicators=self._format_technical_indicators(technical_data),
            news_summary=self._format_news_summary(news_data),
            content_style=request.content_style,
            target_audience=request.target_audience,
            analysis_depth=request.analysis_depth,
            max_words=request.max_words
        )
```

### 3. å…§å®¹å¯©æ ¸ç³»çµ±

#### å¯©æ ¸é…ç½®
```python
class ContentReviewConfig:
    def __init__(self):
        self.auto_review_enabled = True
        self.manual_review_enabled = True
        self.skip_review_for_scheduled = True  # æ’ç¨‹å…§å®¹è·³éå¯©æ ¸
        self.quality_threshold = 0.8
        self.risk_keywords = ['æŠ•è³‡æœ‰é¢¨éšª', 'è¬¹æ…æŠ•è³‡', 'é¢¨éšªè‡ªè² ']
    
    def should_skip_review(self, content: GeneratedContent, request: PostingRequest) -> bool:
        """åˆ¤æ–·æ˜¯å¦è·³éå¯©æ ¸"""
        # æ’ç¨‹å…§å®¹è·³éå¯©æ ¸
        if request.batch_mode and self.skip_review_for_scheduled:
            return True
        
        # é«˜å“è³ªå…§å®¹è·³éå¯©æ ¸
        if content.quality_score >= self.quality_threshold:
            return True
        
        return False
```

#### è‡ªå‹•å¯©æ ¸é‚è¼¯
```python
class AutoContentReviewer:
    def __init__(self):
        self.risk_keywords = ['æŠ•è³‡æœ‰é¢¨éšª', 'è¬¹æ…æŠ•è³‡', 'é¢¨éšªè‡ªè² ']
        self.prohibited_keywords = ['ä¿è­‰ç²åˆ©', 'ç©©è³ºä¸è³ ', 'å…§ç·šæ¶ˆæ¯']
        self.min_length = 100
        self.max_length = 5000
    
    async def review_content(self, content: GeneratedContent) -> ReviewResult:
        """è‡ªå‹•å¯©æ ¸å…§å®¹"""
        issues = []
        
        # 1. é•·åº¦æª¢æŸ¥
        if len(content.content) < self.min_length:
            issues.append(f"å…§å®¹éçŸ­ï¼Œå°‘æ–¼ {self.min_length} å­—")
        
        if len(content.content) > self.max_length:
            issues.append(f"å…§å®¹éé•·ï¼Œè¶…é {self.max_length} å­—")
        
        # 2. é¢¨éšªè­¦å‘Šæª¢æŸ¥
        if not any(keyword in content.content for keyword in self.risk_keywords):
            issues.append("ç¼ºå°‘é¢¨éšªè­¦å‘Š")
        
        # 3. ç¦ç”¨è©å½™æª¢æŸ¥
        for keyword in self.prohibited_keywords:
            if keyword in content.content:
                issues.append(f"åŒ…å«ç¦ç”¨è©å½™: {keyword}")
        
        # 4. æ ¼å¼æª¢æŸ¥
        if not content.title or len(content.title.strip()) == 0:
            issues.append("æ¨™é¡Œç‚ºç©º")
        
        # 5. å“è³ªåˆ†æ•¸æª¢æŸ¥
        if content.quality_score < 0.6:
            issues.append(f"å“è³ªåˆ†æ•¸éä½: {content.quality_score}")
        
        # æ±ºå®šå¯©æ ¸çµæœ
        if len(issues) == 0:
            return ReviewResult(
                status='approved',
                issues=[],
                score=content.quality_score
            )
        elif len(issues) <= 2:
            return ReviewResult(
                status='needs_revision',
                issues=issues,
                score=content.quality_score
            )
        else:
            return ReviewResult(
                status='rejected',
                issues=issues,
                score=content.quality_score
            )
```

### 4. å€‹äººåŒ–è™•ç†éšæ®µ

#### å€‹äººåŒ–æ¨¡çµ„æ¶æ§‹
```python
class EnhancedPersonalizationProcessor:
    """å¢å¼·ç‰ˆå€‹äººåŒ–è™•ç†å™¨"""
    
    def __init__(self):
        self.kol_service = KOLDatabaseService()
        self.llm_processor = cLLMPersonalizationProcessor()
        self.style_randomizer = PostingStyleRandomizer()
        self.parameter_mapper = ParameterMapper()
        self.logger = logging.getLogger(__name__)
    
    def personalize_content(self, standard_title: str, standard_content: str, kol_serial: str, 
                          batch_config: Dict = None, serper_analysis: Dict = None, 
                          trigger_type: str = None, real_time_price_data: Dict = None) -> Tuple[str, str]:
        """å€‹äººåŒ–å…§å®¹è™•ç†"""
        
        try:
            # 1. ç²å– KOL è¨­å®š
            kol_profile = self.kol_service.get_kol_by_serial(int(kol_serial))
            if not kol_profile:
                self.logger.warning(f"âš ï¸ æ‰¾ä¸åˆ° KOL {kol_serial}ï¼Œè¿”å›åŸå§‹å…§å®¹")
                return standard_title, standard_content
            
            # 2. æ±ºå®šç™¼æ–‡å½¢æ…‹ (æå• vs ç™¼è¡¨çœ‹æ³•)
            style_type, style_params = self.style_randomizer.determine_posting_style(kol_profile)
            self.logger.info(f"ğŸ“ ç™¼æ–‡å½¢æ…‹: {style_type}")
            
            # 3. æ ¹æ“šç™¼æ–‡å½¢æ…‹æ±ºå®šå…§å®¹é•·åº¦
            content_length = self.resolve_content_length_with_style(kol_profile, batch_config or {}, style_type)
            self.logger.info(f"ğŸ“ å…§å®¹é•·åº¦: {content_length}")
            
            # 4. æ˜ å°„åƒæ•¸
            prompt_params = self.parameter_mapper.map_kol_to_prompt(kol_profile, style_params, content_length)
            prompt_params.update({
                'standard_title': standard_title,
                'standard_content': standard_content,
                'style_instructions': self.parameter_mapper.get_style_instructions(style_type, style_params)
            })
            
            # 5. ä½¿ç”¨ LLM ç”Ÿæˆå€‹äººåŒ–å…§å®¹
            personalized_content = self.llm_processor.generate_personalized_content(
                standard_content, kol_profile, trigger_type
            )
            
            # 6. ä½¿ç”¨ LLM ç”Ÿæˆå€‹äººåŒ–æ¨™é¡Œ
            personalized_title = self.llm_processor.generate_personalized_title(
                personalized_content, kol_profile, standard_title
            )
            
            # 7. æ•´åˆæ–°èä¾†æº
            if serper_analysis and serper_analysis.get('news_items'):
                personalized_content = self._integrate_news_sources(personalized_content, serper_analysis)
            
            # 8. å¢å¼·å¯¦æ™‚æ•¸æ“š
            if real_time_price_data:
                personalized_content = self._enhance_content_with_realtime_data(
                    personalized_content, real_time_price_data, trigger_type
                )
            
            self.logger.info(f"âœ… å€‹äººåŒ–å®Œæˆ - KOL: {kol_serial}, æ¨™é¡Œ: {personalized_title}")
            return personalized_title, personalized_content
            
        except Exception as e:
            self.logger.error(f"âŒ å€‹äººåŒ–è™•ç†å¤±æ•—: {e}")
            return standard_title, standard_content
```

#### LLM å€‹äººåŒ–è™•ç†å™¨
```python
class cLLMPersonalizationProcessor:
    """LLM é©…å‹•çš„å€‹äººåŒ–è™•ç†å™¨"""
    
    def generate_personalized_content(self, standard_content: str, kol_profile: KOLProfile, trigger_type: str = None) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆå€‹äººåŒ–å…§å®¹"""
        
        try:
            # 1. æ§‹å»ºå‹•æ…‹ prompt
            prompt = self._build_dynamic_prompt(standard_content, kol_profile, trigger_type)
            
            # 2. èª¿ç”¨æŒ‡å®šçš„ GPT æ¨¡å‹
            response = self._call_llm(prompt, kol_profile)
            
            # 3. å¾Œè™•ç†å’Œé©—è­‰
            personalized_content = self._post_process_content(response, kol_profile)
            
            self.logger.info(f"ğŸ¤– LLM å€‹äººåŒ–å®Œæˆ - æ¨¡å‹: {kol_profile.model_id}, é•·åº¦: {len(personalized_content)} å­—")
            return personalized_content
            
        except Exception as e:
            self.logger.error(f"âŒ LLM å€‹äººåŒ–å¤±æ•—: {e}")
            # å›é€€åˆ°é…ç½®é©…å‹•
            return self._fallback_to_config(standard_content, kol_profile)
    
    def _build_dynamic_prompt(self, standard_content: str, kol_profile: KOLProfile, trigger_type: str = None) -> str:
        """æ§‹å»ºå‹•æ…‹å€‹äººåŒ– prompt"""
        
        prompt_template = """
ä½ æ˜¯ä¸€å€‹{persona}é¢¨æ ¼çš„è‚¡ç¥¨åˆ†æå¸«ï¼Œåç‚º{nickname}ã€‚

## è§’è‰²èƒŒæ™¯
{backstory}

## å°ˆæ¥­é ˜åŸŸ
{expertise}

## å¯«ä½œé¢¨æ ¼è¨­å®š
- èªæ°£é¢¨æ ¼ï¼š{tone_style}
- æ‰“å­—ç¿’æ…£ï¼š{typing_habit}
- å¸¸ç”¨è¡“èªï¼š{common_terms}
- å£èªåŒ–ç”¨è©ï¼š{colloquial_terms}

## èªèª¿æ§åˆ¶
- æ­£å¼ç¨‹åº¦ï¼š{tone_formal}/10
- æƒ…æ„Ÿå¼·åº¦ï¼š{tone_emotion}/10
- è‡ªä¿¡ç¨‹åº¦ï¼š{tone_confidence}/10
- ç·Šè¿«æ„Ÿï¼š{tone_urgency}/10

## å…§å®¹çµæ§‹åå¥½
- å…§å®¹éª¨æ¶ï¼š{prompt_skeleton}
- è¡Œå‹•å‘¼ç±²ï¼š{prompt_cta}
- æ¨™ç±¤é¢¨æ ¼ï¼š{prompt_hashtags}
- å€‹äººç°½åï¼š{signature}

## äº’å‹•é¢¨æ ¼
- æå•æ¯”ä¾‹ï¼š{question_ratio}%
- å¹½é»˜æ©Ÿç‡ï¼š{humor_probability}%
- äº’å‹•é–‹å ´ç™½ï¼š{interaction_starters}

## ç›®æ¨™å—çœ¾
{target_audience}

## ä»»å‹™
è«‹å°‡ä»¥ä¸‹æ¨™æº–åŒ–å…§å®¹è½‰æ›ç‚ºç¬¦åˆä½ å€‹äººé¢¨æ ¼çš„ç‰ˆæœ¬ï¼š

**æ¨™æº–å…§å®¹ï¼š** {standard_content}

**è¦æ±‚ï¼š**
1. ä¿æŒæ ¸å¿ƒè³‡è¨Šä¸è®Š
2. ç¬¦åˆä½ çš„å¯«ä½œé¢¨æ ¼è¨­å®š
3. èªèª¿è¦ç¬¦åˆä½ çš„è¨­å®š
4. å…§å®¹è¦è‡ªç„¶æµæš¢ï¼ŒåƒçœŸäººå¯«çš„åˆ†æ
5. ä¸è¦ä½¿ç”¨çµæ§‹åŒ–æ¨™é¡Œï¼ˆå¦‚ï¼šã€æŠ€è¡“åˆ†æã€‘ç­‰ï¼‰
6. ä¸è¦ä½¿ç”¨ emoji è¡¨æƒ…ç¬¦è™Ÿ

**è¼¸å‡ºæ ¼å¼ï¼š**
[å€‹äººåŒ–å…§å®¹]
"""
        
        return prompt_template.format(
            persona=kol_profile.persona,
            nickname=kol_profile.nickname,
            backstory=kol_profile.backstory or 'è³‡æ·±è‚¡ç¥¨åˆ†æå¸«',
            expertise=kol_profile.expertise or 'è‚¡ç¥¨åˆ†æ',
            tone_style=kol_profile.tone_style or 'å°ˆæ¥­ç†æ€§',
            typing_habit=kol_profile.typing_habit or 'æ¨™æº–æ¨™é»ç¬¦è™Ÿ',
            common_terms=kol_profile.common_terms or 'å°ˆæ¥­è¡“èª',
            colloquial_terms=kol_profile.colloquial_terms or 'å£èªåŒ–è¡¨é”',
            tone_formal=kol_profile.tone_formal or 7,
            tone_emotion=kol_profile.tone_emotion or 5,
            tone_confidence=kol_profile.tone_confidence or 7,
            tone_urgency=kol_profile.tone_urgency or 6,
            prompt_skeleton=kol_profile.prompt_skeleton or 'æ¨™æº–åˆ†æçµæ§‹',
            prompt_cta=kol_profile.prompt_cta or 'æ­¡è¿è¨è«–',
            prompt_hashtags=kol_profile.prompt_hashtags or 'ç›¸é—œæ¨™ç±¤',
            signature=kol_profile.signature or '',
            question_ratio=int((kol_profile.question_ratio or 0.3) * 100),
            humor_probability=int((kol_profile.humor_probability or 0.3) * 100),
            interaction_starters=', '.join(kol_profile.interaction_starters) if kol_profile.interaction_starters else 'ä½ è¦ºå¾—å‘¢ï¼Ÿ',
            target_audience=kol_profile.target_audience or 'ä¸€èˆ¬æŠ•è³‡è€…',
            standard_content=standard_content
        )
```

### 5. ç™¼æ–‡å½¢æ…‹éš¨æ©Ÿå™¨

#### ç™¼æ–‡å½¢æ…‹æ±ºå®šé‚è¼¯
```python
class PostingStyleRandomizer:
    """ç™¼æ–‡å½¢æ…‹éš¨æ©Ÿå™¨"""
    
    def determine_posting_style(self, kol_profile: KOLProfile) -> Tuple[str, Dict]:
        """æ±ºå®šç™¼æ–‡å½¢æ…‹"""
        
        # æ ¹æ“š KOL è¨­å®šæ±ºå®šç™¼æ–‡å½¢æ…‹
        if kol_profile.posting_style_preference == 'interaction':
            return 'interaction', {
                'question_ratio': 0.7,
                'interaction_focus': True,
                'call_to_action': True
            }
        elif kol_profile.posting_style_preference == 'analysis':
            return 'analysis', {
                'analysis_depth': 'detailed',
                'technical_focus': True,
                'data_driven': True
            }
        else:
            # éš¨æ©Ÿæ±ºå®š
            import random
            if random.random() < 0.5:
                return 'interaction', {
                    'question_ratio': 0.6,
                    'interaction_focus': True,
                    'call_to_action': True
                }
            else:
                return 'analysis', {
                    'analysis_depth': 'comprehensive',
                    'technical_focus': True,
                    'data_driven': True
                }
```

### 6. æ‰¹æ¬¡å…§å®¹ç”Ÿæˆ

#### ä¸¦è¡Œæ‰¹æ¬¡ç”Ÿæˆ
```python
class ParallelBatchGenerator:
    """ä¸¦è¡Œæ‰¹æ¬¡ç”Ÿæˆå™¨"""
    
    def __init__(self, max_concurrent: int = 2, timeout: int = 120):
        self.post_generation_processor = PostGenerationProcessor(max_concurrent, timeout)
        self.personalization_processor = EnhancedPersonalizationProcessor()
    
    async def generate_posts_parallel_stream(self, request: BatchRequest, progress_callback: Optional[Callable] = None) -> AsyncGenerator[str, None]:
        """ä¸¦è¡Œæ‰¹é‡ç”Ÿæˆè²¼æ–‡ï¼Œä¸¦é€šé SSE æµå¼è¿”å›é€²åº¦"""
        
        total_posts = len(request.posts)
        successful_posts = 0
        failed_posts = 0
        
        self.logger.info(f"ğŸš€ é–‹å§‹ä¸¦è¡Œæ‰¹é‡ç™¼æ–‡ç”Ÿæˆ - æœƒè©±ID: {request.session_id}, è²¼æ–‡æ•¸é‡: {total_posts}")
        
        # ç”Ÿæˆæ‰¹æ¬¡ç´šåˆ¥çš„å…±äº« commodity tags
        batch_commodity_tags = await self._generate_batch_tags(request)
        
        yield f"data: {json.dumps({'type': 'batch_start', 'total': total_posts, 'session_id': request.session_id, 'shared_tags_count': len(batch_commodity_tags)})}\n\n"
        
        tasks = [
            (self._generate_single_post_task, post_data, request, batch_commodity_tags)
            for post_data in request.posts
        ]
        
        async for result_event in self.post_generation_processor.process_batch_stream(tasks, progress_callback):
            if result_event.get('success'):
                successful_posts += 1
            else:
                failed_posts += 1
            
            # æ·»åŠ é€²åº¦ä¿¡æ¯
            result_event['progress'] = {
                'current': successful_posts + failed_posts,
                'total': total_posts,
                'percentage': round((successful_posts + failed_posts) / total_posts * 100, 1),
                'successful': successful_posts,
                'failed': failed_posts
            }
            yield f"data: {json.dumps(result_event)}\n\n"
        
        yield f"data: {json.dumps({'type': 'batch_end', 'total': total_posts, 'successful': successful_posts, 'failed': failed_posts, 'timestamp': datetime.now().isoformat()})}\n\n"
    
    async def _generate_single_post_task(self, post_data: Dict[str, Any], request: Any, batch_commodity_tags: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆå–®å€‹è²¼æ–‡çš„ç•°æ­¥ä»»å‹™"""
        try:
            self.logger.info(f"ğŸ“ é–‹å§‹ç”Ÿæˆå–®ç¯‡è²¼æ–‡: {post_data.get('stock_name', post_data.get('stock_code'))}")
            
            # 1. ç”Ÿæˆæ¨™æº–å…§å®¹
            standard_content = await self._generate_standard_content(post_data, request)
            
            # 2. å…§å®¹å¯©æ ¸ï¼ˆå¯é…ç½®è·³éï¼‰
            if not self._should_skip_review(request):
                review_result = await self._review_content(standard_content)
                if review_result.status == 'rejected':
                    return {
                        'type': 'post_generated',
                        'success': False,
                        'error': f"å…§å®¹å¯©æ ¸å¤±æ•—: {', '.join(review_result.issues)}",
                        'timestamp': datetime.now().isoformat()
                    }
            
            # 3. å€‹äººåŒ–è™•ç†
            personalized_title, personalized_content = self.personalization_processor.personalize_content(
                standard_content.title,
                standard_content.content,
                post_data.get('kol_serial'),
                request.batch_config,
                standard_content.serper_data,
                request.batch_config.get('trigger_type')
            )
            
            # 4. ä¿å­˜åˆ°æ•¸æ“šåº«
            post_record = await self._save_post_record(
                personalized_title,
                personalized_content,
                post_data,
                request,
                batch_commodity_tags
            )
            
            self.logger.info(f"âœ… è²¼æ–‡ç”Ÿæˆå®Œæˆ: {post_record.post_id}")
            return {
                'type': 'post_generated',
                'success': True,
                'post_id': post_record.post_id,
                'content': personalized_content,
                'timestamp': datetime.now().isoformat(),
                'kol_serial': post_data.get('kol_serial'),
                'stock_name': post_data.get('stock_name')
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆè²¼æ–‡å¤±æ•—: {e}")
            return {
                'type': 'post_generated',
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
```

## ğŸ“Š å…§å®¹ç”Ÿæˆç›£æ§

### ç”Ÿæˆçµ±è¨ˆ
```python
class ContentGenerationStats:
    def __init__(self):
        self.stats = {
            'total_generated': 0,
            'successful_generated': 0,
            'failed_generated': 0,
            'review_passed': 0,
            'review_failed': 0,
            'personalization_success': 0,
            'personalization_failed': 0,
            'average_generation_time': 0,
            'average_quality_score': 0
        }
    
    def record_generation(self, success: bool, generation_time: float, quality_score: float = None):
        """è¨˜éŒ„ç”Ÿæˆçµ±è¨ˆ"""
        self.stats['total_generated'] += 1
        
        if success:
            self.stats['successful_generated'] += 1
        else:
            self.stats['failed_generated'] += 1
        
        if quality_score:
            self.stats['average_quality_score'] = (
                (self.stats['average_quality_score'] * (self.stats['total_generated'] - 1) + quality_score) / 
                self.stats['total_generated']
            )
        
        # æ›´æ–°å¹³å‡ç”Ÿæˆæ™‚é–“
        self.stats['average_generation_time'] = (
            (self.stats['average_generation_time'] * (self.stats['total_generated'] - 1) + generation_time) / 
            self.stats['total_generated']
        )
```

### å“è³ªç›£æ§
```python
class ContentQualityMonitor:
    def __init__(self):
        self.quality_threshold = 0.7
        self.risk_keywords = ['æŠ•è³‡æœ‰é¢¨éšª', 'è¬¹æ…æŠ•è³‡', 'é¢¨éšªè‡ªè² ']
    
    def calculate_quality_score(self, content: str, title: str) -> float:
        """è¨ˆç®—å…§å®¹å“è³ªåˆ†æ•¸"""
        score = 0.0
        
        # 1. é•·åº¦åˆ†æ•¸ (30%)
        length_score = min(len(content) / 500, 1.0) * 0.3
        score += length_score
        
        # 2. çµæ§‹åˆ†æ•¸ (25%)
        structure_score = self._calculate_structure_score(content) * 0.25
        score += structure_score
        
        # 3. é¢¨éšªè­¦å‘Šåˆ†æ•¸ (20%)
        risk_score = self._calculate_risk_score(content) * 0.2
        score += risk_score
        
        # 4. å°ˆæ¥­æ€§åˆ†æ•¸ (15%)
        professionalism_score = self._calculate_professionalism_score(content) * 0.15
        score += professionalism_score
        
        # 5. å¯è®€æ€§åˆ†æ•¸ (10%)
        readability_score = self._calculate_readability_score(content) * 0.1
        score += readability_score
        
        return min(score, 1.0)
    
    def _calculate_structure_score(self, content: str) -> float:
        """è¨ˆç®—çµæ§‹åˆ†æ•¸"""
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ¨™æº–åˆ†æçµæ§‹
        structure_keywords = ['é¡Œæé¢', 'åŸºæœ¬é¢', 'æŠ€è¡“é¢', 'ç±Œç¢¼é¢', 'æ“ä½œå»ºè­°', 'é¢¨éšªæé†’']
        found_keywords = sum(1 for keyword in structure_keywords if keyword in content)
        return found_keywords / len(structure_keywords)
    
    def _calculate_risk_score(self, content: str) -> float:
        """è¨ˆç®—é¢¨éšªè­¦å‘Šåˆ†æ•¸"""
        found_risk_keywords = sum(1 for keyword in self.risk_keywords if keyword in content)
        return min(found_risk_keywords / len(self.risk_keywords), 1.0)
```

## ğŸ”§ å…§å®¹ç”Ÿæˆé…ç½®

### ç”Ÿæˆåƒæ•¸é…ç½®
```python
@dataclass
class GenerationParams:
    # KOL è¨­å®š
    kol_persona: str
    content_style: str
    target_audience: str
    
    # å…§å®¹é…ç½®
    article_type_distribution: Optional[Dict[str, int]] = None
    content_length_distribution: Optional[Dict[str, int]] = None
    content_style_distribution: Optional[Dict[str, int]] = None
    analysis_depth_distribution: Optional[Dict[str, int]] = None
    
    # æŠ€è¡“åƒæ•¸
    max_words: Optional[int] = None
    include_charts: Optional[bool] = None
    include_risk_warning: Optional[bool] = None
    
    # è§¸ç™¼å™¨ä¿¡æ¯
    trigger_type: Optional[str] = None
    
    # å¯©æ ¸è¨­å®š
    skip_review: bool = False
    auto_approve: bool = False
    
    # å€‹äººåŒ–è¨­å®š
    enable_personalization: bool = True
    personalization_level: str = 'full'  # full, basic, none
```

### å¯©æ ¸é–‹é—œé…ç½®
```python
class ReviewConfig:
    def __init__(self):
        self.auto_review_enabled = True
        self.manual_review_enabled = True
        self.skip_review_for_scheduled = True  # æ’ç¨‹å…§å®¹è·³éå¯©æ ¸
        self.skip_review_for_high_quality = True  # é«˜å“è³ªå…§å®¹è·³éå¯©æ ¸
        self.quality_threshold = 0.8
        self.auto_approve_threshold = 0.9
    
    def should_review(self, content: GeneratedContent, request: PostingRequest) -> bool:
        """åˆ¤æ–·æ˜¯å¦éœ€è¦å¯©æ ¸"""
        # æ’ç¨‹å…§å®¹è·³éå¯©æ ¸
        if request.batch_mode and self.skip_review_for_scheduled:
            return False
        
        # é«˜å“è³ªå…§å®¹è·³éå¯©æ ¸
        if content.quality_score >= self.quality_threshold and self.skip_review_for_high_quality:
            return False
        
        # æ‰‹å‹•è¨­å®šè·³éå¯©æ ¸
        if request.generation_params and request.generation_params.get('skip_review'):
            return False
        
        return True
    
    def should_auto_approve(self, content: GeneratedContent) -> bool:
        """åˆ¤æ–·æ˜¯å¦è‡ªå‹•é€šé"""
        return content.quality_score >= self.auto_approve_threshold
```

## ğŸ­ å€‹äººåŒ–æ¨¡çµ„è©³ç´°æµç¨‹

### å•é¡Œåˆ†æï¼šç¾æœ‰å€‹äººåŒ–æ¨¡çµ„çš„é™åˆ¶

#### ç¾æœ‰å•é¡Œï¼š
1. **éåº¦çµæ§‹åŒ–** - å›ºå®šçš„ prompt æ¨¡æ¿ï¼Œç¼ºä¹è‡ªç„¶æ€§
2. **AI æ„Ÿæ˜é¡¯** - ç°½åæª”ã€emojiã€æ ¼å¼åŒ–æ¨™é¡Œç­‰è®“å…§å®¹çœ‹èµ·ä¾†å¾ˆå‡
3. **å–®ä¸€é¢¨æ ¼** - æ¯å€‹ KOL åªèƒ½æœ‰ä¸€ç¨®å›ºå®šé¢¨æ ¼ï¼Œç¼ºä¹è®ŠåŒ–
4. **ç¼ºä¹æƒ…å¢ƒæ„ŸçŸ¥** - ç„¡æ³•æ ¹æ“šä¸åŒç™¼æ–‡æƒ…å¢ƒèª¿æ•´è¡¨é”æ–¹å¼

#### ChatGPT çš„å„ªå‹¢ï¼š
- **è‡ªç„¶å¤šæ¨£æ€§** - åŒæ¨£å…§å®¹å¯ä»¥ç”¢ç”Ÿå®Œå…¨ä¸åŒçš„è¡¨é”
- **æƒ…å¢ƒé©æ‡‰** - èƒ½æ ¹æ“šå¹³å°ã€å—çœ¾ã€ç›®çš„èª¿æ•´é¢¨æ ¼
- **é¢¨æ ¼éˆæ´»** - å¯ä»¥åŒæ™‚å…·å‚™å¤šç¨®è¡¨é”æ–¹å¼

### æ–°çš„å€‹äººåŒ–æ¶æ§‹è¨­è¨ˆ

#### 1. ç°¡åŒ–çš„ KOL è¨­å®š
```python
@dataclass
class SimplifiedKOLProfile:
    """ç°¡åŒ–çš„ KOL è¨­å®š - ç§»é™¤ AI æ„Ÿå…ƒç´ """
    # åŸºæœ¬èº«ä»½
    nickname: str
    persona: str  # æŠ€è¡“æ´¾ã€åŸºæœ¬é¢æ´¾ã€çŸ­ç·šå®¢ã€é•·ç·šæŠ•è³‡è€…
    
    # æ ¸å¿ƒé¢¨æ ¼ï¼ˆåªä¿ç•™æœ€é‡è¦çš„ï¼‰
    tone: str  # casual, professional, analytical, emotional
    expertise: str  # å°ˆç²¾é ˜åŸŸ
    
    # è¡¨é”ç¿’æ…£
    question_style: str  # direct, rhetorical, open_ended
    conclusion_style: str  # confident, cautious, neutral
    
    # å…§å®¹åå¥½
    content_length_preference: str  # short, medium, long
    technical_level: str  # beginner, intermediate, advanced
```

#### 2. æƒ…å¢ƒé©…å‹•çš„å€‹äººåŒ–
```python
@dataclass
class PersonalizationContext:
    """å€‹äººåŒ–æƒ…å¢ƒè¨­å®š"""
    # ç™¼æ–‡æƒ…å¢ƒ
    platform: str  # cmoney, facebook, line
    audience: str  # general, professional, casual
    purpose: str  # analysis, discussion, entertainment
    
    # å…§å®¹æƒ…å¢ƒ
    market_sentiment: str  # bullish, bearish, neutral
    stock_performance: str  # strong, weak, volatile
    news_impact: str  # high, medium, low
    
    # æ™‚é–“æƒ…å¢ƒ
    posting_time: str  # morning, afternoon, evening
    market_session: str  # pre_market, trading, after_hours
```

#### 3. å®Œå…¨éš¨æ©ŸåŒ–ç”Ÿæˆå™¨
```python
class TrulyNaturalGenerator:
    """çœŸæ­£è‡ªç„¶çš„ç”Ÿæˆå™¨ - å®Œå…¨éš¨æ©ŸåŒ–ï¼Œç„¡æ¨¡æ¿"""
    
    def __init__(self):
        self.openai_client = OpenAIClient()
        self.generation_count = 0  # è¨˜éŒ„ç”Ÿæˆæ¬¡æ•¸ï¼Œå¢åŠ éš¨æ©Ÿæ€§
    
    def generate_multiple_variations(self, base_content: str, kol_profile: SimplifiedKOLProfile, 
                                   context: PersonalizationContext, num_versions: int = 5) -> List[str]:
        """ç”Ÿæˆå¤šå€‹å®Œå…¨ä¸åŒçš„ç‰ˆæœ¬ä¾›é¸æ“‡"""
        
        # 1. æå–æ ¸å¿ƒä¿¡æ¯
        core_info = self._extract_core_information(base_content)
        
        # 2. ç”Ÿæˆå¤šå€‹å®Œå…¨ä¸åŒçš„ç‰ˆæœ¬
        variations = []
        for i in range(num_versions):
            variation = self._generate_completely_random_version(core_info, kol_profile, context, i)
            variations.append(variation)
        
        return variations
    
    def _generate_completely_random_version(self, core_info: Dict, kol_profile: SimplifiedKOLProfile, 
                                          context: PersonalizationContext, version_id: int) -> str:
        """ç”Ÿæˆå®Œå…¨éš¨æ©Ÿçš„ç‰ˆæœ¬ - æ¯æ¬¡éƒ½ä¸ä¸€æ¨£"""
        
        # æ§‹å»ºå®Œå…¨éš¨æ©Ÿçš„ prompt
        random_prompt = self._build_random_prompt(core_info, kol_profile, context, version_id)
        
        # èª¿ç”¨ OpenAI ç”Ÿæˆ
        response = self.openai_client.generate_content(random_prompt)
        
        # å¾Œè™•ç† - ç§»é™¤ AI æ„Ÿ
        return self._remove_ai_artifacts(response)
    
    def _build_random_prompt(self, core_info: Dict, kol_profile: SimplifiedKOLProfile, 
                           context: PersonalizationContext, version_id: int) -> str:
        """æ§‹å»ºå®Œå…¨éš¨æ©Ÿçš„ prompt - æ¯æ¬¡éƒ½ä¸ä¸€æ¨£"""
        
        # éš¨æ©Ÿé¸æ“‡è¡¨é”æ–¹å¼
        expression_styles = [
            "ç”¨æœ€è‡ªç„¶çš„å£èªåŒ–æ–¹å¼",
            "åƒåœ¨è·Ÿæœ‹å‹èŠå¤©ä¸€æ¨£",
            "ç”¨æœ€éš¨æ€§çš„èªæ°£",
            "åƒåœ¨ç™¼æœ‹å‹åœˆä¸€æ¨£",
            "ç”¨æœ€çœŸå¯¦çš„æ„Ÿå—"
        ]
        
        # éš¨æ©Ÿé¸æ“‡é•·åº¦
        length_styles = [
            "ç°¡çŸ­å¹¾å¥è©±",
            "ä¸­ç­‰é•·åº¦",
            "ç¨å¾®è©³ç´°ä¸€é»",
            "ç°¡æ½”æœ‰åŠ›",
            "éš¨æ„ç™¼æ®"
        ]
        
        # éš¨æ©Ÿé¸æ“‡é¢¨æ ¼
        tone_styles = [
            "è¼•é¬†ä¸€é»",
            "å°ˆæ¥­ä¸€é»",
            "æ„Ÿæ€§ä¸€é»",
            "ç†æ€§ä¸€é»",
            "éš¨æ€§ä¸€é»"
        ]
        
        import random
        expression = random.choice(expression_styles)
        length = random.choice(length_styles)
        tone = random.choice(tone_styles)
        
        # å¢åŠ æ™‚é–“æˆ³éš¨æ©Ÿæ€§
        timestamp = self.generation_count + version_id
        self.generation_count += 1
        
        prompt = f"""
ä½ æ˜¯ä¸€å€‹{kol_profile.persona}é¢¨æ ¼çš„æŠ•è³‡è€…ï¼Œåå«{kol_profile.nickname}ã€‚

ç¾åœ¨è¦ç™¼æ–‡è¨è«–é€™æ”¯è‚¡ç¥¨ï¼š{core_info['stock_name']}

æ ¸å¿ƒä¿¡æ¯ï¼š
- è‚¡ç¥¨è¡¨ç¾ï¼š{core_info['stock_performance']}
- ä¸»è¦è§€é»ï¼š{core_info['main_points']}
- å¸‚å ´æƒ…æ³ï¼š{context.market_sentiment}

è¦æ±‚ï¼š
1. {expression}è¡¨é”
2. {length}
3. {tone}
4. å®Œå…¨ä¸è¦ç”¨ä»»ä½•æ ¼å¼åŒ–æ¨™é¡Œï¼ˆå¦‚ã€æŠ€è¡“åˆ†æã€‘ç­‰ï¼‰
5. ä¸è¦ç”¨ emoji
6. ä¸è¦ç”¨ç°½åæª”
7. å°±åƒçœŸäººåœ¨èŠå¤©ä¸€æ¨£è‡ªç„¶
8. æ¯æ¬¡è¡¨é”éƒ½è¦ä¸ä¸€æ¨£ï¼Œè¦æœ‰è‡ªå·±çš„å€‹æ€§

è«‹ç”Ÿæˆä¸€æ®µå®Œå…¨è‡ªç„¶çš„å…§å®¹ï¼Œå°±åƒä½ çœŸçš„åœ¨è·Ÿæœ‹å‹åˆ†äº«ä½ çš„çœ‹æ³•ä¸€æ¨£ã€‚
"""
        
        return prompt
    
    def _extract_core_information(self, content: str) -> Dict:
        """æå–æ ¸å¿ƒä¿¡æ¯ï¼Œå»é™¤æ‰€æœ‰æ ¼å¼åŒ–å…ƒç´ """
        return {
            'stock_name': self._extract_stock_name(content),
            'stock_performance': self._extract_performance(content),
            'main_points': self._extract_main_points(content)
        }
```

#### 4. æ ¸å¿ƒå€‹äººåŒ–æµç¨‹
```python
class EnhancedPersonalizationFlow:
    """å¢å¼·ç‰ˆå€‹äººåŒ–æµç¨‹ - å®Œå…¨éš¨æ©ŸåŒ–ï¼Œç„¡æ¨¡æ¿"""
    
    def __init__(self):
        self.natural_generator = TrulyNaturalGenerator()
        self.context_analyzer = ContextAnalyzer()
    
    def personalize_content(self, standard_content: str, kol_serial: str, 
                          trigger_data: Dict = None) -> Tuple[str, str]:
        """å€‹äººåŒ–å…§å®¹è™•ç† - å®Œå…¨éš¨æ©ŸåŒ–ï¼Œç”Ÿæˆå¤šå€‹ç‰ˆæœ¬ä¾›é¸æ“‡"""
        
        try:
            # 1. ç²å– KOL è¨­å®š
            kol_profile = self._get_kol_profile(kol_serial)
            
            # 2. åˆ†æç™¼æ–‡æƒ…å¢ƒ
            context = self.context_analyzer.analyze_context(trigger_data, standard_content)
            
            # 3. ç”Ÿæˆå¤šå€‹å®Œå…¨éš¨æ©Ÿçš„è‡ªç„¶å…§å®¹ç‰ˆæœ¬
            variations = self.natural_generator.generate_multiple_variations(
                standard_content, kol_profile, context, num_versions=5
            )
            
            # 4. é¸æ“‡æœ€ä½³ç‰ˆæœ¬ï¼ˆå¯ä»¥æ ¹æ“šå“è³ªã€è‡ªç„¶åº¦ç­‰æ¨™æº–ï¼‰
            selected_content = self._select_best_version(variations, kol_profile, context)
            
            # 5. ç”Ÿæˆéš¨æ©Ÿæ¨™é¡Œ
            personalized_title = self._generate_random_title(
                selected_content, kol_profile, context
            )
            
            # 6. æœ€çµ‚æ¸…ç† - ç§»é™¤ä»»ä½•æ®˜ç•™çš„ AI æ„Ÿ
            final_content = self._final_cleanup(selected_content)
            final_title = self._final_cleanup(personalized_title)
            
            return final_title, final_content
            
        except Exception as e:
            logger.error(f"âŒ å€‹äººåŒ–è™•ç†å¤±æ•—: {e}")
            return self._fallback_to_simple_personalization(standard_content, kol_serial)
    
    def _select_best_version(self, variations: List[str], kol_profile: SimplifiedKOLProfile, 
                           context: PersonalizationContext) -> str:
        """é¸æ“‡æœ€ä½³ç‰ˆæœ¬ - å¯ä»¥æ ¹æ“šå¤šç¨®æ¨™æº–"""
        
        # å¯ä»¥æ ¹æ“šä¸åŒæ¨™æº–é¸æ“‡ï¼š
        # 1. éš¨æ©Ÿé¸æ“‡ï¼ˆæœ€ç°¡å–®ï¼‰
        # 2. æ ¹æ“šå“è³ªåˆ†æ•¸é¸æ“‡
        # 3. æ ¹æ“šè‡ªç„¶åº¦é¸æ“‡
        # 4. æ ¹æ“š KOL é¢¨æ ¼åŒ¹é…åº¦é¸æ“‡
        
        import random
        
        # æš«æ™‚ä½¿ç”¨éš¨æ©Ÿé¸æ“‡ï¼Œå¾ŒçºŒå¯ä»¥åŠ å…¥æ›´è¤‡é›œçš„é¸æ“‡é‚è¼¯
        return random.choice(variations)
    
    def _generate_random_title(self, content: str, kol_profile: SimplifiedKOLProfile, 
                             context: PersonalizationContext) -> str:
        """ç”Ÿæˆå®Œå…¨éš¨æ©Ÿçš„æ¨™é¡Œ"""
        
        # æå–è‚¡ç¥¨åç¨±
        stock_name = self._extract_stock_name(content)
        
        # å®Œå…¨éš¨æ©Ÿçš„æ¨™é¡Œç”Ÿæˆæ–¹å¼
        import random
        
        # éš¨æ©Ÿé¸æ“‡æ¨™é¡Œé¢¨æ ¼
        title_approaches = [
            lambda: f"{stock_name} {random.choice(['ä»Šå¤©', 'é€™å€‹', 'é€™æ”¯'])} {random.choice(['èµ°å‹¢', 'è¡¨ç¾', 'ç›¤'])}",
            lambda: f"{random.choice(['çœ‹åˆ°', 'è§€å¯Ÿ', 'åˆ†æ'])} {stock_name}",
            lambda: f"{stock_name} {random.choice(['ä½ å€‘', 'å¤§å®¶', 'æœ‰äºº'])} {random.choice(['æ€éº¼çœ‹', 'è¦ºå¾—', 'æƒ³æ³•'])}ï¼Ÿ",
            lambda: f"{random.choice(['é—œæ–¼', 'å°æ–¼', 'é€™æ”¯'])} {stock_name}",
            lambda: f"{stock_name} {random.choice(['åˆ†æ', 'çœ‹æ³•', 'è§€å¯Ÿ', 'è§€é»'])}"
        ]
        
        # éš¨æ©Ÿé¸æ“‡ä¸€ç¨®æ–¹å¼
        selected_approach = random.choice(title_approaches)
        return selected_approach()
    
    def _final_cleanup(self, content: str) -> str:
        """æœ€çµ‚æ¸…ç† - ç§»é™¤ä»»ä½•æ®˜ç•™çš„ AI æ„Ÿ"""
        
        # ç§»é™¤æ‰€æœ‰å¯èƒ½çš„ AI æ ¼å¼åŒ–å…ƒç´ 
        content = re.sub(r'ã€.*?ã€‘', '', content)
        content = re.sub(r'## .*?\n', '', content)
        content = re.sub(r'â¸».*$', '', content, flags=re.MULTILINE)
        content = re.sub(r'---.*$', '', content, flags=re.MULTILINE)
        content = re.sub(r'[ğŸ˜€-ğŸ™]{2,}', '', content)
        content = re.sub(r'^\d+ï¸âƒ£\s*', '', content, flags=re.MULTILINE)
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        # ç§»é™¤éæ–¼æ­£å¼çš„ç”¨è©
        formal_words = ['å› æ­¤', 'ç„¶è€Œ', 'æ­¤å¤–', 'å€¼å¾—æ³¨æ„çš„æ˜¯', 'ç¸½è€Œè¨€ä¹‹']
        for word in formal_words:
            content = content.replace(word, '')
        
        return content.strip()
    
    def _remove_ai_artifacts(self, content: str) -> str:
        """ç§»é™¤ AI æ„Ÿå…ƒç´ """
        
        # ç§»é™¤æ ¼å¼åŒ–æ¨™é¡Œ
        content = re.sub(r'ã€.*?ã€‘', '', content)
        content = re.sub(r'## .*?\n', '', content)
        
        # ç§»é™¤ç°½åæª”
        content = re.sub(r'â¸».*$', '', content, flags=re.MULTILINE)
        content = re.sub(r'---.*$', '', content, flags=re.MULTILINE)
        
        # ç§»é™¤éå¤šçš„ emoji
        content = re.sub(r'[ğŸ˜€-ğŸ™]{2,}', '', content)
        
        # ç§»é™¤éåº¦çµæ§‹åŒ–çš„ç·¨è™Ÿ
        content = re.sub(r'^\d+ï¸âƒ£\s*', '', content, flags=re.MULTILINE)
        
        # æ¸…ç†å¤šé¤˜çš„æ›è¡Œ
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        return content.strip()
    
    def _generate_natural_title(self, content: str, kol_profile: SimplifiedKOLProfile, 
                              context: PersonalizationContext) -> str:
        """ç”Ÿæˆè‡ªç„¶çš„æ¨™é¡Œ"""
        
        # æå–è‚¡ç¥¨åç¨±
        stock_name = self._extract_stock_name(content)
        
        # æ ¹æ“š KOL é¢¨æ ¼ç”Ÿæˆæ¨™é¡Œ
        if kol_profile.tone == 'casual':
            title_templates = [
                f"{stock_name} ä»Šå¤©é€™å€‹èµ°å‹¢",
                f"{stock_name} ä½ å€‘æ€éº¼çœ‹ï¼Ÿ",
                f"{stock_name} é€™å€‹ç›¤"
            ]
        elif kol_profile.tone == 'professional':
            title_templates = [
                f"{stock_name} æŠ€è¡“åˆ†æ",
                f"{stock_name} ç›¤å‹¢è§€å¯Ÿ",
                f"{stock_name} æŠ•è³‡è§€é»"
            ]
        else:
            title_templates = [
                f"{stock_name} åˆ†æ",
                f"{stock_name} çœ‹æ³•",
                f"{stock_name} è§€å¯Ÿ"
            ]
        
        import random
        return random.choice(title_templates)
```

#### 5. æƒ…å¢ƒåˆ†æå™¨
```python
class ContextAnalyzer:
    """æƒ…å¢ƒåˆ†æå™¨ - åˆ†æç™¼æ–‡æƒ…å¢ƒ"""
    
    def analyze_context(self, trigger_data: Dict, content: str) -> PersonalizationContext:
        """åˆ†æç™¼æ–‡æƒ…å¢ƒ"""
        
        # åˆ†æå¸‚å ´æƒ…ç·’
        market_sentiment = self._analyze_market_sentiment(content, trigger_data)
        
        # åˆ†æè‚¡ç¥¨è¡¨ç¾
        stock_performance = self._analyze_stock_performance(trigger_data)
        
        # åˆ†ææ–°èå½±éŸ¿
        news_impact = self._analyze_news_impact(trigger_data)
        
        # åˆ†ææ™‚é–“æƒ…å¢ƒ
        posting_time = self._get_posting_time()
        market_session = self._get_market_session()
        
        return PersonalizationContext(
            platform='cmoney',  # é è¨­å¹³å°
            audience='general',
            purpose='analysis',
            market_sentiment=market_sentiment,
            stock_performance=stock_performance,
            news_impact=news_impact,
            posting_time=posting_time,
            market_session=market_session
        )
    
    def _analyze_market_sentiment(self, content: str, trigger_data: Dict) -> str:
        """åˆ†æå¸‚å ´æƒ…ç·’"""
        bullish_keywords = ['ä¸Šæ¼²', 'çªç ´', 'å¼·å‹¢', 'çœ‹å¥½', 'åˆ©å¤š']
        bearish_keywords = ['ä¸‹è·Œ', 'è·Œç ´', 'å¼±å‹¢', 'çœ‹ç©º', 'åˆ©ç©º']
        
        content_lower = content.lower()
        bullish_count = sum(1 for keyword in bullish_keywords if keyword in content_lower)
        bearish_count = sum(1 for keyword in bearish_keywords if keyword in content_lower)
        
        if bullish_count > bearish_count:
            return 'bullish'
        elif bearish_count > bullish_count:
            return 'bearish'
        else:
            return 'neutral'
```

### æ–°çš„å€‹äººåŒ–æµç¨‹åœ–

```mermaid
graph TD
    A[æ¨™æº–å…§å®¹] --> B[æå–æ ¸å¿ƒä¿¡æ¯]
    B --> C[åˆ†æç™¼æ–‡æƒ…å¢ƒ]
    C --> D[å®Œå…¨éš¨æ©ŸåŒ–ç”Ÿæˆ]
    D --> E[ç”Ÿæˆ 5 å€‹ä¸åŒç‰ˆæœ¬]
    E --> F[é¸æ“‡æœ€ä½³ç‰ˆæœ¬]
    F --> G[æœ€çµ‚æ¸…ç† AI æ„Ÿ]
    G --> H[éš¨æ©Ÿç”Ÿæˆæ¨™é¡Œ]
    H --> I[æœ€çµ‚å€‹äººåŒ–å…§å®¹]
    I --> J{æ˜¯å¦éœ€è¦å¯©æ ¸}
    J -->|æ˜¯| K[æ–‡ç« å¯©æ ¸]
    J -->|å¦| L[ç›´æ¥ç™¼å¸ƒ]
    K --> M{å¯©æ ¸çµæœ}
    M -->|é€šé| L[ç™¼å¸ƒè²¼æ–‡]
    M -->|æ‹’çµ•| N[é‡æ–°å€‹äººåŒ–]
    N --> D
    
    O[KOL è¨­å®š] --> D
    P[è§¸ç™¼å™¨æ•¸æ“š] --> C
    Q[æ™‚é–“æƒ…å¢ƒ] --> C
    R[éš¨æ©Ÿç¨®å­] --> D
```

### é—œéµæ”¹é€²é»

#### 1. å®Œå…¨éš¨æ©ŸåŒ– - ç„¡æ¨¡æ¿
- âŒ å®Œå…¨ç§»é™¤æ‰€æœ‰æ¨¡æ¿å’Œå›ºå®šæ ¼å¼
- âŒ ä¸å†ä½¿ç”¨é å®šç¾©çš„é–‹å ´ç™½ã€è½‰æŠ˜è©ã€çµå°¾
- âœ… æ¯æ¬¡ç”Ÿæˆéƒ½å®Œå…¨ä¸åŒï¼Œå°±åƒ ChatGPT ä¸€æ¨£

#### 2. çœŸæ­£çš„å¤šæ¨£æ€§
- æ¯æ¬¡ç”Ÿæˆ 5 å€‹å®Œå…¨ä¸åŒçš„ç‰ˆæœ¬
- éš¨æ©Ÿé¸æ“‡å…¶ä¸­ä¸€å€‹ï¼ˆä¸é¸æ“‡"æœ€è‡ªç„¶"çš„ï¼‰
- å¢åŠ æ™‚é–“æˆ³å’Œç‰ˆæœ¬ ID ä½œç‚ºéš¨æ©Ÿç¨®å­

#### 3. å‹•æ…‹ Prompt æ§‹å»º
- éš¨æ©Ÿé¸æ“‡è¡¨é”æ–¹å¼ã€é•·åº¦ã€é¢¨æ ¼
- æ¯æ¬¡ prompt éƒ½ä¸ä¸€æ¨£
- é¿å…é‡è¤‡çš„è¡¨é”æ¨¡å¼

#### 4. å¾¹åº•æ¸…ç† AI æ„Ÿ
- ç§»é™¤æ‰€æœ‰æ ¼å¼åŒ–å…ƒç´ 
- ç§»é™¤éæ–¼æ­£å¼çš„ç”¨è©
- ä¿æŒæœ€è‡ªç„¶çš„å£èªåŒ–è¡¨é”

### å¯¦ç¾å»ºè­°

1. **æ¼¸é€²å¼æ”¹é€²** - å…ˆå¯¦ç¾æ ¸å¿ƒæµç¨‹ï¼Œå†é€æ­¥å„ªåŒ–
2. **A/B æ¸¬è©¦** - å°æ¯”æ–°èˆŠå€‹äººåŒ–æ•ˆæœ
3. **ç”¨æˆ¶åé¥‹** - æ”¶é›†çœŸå¯¦ç”¨æˆ¶å°å…§å®¹è‡ªç„¶æ€§çš„è©•åƒ¹
4. **æŒçºŒå„ªåŒ–** - æ ¹æ“šæ•ˆæœèª¿æ•´é¢¨æ ¼æ¨¡æ¿å’Œæƒ…å¢ƒåˆ†æ

é€™å€‹æ¶æ§‹çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**ç”¨ç°¡å–®çš„æ–¹æ³•å¯¦ç¾è¤‡é›œçš„è‡ªç„¶æ€§**ï¼Œè€Œä¸æ˜¯ç”¨è¤‡é›œçš„æ–¹æ³•å¯¦ç¾ç°¡å–®çš„æ•ˆæœã€‚
