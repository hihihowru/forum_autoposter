#!/bin/bash

# =============================================================================
# Git Ê™îÊ°àÊïëÊè¥ËÖ≥Êú¨ v2ÔºöÂæû Cursor Local History ÈÇÑÂéüÊ™îÊ°àÂà∞Êö´Â≠òÂçÄ
# ‰ΩøÁî®ÊñπÊ≥ïÔºöchmod +x restore_from_local_history_v2.sh && ./restore_from_local_history_v2.sh
# ‰øÆÊîπËÆäÊï∏ÔºöDIAG_DIR (ÂàÜÊûêËº∏Âá∫Ë≥áÊñôÂ§æÂêçÁ®±)
# =============================================================================

# Ë®≠ÂÆöÂàÜÊûêËº∏Âá∫Ë≥áÊñôÂ§æ
DIAG_DIR="n8n-migration-project_DIAG_20251013_113216"

# Ê™¢Êü•Ë≥áÊñôÂ§æÊòØÂê¶Â≠òÂú®
if [ ! -d "$DIAG_DIR" ]; then
    echo "‚ùå ÈåØË™§ÔºöÊâæ‰∏çÂà∞ÂàÜÊûêË≥áÊñôÂ§æ '$DIAG_DIR'"
    echo "Ë´ãÁ¢∫Ë™çË≥áÊñôÂ§æÂ≠òÂú®ÔºåÊàñ‰øÆÊîπËÖ≥Êú¨‰∏≠ÁöÑ DIAG_DIR ËÆäÊï∏"
    exit 1
fi

# Ë®≠ÂÆöË∑ØÂæë
RESTORE_STAGE_DIR="$DIAG_DIR/RESTORE_STAGE"
CURSOR_BASE_DIR="$HOME/Library/Application Support/Cursor"
REPORT_FILE="$RESTORE_STAGE_DIR/report_map.csv"
NOT_FOUND_FILE="$RESTORE_STAGE_DIR/not_found.txt"
ALTERNATIVES_FILE="$RESTORE_STAGE_DIR/alternatives.txt"
SUMMARY_FILE="$RESTORE_STAGE_DIR/_SUMMARY.txt"

# Âª∫Á´ãÊö´Â≠òÁõÆÈåÑ
mkdir -p "$RESTORE_STAGE_DIR"

echo "üîç ÈñãÂßãÂæû Cursor Local History ÈÇÑÂéüÊ™îÊ°à..."
echo "üìÅ Êö´Â≠òÁõÆÈåÑÔºö$RESTORE_STAGE_DIR"
echo ""

# Ê∏ÖÁ©∫Ëº∏Âá∫Ê™îÊ°à
> "$REPORT_FILE"
> "$NOT_FOUND_FILE"
> "$ALTERNATIVES_FILE"

# ÂØ´ÂÖ• CSV Ê®ôÈ°å
echo "Áõ∏Â∞çË∑ØÂæë,‰æÜÊ∫êÊ™î,Êö´Â≠òË∑ØÂæë,‰øÆÊîπÊôÇÈñì,Ê™îÊ°àÂ§ßÂ∞è" > "$REPORT_FILE"

# URL Ëß£Á¢ºÂáΩÊï∏
url_decode() {
    echo "$1" | python3 -c "
import sys
import urllib.parse
for line in sys.stdin:
    print(urllib.parse.unquote(line.strip()))
"
}

# Âêà‰ΩµÊ∏ÖÂñÆÊ™îÊ°à
TEMP_LIST="$RESTORE_STAGE_DIR/temp_file_list.txt"
cat "$DIAG_DIR/maybe_deleted_paths.txt" "$DIAG_DIR/maybe_overwritten_paths.txt" 2>/dev/null | sort | uniq > "$TEMP_LIST"

TOTAL_FILES=$(wc -l < "$TEMP_LIST")
FOUND_COUNT=0
NOT_FOUND_COUNT=0
ALTERNATIVES_COUNT=0

echo "üìã Á∏ΩÂÖ±ÈúÄË¶ÅËôïÁêÜ $TOTAL_FILES ÂÄãÊ™îÊ°à"
echo ""

# ËôïÁêÜÊØèÂÄãÊ™îÊ°à
while IFS= read -r file_path; do
    if [ -z "$file_path" ]; then
        continue
    fi
    
    echo "üîç ËôïÁêÜÔºö$file_path"
    
    # URL Ëß£Á¢ºÊ™îÊ°àË∑ØÂæë
    decoded_path=$(url_decode "$file_path")
    filename=$(basename "$decoded_path")
    
    # ÊêúÂ∞ãÂÄôÈÅ∏Ê™îÊ°à
    candidates=()
    
    # ÊêúÂ∞ãÁØÑÂúç
    search_paths=(
        "$CURSOR_BASE_DIR/User/History"
        "$CURSOR_BASE_DIR/User/workspaceStorage"
        "$CURSOR_BASE_DIR/.cursor"
        ".history"
        ".cursor"
        ".vscode"
    )
    
    # Âú®ÊØèÂÄãÊêúÂ∞ãË∑ØÂæë‰∏≠Â∞ãÊâæÊ™îÊ°à
    for search_path in "${search_paths[@]}"; do
        if [ -d "$search_path" ]; then
            # ÊêúÂ∞ã entries.json Ê™îÊ°à
            while IFS= read -r entry_file; do
                if [ -f "$entry_file" ]; then
                    # Ê™¢Êü•ÊòØÂê¶ÂåÖÂê´ÁõÆÊ®ôÊ™îÊ°àË∑ØÂæë
                    if grep -q "$file_path" "$entry_file" 2>/dev/null || grep -q "$decoded_path" "$entry_file" 2>/dev/null || grep -q "$filename" "$entry_file" 2>/dev/null; then
                        # ÂèñÂæóË©≤ entry ÁöÑ‰øÆÊîπÊôÇÈñì
                        mod_time=$(stat -f "%m" "$entry_file" 2>/dev/null || echo "0")
                        candidates+=("$entry_file|$mod_time")
                    fi
                fi
            done < <(find "$search_path" -name "entries.json" 2>/dev/null)
            
            # ÊêúÂ∞ãÂØ¶ÈöõÊ™îÊ°àÂÖßÂÆπ
            while IFS= read -r content_file; do
                if [ -f "$content_file" ]; then
                    # Ê™¢Êü•Ê™îÊ°àÂÖßÂÆπÊòØÂê¶ÂåÖÂê´ÁõÆÊ®ôË∑ØÂæëÊàñÊ™îÂêç
                    if grep -q "$file_path" "$content_file" 2>/dev/null || grep -q "$decoded_path" "$content_file" 2>/dev/null || grep -q "$filename" "$content_file" 2>/dev/null; then
                        mod_time=$(stat -f "%m" "$content_file" 2>/dev/null || echo "0")
                        candidates+=("$content_file|$mod_time")
                    fi
                fi
            done < <(find "$search_path" -type f \( -name "*.tsx" -o -name "*.ts" -o -name "*.jsx" -o -name "*.js" -o -name "*.py" -o -name "*.json" -o -name "*.md" \) 2>/dev/null)
        fi
    done
    
    # ÈÅ∏ÊìáÊúÄÊñ∞ÁöÑÊ™îÊ°à
    if [ ${#candidates[@]} -gt 0 ]; then
        # Êåâ‰øÆÊîπÊôÇÈñìÊéíÂ∫èÔºåÂèñÊúÄÊñ∞ÁöÑ
        latest_file=""
        latest_time=0
        
        for candidate in "${candidates[@]}"; do
            candidate_file=$(echo "$candidate" | cut -d'|' -f1)
            candidate_time=$(echo "$candidate" | cut -d'|' -f2)
            
            if [ "$candidate_time" -gt "$latest_time" ]; then
                latest_time="$candidate_time"
                latest_file="$candidate_file"
            fi
        done
        
        # ÂòóË©¶ÂæûÊ™îÊ°à‰∏≠ÊèêÂèñÂÖßÂÆπ
        if [ -f "$latest_file" ]; then
            # Ê™¢Êü•ÊòØÂê¶ÁÇ∫ entries.json
            if [[ "$latest_file" == *"entries.json" ]]; then
                # Âæû JSON ‰∏≠ÊèêÂèñÊ™îÊ°àÂÖßÂÆπ
                temp_content=$(mktemp)
                
                python3 -c "
import json
import sys
import os

try:
    with open('$latest_file', 'r') as f:
        data = json.load(f)
    
    # Â∞ãÊâæÂåÖÂê´ÁõÆÊ®ôË∑ØÂæëÁöÑË≥áÊ∫ê
    target_path = '$file_path'
    decoded_path = '$decoded_path'
    target_filename = '$filename'
    
    for entry in data.get('entries', []):
        entry_id = entry.get('id', '')
        # Ê™¢Êü•ÊòØÂê¶ÊúâÂ∞çÊáâÁöÑÊ™îÊ°àÂÖßÂÆπ
        entry_dir = os.path.dirname('$latest_file')
        content_file = os.path.join(entry_dir, entry_id)
        
        if os.path.exists(content_file):
            with open(content_file, 'r', encoding='utf-8', errors='ignore') as cf:
                content = cf.read()
                if target_path in content or decoded_path in content or target_filename in content:
                    print(content)
                    break
except Exception as e:
    pass
" > "$temp_content" 2>/dev/null
                
                # Ê™¢Êü•ÊòØÂê¶ÊúâÂÖßÂÆπ
                if [ -s "$temp_content" ]; then
                    content_source="$temp_content"
                else
                    rm -f "$temp_content"
                    content_source="$latest_file"
                fi
            else
                content_source="$latest_file"
            fi
            
            # Âª∫Á´ãÁõÆÊ®ôÁõÆÈåÑ
            target_dir="$RESTORE_STAGE_DIR/$(dirname "$decoded_path")"
            mkdir -p "$target_dir"
            
            # ËôïÁêÜÈáçË§áÊ™îÂêç
            target_file="$RESTORE_STAGE_DIR/$decoded_path"
            counter=1
            while [ -f "$target_file" ]; do
                target_file="${target_file%.*}.alt${counter}.${target_file##*.}"
                counter=$((counter + 1))
            done
            
            # Ë§áË£ΩÊ™îÊ°à
            cp "$content_source" "$target_file"
            
            if [ $? -eq 0 ]; then
                # ÂèñÂæóÊ™îÊ°àË≥áË®ä
                file_size=$(stat -f "%z" "$target_file" 2>/dev/null || echo "0")
                mod_time_str=$(date -r "$latest_time" "+%Y-%m-%d %H:%M:%S" 2>/dev/null || echo "Êú™Áü•")
                
                # Ë®òÈåÑÂà∞ CSV
                echo "$decoded_path,$latest_file,$target_file,$mod_time_str,$file_size" >> "$REPORT_FILE"
                
                echo "  ‚úÖ Â∑≤Êö´Â≠òÔºö$target_file"
                FOUND_COUNT=$((FOUND_COUNT + 1))
                
                # Ë®òÈåÑÊõø‰ª£ÈÅ∏È†Ö
                if [ ${#candidates[@]} -gt 1 ]; then
                    echo "$decoded_path: ${#candidates[@]} ÂÄãÂÄôÈÅ∏Ê™îÊ°à" >> "$ALTERNATIVES_FILE"
                    ALTERNATIVES_COUNT=$((ALTERNATIVES_COUNT + 1))
                fi
            else
                echo "$file_path" >> "$NOT_FOUND_FILE"
                echo "  ‚ùå Ë§áË£ΩÂ§±Êïó"
                NOT_FOUND_COUNT=$((NOT_FOUND_COUNT + 1))
            fi
            
            # Ê∏ÖÁêÜÊö´Â≠òÊ™îÊ°à
            if [ -n "$temp_content" ] && [ -f "$temp_content" ]; then
                rm -f "$temp_content"
            fi
        else
            echo "$file_path" >> "$NOT_FOUND_FILE"
            echo "  ‚ùå Êâæ‰∏çÂà∞Ê™îÊ°à"
            NOT_FOUND_COUNT=$((NOT_FOUND_COUNT + 1))
        fi
    else
        echo "$file_path" >> "$NOT_FOUND_FILE"
        echo "  ‚ùå Êâæ‰∏çÂà∞ÂÄôÈÅ∏Ê™î"
        NOT_FOUND_COUNT=$((NOT_FOUND_COUNT + 1))
    fi
    
    echo ""
done < "$TEMP_LIST"

# ÁîüÊàêÁ∏ΩÁµêÂ†±Âëä
cat > "$SUMMARY_FILE" << EOF
Git Ê™îÊ°àÊïëÊè¥Á∏ΩÁµêÂ†±Âëä v2
ÁîüÊàêÊôÇÈñìÔºö$(date)
===========================================

üìä ËôïÁêÜÁµêÊûúÔºö
- Á∏ΩÊ™îÊ°àÊï∏Ôºö$TOTAL_FILES
- ÊàêÂäüÈÇÑÂéüÔºö$FOUND_COUNT
- Êâæ‰∏çÂà∞Ôºö$NOT_FOUND_COUNT
- ÊúâÊõø‰ª£ÈÅ∏È†ÖÔºö$ALTERNATIVES_COUNT
- ÊàêÂäüÁéáÔºö$(( (FOUND_COUNT * 100) / TOTAL_FILES ))%

üìÅ Ëº∏Âá∫Ê™îÊ°àÔºö
- report_map.csvÔºöË©≥Á¥∞ÈÇÑÂéüË®òÈåÑ
- not_found.txtÔºöÊâæ‰∏çÂà∞ÁöÑÊ™îÊ°àÊ∏ÖÂñÆ
- alternatives.txtÔºöÊúâÂ§öÂÄãÂÄôÈÅ∏ÁöÑÊ™îÊ°à
- RESTORE_STAGE/ÔºöÈÇÑÂéüÁöÑÊ™îÊ°àÊö´Â≠òÂçÄ

üîß ‰∏ã‰∏ÄÊ≠•Ôºö
1. Ê™¢Êü• RESTORE_STAGE/ ÁõÆÈåÑ‰∏≠ÁöÑÊ™îÊ°à
2. Âª∫Á´ã apply_list.txtÔºà‰∏ÄË°å‰∏ÄÂÄãË¶ÅÈÇÑÂéüÁöÑÊ™îÊ°àË∑ØÂæëÔºâ
3. Âü∑Ë°å apply_staged_restore.sh Â•óÁî®ÈÇÑÂéü

‚ö†Ô∏è  Ê≥®ÊÑèÔºö
- ÊâÄÊúâÊ™îÊ°àÈÉΩÂ∑≤Ë§áË£ΩÂà∞Êö´Â≠òÂçÄÔºå‰∏çÊúÉË¶ÜËìãÂéüÂ∞àÊ°à
- Ë´ã‰ªîÁ¥∞Ê™¢Êü•Ê™îÊ°àÂÖßÂÆπÂæåÂÜçÊ±∫ÂÆöÊòØÂê¶Â•óÁî®
- ÊîØÊè¥ URL Á∑®Á¢ºÊ™îÂêçËá™ÂãïËß£Á¢º
EOF

# Ê∏ÖÁêÜÊö´Â≠òÊ™îÊ°à
rm -f "$TEMP_LIST"

echo "‚úÖ ÈÇÑÂéüÂÆåÊàêÔºÅ"
echo "üìÅ Êö´Â≠òÁõÆÈåÑÔºö$RESTORE_STAGE_DIR"
echo "üìä ÊàêÂäüÈÇÑÂéüÔºö$FOUND_COUNT/$TOTAL_FILES ÂÄãÊ™îÊ°à"
echo "üìã Ë©≥Á¥∞Â†±ÂëäÔºö$SUMMARY_FILE"
echo ""
echo "üîß ‰∏ã‰∏ÄÊ≠•Ôºö"
echo "   1. Ê™¢Êü• RESTORE_STAGE/ ÁõÆÈåÑ‰∏≠ÁöÑÊ™îÊ°à"
echo "   2. Âª∫Á´ã apply_list.txt"
echo "   3. Âü∑Ë°å apply_staged_restore.sh"

