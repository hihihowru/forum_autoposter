#!/usr/bin/env python3
"""
ç›¤å¾Œæ¼²åœæ©Ÿå™¨äººç¯„ä¾‹æ–‡ç« ç”Ÿæˆå™¨
ç”Ÿæˆä¸‰å€‹ä¸åŒæ•¸æ“šçµ„åˆçš„ç¯„ä¾‹æ–‡ç« ï¼š
1. Serper API + æœˆç‡Ÿæ”¶
2. Serper API + è²¡å ±  
3. Serper API + è‚¡åƒ¹OHLC/æˆäº¤é‡è®ŠåŒ–
"""

import asyncio
import os
import sys
from datetime import datetime
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.core.main_workflow_engine import MainWorkflowEngine, WorkflowConfig, WorkflowType
from src.utils.logger import setup_logger

logger = setup_logger(__name__)

class AfterHoursLimitUpExampleGenerator:
    """ç›¤å¾Œæ¼²åœç¯„ä¾‹æ–‡ç« ç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.workflow_engine = MainWorkflowEngine()
        logger.info("ç›¤å¾Œæ¼²åœç¯„ä¾‹æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def generate_example_articles(self):
        """ç”Ÿæˆä¸‰å€‹ç¯„ä¾‹æ–‡ç« """
        logger.info("é–‹å§‹ç”Ÿæˆä¸‰å€‹ç¯„ä¾‹æ–‡ç« ...")
        
        # ç¯„ä¾‹è‚¡ç¥¨æ•¸æ“š
        example_stocks = [
            {
                "stock_id": "4968",
                "stock_name": "ç«‹ç©",
                "change_percent": 9.8,
                "volume_amount": 2.5,  # 2.5å„„å…ƒ
                "volume_rank": 15,
                "data_type": "revenue"  # æœˆç‡Ÿæ”¶
            },
            {
                "stock_id": "3491", 
                "stock_name": "æ˜‡é”ç§‘æŠ€",
                "change_percent": 9.9,
                "volume_amount": 1.8,  # 1.8å„„å…ƒ
                "volume_rank": 25,
                "data_type": "earnings"  # è²¡å ±
            },
            {
                "stock_id": "8033",
                "stock_name": "é›·è™",
                "change_percent": 9.7,
                "volume_amount": 3.2,  # 3.2å„„å…ƒ
                "volume_rank": 8,
                "data_type": "ohlc"  # OHLC/æˆäº¤é‡
            }
        ]
        
        generated_articles = []
        
        for i, stock_data in enumerate(example_stocks, 1):
            logger.info(f"ç”Ÿæˆç¬¬ {i} å€‹ç¯„ä¾‹æ–‡ç« : {stock_data['stock_name']} ({stock_data['data_type']})")
            
            try:
                # ç”Ÿæˆæ–‡ç« å…§å®¹
                article = await self._generate_single_article(stock_data)
                generated_articles.append(article)
                
                logger.info(f"âœ… ç¬¬ {i} å€‹ç¯„ä¾‹æ–‡ç« ç”Ÿæˆå®Œæˆ")
                
            except Exception as e:
                logger.error(f"âŒ ç¬¬ {i} å€‹ç¯„ä¾‹æ–‡ç« ç”Ÿæˆå¤±æ•—: {e}")
                continue
        
        # è¨˜éŒ„åˆ° Google Sheets
        await self._record_articles_to_sheets(generated_articles)
        
        logger.info(f"ğŸ‰ ç¯„ä¾‹æ–‡ç« ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(generated_articles)} ç¯‡æ–‡ç« ")
        return generated_articles
    
    async def _generate_single_article(self, stock_data):
        """ç”Ÿæˆå–®ç¯‡æ–‡ç« """
        try:
            # ç²å– KOL è¨­å®š
            kol_settings = self.workflow_engine.config_manager.get_kol_personalization_settings()
            kol_list = list(kol_settings.keys())
            
            # éš¨æ©Ÿé¸æ“‡ä¸€å€‹ KOL
            import random
            kol_serial = random.choice(kol_list)
            kol_config = kol_settings[kol_serial]
            
            # ç²å– Serper API æ–°èé€£çµ
            news_links = await self.workflow_engine._get_serper_news_links(
                stock_data['stock_id'], 
                stock_data['stock_name']
            )
            
            # æ ¹æ“šæ•¸æ“šé¡å‹ç²å–ç›¸æ‡‰çš„æ•¸æ“š
            additional_data = await self._get_additional_data(stock_data)
            
            # ç”Ÿæˆæ–‡ç« å…§å®¹
            content = await self._generate_content_with_data(
                stock_data, kol_config, news_links, additional_data
            )
            
            # ç”Ÿæˆæ¨™é¡Œ
            title = await self._generate_title(stock_data, kol_config)
            
            return {
                "stock_id": stock_data['stock_id'],
                "stock_name": stock_data['stock_name'],
                "title": title,
                "content": content,
                "kol_serial": kol_serial,
                "kol_nickname": kol_config.get('persona', 'æœªçŸ¥'),
                "data_type": stock_data['data_type'],
                "news_links": news_links,
                "generated_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå–®ç¯‡æ–‡ç« å¤±æ•—: {e}")
            raise
    
    async def _get_additional_data(self, stock_data):
        """æ ¹æ“šæ•¸æ“šé¡å‹ç²å–é¡å¤–æ•¸æ“š"""
        data_type = stock_data['data_type']
        
        if data_type == "revenue":
            # ç²å–æœˆç‡Ÿæ”¶æ•¸æ“š
            return await self.workflow_engine._get_finlab_revenue_data(stock_data['stock_id'])
        
        elif data_type == "earnings":
            # ç²å–è²¡å ±æ•¸æ“š
            return await self.workflow_engine._get_finlab_earnings_data(stock_data['stock_id'])
        
        elif data_type == "ohlc":
            # ç²å–è‚¡åƒ¹OHLC/æˆäº¤é‡æ•¸æ“š
            return await self.workflow_engine._get_finlab_stock_data(stock_data['stock_id'])
        
        return {}
    
    async def _generate_content_with_data(self, stock_data, kol_config, news_links, additional_data):
        """æ ¹æ“šæ•¸æ“šé¡å‹ç”Ÿæˆå…§å®¹"""
        data_type = stock_data['data_type']
        
        # åŸºç¤å…§å®¹
        base_content = f"{stock_data['stock_name']}({stock_data['stock_id']}) ä»Šæ—¥æ¼²åœ {stock_data['change_percent']:.1f}%ï¼"
        
        # æ ¹æ“šæ•¸æ“šé¡å‹æ·»åŠ ç‰¹å®šå…§å®¹
        if data_type == "revenue" and additional_data:
            revenue_content = f"""
æœˆç‡Ÿæ”¶è¡¨ç¾äº®çœ¼ï¼š
â€¢ ç•¶æœˆç‡Ÿæ”¶ï¼š{additional_data.get('current_month_revenue_formatted', 'N/A')}
â€¢ æœˆå¢ç‡ï¼š{additional_data.get('mom_growth_pct', 0):.1f}%
â€¢ å¹´å¢ç‡ï¼š{additional_data.get('yoy_growth_pct', 0):.1f}%
â€¢ ç´¯è¨ˆç‡Ÿæ”¶ï¼š{additional_data.get('ytd_revenue_formatted', 'N/A')}
"""
            base_content += revenue_content
        
        elif data_type == "earnings" and additional_data:
            earnings_content = f"""
è²¡å ±è¡¨ç¾å„ªç•°ï¼š
â€¢ EPSï¼š{additional_data.get('eps', 'N/A')}
â€¢ ç‡Ÿæ”¶ï¼š{additional_data.get('revenue_formatted', 'N/A')}
â€¢ æ¯›åˆ©ç‡ï¼š{additional_data.get('gross_margin', 0):.1f}%
â€¢ ç‡Ÿç›Šç‡ï¼š{additional_data.get('operating_margin', 0):.1f}%
"""
            base_content += earnings_content
        
        elif data_type == "ohlc" and additional_data:
            ohlc_content = f"""
æŠ€è¡“é¢è¡¨ç¾å¼·å‹¢ï¼š
â€¢ é–‹ç›¤åƒ¹ï¼š{additional_data.get('open', 'N/A')}å…ƒ
â€¢ æœ€é«˜åƒ¹ï¼š{additional_data.get('high', 'N/A')}å…ƒ
â€¢ æœ€ä½åƒ¹ï¼š{additional_data.get('low', 'N/A')}å…ƒ
â€¢ æ”¶ç›¤åƒ¹ï¼š{additional_data.get('close', 'N/A')}å…ƒ
â€¢ æˆäº¤é‡ï¼š{additional_data.get('volume_formatted', 'N/A')}
â€¢ æˆäº¤é‡‘é¡ï¼š{stock_data['volume_amount']:.2f}å„„å…ƒ
"""
            base_content += ohlc_content
        
        # æ·»åŠ æ–°èé€£çµ
        if news_links:
            base_content += f"\n\nç›¸é—œæ–°èé€£çµï¼š\n{news_links}"
        
        return base_content
    
    async def _generate_title(self, stock_data, kol_config):
        """ç”Ÿæˆæ¨™é¡Œ"""
        # æ ¹æ“š KOL é¢¨æ ¼ç”Ÿæˆä¸åŒæ¨™é¡Œ
        persona = kol_config.get('persona', 'æœªçŸ¥')
        
        if 'æŠ€è¡“' in persona:
            return f"{stock_data['stock_name']}æŠ€è¡“é¢çªç ´ï¼"
        elif 'å…«å¦' in persona or 'çˆ†æ–™' in persona:
            return f"{stock_data['stock_name']}å…§å¹•æ¶ˆæ¯æ›å…‰ï¼"
        elif 'å¹½é»˜' in persona:
            return f"{stock_data['stock_name']}æ¼²åœåŸå› ç«Ÿç„¶æ˜¯..."
        else:
            return f"{stock_data['stock_name']}æ¼²åœåˆ†æ"
    
    async def _record_articles_to_sheets(self, articles):
        """å°‡æ–‡ç« è¨˜éŒ„åˆ° Google Sheets"""
        try:
            logger.info("é–‹å§‹è¨˜éŒ„æ–‡ç« åˆ° Google Sheets...")
            
            # æº–å‚™è¨˜éŒ„æ•¸æ“š
            records = []
            for article in articles:
                record = {
                    "timestamp": article['generated_at'],
                    "status": "ready_to_post",
                    "workflow_type": "after_hours_limit_up",
                    "post_status": "ready_to_post",
                    "priority": "high",
                    "batch_id": f"example_batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "kol_serial": article['kol_serial'],
                    "kol_nickname": article['kol_nickname'],
                    "kol_id": article['kol_serial'],
                    "kol_persona": article['kol_nickname'],
                    "stock_id": article['stock_id'],
                    "stock_name": article['stock_name'],
                    "workflow_type_detail": "after_hours_limit_up",
                    "data_source": "price",
                    "analysis_type": "price_analysis",
                    "priority_level": "high",
                    "post_id": f"limit_up_{article['stock_id']}_{datetime.now().strftime('%Y%m%d')}",
                    "title": article['title'],
                    "tags": f"æ¼²åœè‚¡,{article['stock_name']},price",
                    "has_news": "True" if article['news_links'] else "False",
                    "trigger_type": "limit_up",
                    "content": article['content'],
                    "content_length": len(article['content']),
                    "content_type": "åˆ†æ",
                    "interaction_count": 0,
                    "post_record_id": f"{article['stock_id']}_{article['kol_serial']}_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                    "quality_score": 8.5,
                    "content_category": "stock_analysis",
                    "difficulty_level": "medium",
                    "ai_detection_risk_score": 0.2,
                    "personalization_level": 0.8,
                    "creativity_score": 0.7,
                    "coherence_score": 0.9,
                    "model_used": "gpt-3.5-turbo",
                    "token_count": len(article['content'].split()) * 1.3,
                    "persona": article['kol_nickname'],
                    "engagement_score": 0.8,
                    "data_type": article['data_type']
                }
                records.append(record)
            
            # è¨˜éŒ„åˆ° Google Sheets
            await self.workflow_engine.sheets_client.write_records('è²¼æ–‡ç´€éŒ„è¡¨', records)
            
            logger.info(f"âœ… æˆåŠŸè¨˜éŒ„ {len(records)} ç¯‡æ–‡ç« åˆ° Google Sheets")
            
        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„æ–‡ç« åˆ° Google Sheets å¤±æ•—: {e}")
            raise

async def main():
    """ä¸»å‡½æ•¸"""
    try:
        logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œç›¤å¾Œæ¼²åœç¯„ä¾‹æ–‡ç« ç”Ÿæˆå™¨")
        
        generator = AfterHoursLimitUpExampleGenerator()
        articles = await generator.generate_example_articles()
        
        # é¡¯ç¤ºç”Ÿæˆçµæœ
        print("\n" + "="*60)
        print("ğŸ“Š ç¯„ä¾‹æ–‡ç« ç”Ÿæˆçµæœ")
        print("="*60)
        
        for i, article in enumerate(articles, 1):
            print(f"\nğŸ“ ç¬¬ {i} ç¯‡æ–‡ç« :")
            print(f"è‚¡ç¥¨: {article['stock_name']}({article['stock_id']})")
            print(f"æ•¸æ“šé¡å‹: {article['data_type']}")
            print(f"KOL: {article['kol_nickname']}")
            print(f"æ¨™é¡Œ: {article['title']}")
            print(f"å…§å®¹é•·åº¦: {len(article['content'])} å­—")
            print(f"æ–°èé€£çµ: {'æœ‰' if article['news_links'] else 'ç„¡'}")
            print("-" * 40)
        
        print(f"\nğŸ‰ ç¸½å…±ç”Ÿæˆ {len(articles)} ç¯‡ç¯„ä¾‹æ–‡ç« ")
        print("âœ… æ‰€æœ‰æ–‡ç« å·²è¨˜éŒ„åˆ° Google Sheets")
        
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())








