#!/usr/bin/env python3
"""
å°å…¥ post_records æ•¸æ“šåˆ° Railway æ•¸æ“šåº«
é€™å€‹è…³æœ¬éœ€è¦åœ¨ Railway ç’°å¢ƒä¸­é‹è¡Œ
"""

import os
import sys
import logging
import psycopg2
from psycopg2.extras import RealDictCursor
import json
from datetime import datetime

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_railway_db_connection():
    """ç²å– Railway æ•¸æ“šåº«é€£æ¥"""
    try:
        # Railway æ•¸æ“šåº«é€£æ¥
        railway_db_url = os.getenv("DATABASE_URL")
        if not railway_db_url:
            raise Exception("æœªæ‰¾åˆ° DATABASE_URL ç’°å¢ƒè®Šæ•¸")
        
        # Railway PostgreSQL URL æ ¼å¼è½‰æ›
        if railway_db_url.startswith("postgres://"):
            railway_db_url = railway_db_url.replace("postgres://", "postgresql://", 1)
        
        return psycopg2.connect(railway_db_url)
    except Exception as e:
        logger.error(f"âŒ é€£æ¥ Railway æ•¸æ“šåº«å¤±æ•—: {e}")
        raise

def load_json_data(json_file="post_records_1788.json"):
    """å¾ JSON æ–‡ä»¶åŠ è¼‰æ•¸æ“š"""
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            records = json.load(f)
        
        logger.info(f"ğŸ“Š å¾ {json_file} åŠ è¼‰ {len(records)} ç­†è¨˜éŒ„")
        return records
    except Exception as e:
        logger.error(f"âŒ åŠ è¼‰ JSON æ•¸æ“šå¤±æ•—: {e}")
        raise

def import_to_railway(railway_conn, records):
    """å°å…¥æ•¸æ“šåˆ° Railway æ•¸æ“šåº«"""
    try:
        with railway_conn.cursor() as cursor:
            # æ¸…ç©ºç¾æœ‰æ•¸æ“šï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            cursor.execute("DELETE FROM post_records")
            logger.info("ğŸ—‘ï¸ æ¸…ç©º Railway æ•¸æ“šåº«ä¸­çš„ç¾æœ‰æ•¸æ“š")
            
            # æ‰¹é‡æ’å…¥æ•¸æ“š
            insert_sql = """
                INSERT INTO post_records (
                    post_id, created_at, updated_at, session_id, kol_serial, kol_nickname, 
                    kol_persona, stock_code, stock_name, title, content, content_md, 
                    status, reviewer_notes, approved_by, approved_at, scheduled_at, 
                    published_at, cmoney_post_id, cmoney_post_url, publish_error, 
                    views, likes, comments, shares, topic_id, topic_title, 
                    technical_analysis, serper_data, quality_score, ai_detection_score, 
                    risk_level, generation_params, commodity_tags, alternative_versions
                ) VALUES (
                    %(post_id)s, %(created_at)s, %(updated_at)s, %(session_id)s, 
                    %(kol_serial)s, %(kol_nickname)s, %(kol_persona)s, %(stock_code)s, 
                    %(stock_name)s, %(title)s, %(content)s, %(content_md)s, %(status)s, 
                    %(reviewer_notes)s, %(approved_by)s, %(approved_at)s, %(scheduled_at)s, 
                    %(published_at)s, %(cmoney_post_id)s, %(cmoney_post_url)s, 
                    %(publish_error)s, %(views)s, %(likes)s, %(comments)s, %(shares)s, 
                    %(topic_id)s, %(topic_title)s, %(technical_analysis)s, %(serper_data)s, 
                    %(quality_score)s, %(ai_detection_score)s, %(risk_level)s, 
                    %(generation_params)s, %(commodity_tags)s, %(alternative_versions)s
                )
            """
            
            # è½‰æ›è¨˜éŒ„æ ¼å¼
            records_dict = []
            for record in records:
                record_dict = dict(record)
                
                # è™•ç† datetime å­—ç¬¦ä¸²
                for datetime_field in ['created_at', 'updated_at', 'approved_at', 'scheduled_at', 'published_at']:
                    if record_dict.get(datetime_field):
                        if isinstance(record_dict[datetime_field], str):
                            try:
                                record_dict[datetime_field] = datetime.fromisoformat(record_dict[datetime_field].replace('Z', '+00:00'))
                            except:
                                record_dict[datetime_field] = None
                        elif not isinstance(record_dict[datetime_field], datetime):
                            record_dict[datetime_field] = None
                    else:
                        record_dict[datetime_field] = None
                
                # è™•ç† JSON å­—æ®µ
                for json_field in ['technical_analysis', 'serper_data', 'generation_params', 'commodity_tags', 'alternative_versions']:
                    if record_dict.get(json_field):
                        if isinstance(record_dict[json_field], str):
                            try:
                                record_dict[json_field] = json.loads(record_dict[json_field])
                            except:
                                record_dict[json_field] = None
                        elif not isinstance(record_dict[json_field], dict):
                            record_dict[json_field] = None
                    else:
                        record_dict[json_field] = None
                
                records_dict.append(record_dict)
            
            # æ‰¹é‡æ’å…¥
            cursor.executemany(insert_sql, records_dict)
            railway_conn.commit()
            
            logger.info(f"âœ… æˆåŠŸå°å…¥ {len(records_dict)} ç­†è¨˜éŒ„åˆ° Railway æ•¸æ“šåº«")
            
            # é©—è­‰å°å…¥çµæœ
            cursor.execute("SELECT COUNT(*) FROM post_records")
            count = cursor.fetchone()[0]
            logger.info(f"ğŸ“Š Railway æ•¸æ“šåº«ä¸­ç¾æœ‰ {count} ç­†è¨˜éŒ„")
            
            # é¡¯ç¤ºç‹€æ…‹çµ±è¨ˆ
            cursor.execute("SELECT status, COUNT(*) FROM post_records GROUP BY status")
            status_stats = cursor.fetchall()
            logger.info("ğŸ“Š ç‹€æ…‹çµ±è¨ˆ:")
            for status, count in status_stats:
                logger.info(f"  {status}: {count} ç­†")
            
    except Exception as e:
        logger.error(f"âŒ å°å…¥æ•¸æ“šåˆ° Railway å¤±æ•—: {e}")
        railway_conn.rollback()
        raise

def main():
    """ä¸»å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹å°å…¥ post_records æ•¸æ“šåˆ° Railway...")
    
    railway_conn = None
    
    try:
        # é€£æ¥ Railway æ•¸æ“šåº«
        logger.info("ğŸ”— é€£æ¥ Railway æ•¸æ“šåº«...")
        railway_conn = get_railway_db_connection()
        
        # åŠ è¼‰ JSON æ•¸æ“š
        logger.info("ğŸ“¤ åŠ è¼‰ JSON æ•¸æ“š...")
        records = load_json_data()
        
        # å°å…¥åˆ° Railway
        logger.info("ğŸ“¥ å°å…¥æ•¸æ“šåˆ° Railway...")
        import_to_railway(railway_conn, records)
        
        logger.info("ğŸ‰ æ•¸æ“šå°å…¥å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ æ•¸æ“šå°å…¥å¤±æ•—: {e}")
        sys.exit(1)
    finally:
        if railway_conn:
            railway_conn.close()

if __name__ == "__main__":
    main()
